[2019-10-05 03:51:38,727] {{logging_mixin.py:95}} INFO - [2019-10-05 03:51:38,726] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:51:40,443] {{jobs.py:386}} INFO - Started process (PID=5015) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:51:43,245] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:51:43,245] {{logging_mixin.py:95}} INFO - [2019-10-05 03:51:43,245] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:52:02,614] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:52:10,342] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:52:10,543] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:52:10,549] {{logging_mixin.py:95}} INFO - [2019-10-05 03:52:10,549] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:52:10,550] {{logging_mixin.py:95}} INFO - [2019-10-05 03:52:10,549] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:47:10.549350+00:00
[2019-10-05 03:52:10,556] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 30.113 seconds
[2019-10-05 03:52:23,073] {{logging_mixin.py:95}} INFO - [2019-10-05 03:52:23,072] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:52:23,076] {{jobs.py:386}} INFO - Started process (PID=5025) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:52:23,080] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:52:23,080] {{logging_mixin.py:95}} INFO - [2019-10-05 03:52:23,080] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:52:23,095] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:52:24,036] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:52:24,041] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:52:24,048] {{logging_mixin.py:95}} INFO - [2019-10-05 03:52:24,048] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:52:24,050] {{logging_mixin.py:95}} INFO - [2019-10-05 03:52:24,049] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:47:24.049738+00:00
[2019-10-05 03:52:24,056] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.980 seconds
[2019-10-05 03:52:34,541] {{logging_mixin.py:95}} INFO - [2019-10-05 03:52:34,541] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:52:34,545] {{jobs.py:386}} INFO - Started process (PID=5029) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:52:34,547] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:52:34,548] {{logging_mixin.py:95}} INFO - [2019-10-05 03:52:34,548] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:52:34,567] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:52:35,019] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:52:35,026] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:52:35,037] {{logging_mixin.py:95}} INFO - [2019-10-05 03:52:35,037] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:52:35,039] {{logging_mixin.py:95}} INFO - [2019-10-05 03:52:35,038] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:47:35.038876+00:00
[2019-10-05 03:52:35,047] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.503 seconds
[2019-10-05 03:52:46,627] {{logging_mixin.py:95}} INFO - [2019-10-05 03:52:46,627] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:52:46,629] {{jobs.py:386}} INFO - Started process (PID=5038) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:52:46,632] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:52:46,632] {{logging_mixin.py:95}} INFO - [2019-10-05 03:52:46,632] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:52:46,650] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:52:46,840] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:52:46,846] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:52:46,854] {{logging_mixin.py:95}} INFO - [2019-10-05 03:52:46,854] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:52:46,855] {{logging_mixin.py:95}} INFO - [2019-10-05 03:52:46,854] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:47:46.854898+00:00
[2019-10-05 03:52:46,862] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.232 seconds
[2019-10-05 03:52:57,717] {{logging_mixin.py:95}} INFO - [2019-10-05 03:52:57,717] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:52:57,721] {{jobs.py:386}} INFO - Started process (PID=5041) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:52:57,725] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:52:57,729] {{logging_mixin.py:95}} INFO - [2019-10-05 03:52:57,728] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:52:58,620] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:52:59,939] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:52:59,946] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:52:59,956] {{logging_mixin.py:95}} INFO - [2019-10-05 03:52:59,956] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:52:59,959] {{logging_mixin.py:95}} INFO - [2019-10-05 03:52:59,957] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:47:59.957472+00:00
[2019-10-05 03:53:00,050] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.330 seconds
[2019-10-05 03:53:11,365] {{logging_mixin.py:95}} INFO - [2019-10-05 03:53:11,365] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:53:11,369] {{jobs.py:386}} INFO - Started process (PID=5044) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:53:11,376] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:53:11,378] {{logging_mixin.py:95}} INFO - [2019-10-05 03:53:11,378] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:53:11,404] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:53:12,281] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:53:12,292] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:53:12,305] {{logging_mixin.py:95}} INFO - [2019-10-05 03:53:12,305] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:53:12,307] {{logging_mixin.py:95}} INFO - [2019-10-05 03:53:12,306] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:48:12.306412+00:00
[2019-10-05 03:53:12,315] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.945 seconds
[2019-10-05 03:53:22,786] {{logging_mixin.py:95}} INFO - [2019-10-05 03:53:22,785] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:53:22,790] {{jobs.py:386}} INFO - Started process (PID=5053) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:53:22,795] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:53:22,797] {{logging_mixin.py:95}} INFO - [2019-10-05 03:53:22,796] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:53:22,815] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:53:24,191] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:53:24,199] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:53:24,212] {{logging_mixin.py:95}} INFO - [2019-10-05 03:53:24,212] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:53:24,214] {{logging_mixin.py:95}} INFO - [2019-10-05 03:53:24,213] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:48:24.213449+00:00
[2019-10-05 03:53:24,221] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.431 seconds
[2019-10-05 03:53:36,867] {{logging_mixin.py:95}} INFO - [2019-10-05 03:53:36,867] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:53:36,871] {{jobs.py:386}} INFO - Started process (PID=5057) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:53:36,874] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:53:36,875] {{logging_mixin.py:95}} INFO - [2019-10-05 03:53:36,875] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:53:36,910] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:53:39,085] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:53:39,092] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:53:39,374] {{logging_mixin.py:95}} INFO - [2019-10-05 03:53:39,374] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:53:39,377] {{logging_mixin.py:95}} INFO - [2019-10-05 03:53:39,376] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:48:39.376100+00:00
[2019-10-05 03:53:39,392] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.521 seconds
[2019-10-05 03:53:50,205] {{logging_mixin.py:95}} INFO - [2019-10-05 03:53:50,205] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:53:50,238] {{jobs.py:386}} INFO - Started process (PID=5061) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:53:50,486] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:53:50,488] {{logging_mixin.py:95}} INFO - [2019-10-05 03:53:50,487] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:53:50,687] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:53:52,902] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:53:52,964] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:53:52,971] {{logging_mixin.py:95}} INFO - [2019-10-05 03:53:52,971] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:53:52,973] {{logging_mixin.py:95}} INFO - [2019-10-05 03:53:52,972] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:48:52.972756+00:00
[2019-10-05 03:53:52,980] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.743 seconds
[2019-10-05 03:54:04,997] {{logging_mixin.py:95}} INFO - [2019-10-05 03:54:04,997] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:54:05,272] {{jobs.py:386}} INFO - Started process (PID=5074) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:54:15,218] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:54:16,343] {{logging_mixin.py:95}} INFO - [2019-10-05 03:54:16,343] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:54:30,923] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:54:44,359] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:54:48,347] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:54:53,505] {{logging_mixin.py:95}} INFO - [2019-10-05 03:54:53,505] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:54:53,803] {{logging_mixin.py:95}} INFO - [2019-10-05 03:54:53,535] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:49:53.535497+00:00
[2019-10-05 03:54:55,144] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 49.872 seconds
[2019-10-05 03:55:09,373] {{logging_mixin.py:95}} INFO - [2019-10-05 03:55:09,373] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:55:15,152] {{jobs.py:386}} INFO - Started process (PID=5083) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:55:15,159] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:55:15,160] {{logging_mixin.py:95}} INFO - [2019-10-05 03:55:15,160] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:55:15,200] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:55:15,542] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:55:15,624] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:55:15,632] {{logging_mixin.py:95}} INFO - [2019-10-05 03:55:15,632] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:55:15,634] {{logging_mixin.py:95}} INFO - [2019-10-05 03:55:15,633] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:50:15.633498+00:00
[2019-10-05 03:55:15,640] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.489 seconds
[2019-10-05 03:55:26,632] {{logging_mixin.py:95}} INFO - [2019-10-05 03:55:26,631] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:55:26,635] {{jobs.py:386}} INFO - Started process (PID=5092) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:55:26,638] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:55:26,639] {{logging_mixin.py:95}} INFO - [2019-10-05 03:55:26,639] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:55:26,657] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:55:27,130] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:55:27,136] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:55:27,151] {{logging_mixin.py:95}} INFO - [2019-10-05 03:55:27,151] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:55:27,152] {{logging_mixin.py:95}} INFO - [2019-10-05 03:55:27,151] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:50:27.151639+00:00
[2019-10-05 03:55:27,163] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.528 seconds
[2019-10-05 03:55:38,735] {{logging_mixin.py:95}} INFO - [2019-10-05 03:55:38,735] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:55:38,742] {{jobs.py:386}} INFO - Started process (PID=5096) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:55:38,828] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:55:38,830] {{logging_mixin.py:95}} INFO - [2019-10-05 03:55:38,830] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:55:39,266] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:55:39,814] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:55:39,822] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:55:40,374] {{logging_mixin.py:95}} INFO - [2019-10-05 03:55:40,273] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:55:40,413] {{logging_mixin.py:95}} INFO - [2019-10-05 03:55:40,377] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:50:40.377296+00:00
[2019-10-05 03:55:40,631] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.889 seconds
[2019-10-05 03:55:53,760] {{logging_mixin.py:95}} INFO - [2019-10-05 03:55:53,760] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:55:54,397] {{jobs.py:386}} INFO - Started process (PID=5106) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:55:57,139] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:55:57,143] {{logging_mixin.py:95}} INFO - [2019-10-05 03:55:57,143] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:56:01,480] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:56:06,567] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:56:06,598] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:56:06,704] {{logging_mixin.py:95}} INFO - [2019-10-05 03:56:06,704] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:56:06,707] {{logging_mixin.py:95}} INFO - [2019-10-05 03:56:06,707] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:51:06.707363+00:00
[2019-10-05 03:56:07,034] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 12.637 seconds
[2019-10-05 03:56:19,405] {{logging_mixin.py:95}} INFO - [2019-10-05 03:56:19,404] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:56:19,412] {{jobs.py:386}} INFO - Started process (PID=5110) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:56:19,423] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:56:19,427] {{logging_mixin.py:95}} INFO - [2019-10-05 03:56:19,427] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:56:20,904] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:56:25,196] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:56:25,219] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:56:25,252] {{logging_mixin.py:95}} INFO - [2019-10-05 03:56:25,251] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:56:25,253] {{logging_mixin.py:95}} INFO - [2019-10-05 03:56:25,252] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:51:25.252436+00:00
[2019-10-05 03:56:25,274] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.862 seconds
[2019-10-05 03:56:36,916] {{logging_mixin.py:95}} INFO - [2019-10-05 03:56:36,916] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:56:36,924] {{jobs.py:386}} INFO - Started process (PID=5121) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:56:36,940] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:56:36,947] {{logging_mixin.py:95}} INFO - [2019-10-05 03:56:36,947] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:56:37,016] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:56:37,364] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:56:37,475] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:56:37,631] {{logging_mixin.py:95}} INFO - [2019-10-05 03:56:37,631] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:56:37,758] {{logging_mixin.py:95}} INFO - [2019-10-05 03:56:37,742] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:51:37.741990+00:00
[2019-10-05 03:56:37,912] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.988 seconds
[2019-10-05 03:56:49,005] {{logging_mixin.py:95}} INFO - [2019-10-05 03:56:49,005] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:56:49,009] {{jobs.py:386}} INFO - Started process (PID=5125) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:56:49,012] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:56:49,013] {{logging_mixin.py:95}} INFO - [2019-10-05 03:56:49,013] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:56:49,040] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:56:49,726] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:56:49,735] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:56:49,746] {{logging_mixin.py:95}} INFO - [2019-10-05 03:56:49,746] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:56:49,750] {{logging_mixin.py:95}} INFO - [2019-10-05 03:56:49,749] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:51:49.748936+00:00
[2019-10-05 03:56:49,764] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.756 seconds
[2019-10-05 03:57:01,051] {{logging_mixin.py:95}} INFO - [2019-10-05 03:57:01,050] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:57:01,054] {{jobs.py:386}} INFO - Started process (PID=5135) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:57:01,056] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:57:01,057] {{logging_mixin.py:95}} INFO - [2019-10-05 03:57:01,057] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:57:01,079] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:57:01,203] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:57:01,208] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:57:01,216] {{logging_mixin.py:95}} INFO - [2019-10-05 03:57:01,216] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:57:01,217] {{logging_mixin.py:95}} INFO - [2019-10-05 03:57:01,216] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:52:01.216741+00:00
[2019-10-05 03:57:01,224] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.170 seconds
[2019-10-05 03:57:12,422] {{logging_mixin.py:95}} INFO - [2019-10-05 03:57:12,421] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:57:12,425] {{jobs.py:386}} INFO - Started process (PID=5139) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:57:12,556] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:57:12,557] {{logging_mixin.py:95}} INFO - [2019-10-05 03:57:12,557] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:57:12,579] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:57:12,878] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:57:12,883] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:57:12,893] {{logging_mixin.py:95}} INFO - [2019-10-05 03:57:12,893] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:57:12,894] {{logging_mixin.py:95}} INFO - [2019-10-05 03:57:12,894] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:52:12.894205+00:00
[2019-10-05 03:57:12,900] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.476 seconds
[2019-10-05 03:57:23,972] {{logging_mixin.py:95}} INFO - [2019-10-05 03:57:23,972] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:57:23,976] {{jobs.py:386}} INFO - Started process (PID=5143) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:57:23,980] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:57:23,982] {{logging_mixin.py:95}} INFO - [2019-10-05 03:57:23,981] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:57:24,009] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:57:24,280] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:57:24,287] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:57:24,312] {{logging_mixin.py:95}} INFO - [2019-10-05 03:57:24,312] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:57:24,317] {{logging_mixin.py:95}} INFO - [2019-10-05 03:57:24,316] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:52:24.316066+00:00
[2019-10-05 03:57:24,485] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.509 seconds
[2019-10-05 03:57:35,441] {{logging_mixin.py:95}} INFO - [2019-10-05 03:57:35,441] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:57:35,449] {{jobs.py:386}} INFO - Started process (PID=5152) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:57:35,452] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:57:35,454] {{logging_mixin.py:95}} INFO - [2019-10-05 03:57:35,453] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:57:35,651] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:57:35,926] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:57:35,936] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:57:35,945] {{logging_mixin.py:95}} INFO - [2019-10-05 03:57:35,945] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:57:36,012] {{logging_mixin.py:95}} INFO - [2019-10-05 03:57:35,946] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:52:35.946021+00:00
[2019-10-05 03:57:36,132] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.684 seconds
[2019-10-05 03:57:46,878] {{logging_mixin.py:95}} INFO - [2019-10-05 03:57:46,878] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:57:46,881] {{jobs.py:386}} INFO - Started process (PID=5156) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:57:46,884] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:57:46,885] {{logging_mixin.py:95}} INFO - [2019-10-05 03:57:46,885] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:57:46,908] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:57:47,469] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:57:47,475] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:57:47,487] {{logging_mixin.py:95}} INFO - [2019-10-05 03:57:47,486] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:57:47,492] {{logging_mixin.py:95}} INFO - [2019-10-05 03:57:47,491] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:52:47.491803+00:00
[2019-10-05 03:57:47,502] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.622 seconds
[2019-10-05 03:57:58,323] {{logging_mixin.py:95}} INFO - [2019-10-05 03:57:58,322] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:57:58,327] {{jobs.py:386}} INFO - Started process (PID=5160) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:57:58,331] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:57:58,331] {{logging_mixin.py:95}} INFO - [2019-10-05 03:57:58,331] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:57:58,360] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:57:58,651] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:57:58,656] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:57:58,670] {{logging_mixin.py:95}} INFO - [2019-10-05 03:57:58,670] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:57:58,679] {{logging_mixin.py:95}} INFO - [2019-10-05 03:57:58,678] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:52:58.678569+00:00
[2019-10-05 03:57:58,687] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.360 seconds
[2019-10-05 03:58:09,771] {{logging_mixin.py:95}} INFO - [2019-10-05 03:58:09,771] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:58:09,776] {{jobs.py:386}} INFO - Started process (PID=5170) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:58:09,780] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:58:09,781] {{logging_mixin.py:95}} INFO - [2019-10-05 03:58:09,781] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:58:09,801] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:58:13,430] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:58:13,469] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:58:13,481] {{logging_mixin.py:95}} INFO - [2019-10-05 03:58:13,481] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:58:13,483] {{logging_mixin.py:95}} INFO - [2019-10-05 03:58:13,482] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:53:13.482121+00:00
[2019-10-05 03:58:13,491] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.716 seconds
[2019-10-05 03:58:25,629] {{logging_mixin.py:95}} INFO - [2019-10-05 03:58:25,628] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:58:25,636] {{jobs.py:386}} INFO - Started process (PID=5174) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:58:25,940] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:58:25,942] {{logging_mixin.py:95}} INFO - [2019-10-05 03:58:25,942] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:58:27,231] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:58:32,063] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:58:34,160] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:58:34,170] {{logging_mixin.py:95}} INFO - [2019-10-05 03:58:34,170] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:58:34,171] {{logging_mixin.py:95}} INFO - [2019-10-05 03:58:34,171] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:53:34.171072+00:00
[2019-10-05 03:58:36,175] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 10.539 seconds
[2019-10-05 03:58:49,313] {{logging_mixin.py:95}} INFO - [2019-10-05 03:58:49,313] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:58:49,317] {{jobs.py:386}} INFO - Started process (PID=5182) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:58:49,320] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:58:49,322] {{logging_mixin.py:95}} INFO - [2019-10-05 03:58:49,322] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:58:49,346] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:58:54,630] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:58:54,644] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:58:54,653] {{logging_mixin.py:95}} INFO - [2019-10-05 03:58:54,653] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:58:54,655] {{logging_mixin.py:95}} INFO - [2019-10-05 03:58:54,654] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:53:54.654333+00:00
[2019-10-05 03:58:54,664] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.348 seconds
[2019-10-05 03:59:07,693] {{logging_mixin.py:95}} INFO - [2019-10-05 03:59:07,693] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:59:07,717] {{jobs.py:386}} INFO - Started process (PID=5185) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:59:09,012] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:59:09,013] {{logging_mixin.py:95}} INFO - [2019-10-05 03:59:09,013] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:59:10,937] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:59:16,050] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:59:16,061] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:59:16,076] {{logging_mixin.py:95}} INFO - [2019-10-05 03:59:16,076] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:59:16,078] {{logging_mixin.py:95}} INFO - [2019-10-05 03:59:16,077] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:54:16.077179+00:00
[2019-10-05 03:59:16,093] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 8.376 seconds
[2019-10-05 03:59:27,678] {{logging_mixin.py:95}} INFO - [2019-10-05 03:59:27,678] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:59:27,831] {{jobs.py:386}} INFO - Started process (PID=5189) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:59:29,387] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:59:29,389] {{logging_mixin.py:95}} INFO - [2019-10-05 03:59:29,389] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:59:33,035] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:59:43,530] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:59:43,691] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:59:43,700] {{logging_mixin.py:95}} INFO - [2019-10-05 03:59:43,700] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:59:43,704] {{logging_mixin.py:95}} INFO - [2019-10-05 03:59:43,703] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:54:43.703308+00:00
[2019-10-05 03:59:44,007] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 16.176 seconds
[2019-10-05 03:59:55,576] {{logging_mixin.py:95}} INFO - [2019-10-05 03:59:55,576] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 03:59:55,630] {{jobs.py:386}} INFO - Started process (PID=5198) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:59:55,634] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 03:59:55,639] {{logging_mixin.py:95}} INFO - [2019-10-05 03:59:55,639] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:59:55,669] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 03:59:55,958] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 03:59:55,965] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 03:59:55,976] {{logging_mixin.py:95}} INFO - [2019-10-05 03:59:55,976] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 03:59:55,979] {{logging_mixin.py:95}} INFO - [2019-10-05 03:59:55,977] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:54:55.977635+00:00
[2019-10-05 03:59:55,989] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.359 seconds
[2019-10-05 04:00:07,256] {{logging_mixin.py:95}} INFO - [2019-10-05 04:00:07,255] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:00:07,271] {{jobs.py:386}} INFO - Started process (PID=5203) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:00:07,282] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:00:07,282] {{logging_mixin.py:95}} INFO - [2019-10-05 04:00:07,282] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:00:07,331] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:00:07,675] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:00:07,681] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:00:07,692] {{logging_mixin.py:95}} INFO - [2019-10-05 04:00:07,692] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:00:07,693] {{logging_mixin.py:95}} INFO - [2019-10-05 04:00:07,693] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:55:07.693075+00:00
[2019-10-05 04:00:07,701] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.430 seconds
[2019-10-05 04:00:18,785] {{logging_mixin.py:95}} INFO - [2019-10-05 04:00:18,785] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:00:18,790] {{jobs.py:386}} INFO - Started process (PID=5207) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:00:18,793] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:00:18,807] {{logging_mixin.py:95}} INFO - [2019-10-05 04:00:18,807] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:00:19,251] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:00:20,443] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:00:20,448] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:00:20,455] {{logging_mixin.py:95}} INFO - [2019-10-05 04:00:20,455] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:00:20,457] {{logging_mixin.py:95}} INFO - [2019-10-05 04:00:20,456] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:55:20.456592+00:00
[2019-10-05 04:00:20,473] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.683 seconds
[2019-10-05 04:00:31,601] {{logging_mixin.py:95}} INFO - [2019-10-05 04:00:31,601] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:00:31,605] {{jobs.py:386}} INFO - Started process (PID=5220) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:00:31,609] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:00:31,615] {{logging_mixin.py:95}} INFO - [2019-10-05 04:00:31,614] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:00:31,645] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:00:32,961] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:00:32,967] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:00:32,980] {{logging_mixin.py:95}} INFO - [2019-10-05 04:00:32,979] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:00:32,981] {{logging_mixin.py:95}} INFO - [2019-10-05 04:00:32,981] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:55:32.981110+00:00
[2019-10-05 04:00:33,082] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.477 seconds
[2019-10-05 04:00:44,095] {{logging_mixin.py:95}} INFO - [2019-10-05 04:00:44,094] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:00:44,173] {{jobs.py:386}} INFO - Started process (PID=5225) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:00:44,343] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:00:44,345] {{logging_mixin.py:95}} INFO - [2019-10-05 04:00:44,345] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:00:44,732] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:00:57,979] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:00:57,987] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:00:58,001] {{logging_mixin.py:95}} INFO - [2019-10-05 04:00:58,001] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:00:58,003] {{logging_mixin.py:95}} INFO - [2019-10-05 04:00:58,003] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:55:58.002980+00:00
[2019-10-05 04:00:58,496] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 14.322 seconds
[2019-10-05 04:01:10,150] {{logging_mixin.py:95}} INFO - [2019-10-05 04:01:10,150] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:01:10,153] {{jobs.py:386}} INFO - Started process (PID=5234) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:01:10,201] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:01:10,203] {{logging_mixin.py:95}} INFO - [2019-10-05 04:01:10,203] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:01:10,417] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:01:10,627] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:01:10,636] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:01:10,645] {{logging_mixin.py:95}} INFO - [2019-10-05 04:01:10,645] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:01:10,647] {{logging_mixin.py:95}} INFO - [2019-10-05 04:01:10,646] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:56:10.646436+00:00
[2019-10-05 04:01:10,656] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.503 seconds
[2019-10-05 04:01:21,911] {{logging_mixin.py:95}} INFO - [2019-10-05 04:01:21,911] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:01:22,000] {{jobs.py:386}} INFO - Started process (PID=5238) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:01:22,466] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:01:22,482] {{logging_mixin.py:95}} INFO - [2019-10-05 04:01:22,482] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:01:23,100] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:01:26,124] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:01:26,237] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:01:26,253] {{logging_mixin.py:95}} INFO - [2019-10-05 04:01:26,253] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:01:26,256] {{logging_mixin.py:95}} INFO - [2019-10-05 04:01:26,255] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:56:26.254759+00:00
[2019-10-05 04:01:26,303] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.303 seconds
[2019-10-05 04:01:39,624] {{logging_mixin.py:95}} INFO - [2019-10-05 04:01:39,624] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:01:39,825] {{jobs.py:386}} INFO - Started process (PID=5242) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:01:41,156] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:01:41,157] {{logging_mixin.py:95}} INFO - [2019-10-05 04:01:41,157] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:01:42,584] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:01:59,786] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:02:00,028] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:02:00,038] {{logging_mixin.py:95}} INFO - [2019-10-05 04:02:00,038] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:02:00,040] {{logging_mixin.py:95}} INFO - [2019-10-05 04:02:00,039] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:57:00.039551+00:00
[2019-10-05 04:02:01,695] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 21.870 seconds
[2019-10-05 04:02:13,525] {{logging_mixin.py:95}} INFO - [2019-10-05 04:02:13,525] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:02:13,624] {{jobs.py:386}} INFO - Started process (PID=5251) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:02:14,026] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:02:14,028] {{logging_mixin.py:95}} INFO - [2019-10-05 04:02:14,028] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:02:15,840] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:02:23,901] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:02:24,342] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:02:24,350] {{logging_mixin.py:95}} INFO - [2019-10-05 04:02:24,350] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:02:24,352] {{logging_mixin.py:95}} INFO - [2019-10-05 04:02:24,351] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:57:24.351481+00:00
[2019-10-05 04:02:25,920] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 12.296 seconds
[2019-10-05 04:02:37,664] {{logging_mixin.py:95}} INFO - [2019-10-05 04:02:37,663] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:02:37,668] {{jobs.py:386}} INFO - Started process (PID=5255) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:02:38,496] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:02:38,497] {{logging_mixin.py:95}} INFO - [2019-10-05 04:02:38,497] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:02:39,073] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:02:40,163] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:02:40,170] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:02:40,180] {{logging_mixin.py:95}} INFO - [2019-10-05 04:02:40,180] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:02:40,185] {{logging_mixin.py:95}} INFO - [2019-10-05 04:02:40,184] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:57:40.184598+00:00
[2019-10-05 04:02:40,193] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.525 seconds
[2019-10-05 04:02:51,180] {{logging_mixin.py:95}} INFO - [2019-10-05 04:02:51,179] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:02:51,184] {{jobs.py:386}} INFO - Started process (PID=5265) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:02:51,188] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:02:51,195] {{logging_mixin.py:95}} INFO - [2019-10-05 04:02:51,194] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:02:51,230] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:02:51,453] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:02:51,461] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:02:51,623] {{logging_mixin.py:95}} INFO - [2019-10-05 04:02:51,622] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:02:51,782] {{logging_mixin.py:95}} INFO - [2019-10-05 04:02:51,625] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:57:51.625196+00:00
[2019-10-05 04:02:52,305] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.122 seconds
[2019-10-05 04:03:04,132] {{logging_mixin.py:95}} INFO - [2019-10-05 04:03:04,132] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:03:04,136] {{jobs.py:386}} INFO - Started process (PID=5271) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:03:04,139] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:03:04,140] {{logging_mixin.py:95}} INFO - [2019-10-05 04:03:04,140] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:03:04,162] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:03:04,654] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:03:04,659] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:03:04,666] {{logging_mixin.py:95}} INFO - [2019-10-05 04:03:04,666] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:03:04,670] {{logging_mixin.py:95}} INFO - [2019-10-05 04:03:04,670] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:58:04.670088+00:00
[2019-10-05 04:03:04,677] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.541 seconds
[2019-10-05 04:03:15,578] {{logging_mixin.py:95}} INFO - [2019-10-05 04:03:15,578] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:03:15,582] {{jobs.py:386}} INFO - Started process (PID=5280) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:03:15,586] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:03:15,588] {{logging_mixin.py:95}} INFO - [2019-10-05 04:03:15,587] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:03:15,609] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:03:17,384] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:03:17,391] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:03:17,401] {{logging_mixin.py:95}} INFO - [2019-10-05 04:03:17,401] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:03:17,403] {{logging_mixin.py:95}} INFO - [2019-10-05 04:03:17,402] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:58:17.402587+00:00
[2019-10-05 04:03:17,411] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.830 seconds
[2019-10-05 04:03:28,011] {{logging_mixin.py:95}} INFO - [2019-10-05 04:03:28,011] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:03:28,014] {{jobs.py:386}} INFO - Started process (PID=5283) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:03:28,018] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:03:28,019] {{logging_mixin.py:95}} INFO - [2019-10-05 04:03:28,019] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:03:28,049] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:03:28,346] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:03:28,360] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:03:28,378] {{logging_mixin.py:95}} INFO - [2019-10-05 04:03:28,378] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:03:28,380] {{logging_mixin.py:95}} INFO - [2019-10-05 04:03:28,379] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:58:28.379436+00:00
[2019-10-05 04:03:28,397] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.383 seconds
[2019-10-05 04:03:39,375] {{logging_mixin.py:95}} INFO - [2019-10-05 04:03:39,375] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:03:39,382] {{jobs.py:386}} INFO - Started process (PID=5287) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:03:39,387] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:03:39,389] {{logging_mixin.py:95}} INFO - [2019-10-05 04:03:39,389] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:03:39,423] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:03:39,676] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:03:39,687] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:03:39,710] {{logging_mixin.py:95}} INFO - [2019-10-05 04:03:39,710] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:03:39,713] {{logging_mixin.py:95}} INFO - [2019-10-05 04:03:39,712] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:58:39.711948+00:00
[2019-10-05 04:03:39,728] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.346 seconds
[2019-10-05 04:03:51,378] {{logging_mixin.py:95}} INFO - [2019-10-05 04:03:51,378] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:03:51,384] {{jobs.py:386}} INFO - Started process (PID=5291) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:03:51,508] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:03:51,509] {{logging_mixin.py:95}} INFO - [2019-10-05 04:03:51,509] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:03:51,967] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:03:52,642] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:03:52,649] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:03:52,660] {{logging_mixin.py:95}} INFO - [2019-10-05 04:03:52,660] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:03:52,660] {{logging_mixin.py:95}} INFO - [2019-10-05 04:03:52,660] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:58:52.660338+00:00
[2019-10-05 04:03:52,954] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.570 seconds
[2019-10-05 04:04:04,727] {{logging_mixin.py:95}} INFO - [2019-10-05 04:04:04,698] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:04:04,749] {{jobs.py:386}} INFO - Started process (PID=5300) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:04:05,050] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:04:05,051] {{logging_mixin.py:95}} INFO - [2019-10-05 04:04:05,051] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:04:06,707] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:04:09,493] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:04:09,612] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:04:09,695] {{logging_mixin.py:95}} INFO - [2019-10-05 04:04:09,695] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:04:09,697] {{logging_mixin.py:95}} INFO - [2019-10-05 04:04:09,696] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 03:59:09.696769+00:00
[2019-10-05 04:04:09,887] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.138 seconds
[2019-10-05 04:04:21,508] {{logging_mixin.py:95}} INFO - [2019-10-05 04:04:21,508] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:04:21,593] {{jobs.py:386}} INFO - Started process (PID=5304) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:04:22,270] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:04:22,272] {{logging_mixin.py:95}} INFO - [2019-10-05 04:04:22,271] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:04:23,280] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:04:44,446] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 04:05:23,566] {{logging_mixin.py:95}} INFO - [2019-10-05 04:05:23,498] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:05:23,714] {{jobs.py:386}} INFO - Started process (PID=5306) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:05:24,859] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:05:24,861] {{logging_mixin.py:95}} INFO - [2019-10-05 04:05:24,860] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:05:26,215] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:05:47,199] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 04:06:09,979] {{logging_mixin.py:95}} INFO - [2019-10-05 04:06:09,645] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:06:10,488] {{jobs.py:386}} INFO - Started process (PID=5308) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:06:11,170] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:06:11,172] {{logging_mixin.py:95}} INFO - [2019-10-05 04:06:11,172] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:06:13,851] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:06:35,624] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 04:07:45,491] {{logging_mixin.py:95}} INFO - [2019-10-05 04:07:45,377] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:07:45,606] {{jobs.py:386}} INFO - Started process (PID=5310) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:07:46,282] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:07:46,284] {{logging_mixin.py:95}} INFO - [2019-10-05 04:07:46,284] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:07:48,713] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:08:17,051] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 04:08:49,671] {{logging_mixin.py:95}} INFO - [2019-10-05 04:08:49,476] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:08:50,002] {{jobs.py:386}} INFO - Started process (PID=5312) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:08:51,230] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:08:51,232] {{logging_mixin.py:95}} INFO - [2019-10-05 04:08:51,231] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:08:53,836] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:09:18,254] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 04:10:43,776] {{logging_mixin.py:95}} INFO - [2019-10-05 04:10:43,776] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:10:43,905] {{jobs.py:386}} INFO - Started process (PID=5314) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:10:44,799] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:10:44,801] {{logging_mixin.py:95}} INFO - [2019-10-05 04:10:44,801] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:10:46,884] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:10:48,344] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:10:48,349] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:10:48,371] {{logging_mixin.py:95}} INFO - [2019-10-05 04:10:48,371] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:10:48,372] {{logging_mixin.py:95}} INFO - [2019-10-05 04:10:48,372] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:05:48.372194+00:00
[2019-10-05 04:10:48,486] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.581 seconds
[2019-10-05 04:10:59,531] {{logging_mixin.py:95}} INFO - [2019-10-05 04:10:59,531] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:10:59,536] {{jobs.py:386}} INFO - Started process (PID=5318) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:10:59,590] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:10:59,596] {{logging_mixin.py:95}} INFO - [2019-10-05 04:10:59,596] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:10:59,631] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:10:59,976] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:11:00,019] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:11:00,027] {{logging_mixin.py:95}} INFO - [2019-10-05 04:11:00,027] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:11:00,063] {{logging_mixin.py:95}} INFO - [2019-10-05 04:11:00,062] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:06:00.062601+00:00
[2019-10-05 04:11:00,077] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.540 seconds
[2019-10-05 04:11:10,847] {{logging_mixin.py:95}} INFO - [2019-10-05 04:11:10,846] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:11:10,850] {{jobs.py:386}} INFO - Started process (PID=5327) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:11:10,853] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:11:10,860] {{logging_mixin.py:95}} INFO - [2019-10-05 04:11:10,858] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:11:10,900] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:11:11,080] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:11:11,086] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:11:11,096] {{logging_mixin.py:95}} INFO - [2019-10-05 04:11:11,096] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:11:11,097] {{logging_mixin.py:95}} INFO - [2019-10-05 04:11:11,096] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:06:11.096752+00:00
[2019-10-05 04:11:11,102] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.253 seconds
[2019-10-05 04:11:22,614] {{logging_mixin.py:95}} INFO - [2019-10-05 04:11:22,614] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:11:22,872] {{jobs.py:386}} INFO - Started process (PID=5331) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:11:22,978] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:11:22,981] {{logging_mixin.py:95}} INFO - [2019-10-05 04:11:22,981] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:11:23,543] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:11:24,502] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:11:24,656] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:11:24,663] {{logging_mixin.py:95}} INFO - [2019-10-05 04:11:24,662] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:11:24,664] {{logging_mixin.py:95}} INFO - [2019-10-05 04:11:24,663] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:06:24.663698+00:00
[2019-10-05 04:11:24,676] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.804 seconds
[2019-10-05 04:11:36,384] {{logging_mixin.py:95}} INFO - [2019-10-05 04:11:36,383] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:11:36,510] {{jobs.py:386}} INFO - Started process (PID=5335) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:11:36,789] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:11:36,791] {{logging_mixin.py:95}} INFO - [2019-10-05 04:11:36,791] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:11:37,938] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:11:41,664] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:11:41,701] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:11:41,850] {{logging_mixin.py:95}} INFO - [2019-10-05 04:11:41,850] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:11:41,914] {{logging_mixin.py:95}} INFO - [2019-10-05 04:11:41,851] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:06:41.851235+00:00
[2019-10-05 04:11:41,921] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.411 seconds
[2019-10-05 04:11:53,095] {{logging_mixin.py:95}} INFO - [2019-10-05 04:11:53,095] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:11:53,099] {{jobs.py:386}} INFO - Started process (PID=5348) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:11:53,101] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:11:53,102] {{logging_mixin.py:95}} INFO - [2019-10-05 04:11:53,102] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:11:53,185] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:11:54,103] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:11:54,108] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:11:54,133] {{logging_mixin.py:95}} INFO - [2019-10-05 04:11:54,133] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:11:54,134] {{logging_mixin.py:95}} INFO - [2019-10-05 04:11:54,133] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:06:54.133751+00:00
[2019-10-05 04:11:54,142] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.044 seconds
[2019-10-05 04:12:05,595] {{logging_mixin.py:95}} INFO - [2019-10-05 04:12:05,594] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:12:05,601] {{jobs.py:386}} INFO - Started process (PID=5352) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:12:05,676] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:12:05,677] {{logging_mixin.py:95}} INFO - [2019-10-05 04:12:05,676] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:12:05,704] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:12:06,734] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:12:06,740] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:12:06,753] {{logging_mixin.py:95}} INFO - [2019-10-05 04:12:06,753] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:12:06,755] {{logging_mixin.py:95}} INFO - [2019-10-05 04:12:06,754] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:07:06.754062+00:00
[2019-10-05 04:12:06,765] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.164 seconds
[2019-10-05 04:12:18,220] {{logging_mixin.py:95}} INFO - [2019-10-05 04:12:18,220] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:12:18,529] {{jobs.py:386}} INFO - Started process (PID=5361) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:12:19,206] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:12:19,211] {{logging_mixin.py:95}} INFO - [2019-10-05 04:12:19,211] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:12:19,760] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:12:21,766] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:12:21,816] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:12:21,830] {{logging_mixin.py:95}} INFO - [2019-10-05 04:12:21,830] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:12:21,832] {{logging_mixin.py:95}} INFO - [2019-10-05 04:12:21,831] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:07:21.831172+00:00
[2019-10-05 04:12:21,839] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.310 seconds
[2019-10-05 04:12:33,409] {{logging_mixin.py:95}} INFO - [2019-10-05 04:12:33,408] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:12:33,414] {{jobs.py:386}} INFO - Started process (PID=5365) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:12:33,436] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:12:33,444] {{logging_mixin.py:95}} INFO - [2019-10-05 04:12:33,444] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:12:33,489] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:12:33,971] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:12:33,977] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:12:33,986] {{logging_mixin.py:95}} INFO - [2019-10-05 04:12:33,986] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:12:33,986] {{logging_mixin.py:95}} INFO - [2019-10-05 04:12:33,986] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:07:33.986382+00:00
[2019-10-05 04:12:34,135] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.721 seconds
[2019-10-05 04:12:44,812] {{logging_mixin.py:95}} INFO - [2019-10-05 04:12:44,812] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:12:44,817] {{jobs.py:386}} INFO - Started process (PID=5374) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:12:44,820] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:12:44,821] {{logging_mixin.py:95}} INFO - [2019-10-05 04:12:44,821] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:12:44,851] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:12:45,498] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:12:45,505] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:12:45,514] {{logging_mixin.py:95}} INFO - [2019-10-05 04:12:45,514] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:12:45,515] {{logging_mixin.py:95}} INFO - [2019-10-05 04:12:45,515] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:07:45.515082+00:00
[2019-10-05 04:12:46,000] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.183 seconds
[2019-10-05 04:12:57,526] {{logging_mixin.py:95}} INFO - [2019-10-05 04:12:57,525] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:12:57,583] {{jobs.py:386}} INFO - Started process (PID=5378) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:12:57,950] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:12:57,951] {{logging_mixin.py:95}} INFO - [2019-10-05 04:12:57,951] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:12:58,143] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:12:58,692] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:12:58,699] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:12:58,714] {{logging_mixin.py:95}} INFO - [2019-10-05 04:12:58,714] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:12:58,715] {{logging_mixin.py:95}} INFO - [2019-10-05 04:12:58,715] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:07:58.715174+00:00
[2019-10-05 04:12:58,725] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.143 seconds
[2019-10-05 04:13:10,134] {{logging_mixin.py:95}} INFO - [2019-10-05 04:13:10,133] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:13:10,149] {{jobs.py:386}} INFO - Started process (PID=5382) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:13:10,151] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:13:10,154] {{logging_mixin.py:95}} INFO - [2019-10-05 04:13:10,154] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:13:10,200] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:13:11,771] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:13:11,801] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:13:11,810] {{logging_mixin.py:95}} INFO - [2019-10-05 04:13:11,810] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:13:11,811] {{logging_mixin.py:95}} INFO - [2019-10-05 04:13:11,811] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:08:11.811037+00:00
[2019-10-05 04:13:11,821] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.673 seconds
[2019-10-05 04:13:23,451] {{logging_mixin.py:95}} INFO - [2019-10-05 04:13:23,216] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:13:23,579] {{jobs.py:386}} INFO - Started process (PID=5391) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:13:23,792] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:13:23,793] {{logging_mixin.py:95}} INFO - [2019-10-05 04:13:23,793] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:13:24,499] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:13:25,459] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:13:25,467] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:13:25,603] {{logging_mixin.py:95}} INFO - [2019-10-05 04:13:25,603] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:13:25,605] {{logging_mixin.py:95}} INFO - [2019-10-05 04:13:25,604] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:08:25.604750+00:00
[2019-10-05 04:13:25,696] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.117 seconds
[2019-10-05 04:13:36,161] {{logging_mixin.py:95}} INFO - [2019-10-05 04:13:36,160] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:13:36,184] {{jobs.py:386}} INFO - Started process (PID=5395) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:13:36,187] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:13:36,189] {{logging_mixin.py:95}} INFO - [2019-10-05 04:13:36,189] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:13:36,299] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:13:37,062] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:13:37,079] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:13:37,097] {{logging_mixin.py:95}} INFO - [2019-10-05 04:13:37,097] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:13:37,099] {{logging_mixin.py:95}} INFO - [2019-10-05 04:13:37,098] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:08:37.098490+00:00
[2019-10-05 04:13:37,105] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.922 seconds
[2019-10-05 04:13:47,676] {{logging_mixin.py:95}} INFO - [2019-10-05 04:13:47,647] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:13:47,701] {{jobs.py:386}} INFO - Started process (PID=5399) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:13:47,853] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:13:47,855] {{logging_mixin.py:95}} INFO - [2019-10-05 04:13:47,854] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:13:48,312] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:13:51,368] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:13:51,419] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:13:51,428] {{logging_mixin.py:95}} INFO - [2019-10-05 04:13:51,428] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:13:51,429] {{logging_mixin.py:95}} INFO - [2019-10-05 04:13:51,429] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:08:51.429122+00:00
[2019-10-05 04:13:51,492] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.791 seconds
[2019-10-05 04:14:03,238] {{logging_mixin.py:95}} INFO - [2019-10-05 04:14:03,238] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:14:03,277] {{jobs.py:386}} INFO - Started process (PID=5411) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:14:03,375] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:14:03,377] {{logging_mixin.py:95}} INFO - [2019-10-05 04:14:03,377] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:14:04,104] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:14:07,130] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:14:07,265] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:14:07,274] {{logging_mixin.py:95}} INFO - [2019-10-05 04:14:07,274] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:14:07,276] {{logging_mixin.py:95}} INFO - [2019-10-05 04:14:07,275] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:09:07.275656+00:00
[2019-10-05 04:14:07,382] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.106 seconds
[2019-10-05 04:14:20,150] {{logging_mixin.py:95}} INFO - [2019-10-05 04:14:20,016] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:14:20,313] {{jobs.py:386}} INFO - Started process (PID=5415) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:14:21,420] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:14:21,422] {{logging_mixin.py:95}} INFO - [2019-10-05 04:14:21,422] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:14:22,762] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:14:31,453] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:14:32,703] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:14:32,725] {{logging_mixin.py:95}} INFO - [2019-10-05 04:14:32,725] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:14:32,728] {{logging_mixin.py:95}} INFO - [2019-10-05 04:14:32,727] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:09:32.727350+00:00
[2019-10-05 04:14:34,668] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 14.355 seconds
[2019-10-05 04:14:46,981] {{logging_mixin.py:95}} INFO - [2019-10-05 04:14:46,981] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:14:47,115] {{jobs.py:386}} INFO - Started process (PID=5424) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:14:47,605] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:14:47,606] {{logging_mixin.py:95}} INFO - [2019-10-05 04:14:47,606] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:14:50,230] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:15:00,998] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:15:01,584] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:15:01,595] {{logging_mixin.py:95}} INFO - [2019-10-05 04:15:01,594] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:15:01,596] {{logging_mixin.py:95}} INFO - [2019-10-05 04:15:01,596] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:10:01.596148+00:00
[2019-10-05 04:15:02,548] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 15.433 seconds
[2019-10-05 04:15:13,934] {{logging_mixin.py:95}} INFO - [2019-10-05 04:15:13,934] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:15:13,944] {{jobs.py:386}} INFO - Started process (PID=5428) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:15:14,075] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:15:14,087] {{logging_mixin.py:95}} INFO - [2019-10-05 04:15:14,087] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:15:14,381] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:15:14,590] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:15:14,597] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:15:14,612] {{logging_mixin.py:95}} INFO - [2019-10-05 04:15:14,612] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:15:14,613] {{logging_mixin.py:95}} INFO - [2019-10-05 04:15:14,613] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:10:14.613148+00:00
[2019-10-05 04:15:14,637] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.693 seconds
[2019-10-05 04:15:25,237] {{logging_mixin.py:95}} INFO - [2019-10-05 04:15:25,236] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:15:25,242] {{jobs.py:386}} INFO - Started process (PID=5432) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:15:25,259] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:15:25,261] {{logging_mixin.py:95}} INFO - [2019-10-05 04:15:25,261] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:15:25,303] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:15:25,437] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:15:25,444] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:15:25,452] {{logging_mixin.py:95}} INFO - [2019-10-05 04:15:25,452] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:15:25,453] {{logging_mixin.py:95}} INFO - [2019-10-05 04:15:25,453] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:10:25.453144+00:00
[2019-10-05 04:15:25,466] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.224 seconds
[2019-10-05 04:15:36,561] {{logging_mixin.py:95}} INFO - [2019-10-05 04:15:36,561] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:15:36,663] {{jobs.py:386}} INFO - Started process (PID=5436) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:15:37,036] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:15:37,038] {{logging_mixin.py:95}} INFO - [2019-10-05 04:15:37,038] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:15:37,585] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:15:39,379] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:15:39,387] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:15:39,400] {{logging_mixin.py:95}} INFO - [2019-10-05 04:15:39,397] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:15:39,401] {{logging_mixin.py:95}} INFO - [2019-10-05 04:15:39,400] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:10:39.400796+00:00
[2019-10-05 04:15:39,409] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.746 seconds
[2019-10-05 04:15:50,343] {{logging_mixin.py:95}} INFO - [2019-10-05 04:15:50,343] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:15:50,349] {{jobs.py:386}} INFO - Started process (PID=5451) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:15:50,451] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:15:50,452] {{logging_mixin.py:95}} INFO - [2019-10-05 04:15:50,452] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:15:50,924] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:15:54,012] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:15:54,118] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:15:54,131] {{logging_mixin.py:95}} INFO - [2019-10-05 04:15:54,131] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:15:54,132] {{logging_mixin.py:95}} INFO - [2019-10-05 04:15:54,132] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:10:54.132426+00:00
[2019-10-05 04:15:54,267] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.918 seconds
[2019-10-05 04:16:05,878] {{logging_mixin.py:95}} INFO - [2019-10-05 04:16:05,831] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:16:05,902] {{jobs.py:386}} INFO - Started process (PID=5455) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:16:06,717] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:16:06,721] {{logging_mixin.py:95}} INFO - [2019-10-05 04:16:06,721] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:16:08,825] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:16:16,112] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:16:16,171] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:16:16,182] {{logging_mixin.py:95}} INFO - [2019-10-05 04:16:16,182] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:16:16,184] {{logging_mixin.py:95}} INFO - [2019-10-05 04:16:16,183] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:11:16.183570+00:00
[2019-10-05 04:16:16,314] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 10.413 seconds
[2019-10-05 04:16:27,384] {{logging_mixin.py:95}} INFO - [2019-10-05 04:16:27,383] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:16:27,443] {{jobs.py:386}} INFO - Started process (PID=5464) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:16:27,815] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:16:27,816] {{logging_mixin.py:95}} INFO - [2019-10-05 04:16:27,816] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:16:28,390] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:16:45,805] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:16:46,263] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:16:46,353] {{logging_mixin.py:95}} INFO - [2019-10-05 04:16:46,353] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:16:46,355] {{logging_mixin.py:95}} INFO - [2019-10-05 04:16:46,354] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:11:46.354418+00:00
[2019-10-05 04:16:46,870] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 19.427 seconds
[2019-10-05 04:16:59,860] {{logging_mixin.py:95}} INFO - [2019-10-05 04:16:59,792] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:16:59,942] {{jobs.py:386}} INFO - Started process (PID=5473) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:17:00,975] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:17:00,977] {{logging_mixin.py:95}} INFO - [2019-10-05 04:17:00,977] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:17:03,865] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:17:21,426] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 04:17:41,293] {{logging_mixin.py:95}} INFO - [2019-10-05 04:17:41,293] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:17:41,448] {{jobs.py:386}} INFO - Started process (PID=5475) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:17:41,922] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:17:41,924] {{logging_mixin.py:95}} INFO - [2019-10-05 04:17:41,923] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:17:42,637] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:17:43,172] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:17:43,181] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:17:43,200] {{logging_mixin.py:95}} INFO - [2019-10-05 04:17:43,199] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:17:43,203] {{logging_mixin.py:95}} INFO - [2019-10-05 04:17:43,202] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:12:43.202001+00:00
[2019-10-05 04:17:43,219] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.770 seconds
[2019-10-05 04:17:54,947] {{logging_mixin.py:95}} INFO - [2019-10-05 04:17:54,947] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:17:55,022] {{jobs.py:386}} INFO - Started process (PID=5479) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:17:55,150] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:17:55,152] {{logging_mixin.py:95}} INFO - [2019-10-05 04:17:55,152] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:17:55,367] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:17:56,088] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:17:56,174] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:17:56,196] {{logging_mixin.py:95}} INFO - [2019-10-05 04:17:56,196] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:17:56,197] {{logging_mixin.py:95}} INFO - [2019-10-05 04:17:56,197] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:12:56.197084+00:00
[2019-10-05 04:17:56,288] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.266 seconds
[2019-10-05 04:18:07,220] {{logging_mixin.py:95}} INFO - [2019-10-05 04:18:07,219] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:18:07,297] {{jobs.py:386}} INFO - Started process (PID=5490) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:18:07,301] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:18:07,317] {{logging_mixin.py:95}} INFO - [2019-10-05 04:18:07,317] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:18:07,424] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:18:09,403] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:18:09,491] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:18:09,501] {{logging_mixin.py:95}} INFO - [2019-10-05 04:18:09,501] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:18:09,503] {{logging_mixin.py:95}} INFO - [2019-10-05 04:18:09,502] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:13:09.502935+00:00
[2019-10-05 04:18:09,513] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.217 seconds
[2019-10-05 04:18:20,216] {{logging_mixin.py:95}} INFO - [2019-10-05 04:18:20,216] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:18:20,289] {{jobs.py:386}} INFO - Started process (PID=5494) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:18:20,455] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:18:20,458] {{logging_mixin.py:95}} INFO - [2019-10-05 04:18:20,457] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:18:21,069] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:18:21,249] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:18:21,261] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:18:21,276] {{logging_mixin.py:95}} INFO - [2019-10-05 04:18:21,276] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:18:21,278] {{logging_mixin.py:95}} INFO - [2019-10-05 04:18:21,277] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:13:21.277588+00:00
[2019-10-05 04:18:21,286] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.997 seconds
[2019-10-05 04:18:32,422] {{logging_mixin.py:95}} INFO - [2019-10-05 04:18:32,422] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:18:32,428] {{jobs.py:386}} INFO - Started process (PID=5498) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:18:32,436] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:18:32,436] {{logging_mixin.py:95}} INFO - [2019-10-05 04:18:32,436] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:18:32,474] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:18:32,652] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:18:32,715] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:18:32,726] {{logging_mixin.py:95}} INFO - [2019-10-05 04:18:32,726] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:18:32,727] {{logging_mixin.py:95}} INFO - [2019-10-05 04:18:32,727] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:13:32.727155+00:00
[2019-10-05 04:18:32,735] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.306 seconds
[2019-10-05 04:18:44,492] {{logging_mixin.py:95}} INFO - [2019-10-05 04:18:44,491] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:18:44,587] {{jobs.py:386}} INFO - Started process (PID=5502) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:18:45,002] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:18:45,003] {{logging_mixin.py:95}} INFO - [2019-10-05 04:18:45,003] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:18:45,621] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:18:58,714] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:18:58,824] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:18:58,998] {{logging_mixin.py:95}} INFO - [2019-10-05 04:18:58,998] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:18:59,000] {{logging_mixin.py:95}} INFO - [2019-10-05 04:18:58,999] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:13:58.999945+00:00
[2019-10-05 04:18:59,528] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 14.941 seconds
[2019-10-05 04:19:12,350] {{logging_mixin.py:95}} INFO - [2019-10-05 04:19:12,350] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:19:12,611] {{jobs.py:386}} INFO - Started process (PID=5511) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:19:12,972] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:19:12,974] {{logging_mixin.py:95}} INFO - [2019-10-05 04:19:12,974] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:19:14,907] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:19:25,414] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:19:30,681] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:19:30,692] {{logging_mixin.py:95}} INFO - [2019-10-05 04:19:30,692] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:19:30,694] {{logging_mixin.py:95}} INFO - [2019-10-05 04:19:30,693] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:14:30.693481+00:00
[2019-10-05 04:19:32,632] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 20.021 seconds
[2019-10-05 04:19:46,392] {{logging_mixin.py:95}} INFO - [2019-10-05 04:19:46,287] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:19:46,543] {{jobs.py:386}} INFO - Started process (PID=5520) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:19:49,079] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:19:49,082] {{logging_mixin.py:95}} INFO - [2019-10-05 04:19:49,082] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:19:54,516] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:20:00,675] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:20:00,728] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:20:00,739] {{logging_mixin.py:95}} INFO - [2019-10-05 04:20:00,739] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:20:00,740] {{logging_mixin.py:95}} INFO - [2019-10-05 04:20:00,739] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:15:00.739584+00:00
[2019-10-05 04:20:00,836] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 14.294 seconds
[2019-10-05 04:20:12,309] {{logging_mixin.py:95}} INFO - [2019-10-05 04:20:12,309] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:20:12,404] {{jobs.py:386}} INFO - Started process (PID=5524) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:20:12,474] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:20:12,475] {{logging_mixin.py:95}} INFO - [2019-10-05 04:20:12,475] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:20:12,519] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:20:12,747] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:20:12,753] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:20:12,761] {{logging_mixin.py:95}} INFO - [2019-10-05 04:20:12,761] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:20:12,762] {{logging_mixin.py:95}} INFO - [2019-10-05 04:20:12,762] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:15:12.762387+00:00
[2019-10-05 04:20:12,771] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.367 seconds
[2019-10-05 04:20:23,639] {{logging_mixin.py:95}} INFO - [2019-10-05 04:20:23,639] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:20:23,647] {{jobs.py:386}} INFO - Started process (PID=5528) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:20:23,688] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:20:23,689] {{logging_mixin.py:95}} INFO - [2019-10-05 04:20:23,689] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:20:24,289] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:20:25,352] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:20:25,360] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:20:25,372] {{logging_mixin.py:95}} INFO - [2019-10-05 04:20:25,371] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:20:25,376] {{logging_mixin.py:95}} INFO - [2019-10-05 04:20:25,375] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:15:25.374971+00:00
[2019-10-05 04:20:25,388] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.742 seconds
[2019-10-05 04:20:36,555] {{logging_mixin.py:95}} INFO - [2019-10-05 04:20:36,555] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:20:36,708] {{jobs.py:386}} INFO - Started process (PID=5537) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:20:36,711] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:20:36,713] {{logging_mixin.py:95}} INFO - [2019-10-05 04:20:36,713] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:20:36,752] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:20:37,951] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:20:37,957] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:20:37,968] {{logging_mixin.py:95}} INFO - [2019-10-05 04:20:37,968] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:20:37,969] {{logging_mixin.py:95}} INFO - [2019-10-05 04:20:37,968] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:15:37.968963+00:00
[2019-10-05 04:20:37,977] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.269 seconds
[2019-10-05 04:20:48,903] {{logging_mixin.py:95}} INFO - [2019-10-05 04:20:48,903] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:20:48,906] {{jobs.py:386}} INFO - Started process (PID=5541) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:20:48,911] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:20:48,915] {{logging_mixin.py:95}} INFO - [2019-10-05 04:20:48,915] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:20:48,943] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:20:49,288] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:20:49,294] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:20:49,308] {{logging_mixin.py:95}} INFO - [2019-10-05 04:20:49,308] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:20:49,310] {{logging_mixin.py:95}} INFO - [2019-10-05 04:20:49,309] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:15:49.309941+00:00
[2019-10-05 04:20:49,323] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.417 seconds
[2019-10-05 04:21:01,768] {{logging_mixin.py:95}} INFO - [2019-10-05 04:21:01,768] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:21:01,890] {{jobs.py:386}} INFO - Started process (PID=5545) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:21:02,638] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:21:02,642] {{logging_mixin.py:95}} INFO - [2019-10-05 04:21:02,642] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:21:05,361] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:21:14,006] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:21:14,125] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:21:14,136] {{logging_mixin.py:95}} INFO - [2019-10-05 04:21:14,136] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:21:14,138] {{logging_mixin.py:95}} INFO - [2019-10-05 04:21:14,137] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:16:14.137429+00:00
[2019-10-05 04:21:14,147] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 12.257 seconds
[2019-10-05 04:21:25,857] {{logging_mixin.py:95}} INFO - [2019-10-05 04:21:25,857] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:21:25,981] {{jobs.py:386}} INFO - Started process (PID=5558) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:21:26,270] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:21:26,271] {{logging_mixin.py:95}} INFO - [2019-10-05 04:21:26,271] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:21:27,378] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:21:38,258] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:21:38,390] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:21:38,396] {{logging_mixin.py:95}} INFO - [2019-10-05 04:21:38,396] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:21:38,397] {{logging_mixin.py:95}} INFO - [2019-10-05 04:21:38,397] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:16:38.397081+00:00
[2019-10-05 04:21:38,404] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 12.423 seconds
[2019-10-05 04:21:48,872] {{logging_mixin.py:95}} INFO - [2019-10-05 04:21:48,871] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:21:48,876] {{jobs.py:386}} INFO - Started process (PID=5562) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:21:48,881] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:21:48,882] {{logging_mixin.py:95}} INFO - [2019-10-05 04:21:48,882] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:21:48,929] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:21:49,602] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:21:49,609] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:21:49,620] {{logging_mixin.py:95}} INFO - [2019-10-05 04:21:49,620] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:21:49,621] {{logging_mixin.py:95}} INFO - [2019-10-05 04:21:49,621] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:16:49.621081+00:00
[2019-10-05 04:21:49,630] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.754 seconds
[2019-10-05 04:22:00,555] {{logging_mixin.py:95}} INFO - [2019-10-05 04:22:00,555] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:22:00,561] {{jobs.py:386}} INFO - Started process (PID=5571) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:22:00,565] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:22:00,566] {{logging_mixin.py:95}} INFO - [2019-10-05 04:22:00,566] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:22:00,596] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:22:00,889] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:22:00,898] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:22:00,915] {{logging_mixin.py:95}} INFO - [2019-10-05 04:22:00,915] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:22:00,919] {{logging_mixin.py:95}} INFO - [2019-10-05 04:22:00,917] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:17:00.917876+00:00
[2019-10-05 04:22:00,932] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.371 seconds
[2019-10-05 04:22:12,920] {{logging_mixin.py:95}} INFO - [2019-10-05 04:22:12,920] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:22:12,925] {{jobs.py:386}} INFO - Started process (PID=5575) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:22:12,928] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:22:12,931] {{logging_mixin.py:95}} INFO - [2019-10-05 04:22:12,931] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:22:12,968] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:22:14,310] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:22:14,323] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:22:14,339] {{logging_mixin.py:95}} INFO - [2019-10-05 04:22:14,339] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:22:14,340] {{logging_mixin.py:95}} INFO - [2019-10-05 04:22:14,339] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:17:14.339877+00:00
[2019-10-05 04:22:14,354] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.429 seconds
[2019-10-05 04:22:26,927] {{logging_mixin.py:95}} INFO - [2019-10-05 04:22:26,927] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:22:26,931] {{jobs.py:386}} INFO - Started process (PID=5584) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:22:26,944] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:22:26,945] {{logging_mixin.py:95}} INFO - [2019-10-05 04:22:26,945] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:22:26,972] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:22:28,346] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:22:28,355] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:22:28,366] {{logging_mixin.py:95}} INFO - [2019-10-05 04:22:28,365] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:22:28,368] {{logging_mixin.py:95}} INFO - [2019-10-05 04:22:28,368] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:17:28.368332+00:00
[2019-10-05 04:22:28,389] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.458 seconds
[2019-10-05 04:22:39,893] {{logging_mixin.py:95}} INFO - [2019-10-05 04:22:39,893] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:22:39,898] {{jobs.py:386}} INFO - Started process (PID=5588) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:22:39,903] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:22:39,917] {{logging_mixin.py:95}} INFO - [2019-10-05 04:22:39,917] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:22:39,943] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:22:41,426] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:22:41,439] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:22:41,447] {{logging_mixin.py:95}} INFO - [2019-10-05 04:22:41,447] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:22:41,448] {{logging_mixin.py:95}} INFO - [2019-10-05 04:22:41,448] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:17:41.448081+00:00
[2019-10-05 04:22:41,458] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.560 seconds
[2019-10-05 04:22:52,414] {{logging_mixin.py:95}} INFO - [2019-10-05 04:22:52,413] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:22:52,418] {{jobs.py:386}} INFO - Started process (PID=5592) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:22:52,424] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:22:52,427] {{logging_mixin.py:95}} INFO - [2019-10-05 04:22:52,427] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:22:52,473] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:22:53,419] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:22:53,425] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:22:53,432] {{logging_mixin.py:95}} INFO - [2019-10-05 04:22:53,432] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:22:53,433] {{logging_mixin.py:95}} INFO - [2019-10-05 04:22:53,432] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:17:53.432746+00:00
[2019-10-05 04:22:53,440] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.022 seconds
[2019-10-05 04:23:04,973] {{logging_mixin.py:95}} INFO - [2019-10-05 04:23:04,972] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:23:04,976] {{jobs.py:386}} INFO - Started process (PID=5598) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:23:04,978] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:23:04,980] {{logging_mixin.py:95}} INFO - [2019-10-05 04:23:04,979] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:23:04,997] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:23:06,345] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:23:06,352] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:23:06,362] {{logging_mixin.py:95}} INFO - [2019-10-05 04:23:06,362] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:23:06,364] {{logging_mixin.py:95}} INFO - [2019-10-05 04:23:06,363] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:18:06.363327+00:00
[2019-10-05 04:23:06,372] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.397 seconds
[2019-10-05 04:23:17,766] {{logging_mixin.py:95}} INFO - [2019-10-05 04:23:17,766] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:23:17,770] {{jobs.py:386}} INFO - Started process (PID=5610) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:23:17,773] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:23:17,774] {{logging_mixin.py:95}} INFO - [2019-10-05 04:23:17,774] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:23:17,796] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:23:17,969] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:23:18,078] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:23:18,092] {{logging_mixin.py:95}} INFO - [2019-10-05 04:23:18,092] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:23:18,095] {{logging_mixin.py:95}} INFO - [2019-10-05 04:23:18,093] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:18:18.093883+00:00
[2019-10-05 04:23:18,103] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.333 seconds
[2019-10-05 04:23:28,969] {{logging_mixin.py:95}} INFO - [2019-10-05 04:23:28,969] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:23:28,974] {{jobs.py:386}} INFO - Started process (PID=5613) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:23:28,997] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:23:28,998] {{logging_mixin.py:95}} INFO - [2019-10-05 04:23:28,998] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:23:29,639] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:23:35,393] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:23:35,490] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:23:35,499] {{logging_mixin.py:95}} INFO - [2019-10-05 04:23:35,498] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:23:35,499] {{logging_mixin.py:95}} INFO - [2019-10-05 04:23:35,499] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:18:35.499205+00:00
[2019-10-05 04:23:35,660] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 6.686 seconds
[2019-10-05 04:23:47,367] {{logging_mixin.py:95}} INFO - [2019-10-05 04:23:47,367] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:23:47,382] {{jobs.py:386}} INFO - Started process (PID=5617) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:23:47,957] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:23:47,958] {{logging_mixin.py:95}} INFO - [2019-10-05 04:23:47,958] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:23:48,410] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:23:48,731] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:23:48,737] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:23:48,751] {{logging_mixin.py:95}} INFO - [2019-10-05 04:23:48,751] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:23:48,753] {{logging_mixin.py:95}} INFO - [2019-10-05 04:23:48,752] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:18:48.752524+00:00
[2019-10-05 04:23:48,764] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.381 seconds
[2019-10-05 04:23:59,956] {{logging_mixin.py:95}} INFO - [2019-10-05 04:23:59,956] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:23:59,961] {{jobs.py:386}} INFO - Started process (PID=5626) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:23:59,967] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:23:59,968] {{logging_mixin.py:95}} INFO - [2019-10-05 04:23:59,968] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:24:00,099] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:24:00,413] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:24:00,419] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:24:00,432] {{logging_mixin.py:95}} INFO - [2019-10-05 04:24:00,432] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:24:00,433] {{logging_mixin.py:95}} INFO - [2019-10-05 04:24:00,433] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:19:00.433300+00:00
[2019-10-05 04:24:00,442] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.482 seconds
[2019-10-05 04:24:13,343] {{logging_mixin.py:95}} INFO - [2019-10-05 04:24:13,343] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:24:13,553] {{jobs.py:386}} INFO - Started process (PID=5630) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:24:14,221] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:24:14,222] {{logging_mixin.py:95}} INFO - [2019-10-05 04:24:14,222] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:24:15,854] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:24:35,808] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:24:36,942] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:24:36,952] {{logging_mixin.py:95}} INFO - [2019-10-05 04:24:36,952] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:24:36,954] {{logging_mixin.py:95}} INFO - [2019-10-05 04:24:36,953] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:19:36.953429+00:00
[2019-10-05 04:24:38,044] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 24.490 seconds
[2019-10-05 04:24:52,689] {{logging_mixin.py:95}} INFO - [2019-10-05 04:24:52,647] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:24:52,726] {{jobs.py:386}} INFO - Started process (PID=5639) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:24:53,620] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:24:53,622] {{logging_mixin.py:95}} INFO - [2019-10-05 04:24:53,622] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:24:54,920] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:24:59,833] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:24:59,848] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:24:59,871] {{logging_mixin.py:95}} INFO - [2019-10-05 04:24:59,871] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:24:59,874] {{logging_mixin.py:95}} INFO - [2019-10-05 04:24:59,872] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:19:59.872930+00:00
[2019-10-05 04:25:00,099] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 7.373 seconds
[2019-10-05 04:25:10,914] {{logging_mixin.py:95}} INFO - [2019-10-05 04:25:10,914] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:25:10,921] {{jobs.py:386}} INFO - Started process (PID=5643) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:25:11,231] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:25:11,277] {{logging_mixin.py:95}} INFO - [2019-10-05 04:25:11,277] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:25:11,307] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:25:11,757] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:25:11,763] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:25:11,775] {{logging_mixin.py:95}} INFO - [2019-10-05 04:25:11,775] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:25:11,776] {{logging_mixin.py:95}} INFO - [2019-10-05 04:25:11,776] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:20:11.776114+00:00
[2019-10-05 04:25:11,785] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.864 seconds
[2019-10-05 04:25:22,322] {{logging_mixin.py:95}} INFO - [2019-10-05 04:25:22,322] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:25:22,335] {{jobs.py:386}} INFO - Started process (PID=5647) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:25:22,341] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:25:22,342] {{logging_mixin.py:95}} INFO - [2019-10-05 04:25:22,341] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:25:22,428] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:25:22,709] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:25:22,714] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:25:22,728] {{logging_mixin.py:95}} INFO - [2019-10-05 04:25:22,728] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:25:22,729] {{logging_mixin.py:95}} INFO - [2019-10-05 04:25:22,728] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:20:22.728402+00:00
[2019-10-05 04:25:22,745] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.411 seconds
[2019-10-05 04:25:34,051] {{logging_mixin.py:95}} INFO - [2019-10-05 04:25:34,050] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:25:34,102] {{jobs.py:386}} INFO - Started process (PID=5651) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:25:34,293] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:25:34,295] {{logging_mixin.py:95}} INFO - [2019-10-05 04:25:34,295] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:25:34,533] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:25:35,846] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:25:35,997] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:25:36,033] {{logging_mixin.py:95}} INFO - [2019-10-05 04:25:36,033] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:25:36,035] {{logging_mixin.py:95}} INFO - [2019-10-05 04:25:36,034] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:20:36.034410+00:00
[2019-10-05 04:25:36,044] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.942 seconds
[2019-10-05 04:25:47,423] {{logging_mixin.py:95}} INFO - [2019-10-05 04:25:47,423] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:25:47,427] {{jobs.py:386}} INFO - Started process (PID=5660) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:25:47,480] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:25:47,499] {{logging_mixin.py:95}} INFO - [2019-10-05 04:25:47,495] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:25:48,211] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:25:51,580] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:25:51,657] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:25:51,669] {{logging_mixin.py:95}} INFO - [2019-10-05 04:25:51,669] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:25:51,673] {{logging_mixin.py:95}} INFO - [2019-10-05 04:25:51,670] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:20:51.670862+00:00
[2019-10-05 04:25:51,681] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.254 seconds
[2019-10-05 04:26:02,066] {{logging_mixin.py:95}} INFO - [2019-10-05 04:26:02,066] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:26:02,069] {{jobs.py:386}} INFO - Started process (PID=5664) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:26:02,178] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:26:02,179] {{logging_mixin.py:95}} INFO - [2019-10-05 04:26:02,179] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:26:02,516] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:26:03,421] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:26:03,428] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:26:03,439] {{logging_mixin.py:95}} INFO - [2019-10-05 04:26:03,438] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:26:03,440] {{logging_mixin.py:95}} INFO - [2019-10-05 04:26:03,440] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:21:03.440054+00:00
[2019-10-05 04:26:03,450] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.380 seconds
[2019-10-05 04:26:14,540] {{logging_mixin.py:95}} INFO - [2019-10-05 04:26:14,540] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:26:14,553] {{jobs.py:386}} INFO - Started process (PID=5668) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:26:14,580] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:26:14,583] {{logging_mixin.py:95}} INFO - [2019-10-05 04:26:14,583] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:26:14,672] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:26:17,190] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:26:17,328] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:26:17,338] {{logging_mixin.py:95}} INFO - [2019-10-05 04:26:17,338] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:26:17,340] {{logging_mixin.py:95}} INFO - [2019-10-05 04:26:17,339] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:21:17.339756+00:00
[2019-10-05 04:26:17,349] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.796 seconds
[2019-10-05 04:26:30,623] {{logging_mixin.py:95}} INFO - [2019-10-05 04:26:30,623] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:26:30,634] {{jobs.py:386}} INFO - Started process (PID=5678) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:26:30,967] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:26:30,969] {{logging_mixin.py:95}} INFO - [2019-10-05 04:26:30,968] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:26:31,758] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:26:38,035] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:26:38,143] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:26:38,173] {{logging_mixin.py:95}} INFO - [2019-10-05 04:26:38,173] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:26:38,179] {{logging_mixin.py:95}} INFO - [2019-10-05 04:26:38,176] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:21:38.176040+00:00
[2019-10-05 04:26:38,204] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 7.570 seconds
[2019-10-05 04:26:50,911] {{logging_mixin.py:95}} INFO - [2019-10-05 04:26:50,911] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:26:50,943] {{jobs.py:386}} INFO - Started process (PID=5682) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:26:51,743] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:26:51,748] {{logging_mixin.py:95}} INFO - [2019-10-05 04:26:51,747] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:26:52,355] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:27:00,443] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:27:01,045] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:27:01,067] {{logging_mixin.py:95}} INFO - [2019-10-05 04:27:01,067] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:27:01,071] {{logging_mixin.py:95}} INFO - [2019-10-05 04:27:01,069] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:22:01.069072+00:00
[2019-10-05 04:27:02,460] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 11.517 seconds
[2019-10-05 04:27:15,534] {{logging_mixin.py:95}} INFO - [2019-10-05 04:27:15,533] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:27:15,858] {{jobs.py:386}} INFO - Started process (PID=5686) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:27:16,904] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:27:16,905] {{logging_mixin.py:95}} INFO - [2019-10-05 04:27:16,905] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:27:19,795] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:27:32,734] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:27:33,109] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:27:33,128] {{logging_mixin.py:95}} INFO - [2019-10-05 04:27:33,127] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:27:33,131] {{logging_mixin.py:95}} INFO - [2019-10-05 04:27:33,129] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:22:33.129472+00:00
[2019-10-05 04:27:33,461] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 17.603 seconds
[2019-10-05 04:27:45,440] {{logging_mixin.py:95}} INFO - [2019-10-05 04:27:45,439] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:27:45,482] {{jobs.py:386}} INFO - Started process (PID=5695) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:27:45,655] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:27:45,659] {{logging_mixin.py:95}} INFO - [2019-10-05 04:27:45,659] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:27:46,092] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:27:46,455] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:27:46,460] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:27:46,468] {{logging_mixin.py:95}} INFO - [2019-10-05 04:27:46,468] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:27:46,470] {{logging_mixin.py:95}} INFO - [2019-10-05 04:27:46,469] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:22:46.469493+00:00
[2019-10-05 04:27:46,481] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.999 seconds
[2019-10-05 04:27:57,344] {{logging_mixin.py:95}} INFO - [2019-10-05 04:27:57,344] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:27:57,349] {{jobs.py:386}} INFO - Started process (PID=5699) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:27:57,352] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:27:57,355] {{logging_mixin.py:95}} INFO - [2019-10-05 04:27:57,354] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:27:57,391] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:27:57,630] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:27:57,638] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:27:57,650] {{logging_mixin.py:95}} INFO - [2019-10-05 04:27:57,650] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:27:57,652] {{logging_mixin.py:95}} INFO - [2019-10-05 04:27:57,651] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:22:57.651632+00:00
[2019-10-05 04:27:57,661] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.313 seconds
[2019-10-05 04:28:08,785] {{logging_mixin.py:95}} INFO - [2019-10-05 04:28:08,784] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:28:08,792] {{jobs.py:386}} INFO - Started process (PID=5703) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:28:08,824] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:28:08,825] {{logging_mixin.py:95}} INFO - [2019-10-05 04:28:08,825] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:28:08,864] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:28:09,044] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:28:09,148] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:28:09,158] {{logging_mixin.py:95}} INFO - [2019-10-05 04:28:09,158] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:28:09,160] {{logging_mixin.py:95}} INFO - [2019-10-05 04:28:09,159] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:23:09.159448+00:00
[2019-10-05 04:28:09,168] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.376 seconds
[2019-10-05 04:28:21,331] {{logging_mixin.py:95}} INFO - [2019-10-05 04:28:21,331] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:28:21,487] {{jobs.py:386}} INFO - Started process (PID=5712) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:28:21,665] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:28:21,667] {{logging_mixin.py:95}} INFO - [2019-10-05 04:28:21,667] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:28:21,908] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:28:24,172] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:28:24,255] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:28:24,270] {{logging_mixin.py:95}} INFO - [2019-10-05 04:28:24,270] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:28:24,271] {{logging_mixin.py:95}} INFO - [2019-10-05 04:28:24,271] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:23:24.271188+00:00
[2019-10-05 04:28:24,279] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.793 seconds
[2019-10-05 04:28:37,943] {{logging_mixin.py:95}} INFO - [2019-10-05 04:28:37,896] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:28:38,019] {{jobs.py:386}} INFO - Started process (PID=5716) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:28:38,891] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:28:39,045] {{logging_mixin.py:95}} INFO - [2019-10-05 04:28:39,045] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:28:40,699] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:28:45,741] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:28:45,747] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:28:45,755] {{logging_mixin.py:95}} INFO - [2019-10-05 04:28:45,755] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:28:45,756] {{logging_mixin.py:95}} INFO - [2019-10-05 04:28:45,756] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:23:45.756137+00:00
[2019-10-05 04:28:45,763] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 7.744 seconds
[2019-10-05 04:28:56,379] {{logging_mixin.py:95}} INFO - [2019-10-05 04:28:56,379] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:28:56,390] {{jobs.py:386}} INFO - Started process (PID=5720) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:28:56,402] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:28:56,404] {{logging_mixin.py:95}} INFO - [2019-10-05 04:28:56,404] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:28:56,448] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:28:56,940] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:28:56,947] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:28:56,960] {{logging_mixin.py:95}} INFO - [2019-10-05 04:28:56,960] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:28:56,962] {{logging_mixin.py:95}} INFO - [2019-10-05 04:28:56,961] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:23:56.961084+00:00
[2019-10-05 04:28:56,973] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.582 seconds
[2019-10-05 04:29:08,246] {{logging_mixin.py:95}} INFO - [2019-10-05 04:29:08,245] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:29:08,333] {{jobs.py:386}} INFO - Started process (PID=5730) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:29:08,692] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:29:08,693] {{logging_mixin.py:95}} INFO - [2019-10-05 04:29:08,693] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:29:09,946] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:29:12,271] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:29:12,291] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:29:12,307] {{logging_mixin.py:95}} INFO - [2019-10-05 04:29:12,307] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:29:12,309] {{logging_mixin.py:95}} INFO - [2019-10-05 04:29:12,307] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:24:12.307937+00:00
[2019-10-05 04:29:12,325] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.993 seconds
[2019-10-05 04:29:24,170] {{logging_mixin.py:95}} INFO - [2019-10-05 04:29:24,168] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:29:24,385] {{jobs.py:386}} INFO - Started process (PID=5734) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:29:24,732] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:29:24,733] {{logging_mixin.py:95}} INFO - [2019-10-05 04:29:24,733] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:29:25,894] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:29:42,256] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:29:44,004] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:29:44,016] {{logging_mixin.py:95}} INFO - [2019-10-05 04:29:44,016] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:29:44,018] {{logging_mixin.py:95}} INFO - [2019-10-05 04:29:44,017] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:24:44.017683+00:00
[2019-10-05 04:29:45,172] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 20.787 seconds
[2019-10-05 04:29:58,152] {{logging_mixin.py:95}} INFO - [2019-10-05 04:29:58,151] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:29:58,209] {{jobs.py:386}} INFO - Started process (PID=5744) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:29:58,666] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:29:58,667] {{logging_mixin.py:95}} INFO - [2019-10-05 04:29:58,666] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:30:01,053] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:30:05,706] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:30:05,726] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:30:05,736] {{logging_mixin.py:95}} INFO - [2019-10-05 04:30:05,736] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:30:05,737] {{logging_mixin.py:95}} INFO - [2019-10-05 04:30:05,736] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:25:05.736967+00:00
[2019-10-05 04:30:06,635] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 8.425 seconds
[2019-10-05 04:30:18,910] {{logging_mixin.py:95}} INFO - [2019-10-05 04:30:18,910] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:30:19,239] {{jobs.py:386}} INFO - Started process (PID=5748) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:30:19,763] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:30:19,765] {{logging_mixin.py:95}} INFO - [2019-10-05 04:30:19,765] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:30:20,275] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:30:25,627] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:30:25,926] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:30:25,937] {{logging_mixin.py:95}} INFO - [2019-10-05 04:30:25,937] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:30:25,938] {{logging_mixin.py:95}} INFO - [2019-10-05 04:30:25,937] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:25:25.937363+00:00
[2019-10-05 04:30:26,342] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 7.103 seconds
[2019-10-05 04:30:39,922] {{logging_mixin.py:95}} INFO - [2019-10-05 04:30:39,567] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:30:40,216] {{jobs.py:386}} INFO - Started process (PID=5752) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:30:40,996] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:30:40,997] {{logging_mixin.py:95}} INFO - [2019-10-05 04:30:40,997] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:30:44,743] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:31:07,385] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 04:31:30,344] {{logging_mixin.py:95}} INFO - [2019-10-05 04:31:29,853] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:31:30,812] {{jobs.py:386}} INFO - Started process (PID=5759) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:31:31,514] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:31:31,516] {{logging_mixin.py:95}} INFO - [2019-10-05 04:31:31,516] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:31:32,775] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:31:53,789] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 04:32:19,954] {{logging_mixin.py:95}} INFO - [2019-10-05 04:32:19,954] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:32:20,293] {{jobs.py:386}} INFO - Started process (PID=5761) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:32:20,909] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:32:20,910] {{logging_mixin.py:95}} INFO - [2019-10-05 04:32:20,910] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:32:25,181] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:32:30,530] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:32:30,719] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:32:30,776] {{logging_mixin.py:95}} INFO - [2019-10-05 04:32:30,775] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:32:30,779] {{logging_mixin.py:95}} INFO - [2019-10-05 04:32:30,779] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:27:30.779032+00:00
[2019-10-05 04:32:30,789] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 10.496 seconds
[2019-10-05 04:32:42,382] {{logging_mixin.py:95}} INFO - [2019-10-05 04:32:42,381] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:32:42,414] {{jobs.py:386}} INFO - Started process (PID=5765) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:32:42,438] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:32:42,441] {{logging_mixin.py:95}} INFO - [2019-10-05 04:32:42,441] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:32:42,532] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:32:43,355] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:32:43,395] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:32:43,414] {{logging_mixin.py:95}} INFO - [2019-10-05 04:32:43,414] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:32:43,417] {{logging_mixin.py:95}} INFO - [2019-10-05 04:32:43,415] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:27:43.415783+00:00
[2019-10-05 04:32:43,433] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.019 seconds
[2019-10-05 04:32:54,840] {{logging_mixin.py:95}} INFO - [2019-10-05 04:32:54,839] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:32:54,850] {{jobs.py:386}} INFO - Started process (PID=5771) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:32:54,856] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:32:54,858] {{logging_mixin.py:95}} INFO - [2019-10-05 04:32:54,857] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:32:54,893] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:32:55,028] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:32:55,038] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:32:55,056] {{logging_mixin.py:95}} INFO - [2019-10-05 04:32:55,056] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:32:55,058] {{logging_mixin.py:95}} INFO - [2019-10-05 04:32:55,057] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:27:55.057859+00:00
[2019-10-05 04:32:55,072] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.222 seconds
[2019-10-05 04:33:06,858] {{logging_mixin.py:95}} INFO - [2019-10-05 04:33:06,858] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:33:06,871] {{jobs.py:386}} INFO - Started process (PID=5779) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:33:06,875] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:33:06,876] {{logging_mixin.py:95}} INFO - [2019-10-05 04:33:06,876] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:33:06,895] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:33:07,203] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:33:07,209] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:33:07,222] {{logging_mixin.py:95}} INFO - [2019-10-05 04:33:07,222] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:33:07,224] {{logging_mixin.py:95}} INFO - [2019-10-05 04:33:07,223] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:28:07.223433+00:00
[2019-10-05 04:33:07,232] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.361 seconds
[2019-10-05 04:33:18,572] {{logging_mixin.py:95}} INFO - [2019-10-05 04:33:18,572] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:33:18,576] {{jobs.py:386}} INFO - Started process (PID=5782) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:33:18,579] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:33:18,580] {{logging_mixin.py:95}} INFO - [2019-10-05 04:33:18,580] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:33:18,646] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:33:19,611] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:33:19,618] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:33:19,629] {{logging_mixin.py:95}} INFO - [2019-10-05 04:33:19,629] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:33:19,632] {{logging_mixin.py:95}} INFO - [2019-10-05 04:33:19,631] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:28:19.631616+00:00
[2019-10-05 04:33:19,642] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.066 seconds
[2019-10-05 04:33:30,753] {{logging_mixin.py:95}} INFO - [2019-10-05 04:33:30,752] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:33:30,758] {{jobs.py:386}} INFO - Started process (PID=5786) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:33:30,769] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:33:30,770] {{logging_mixin.py:95}} INFO - [2019-10-05 04:33:30,770] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:33:30,804] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:33:32,642] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:33:32,654] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:33:32,668] {{logging_mixin.py:95}} INFO - [2019-10-05 04:33:32,668] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:33:32,669] {{logging_mixin.py:95}} INFO - [2019-10-05 04:33:32,668] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:28:32.668834+00:00
[2019-10-05 04:33:32,681] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.923 seconds
[2019-10-05 04:33:43,277] {{logging_mixin.py:95}} INFO - [2019-10-05 04:33:43,277] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:33:43,281] {{jobs.py:386}} INFO - Started process (PID=5796) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:33:43,287] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:33:43,288] {{logging_mixin.py:95}} INFO - [2019-10-05 04:33:43,287] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:33:44,169] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:33:46,908] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:33:46,915] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:33:47,050] {{logging_mixin.py:95}} INFO - [2019-10-05 04:33:47,050] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:33:47,051] {{logging_mixin.py:95}} INFO - [2019-10-05 04:33:47,051] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:28:47.051050+00:00
[2019-10-05 04:33:47,200] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.919 seconds
[2019-10-05 04:33:58,446] {{logging_mixin.py:95}} INFO - [2019-10-05 04:33:58,446] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:33:58,631] {{jobs.py:386}} INFO - Started process (PID=5800) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:33:59,029] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:33:59,030] {{logging_mixin.py:95}} INFO - [2019-10-05 04:33:59,030] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:34:00,019] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:34:07,894] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:34:07,957] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:34:07,968] {{logging_mixin.py:95}} INFO - [2019-10-05 04:34:07,968] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:34:07,970] {{logging_mixin.py:95}} INFO - [2019-10-05 04:34:07,969] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:29:07.969560+00:00
[2019-10-05 04:34:08,041] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 9.410 seconds
[2019-10-05 04:34:19,671] {{logging_mixin.py:95}} INFO - [2019-10-05 04:34:19,670] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:34:19,684] {{jobs.py:386}} INFO - Started process (PID=5810) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:34:19,756] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:34:19,756] {{logging_mixin.py:95}} INFO - [2019-10-05 04:34:19,756] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:34:19,863] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:34:20,904] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:34:20,957] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:34:20,972] {{logging_mixin.py:95}} INFO - [2019-10-05 04:34:20,971] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:34:20,972] {{logging_mixin.py:95}} INFO - [2019-10-05 04:34:20,972] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:29:20.972235+00:00
[2019-10-05 04:34:20,980] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.296 seconds
[2019-10-05 04:34:34,804] {{logging_mixin.py:95}} INFO - [2019-10-05 04:34:34,636] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:34:35,378] {{jobs.py:386}} INFO - Started process (PID=5814) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:34:35,998] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:34:35,999] {{logging_mixin.py:95}} INFO - [2019-10-05 04:34:35,999] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:34:38,349] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:34:46,308] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:34:46,347] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:34:46,356] {{logging_mixin.py:95}} INFO - [2019-10-05 04:34:46,356] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:34:46,358] {{logging_mixin.py:95}} INFO - [2019-10-05 04:34:46,357] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:29:46.357397+00:00
[2019-10-05 04:34:46,381] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 11.002 seconds
[2019-10-05 04:34:58,557] {{logging_mixin.py:95}} INFO - [2019-10-05 04:34:58,557] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:34:58,811] {{jobs.py:386}} INFO - Started process (PID=5823) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:34:59,646] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:34:59,653] {{logging_mixin.py:95}} INFO - [2019-10-05 04:34:59,653] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:35:02,399] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:35:18,832] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:35:22,697] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:35:22,707] {{logging_mixin.py:95}} INFO - [2019-10-05 04:35:22,707] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:35:22,708] {{logging_mixin.py:95}} INFO - [2019-10-05 04:35:22,707] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:30:22.707842+00:00
[2019-10-05 04:35:23,498] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 24.687 seconds
[2019-10-05 04:35:35,410] {{logging_mixin.py:95}} INFO - [2019-10-05 04:35:35,409] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:35:35,520] {{jobs.py:386}} INFO - Started process (PID=5827) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:35:36,090] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:35:36,092] {{logging_mixin.py:95}} INFO - [2019-10-05 04:35:36,092] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:35:37,239] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:35:38,233] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:35:38,237] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:35:38,245] {{logging_mixin.py:95}} INFO - [2019-10-05 04:35:38,245] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:35:38,246] {{logging_mixin.py:95}} INFO - [2019-10-05 04:35:38,245] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:30:38.245630+00:00
[2019-10-05 04:35:38,252] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.732 seconds
[2019-10-05 04:35:49,416] {{logging_mixin.py:95}} INFO - [2019-10-05 04:35:49,416] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:35:49,420] {{jobs.py:386}} INFO - Started process (PID=5831) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:35:49,423] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:35:49,425] {{logging_mixin.py:95}} INFO - [2019-10-05 04:35:49,424] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:35:49,458] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:35:49,918] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:35:49,927] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:35:49,942] {{logging_mixin.py:95}} INFO - [2019-10-05 04:35:49,942] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:35:49,946] {{logging_mixin.py:95}} INFO - [2019-10-05 04:35:49,944] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:30:49.944264+00:00
[2019-10-05 04:35:49,958] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.538 seconds
[2019-10-05 04:36:01,257] {{logging_mixin.py:95}} INFO - [2019-10-05 04:36:01,257] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:36:01,261] {{jobs.py:386}} INFO - Started process (PID=5845) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:36:01,373] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:36:01,374] {{logging_mixin.py:95}} INFO - [2019-10-05 04:36:01,374] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:36:02,027] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:36:04,910] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:36:04,982] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:36:05,160] {{logging_mixin.py:95}} INFO - [2019-10-05 04:36:05,160] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:36:05,162] {{logging_mixin.py:95}} INFO - [2019-10-05 04:36:05,161] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:31:05.161757+00:00
[2019-10-05 04:36:05,170] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.909 seconds
[2019-10-05 04:36:16,705] {{logging_mixin.py:95}} INFO - [2019-10-05 04:36:16,704] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:36:16,709] {{jobs.py:386}} INFO - Started process (PID=5849) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:36:16,813] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:36:16,918] {{logging_mixin.py:95}} INFO - [2019-10-05 04:36:16,918] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:36:17,239] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:36:17,452] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:36:17,457] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:36:17,465] {{logging_mixin.py:95}} INFO - [2019-10-05 04:36:17,465] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:36:17,465] {{logging_mixin.py:95}} INFO - [2019-10-05 04:36:17,465] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:31:17.465370+00:00
[2019-10-05 04:36:17,472] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.763 seconds
[2019-10-05 04:36:28,670] {{logging_mixin.py:95}} INFO - [2019-10-05 04:36:28,670] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:36:28,700] {{jobs.py:386}} INFO - Started process (PID=5853) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:36:28,718] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:36:28,720] {{logging_mixin.py:95}} INFO - [2019-10-05 04:36:28,719] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:36:28,835] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:36:29,817] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:36:29,910] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:36:29,932] {{logging_mixin.py:95}} INFO - [2019-10-05 04:36:29,932] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:36:29,934] {{logging_mixin.py:95}} INFO - [2019-10-05 04:36:29,933] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:31:29.933922+00:00
[2019-10-05 04:36:29,957] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.257 seconds
[2019-10-05 04:36:43,664] {{logging_mixin.py:95}} INFO - [2019-10-05 04:36:43,125] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:36:44,216] {{jobs.py:386}} INFO - Started process (PID=5862) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:36:45,872] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:36:45,875] {{logging_mixin.py:95}} INFO - [2019-10-05 04:36:45,875] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:36:48,651] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:36:55,659] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:36:55,835] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:36:55,862] {{logging_mixin.py:95}} INFO - [2019-10-05 04:36:55,862] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:36:55,879] {{logging_mixin.py:95}} INFO - [2019-10-05 04:36:55,864] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:31:55.864059+00:00
[2019-10-05 04:42:08,978] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 324.762 seconds
[2019-10-05 04:42:20,778] {{logging_mixin.py:95}} INFO - [2019-10-05 04:42:20,778] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:42:20,835] {{jobs.py:386}} INFO - Started process (PID=5907) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:42:21,203] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:42:21,205] {{logging_mixin.py:95}} INFO - [2019-10-05 04:42:21,204] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:42:21,419] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:42:22,218] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:42:22,312] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:42:22,321] {{logging_mixin.py:95}} INFO - [2019-10-05 04:42:22,321] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:42:22,322] {{logging_mixin.py:95}} INFO - [2019-10-05 04:42:22,321] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:37:22.321807+00:00
[2019-10-05 04:42:22,410] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.575 seconds
[2019-10-05 04:42:33,149] {{logging_mixin.py:95}} INFO - [2019-10-05 04:42:33,148] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:42:33,152] {{jobs.py:386}} INFO - Started process (PID=5911) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:42:33,159] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:42:33,161] {{logging_mixin.py:95}} INFO - [2019-10-05 04:42:33,160] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:42:33,233] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:42:34,977] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:42:35,027] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:42:35,042] {{logging_mixin.py:95}} INFO - [2019-10-05 04:42:35,041] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:42:35,045] {{logging_mixin.py:95}} INFO - [2019-10-05 04:42:35,045] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:37:35.045139+00:00
[2019-10-05 04:42:35,053] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.901 seconds
[2019-10-05 04:42:47,157] {{logging_mixin.py:95}} INFO - [2019-10-05 04:42:46,859] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:42:47,590] {{jobs.py:386}} INFO - Started process (PID=5915) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:42:49,415] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:42:49,416] {{logging_mixin.py:95}} INFO - [2019-10-05 04:42:49,416] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:42:52,161] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:43:04,222] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:43:04,453] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:43:04,472] {{logging_mixin.py:95}} INFO - [2019-10-05 04:43:04,472] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:43:04,475] {{logging_mixin.py:95}} INFO - [2019-10-05 04:43:04,474] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:38:04.474011+00:00
[2019-10-05 04:43:04,876] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 17.286 seconds
[2019-10-05 04:43:18,377] {{logging_mixin.py:95}} INFO - [2019-10-05 04:43:18,377] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:43:19,455] {{jobs.py:386}} INFO - Started process (PID=5924) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:43:19,766] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:43:19,767] {{logging_mixin.py:95}} INFO - [2019-10-05 04:43:19,766] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:43:21,827] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:43:26,954] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:43:27,051] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:43:27,121] {{logging_mixin.py:95}} INFO - [2019-10-05 04:43:27,121] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:43:27,122] {{logging_mixin.py:95}} INFO - [2019-10-05 04:43:27,122] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:38:27.121987+00:00
[2019-10-05 04:43:27,208] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 7.752 seconds
[2019-10-05 04:43:38,516] {{logging_mixin.py:95}} INFO - [2019-10-05 04:43:38,516] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:43:38,525] {{jobs.py:386}} INFO - Started process (PID=5928) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:43:38,712] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:43:38,714] {{logging_mixin.py:95}} INFO - [2019-10-05 04:43:38,713] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:43:38,749] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:43:39,375] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:43:39,382] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:43:39,392] {{logging_mixin.py:95}} INFO - [2019-10-05 04:43:39,391] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:43:39,394] {{logging_mixin.py:95}} INFO - [2019-10-05 04:43:39,393] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:38:39.393696+00:00
[2019-10-05 04:43:39,403] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.879 seconds
[2019-10-05 04:43:49,914] {{logging_mixin.py:95}} INFO - [2019-10-05 04:43:49,913] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:43:49,947] {{jobs.py:386}} INFO - Started process (PID=5932) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:43:49,959] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:43:49,967] {{logging_mixin.py:95}} INFO - [2019-10-05 04:43:49,967] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:43:50,040] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:43:50,522] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:43:50,541] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:43:50,566] {{logging_mixin.py:95}} INFO - [2019-10-05 04:43:50,565] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:43:50,568] {{logging_mixin.py:95}} INFO - [2019-10-05 04:43:50,567] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:38:50.567386+00:00
[2019-10-05 04:43:50,581] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.635 seconds
[2019-10-05 04:44:01,668] {{logging_mixin.py:95}} INFO - [2019-10-05 04:44:01,667] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:44:01,713] {{jobs.py:386}} INFO - Started process (PID=5945) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:44:01,763] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:44:01,764] {{logging_mixin.py:95}} INFO - [2019-10-05 04:44:01,764] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:44:02,033] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:44:02,869] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:44:02,876] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:44:02,888] {{logging_mixin.py:95}} INFO - [2019-10-05 04:44:02,888] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:44:02,889] {{logging_mixin.py:95}} INFO - [2019-10-05 04:44:02,888] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:39:02.888532+00:00
[2019-10-05 04:44:02,895] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.182 seconds
[2019-10-05 04:44:14,637] {{logging_mixin.py:95}} INFO - [2019-10-05 04:44:14,637] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:44:14,803] {{jobs.py:386}} INFO - Started process (PID=5949) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:44:15,484] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:44:15,486] {{logging_mixin.py:95}} INFO - [2019-10-05 04:44:15,485] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:44:16,042] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:44:18,992] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:44:19,080] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:44:19,095] {{logging_mixin.py:95}} INFO - [2019-10-05 04:44:19,095] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:44:19,097] {{logging_mixin.py:95}} INFO - [2019-10-05 04:44:19,096] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:39:19.096531+00:00
[2019-10-05 04:44:19,107] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.304 seconds
[2019-10-05 04:44:31,116] {{logging_mixin.py:95}} INFO - [2019-10-05 04:44:31,115] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:44:31,176] {{jobs.py:386}} INFO - Started process (PID=5958) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:44:31,703] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:44:31,705] {{logging_mixin.py:95}} INFO - [2019-10-05 04:44:31,705] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:44:32,575] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:44:35,163] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:44:35,170] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:44:35,179] {{logging_mixin.py:95}} INFO - [2019-10-05 04:44:35,179] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:44:35,180] {{logging_mixin.py:95}} INFO - [2019-10-05 04:44:35,180] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:39:35.180259+00:00
[2019-10-05 04:44:35,188] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.012 seconds
[2019-10-05 04:44:46,046] {{logging_mixin.py:95}} INFO - [2019-10-05 04:44:46,046] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:44:46,049] {{jobs.py:386}} INFO - Started process (PID=5962) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:44:46,052] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:44:46,055] {{logging_mixin.py:95}} INFO - [2019-10-05 04:44:46,055] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:44:46,087] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:44:46,259] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:44:46,263] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:44:46,271] {{logging_mixin.py:95}} INFO - [2019-10-05 04:44:46,271] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:44:46,272] {{logging_mixin.py:95}} INFO - [2019-10-05 04:44:46,272] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:39:46.272024+00:00
[2019-10-05 04:44:46,278] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.229 seconds
[2019-10-05 04:44:57,923] {{logging_mixin.py:95}} INFO - [2019-10-05 04:44:57,922] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:44:57,979] {{jobs.py:386}} INFO - Started process (PID=5966) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:44:58,183] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:44:58,184] {{logging_mixin.py:95}} INFO - [2019-10-05 04:44:58,183] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:44:58,579] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:45:09,562] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 04:45:23,539] {{logging_mixin.py:95}} INFO - [2019-10-05 04:45:23,538] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:45:23,692] {{jobs.py:386}} INFO - Started process (PID=5973) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:45:24,023] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:45:24,024] {{logging_mixin.py:95}} INFO - [2019-10-05 04:45:24,024] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:45:24,754] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:45:42,400] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:45:42,595] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:45:42,626] {{logging_mixin.py:95}} INFO - [2019-10-05 04:45:42,626] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:45:42,627] {{logging_mixin.py:95}} INFO - [2019-10-05 04:45:42,626] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:40:42.626923+00:00
[2019-10-05 04:45:43,655] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 19.963 seconds
[2019-10-05 04:45:56,516] {{logging_mixin.py:95}} INFO - [2019-10-05 04:45:56,516] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:45:56,678] {{jobs.py:386}} INFO - Started process (PID=5977) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:45:58,577] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:45:58,578] {{logging_mixin.py:95}} INFO - [2019-10-05 04:45:58,578] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:46:01,389] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:46:19,046] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:46:20,102] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:46:20,116] {{logging_mixin.py:95}} INFO - [2019-10-05 04:46:20,116] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:46:20,118] {{logging_mixin.py:95}} INFO - [2019-10-05 04:46:20,117] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:41:20.117853+00:00
[2019-10-05 04:46:21,803] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 25.125 seconds
[2019-10-05 04:46:38,048] {{logging_mixin.py:95}} INFO - [2019-10-05 04:46:38,048] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:46:38,797] {{jobs.py:386}} INFO - Started process (PID=5981) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:46:39,701] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:46:39,702] {{logging_mixin.py:95}} INFO - [2019-10-05 04:46:39,702] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:46:42,480] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:47:03,723] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 04:47:24,619] {{logging_mixin.py:95}} INFO - [2019-10-05 04:47:24,504] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:47:24,678] {{jobs.py:386}} INFO - Started process (PID=5988) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:47:25,731] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:47:25,734] {{logging_mixin.py:95}} INFO - [2019-10-05 04:47:25,734] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:47:29,764] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:47:47,913] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 04:48:02,977] {{logging_mixin.py:95}} INFO - [2019-10-05 04:48:02,977] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:48:03,045] {{jobs.py:386}} INFO - Started process (PID=5990) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:48:03,441] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:48:03,441] {{logging_mixin.py:95}} INFO - [2019-10-05 04:48:03,441] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:48:04,139] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:48:04,931] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:48:05,037] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:48:05,043] {{logging_mixin.py:95}} INFO - [2019-10-05 04:48:05,043] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:48:05,044] {{logging_mixin.py:95}} INFO - [2019-10-05 04:48:05,043] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:43:05.043563+00:00
[2019-10-05 04:48:05,054] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.009 seconds
[2019-10-05 04:48:15,974] {{logging_mixin.py:95}} INFO - [2019-10-05 04:48:15,973] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:48:16,004] {{jobs.py:386}} INFO - Started process (PID=5994) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:48:16,038] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:48:16,040] {{logging_mixin.py:95}} INFO - [2019-10-05 04:48:16,040] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:48:16,066] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:48:17,291] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:48:17,353] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:48:17,361] {{logging_mixin.py:95}} INFO - [2019-10-05 04:48:17,361] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:48:17,363] {{logging_mixin.py:95}} INFO - [2019-10-05 04:48:17,362] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:43:17.362793+00:00
[2019-10-05 04:48:17,370] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.366 seconds
[2019-10-05 04:48:28,506] {{logging_mixin.py:95}} INFO - [2019-10-05 04:48:28,506] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:48:28,510] {{jobs.py:386}} INFO - Started process (PID=6005) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:48:28,512] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:48:28,513] {{logging_mixin.py:95}} INFO - [2019-10-05 04:48:28,513] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:48:28,536] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:48:28,643] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:48:28,650] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:48:28,665] {{logging_mixin.py:95}} INFO - [2019-10-05 04:48:28,665] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:48:28,667] {{logging_mixin.py:95}} INFO - [2019-10-05 04:48:28,666] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:43:28.666490+00:00
[2019-10-05 04:48:28,675] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.165 seconds
[2019-10-05 04:48:40,867] {{logging_mixin.py:95}} INFO - [2019-10-05 04:48:40,601] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:48:40,880] {{jobs.py:386}} INFO - Started process (PID=6008) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:48:41,439] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:48:41,441] {{logging_mixin.py:95}} INFO - [2019-10-05 04:48:41,441] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:48:42,372] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:48:43,478] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:48:43,546] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:48:43,555] {{logging_mixin.py:95}} INFO - [2019-10-05 04:48:43,555] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:48:43,556] {{logging_mixin.py:95}} INFO - [2019-10-05 04:48:43,555] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:43:43.555679+00:00
[2019-10-05 04:48:43,565] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.685 seconds
[2019-10-05 04:48:55,481] {{logging_mixin.py:95}} INFO - [2019-10-05 04:48:55,481] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:48:55,716] {{jobs.py:386}} INFO - Started process (PID=6011) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:48:56,130] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:48:56,132] {{logging_mixin.py:95}} INFO - [2019-10-05 04:48:56,132] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:48:56,455] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:49:00,207] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:49:00,242] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:49:00,262] {{logging_mixin.py:95}} INFO - [2019-10-05 04:49:00,262] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:49:00,265] {{logging_mixin.py:95}} INFO - [2019-10-05 04:49:00,264] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:44:00.264352+00:00
[2019-10-05 04:49:00,288] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.572 seconds
[2019-10-05 04:49:12,399] {{logging_mixin.py:95}} INFO - [2019-10-05 04:49:12,359] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:49:12,448] {{jobs.py:386}} INFO - Started process (PID=6020) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:49:13,147] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:49:13,148] {{logging_mixin.py:95}} INFO - [2019-10-05 04:49:13,148] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:49:14,565] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:49:31,265] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:49:31,671] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:49:31,720] {{logging_mixin.py:95}} INFO - [2019-10-05 04:49:31,720] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:49:31,723] {{logging_mixin.py:95}} INFO - [2019-10-05 04:49:31,721] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:44:31.721841+00:00
[2019-10-05 04:49:32,835] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 20.387 seconds
[2019-10-05 04:49:45,448] {{logging_mixin.py:95}} INFO - [2019-10-05 04:49:45,381] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:49:45,467] {{jobs.py:386}} INFO - Started process (PID=6031) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:49:45,723] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:49:45,724] {{logging_mixin.py:95}} INFO - [2019-10-05 04:49:45,724] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:49:48,278] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:49:54,588] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:49:54,883] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:49:54,892] {{logging_mixin.py:95}} INFO - [2019-10-05 04:49:54,892] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:49:54,893] {{logging_mixin.py:95}} INFO - [2019-10-05 04:49:54,893] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:44:54.893106+00:00
[2019-10-05 04:49:55,866] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 10.398 seconds
[2019-10-05 04:50:07,685] {{logging_mixin.py:95}} INFO - [2019-10-05 04:50:07,685] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:50:07,688] {{jobs.py:386}} INFO - Started process (PID=6035) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:50:07,962] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:50:07,964] {{logging_mixin.py:95}} INFO - [2019-10-05 04:50:07,963] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:50:08,101] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:50:08,282] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:50:08,356] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:50:08,369] {{logging_mixin.py:95}} INFO - [2019-10-05 04:50:08,368] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:50:08,370] {{logging_mixin.py:95}} INFO - [2019-10-05 04:50:08,369] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:45:08.369944+00:00
[2019-10-05 04:50:08,388] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.700 seconds
[2019-10-05 04:50:18,954] {{logging_mixin.py:95}} INFO - [2019-10-05 04:50:18,953] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:50:18,957] {{jobs.py:386}} INFO - Started process (PID=6039) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:50:18,961] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:50:18,963] {{logging_mixin.py:95}} INFO - [2019-10-05 04:50:18,963] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:50:18,999] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:50:19,311] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:50:19,319] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:50:19,334] {{logging_mixin.py:95}} INFO - [2019-10-05 04:50:19,334] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:50:19,336] {{logging_mixin.py:95}} INFO - [2019-10-05 04:50:19,335] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:45:19.335388+00:00
[2019-10-05 04:50:19,346] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.389 seconds
[2019-10-05 04:50:30,272] {{logging_mixin.py:95}} INFO - [2019-10-05 04:50:30,271] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:50:30,275] {{jobs.py:386}} INFO - Started process (PID=6048) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:50:30,281] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:50:30,281] {{logging_mixin.py:95}} INFO - [2019-10-05 04:50:30,281] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:50:30,315] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:50:30,670] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:50:30,675] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:50:30,687] {{logging_mixin.py:95}} INFO - [2019-10-05 04:50:30,687] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:50:30,687] {{logging_mixin.py:95}} INFO - [2019-10-05 04:50:30,687] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:45:30.687329+00:00
[2019-10-05 04:50:30,694] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.419 seconds
[2019-10-05 04:50:41,946] {{logging_mixin.py:95}} INFO - [2019-10-05 04:50:41,945] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:50:42,011] {{jobs.py:386}} INFO - Started process (PID=6052) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:50:42,072] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:50:42,073] {{logging_mixin.py:95}} INFO - [2019-10-05 04:50:42,073] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:50:42,255] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:50:44,738] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:50:44,748] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:50:44,756] {{logging_mixin.py:95}} INFO - [2019-10-05 04:50:44,756] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:50:44,759] {{logging_mixin.py:95}} INFO - [2019-10-05 04:50:44,758] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:45:44.758764+00:00
[2019-10-05 04:50:44,793] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.781 seconds
[2019-10-05 04:50:55,609] {{logging_mixin.py:95}} INFO - [2019-10-05 04:50:55,608] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:50:55,613] {{jobs.py:386}} INFO - Started process (PID=6056) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:50:55,616] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:50:55,620] {{logging_mixin.py:95}} INFO - [2019-10-05 04:50:55,620] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:50:55,793] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:50:56,013] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:50:56,019] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:50:56,029] {{logging_mixin.py:95}} INFO - [2019-10-05 04:50:56,029] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:50:56,030] {{logging_mixin.py:95}} INFO - [2019-10-05 04:50:56,030] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:45:56.030295+00:00
[2019-10-05 04:50:56,039] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.426 seconds
[2019-10-05 04:51:07,214] {{logging_mixin.py:95}} INFO - [2019-10-05 04:51:07,214] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:51:07,217] {{jobs.py:386}} INFO - Started process (PID=6060) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:51:07,453] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:51:07,454] {{logging_mixin.py:95}} INFO - [2019-10-05 04:51:07,454] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:51:07,616] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:51:10,009] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:51:10,014] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:51:10,022] {{logging_mixin.py:95}} INFO - [2019-10-05 04:51:10,022] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:51:10,023] {{logging_mixin.py:95}} INFO - [2019-10-05 04:51:10,022] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:46:10.022652+00:00
[2019-10-05 04:51:10,030] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.813 seconds
[2019-10-05 04:51:20,737] {{logging_mixin.py:95}} INFO - [2019-10-05 04:51:20,736] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:51:20,742] {{jobs.py:386}} INFO - Started process (PID=6073) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:51:21,217] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:51:21,218] {{logging_mixin.py:95}} INFO - [2019-10-05 04:51:21,218] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:51:21,367] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:51:23,795] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:51:23,802] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:51:23,812] {{logging_mixin.py:95}} INFO - [2019-10-05 04:51:23,812] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:51:23,813] {{logging_mixin.py:95}} INFO - [2019-10-05 04:51:23,813] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:46:23.813060+00:00
[2019-10-05 04:51:23,821] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.080 seconds
[2019-10-05 04:51:36,315] {{logging_mixin.py:95}} INFO - [2019-10-05 04:51:36,315] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:51:36,343] {{jobs.py:386}} INFO - Started process (PID=6077) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:51:36,836] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:51:36,836] {{logging_mixin.py:95}} INFO - [2019-10-05 04:51:36,836] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:51:37,599] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:51:40,602] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:51:40,627] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:51:40,673] {{logging_mixin.py:95}} INFO - [2019-10-05 04:51:40,673] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:51:40,674] {{logging_mixin.py:95}} INFO - [2019-10-05 04:51:40,673] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:46:40.673779+00:00
[2019-10-05 04:51:40,699] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.356 seconds
[2019-10-05 04:51:52,171] {{logging_mixin.py:95}} INFO - [2019-10-05 04:51:52,171] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:51:52,266] {{jobs.py:386}} INFO - Started process (PID=6088) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:51:52,898] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:51:52,900] {{logging_mixin.py:95}} INFO - [2019-10-05 04:51:52,900] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:51:53,429] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:52:12,279] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:52:12,293] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:52:12,306] {{logging_mixin.py:95}} INFO - [2019-10-05 04:52:12,305] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:52:12,307] {{logging_mixin.py:95}} INFO - [2019-10-05 04:52:12,306] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:47:12.306888+00:00
[2019-10-05 04:52:12,779] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 20.513 seconds
[2019-10-05 04:52:24,306] {{logging_mixin.py:95}} INFO - [2019-10-05 04:52:24,306] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:52:24,407] {{jobs.py:386}} INFO - Started process (PID=6092) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:52:24,931] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:52:24,934] {{logging_mixin.py:95}} INFO - [2019-10-05 04:52:24,934] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:52:27,628] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:52:41,642] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 04:53:05,945] {{logging_mixin.py:95}} INFO - [2019-10-05 04:53:05,945] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:53:06,063] {{jobs.py:386}} INFO - Started process (PID=6099) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:53:06,820] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:53:06,821] {{logging_mixin.py:95}} INFO - [2019-10-05 04:53:06,821] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:53:07,219] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:53:09,403] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:53:09,517] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:53:09,538] {{logging_mixin.py:95}} INFO - [2019-10-05 04:53:09,538] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:53:09,540] {{logging_mixin.py:95}} INFO - [2019-10-05 04:53:09,539] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:48:09.539726+00:00
[2019-10-05 04:53:09,549] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.487 seconds
[2019-10-05 04:53:21,257] {{logging_mixin.py:95}} INFO - [2019-10-05 04:53:21,256] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:53:21,261] {{jobs.py:386}} INFO - Started process (PID=6103) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:53:21,264] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:53:21,264] {{logging_mixin.py:95}} INFO - [2019-10-05 04:53:21,264] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:53:21,288] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:53:21,604] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:53:21,610] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:53:21,620] {{logging_mixin.py:95}} INFO - [2019-10-05 04:53:21,620] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:53:21,621] {{logging_mixin.py:95}} INFO - [2019-10-05 04:53:21,621] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:48:21.621218+00:00
[2019-10-05 04:53:21,629] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.368 seconds
[2019-10-05 04:53:32,573] {{logging_mixin.py:95}} INFO - [2019-10-05 04:53:32,572] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:53:32,576] {{jobs.py:386}} INFO - Started process (PID=6112) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:53:32,578] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:53:32,579] {{logging_mixin.py:95}} INFO - [2019-10-05 04:53:32,579] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:53:32,611] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:53:33,772] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:53:33,781] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:53:33,795] {{logging_mixin.py:95}} INFO - [2019-10-05 04:53:33,795] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:53:33,796] {{logging_mixin.py:95}} INFO - [2019-10-05 04:53:33,795] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:48:33.795829+00:00
[2019-10-05 04:53:33,808] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.232 seconds
[2019-10-05 04:53:45,045] {{logging_mixin.py:95}} INFO - [2019-10-05 04:53:45,045] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:53:45,049] {{jobs.py:386}} INFO - Started process (PID=6117) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:53:45,051] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:53:45,052] {{logging_mixin.py:95}} INFO - [2019-10-05 04:53:45,052] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:53:45,074] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:53:45,565] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:53:45,663] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:53:45,676] {{logging_mixin.py:95}} INFO - [2019-10-05 04:53:45,676] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:53:45,678] {{logging_mixin.py:95}} INFO - [2019-10-05 04:53:45,677] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:48:45.677270+00:00
[2019-10-05 04:53:45,685] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.636 seconds
[2019-10-05 04:53:57,210] {{logging_mixin.py:95}} INFO - [2019-10-05 04:53:57,200] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:53:57,238] {{jobs.py:386}} INFO - Started process (PID=6125) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:53:57,370] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:53:57,373] {{logging_mixin.py:95}} INFO - [2019-10-05 04:53:57,373] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:53:57,529] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:53:58,187] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:53:58,195] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:53:58,211] {{logging_mixin.py:95}} INFO - [2019-10-05 04:53:58,210] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:53:58,213] {{logging_mixin.py:95}} INFO - [2019-10-05 04:53:58,212] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:48:58.212298+00:00
[2019-10-05 04:53:58,290] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.052 seconds
[2019-10-05 04:54:09,507] {{logging_mixin.py:95}} INFO - [2019-10-05 04:54:09,506] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:54:09,514] {{jobs.py:386}} INFO - Started process (PID=6129) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:54:09,520] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:54:09,532] {{logging_mixin.py:95}} INFO - [2019-10-05 04:54:09,523] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:54:09,578] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:54:09,847] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:54:09,855] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:54:09,866] {{logging_mixin.py:95}} INFO - [2019-10-05 04:54:09,866] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:54:09,868] {{logging_mixin.py:95}} INFO - [2019-10-05 04:54:09,867] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:49:09.867544+00:00
[2019-10-05 04:54:09,879] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.365 seconds
[2019-10-05 04:54:21,267] {{logging_mixin.py:95}} INFO - [2019-10-05 04:54:21,223] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:54:21,303] {{jobs.py:386}} INFO - Started process (PID=6133) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:54:22,162] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:54:22,163] {{logging_mixin.py:95}} INFO - [2019-10-05 04:54:22,163] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:54:23,725] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:54:27,561] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:54:27,577] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:54:27,599] {{logging_mixin.py:95}} INFO - [2019-10-05 04:54:27,599] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:54:27,605] {{logging_mixin.py:95}} INFO - [2019-10-05 04:54:27,601] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:49:27.600998+00:00
[2019-10-05 04:54:27,663] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 6.360 seconds
[2019-10-05 04:54:40,210] {{logging_mixin.py:95}} INFO - [2019-10-05 04:54:40,210] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:54:40,425] {{jobs.py:386}} INFO - Started process (PID=6142) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:54:40,704] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:54:40,707] {{logging_mixin.py:95}} INFO - [2019-10-05 04:54:40,706] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:54:41,464] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:54:53,319] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:54:54,654] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:54:54,661] {{logging_mixin.py:95}} INFO - [2019-10-05 04:54:54,661] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:54:54,663] {{logging_mixin.py:95}} INFO - [2019-10-05 04:54:54,662] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:49:54.662378+00:00
[2019-10-05 04:54:55,371] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 14.946 seconds
[2019-10-05 04:55:07,776] {{logging_mixin.py:95}} INFO - [2019-10-05 04:55:07,776] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:55:07,843] {{jobs.py:386}} INFO - Started process (PID=6146) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:55:08,805] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:55:08,807] {{logging_mixin.py:95}} INFO - [2019-10-05 04:55:08,807] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:55:14,596] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:55:29,002] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:55:29,919] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:55:29,938] {{logging_mixin.py:95}} INFO - [2019-10-05 04:55:29,938] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:55:29,940] {{logging_mixin.py:95}} INFO - [2019-10-05 04:55:29,939] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:50:29.939613+00:00
[2019-10-05 04:55:31,503] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 23.661 seconds
[2019-10-05 04:55:43,732] {{logging_mixin.py:95}} INFO - [2019-10-05 04:55:43,731] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:55:43,856] {{jobs.py:386}} INFO - Started process (PID=6155) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:55:44,248] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:55:44,250] {{logging_mixin.py:95}} INFO - [2019-10-05 04:55:44,250] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:55:45,731] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:55:46,595] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:55:46,621] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:55:46,628] {{logging_mixin.py:95}} INFO - [2019-10-05 04:55:46,628] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:55:46,630] {{logging_mixin.py:95}} INFO - [2019-10-05 04:55:46,629] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:50:46.629447+00:00
[2019-10-05 04:55:46,636] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.780 seconds
[2019-10-05 04:55:57,639] {{logging_mixin.py:95}} INFO - [2019-10-05 04:55:57,638] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:55:57,643] {{jobs.py:386}} INFO - Started process (PID=6159) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:55:57,650] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:55:57,652] {{logging_mixin.py:95}} INFO - [2019-10-05 04:55:57,652] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:55:57,701] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:55:57,851] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:55:57,857] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:55:57,867] {{logging_mixin.py:95}} INFO - [2019-10-05 04:55:57,867] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:55:57,869] {{logging_mixin.py:95}} INFO - [2019-10-05 04:55:57,868] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:50:57.868680+00:00
[2019-10-05 04:55:57,877] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.234 seconds
[2019-10-05 04:56:09,188] {{logging_mixin.py:95}} INFO - [2019-10-05 04:56:09,188] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:56:09,197] {{jobs.py:386}} INFO - Started process (PID=6163) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:56:09,202] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:56:09,203] {{logging_mixin.py:95}} INFO - [2019-10-05 04:56:09,203] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:56:09,326] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:56:09,972] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:56:09,983] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:56:10,008] {{logging_mixin.py:95}} INFO - [2019-10-05 04:56:10,008] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:56:10,010] {{logging_mixin.py:95}} INFO - [2019-10-05 04:56:10,009] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:51:10.009802+00:00
[2019-10-05 04:56:10,030] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.833 seconds
[2019-10-05 04:56:20,599] {{logging_mixin.py:95}} INFO - [2019-10-05 04:56:20,599] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:56:20,709] {{jobs.py:386}} INFO - Started process (PID=6172) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:56:20,714] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:56:20,716] {{logging_mixin.py:95}} INFO - [2019-10-05 04:56:20,716] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:56:20,749] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:56:21,018] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:56:21,026] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:56:21,034] {{logging_mixin.py:95}} INFO - [2019-10-05 04:56:21,034] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:56:21,036] {{logging_mixin.py:95}} INFO - [2019-10-05 04:56:21,035] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:51:21.035373+00:00
[2019-10-05 04:56:21,391] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.682 seconds
[2019-10-05 04:56:33,300] {{logging_mixin.py:95}} INFO - [2019-10-05 04:56:33,300] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:56:33,326] {{jobs.py:386}} INFO - Started process (PID=6177) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:56:33,329] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:56:33,329] {{logging_mixin.py:95}} INFO - [2019-10-05 04:56:33,329] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:56:33,379] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:56:33,615] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:56:33,620] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:56:33,630] {{logging_mixin.py:95}} INFO - [2019-10-05 04:56:33,630] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:56:33,630] {{logging_mixin.py:95}} INFO - [2019-10-05 04:56:33,630] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:51:33.630315+00:00
[2019-10-05 04:56:33,640] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.314 seconds
[2019-10-05 04:56:44,661] {{logging_mixin.py:95}} INFO - [2019-10-05 04:56:44,661] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:56:44,665] {{jobs.py:386}} INFO - Started process (PID=6180) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:56:44,669] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:56:44,670] {{logging_mixin.py:95}} INFO - [2019-10-05 04:56:44,670] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:56:44,696] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:56:44,846] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:56:44,852] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:56:44,861] {{logging_mixin.py:95}} INFO - [2019-10-05 04:56:44,861] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:56:44,862] {{logging_mixin.py:95}} INFO - [2019-10-05 04:56:44,862] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:51:44.862034+00:00
[2019-10-05 04:56:44,870] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.205 seconds
[2019-10-05 04:56:56,020] {{logging_mixin.py:95}} INFO - [2019-10-05 04:56:56,019] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:56:56,024] {{jobs.py:386}} INFO - Started process (PID=6193) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:56:56,027] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:56:56,031] {{logging_mixin.py:95}} INFO - [2019-10-05 04:56:56,031] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:56:56,058] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:56:56,205] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:56:56,211] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:56:56,220] {{logging_mixin.py:95}} INFO - [2019-10-05 04:56:56,220] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:56:56,221] {{logging_mixin.py:95}} INFO - [2019-10-05 04:56:56,221] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:51:56.221329+00:00
[2019-10-05 04:56:56,229] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.206 seconds
[2019-10-05 04:57:07,741] {{logging_mixin.py:95}} INFO - [2019-10-05 04:57:07,740] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:57:07,861] {{jobs.py:386}} INFO - Started process (PID=6197) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:57:08,078] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:57:08,080] {{logging_mixin.py:95}} INFO - [2019-10-05 04:57:08,080] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:57:08,502] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:57:09,481] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:57:09,487] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:57:09,495] {{logging_mixin.py:95}} INFO - [2019-10-05 04:57:09,495] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:57:09,496] {{logging_mixin.py:95}} INFO - [2019-10-05 04:57:09,496] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:52:09.495988+00:00
[2019-10-05 04:57:09,503] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.642 seconds
[2019-10-05 04:57:21,903] {{logging_mixin.py:95}} INFO - [2019-10-05 04:57:21,804] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:57:22,145] {{jobs.py:386}} INFO - Started process (PID=6201) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:57:23,008] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:57:23,009] {{logging_mixin.py:95}} INFO - [2019-10-05 04:57:23,009] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:57:24,768] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:57:27,388] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:57:27,466] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:57:27,474] {{logging_mixin.py:95}} INFO - [2019-10-05 04:57:27,474] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:57:27,475] {{logging_mixin.py:95}} INFO - [2019-10-05 04:57:27,475] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:52:27.475376+00:00
[2019-10-05 04:57:27,521] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.375 seconds
[2019-10-05 04:57:41,842] {{logging_mixin.py:95}} INFO - [2019-10-05 04:57:41,822] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:57:42,018] {{jobs.py:386}} INFO - Started process (PID=6210) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:57:42,690] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:57:42,691] {{logging_mixin.py:95}} INFO - [2019-10-05 04:57:42,691] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:57:44,459] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:57:48,655] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:57:48,778] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:57:48,788] {{logging_mixin.py:95}} INFO - [2019-10-05 04:57:48,788] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:57:48,789] {{logging_mixin.py:95}} INFO - [2019-10-05 04:57:48,788] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:52:48.788961+00:00
[2019-10-05 04:57:48,806] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 6.788 seconds
[2019-10-05 04:57:59,968] {{logging_mixin.py:95}} INFO - [2019-10-05 04:57:59,942] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:58:00,075] {{jobs.py:386}} INFO - Started process (PID=6214) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:58:00,464] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:58:00,466] {{logging_mixin.py:95}} INFO - [2019-10-05 04:58:00,466] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:58:01,031] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:58:15,896] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 04:58:37,416] {{logging_mixin.py:95}} INFO - [2019-10-05 04:58:37,293] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:58:37,524] {{jobs.py:386}} INFO - Started process (PID=6221) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:58:37,973] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:58:37,975] {{logging_mixin.py:95}} INFO - [2019-10-05 04:58:37,975] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:58:40,735] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:58:53,790] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:58:54,193] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:58:54,320] {{logging_mixin.py:95}} INFO - [2019-10-05 04:58:54,320] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:58:54,322] {{logging_mixin.py:95}} INFO - [2019-10-05 04:58:54,321] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:53:54.321175+00:00
[2019-10-05 04:58:55,076] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 17.552 seconds
[2019-10-05 04:59:07,148] {{logging_mixin.py:95}} INFO - [2019-10-05 04:59:07,148] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:59:07,299] {{jobs.py:386}} INFO - Started process (PID=6225) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:59:08,170] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:59:08,171] {{logging_mixin.py:95}} INFO - [2019-10-05 04:59:08,171] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:59:08,926] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:59:10,290] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:59:10,295] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:59:10,305] {{logging_mixin.py:95}} INFO - [2019-10-05 04:59:10,305] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:59:10,306] {{logging_mixin.py:95}} INFO - [2019-10-05 04:59:10,306] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:54:10.306221+00:00
[2019-10-05 04:59:10,313] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.014 seconds
[2019-10-05 04:59:21,263] {{logging_mixin.py:95}} INFO - [2019-10-05 04:59:21,263] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:59:21,273] {{jobs.py:386}} INFO - Started process (PID=6229) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:59:21,279] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:59:21,281] {{logging_mixin.py:95}} INFO - [2019-10-05 04:59:21,281] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:59:21,310] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:59:21,666] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:59:21,673] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:59:21,683] {{logging_mixin.py:95}} INFO - [2019-10-05 04:59:21,683] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:59:21,685] {{logging_mixin.py:95}} INFO - [2019-10-05 04:59:21,684] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:54:21.684825+00:00
[2019-10-05 04:59:21,693] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.420 seconds
[2019-10-05 04:59:33,032] {{logging_mixin.py:95}} INFO - [2019-10-05 04:59:33,032] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:59:33,080] {{jobs.py:386}} INFO - Started process (PID=6233) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:59:33,477] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:59:33,478] {{logging_mixin.py:95}} INFO - [2019-10-05 04:59:33,478] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:59:34,052] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:59:36,098] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:59:36,115] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:59:36,124] {{logging_mixin.py:95}} INFO - [2019-10-05 04:59:36,124] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:59:36,125] {{logging_mixin.py:95}} INFO - [2019-10-05 04:59:36,125] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:54:36.124976+00:00
[2019-10-05 04:59:36,133] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.053 seconds
[2019-10-05 04:59:47,675] {{logging_mixin.py:95}} INFO - [2019-10-05 04:59:47,675] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 04:59:47,679] {{jobs.py:386}} INFO - Started process (PID=6245) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:59:47,682] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 04:59:47,685] {{logging_mixin.py:95}} INFO - [2019-10-05 04:59:47,685] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:59:47,706] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 04:59:48,759] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 04:59:48,764] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 04:59:48,773] {{logging_mixin.py:95}} INFO - [2019-10-05 04:59:48,773] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 04:59:48,775] {{logging_mixin.py:95}} INFO - [2019-10-05 04:59:48,774] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:54:48.774605+00:00
[2019-10-05 04:59:48,781] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.102 seconds
[2019-10-05 05:00:00,478] {{logging_mixin.py:95}} INFO - [2019-10-05 05:00:00,478] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:00:00,484] {{jobs.py:386}} INFO - Started process (PID=6249) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:00:00,489] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:00:00,491] {{logging_mixin.py:95}} INFO - [2019-10-05 05:00:00,491] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:00:00,525] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:00:00,824] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:00:00,831] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:00:00,846] {{logging_mixin.py:95}} INFO - [2019-10-05 05:00:00,846] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:00:00,847] {{logging_mixin.py:95}} INFO - [2019-10-05 05:00:00,847] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:55:00.847117+00:00
[2019-10-05 05:00:00,853] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.369 seconds
[2019-10-05 05:00:11,917] {{logging_mixin.py:95}} INFO - [2019-10-05 05:00:11,916] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:00:11,921] {{jobs.py:386}} INFO - Started process (PID=6253) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:00:11,923] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:00:11,924] {{logging_mixin.py:95}} INFO - [2019-10-05 05:00:11,924] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:00:11,944] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:00:12,157] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:00:12,162] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:00:12,171] {{logging_mixin.py:95}} INFO - [2019-10-05 05:00:12,171] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:00:12,172] {{logging_mixin.py:95}} INFO - [2019-10-05 05:00:12,171] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:55:12.171694+00:00
[2019-10-05 05:00:12,179] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.259 seconds
[2019-10-05 05:00:23,885] {{logging_mixin.py:95}} INFO - [2019-10-05 05:00:23,885] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:00:23,895] {{jobs.py:386}} INFO - Started process (PID=6261) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:00:23,898] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:00:23,899] {{logging_mixin.py:95}} INFO - [2019-10-05 05:00:23,899] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:00:23,919] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:00:26,689] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:00:26,695] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:00:26,705] {{logging_mixin.py:95}} INFO - [2019-10-05 05:00:26,704] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:00:26,706] {{logging_mixin.py:95}} INFO - [2019-10-05 05:00:26,705] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:55:26.705736+00:00
[2019-10-05 05:00:26,714] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.819 seconds
[2019-10-05 05:00:38,726] {{logging_mixin.py:95}} INFO - [2019-10-05 05:00:38,707] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:00:38,767] {{jobs.py:386}} INFO - Started process (PID=6264) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:00:38,942] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:00:38,944] {{logging_mixin.py:95}} INFO - [2019-10-05 05:00:38,944] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:00:39,805] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:00:50,103] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:00:50,138] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:00:50,164] {{logging_mixin.py:95}} INFO - [2019-10-05 05:00:50,164] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:00:50,167] {{logging_mixin.py:95}} INFO - [2019-10-05 05:00:50,166] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:55:50.166446+00:00
[2019-10-05 05:00:50,739] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 11.971 seconds
[2019-10-05 05:01:02,291] {{logging_mixin.py:95}} INFO - [2019-10-05 05:01:02,291] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:01:02,325] {{jobs.py:386}} INFO - Started process (PID=6268) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:01:03,190] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:01:03,190] {{logging_mixin.py:95}} INFO - [2019-10-05 05:01:03,190] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:01:05,245] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:01:11,222] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:01:11,337] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:01:11,360] {{logging_mixin.py:95}} INFO - [2019-10-05 05:01:11,360] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:01:11,361] {{logging_mixin.py:95}} INFO - [2019-10-05 05:01:11,360] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:56:11.360786+00:00
[2019-10-05 05:01:12,188] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 9.863 seconds
[2019-10-05 05:01:24,377] {{logging_mixin.py:95}} INFO - [2019-10-05 05:01:24,376] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:01:24,558] {{jobs.py:386}} INFO - Started process (PID=6277) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:01:25,414] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:01:25,415] {{logging_mixin.py:95}} INFO - [2019-10-05 05:01:25,415] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:01:29,070] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:01:44,652] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:01:45,294] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:01:45,301] {{logging_mixin.py:95}} INFO - [2019-10-05 05:01:45,301] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:01:45,302] {{logging_mixin.py:95}} INFO - [2019-10-05 05:01:45,302] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:56:45.302178+00:00
[2019-10-05 05:01:46,896] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 22.338 seconds
[2019-10-05 05:01:59,832] {{logging_mixin.py:95}} INFO - [2019-10-05 05:01:59,796] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:02:00,029] {{jobs.py:386}} INFO - Started process (PID=6281) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:02:00,543] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:02:00,544] {{logging_mixin.py:95}} INFO - [2019-10-05 05:02:00,543] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:02:02,935] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:02:27,258] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 05:02:53,086] {{logging_mixin.py:95}} INFO - [2019-10-05 05:02:53,053] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:02:53,155] {{jobs.py:386}} INFO - Started process (PID=6283) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:02:54,443] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:02:54,445] {{logging_mixin.py:95}} INFO - [2019-10-05 05:02:54,444] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:02:57,903] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:03:10,382] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:03:10,530] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:03:10,546] {{logging_mixin.py:95}} INFO - [2019-10-05 05:03:10,545] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:03:10,548] {{logging_mixin.py:95}} INFO - [2019-10-05 05:03:10,547] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:58:10.546997+00:00
[2019-10-05 05:03:11,746] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 18.590 seconds
[2019-10-05 05:03:23,395] {{logging_mixin.py:95}} INFO - [2019-10-05 05:03:23,394] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:03:23,402] {{jobs.py:386}} INFO - Started process (PID=6287) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:03:23,901] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:03:23,902] {{logging_mixin.py:95}} INFO - [2019-10-05 05:03:23,902] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:03:25,145] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:03:25,588] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:03:25,594] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:03:25,601] {{logging_mixin.py:95}} INFO - [2019-10-05 05:03:25,601] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:03:25,602] {{logging_mixin.py:95}} INFO - [2019-10-05 05:03:25,601] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:58:25.601532+00:00
[2019-10-05 05:03:25,614] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.212 seconds
[2019-10-05 05:03:36,515] {{logging_mixin.py:95}} INFO - [2019-10-05 05:03:36,515] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:03:36,519] {{jobs.py:386}} INFO - Started process (PID=6298) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:03:36,588] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:03:36,590] {{logging_mixin.py:95}} INFO - [2019-10-05 05:03:36,590] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:03:36,709] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:03:36,951] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:03:36,957] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:03:36,967] {{logging_mixin.py:95}} INFO - [2019-10-05 05:03:36,967] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:03:36,968] {{logging_mixin.py:95}} INFO - [2019-10-05 05:03:36,968] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:58:36.968382+00:00
[2019-10-05 05:03:37,157] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.638 seconds
[2019-10-05 05:03:48,145] {{logging_mixin.py:95}} INFO - [2019-10-05 05:03:48,145] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:03:48,243] {{jobs.py:386}} INFO - Started process (PID=6302) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:03:48,449] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:03:48,450] {{logging_mixin.py:95}} INFO - [2019-10-05 05:03:48,450] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:03:48,511] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:03:49,272] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:03:49,358] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:03:49,366] {{logging_mixin.py:95}} INFO - [2019-10-05 05:03:49,366] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:03:49,367] {{logging_mixin.py:95}} INFO - [2019-10-05 05:03:49,367] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:58:49.367245+00:00
[2019-10-05 05:03:49,374] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.131 seconds
[2019-10-05 05:04:00,552] {{logging_mixin.py:95}} INFO - [2019-10-05 05:04:00,551] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:04:00,555] {{jobs.py:386}} INFO - Started process (PID=6312) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:04:01,069] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:04:01,071] {{logging_mixin.py:95}} INFO - [2019-10-05 05:04:01,071] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:04:01,234] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:04:04,153] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:04:04,261] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:04:04,268] {{logging_mixin.py:95}} INFO - [2019-10-05 05:04:04,268] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:04:04,269] {{logging_mixin.py:95}} INFO - [2019-10-05 05:04:04,268] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:59:04.268494+00:00
[2019-10-05 05:04:04,281] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.725 seconds
[2019-10-05 05:04:15,565] {{logging_mixin.py:95}} INFO - [2019-10-05 05:04:15,565] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:04:15,700] {{jobs.py:386}} INFO - Started process (PID=6316) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:04:16,066] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:04:16,067] {{logging_mixin.py:95}} INFO - [2019-10-05 05:04:16,067] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:04:16,520] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:04:17,724] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:04:17,738] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:04:17,753] {{logging_mixin.py:95}} INFO - [2019-10-05 05:04:17,753] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:04:17,754] {{logging_mixin.py:95}} INFO - [2019-10-05 05:04:17,754] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:59:17.754266+00:00
[2019-10-05 05:04:17,761] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.061 seconds
[2019-10-05 05:04:28,536] {{logging_mixin.py:95}} INFO - [2019-10-05 05:04:28,536] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:04:28,539] {{jobs.py:386}} INFO - Started process (PID=6320) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:04:28,543] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:04:28,549] {{logging_mixin.py:95}} INFO - [2019-10-05 05:04:28,548] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:04:28,577] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:04:28,787] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:04:28,793] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:04:28,803] {{logging_mixin.py:95}} INFO - [2019-10-05 05:04:28,802] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:04:28,804] {{logging_mixin.py:95}} INFO - [2019-10-05 05:04:28,804] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:59:28.803986+00:00
[2019-10-05 05:04:28,996] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.457 seconds
[2019-10-05 05:04:40,840] {{logging_mixin.py:95}} INFO - [2019-10-05 05:04:40,839] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:04:40,926] {{jobs.py:386}} INFO - Started process (PID=6335) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:04:41,125] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:04:41,126] {{logging_mixin.py:95}} INFO - [2019-10-05 05:04:41,126] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:04:42,235] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:04:46,171] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:04:46,273] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:04:46,284] {{logging_mixin.py:95}} INFO - [2019-10-05 05:04:46,284] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:04:46,285] {{logging_mixin.py:95}} INFO - [2019-10-05 05:04:46,285] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 04:59:46.285093+00:00
[2019-10-05 05:04:46,293] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.367 seconds
[2019-10-05 05:04:57,528] {{logging_mixin.py:95}} INFO - [2019-10-05 05:04:57,527] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:04:57,601] {{jobs.py:386}} INFO - Started process (PID=6339) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:04:57,872] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:04:57,886] {{logging_mixin.py:95}} INFO - [2019-10-05 05:04:57,886] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:04:58,286] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:05:00,301] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:05:00,376] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:05:00,476] {{logging_mixin.py:95}} INFO - [2019-10-05 05:05:00,476] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:05:00,478] {{logging_mixin.py:95}} INFO - [2019-10-05 05:05:00,477] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:00:00.477817+00:00
[2019-10-05 05:05:00,657] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.055 seconds
[2019-10-05 05:05:13,198] {{logging_mixin.py:95}} INFO - [2019-10-05 05:05:13,197] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:05:13,489] {{jobs.py:386}} INFO - Started process (PID=6343) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:05:14,647] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:05:14,648] {{logging_mixin.py:95}} INFO - [2019-10-05 05:05:14,648] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:05:18,786] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:05:26,564] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:05:26,749] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:05:26,756] {{logging_mixin.py:95}} INFO - [2019-10-05 05:05:26,756] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:05:26,765] {{logging_mixin.py:95}} INFO - [2019-10-05 05:05:26,764] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:00:26.764722+00:00
[2019-10-05 05:05:26,885] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 13.396 seconds
[2019-10-05 05:05:42,014] {{logging_mixin.py:95}} INFO - [2019-10-05 05:05:41,803] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:05:42,147] {{jobs.py:386}} INFO - Started process (PID=6352) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:05:44,284] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:05:44,284] {{logging_mixin.py:95}} INFO - [2019-10-05 05:05:44,284] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:05:45,582] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:05:54,471] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:05:54,479] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:05:54,493] {{logging_mixin.py:95}} INFO - [2019-10-05 05:05:54,493] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:05:54,494] {{logging_mixin.py:95}} INFO - [2019-10-05 05:05:54,493] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:00:54.493689+00:00
[2019-10-05 05:05:56,223] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 14.077 seconds
[2019-10-05 05:06:09,570] {{logging_mixin.py:95}} INFO - [2019-10-05 05:06:09,570] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:06:09,670] {{jobs.py:386}} INFO - Started process (PID=6356) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:06:09,851] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:06:09,852] {{logging_mixin.py:95}} INFO - [2019-10-05 05:06:09,852] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:06:11,225] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:06:28,268] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:06:29,180] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:06:29,191] {{logging_mixin.py:95}} INFO - [2019-10-05 05:06:29,191] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:06:29,192] {{logging_mixin.py:95}} INFO - [2019-10-05 05:06:29,192] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:01:29.192316+00:00
[2019-10-05 05:06:30,587] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 20.917 seconds
[2019-10-05 05:06:42,162] {{logging_mixin.py:95}} INFO - [2019-10-05 05:06:42,162] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:06:42,212] {{jobs.py:386}} INFO - Started process (PID=6365) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:06:43,116] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:06:43,118] {{logging_mixin.py:95}} INFO - [2019-10-05 05:06:43,118] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:06:44,465] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:06:47,491] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:06:47,629] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:06:47,636] {{logging_mixin.py:95}} INFO - [2019-10-05 05:06:47,636] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:06:47,638] {{logging_mixin.py:95}} INFO - [2019-10-05 05:06:47,637] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:01:47.637573+00:00
[2019-10-05 05:06:47,644] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.432 seconds
[2019-10-05 05:06:58,044] {{logging_mixin.py:95}} INFO - [2019-10-05 05:06:58,044] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:06:58,047] {{jobs.py:386}} INFO - Started process (PID=6369) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:06:58,049] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:06:58,049] {{logging_mixin.py:95}} INFO - [2019-10-05 05:06:58,049] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:06:58,065] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:06:58,192] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:06:58,196] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:06:58,203] {{logging_mixin.py:95}} INFO - [2019-10-05 05:06:58,202] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:06:58,203] {{logging_mixin.py:95}} INFO - [2019-10-05 05:06:58,203] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:01:58.203219+00:00
[2019-10-05 05:06:58,276] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.229 seconds
[2019-10-05 05:07:09,475] {{logging_mixin.py:95}} INFO - [2019-10-05 05:07:09,474] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:07:09,478] {{jobs.py:386}} INFO - Started process (PID=6373) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:07:09,607] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:07:09,608] {{logging_mixin.py:95}} INFO - [2019-10-05 05:07:09,608] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:07:10,139] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:07:12,193] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:07:12,277] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:07:12,287] {{logging_mixin.py:95}} INFO - [2019-10-05 05:07:12,286] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:07:12,288] {{logging_mixin.py:95}} INFO - [2019-10-05 05:07:12,287] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:02:12.287935+00:00
[2019-10-05 05:07:12,296] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.818 seconds
[2019-10-05 05:07:24,234] {{logging_mixin.py:95}} INFO - [2019-10-05 05:07:23,947] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:07:24,301] {{jobs.py:386}} INFO - Started process (PID=6383) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:07:24,766] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:07:24,768] {{logging_mixin.py:95}} INFO - [2019-10-05 05:07:24,768] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:07:26,211] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:07:30,937] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:07:31,024] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:07:31,073] {{logging_mixin.py:95}} INFO - [2019-10-05 05:07:31,072] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:07:31,074] {{logging_mixin.py:95}} INFO - [2019-10-05 05:07:31,073] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:02:31.073886+00:00
[2019-10-05 05:07:31,128] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 6.827 seconds
[2019-10-05 05:07:42,902] {{logging_mixin.py:95}} INFO - [2019-10-05 05:07:42,902] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:07:42,908] {{jobs.py:386}} INFO - Started process (PID=6387) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:07:42,912] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:07:42,913] {{logging_mixin.py:95}} INFO - [2019-10-05 05:07:42,913] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:07:42,969] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:07:43,336] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:07:43,342] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:07:43,354] {{logging_mixin.py:95}} INFO - [2019-10-05 05:07:43,354] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:07:43,356] {{logging_mixin.py:95}} INFO - [2019-10-05 05:07:43,355] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:02:43.355616+00:00
[2019-10-05 05:07:43,365] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.457 seconds
[2019-10-05 05:07:56,392] {{logging_mixin.py:95}} INFO - [2019-10-05 05:07:56,326] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:07:56,408] {{jobs.py:386}} INFO - Started process (PID=6396) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:07:57,238] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:07:57,239] {{logging_mixin.py:95}} INFO - [2019-10-05 05:07:57,239] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:07:58,415] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:08:00,993] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:08:01,076] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:08:01,087] {{logging_mixin.py:95}} INFO - [2019-10-05 05:08:01,086] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:08:01,088] {{logging_mixin.py:95}} INFO - [2019-10-05 05:08:01,087] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:03:01.087842+00:00
[2019-10-05 05:08:01,097] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.689 seconds
[2019-10-05 05:08:12,390] {{logging_mixin.py:95}} INFO - [2019-10-05 05:08:12,390] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:08:12,515] {{jobs.py:386}} INFO - Started process (PID=6400) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:08:12,576] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:08:12,582] {{logging_mixin.py:95}} INFO - [2019-10-05 05:08:12,582] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:08:13,480] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:08:15,268] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:08:15,363] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:08:15,373] {{logging_mixin.py:95}} INFO - [2019-10-05 05:08:15,372] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:08:15,376] {{logging_mixin.py:95}} INFO - [2019-10-05 05:08:15,373] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:03:15.373836+00:00
[2019-10-05 05:08:15,451] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.936 seconds
[2019-10-05 05:08:32,572] {{logging_mixin.py:95}} INFO - [2019-10-05 05:08:32,258] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:08:32,789] {{jobs.py:386}} INFO - Started process (PID=6404) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:08:34,113] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:08:34,116] {{logging_mixin.py:95}} INFO - [2019-10-05 05:08:34,116] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:08:35,778] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:08:58,336] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:09:00,126] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:09:00,154] {{logging_mixin.py:95}} INFO - [2019-10-05 05:09:00,153] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:09:00,157] {{logging_mixin.py:95}} INFO - [2019-10-05 05:09:00,155] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:04:00.155847+00:00
[2019-10-05 05:09:01,088] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 28.300 seconds
[2019-10-05 05:09:13,283] {{logging_mixin.py:95}} INFO - [2019-10-05 05:09:13,283] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:09:13,702] {{jobs.py:386}} INFO - Started process (PID=6415) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:09:14,559] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:09:14,562] {{logging_mixin.py:95}} INFO - [2019-10-05 05:09:14,562] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:09:16,501] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:09:39,448] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 05:09:59,768] {{logging_mixin.py:95}} INFO - [2019-10-05 05:09:59,679] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:09:59,810] {{jobs.py:386}} INFO - Started process (PID=6417) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:10:00,264] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:10:00,266] {{logging_mixin.py:95}} INFO - [2019-10-05 05:10:00,266] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:10:02,418] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:10:20,345] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 05:10:38,766] {{logging_mixin.py:95}} INFO - [2019-10-05 05:10:38,679] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:10:38,818] {{jobs.py:386}} INFO - Started process (PID=6419) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:10:39,848] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:10:39,849] {{logging_mixin.py:95}} INFO - [2019-10-05 05:10:39,849] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:10:41,792] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:11:04,783] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 05:11:28,259] {{logging_mixin.py:95}} INFO - [2019-10-05 05:11:28,139] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:11:28,865] {{jobs.py:386}} INFO - Started process (PID=6426) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:11:29,431] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:11:29,435] {{logging_mixin.py:95}} INFO - [2019-10-05 05:11:29,435] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:11:31,011] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:11:53,446] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 05:12:34,636] {{logging_mixin.py:95}} INFO - [2019-10-05 05:12:34,636] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:12:35,027] {{jobs.py:386}} INFO - Started process (PID=6428) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:12:36,373] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:12:36,374] {{logging_mixin.py:95}} INFO - [2019-10-05 05:12:36,374] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:12:37,874] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:12:39,885] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:12:40,005] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:12:40,014] {{logging_mixin.py:95}} INFO - [2019-10-05 05:12:40,013] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:12:40,015] {{logging_mixin.py:95}} INFO - [2019-10-05 05:12:40,014] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:07:40.014758+00:00
[2019-10-05 05:12:40,097] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.070 seconds
[2019-10-05 05:12:50,900] {{logging_mixin.py:95}} INFO - [2019-10-05 05:12:50,899] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:12:50,904] {{jobs.py:386}} INFO - Started process (PID=6432) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:12:50,909] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:12:50,910] {{logging_mixin.py:95}} INFO - [2019-10-05 05:12:50,910] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:12:50,954] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:12:51,150] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:12:51,166] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:12:51,181] {{logging_mixin.py:95}} INFO - [2019-10-05 05:12:51,181] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:12:51,183] {{logging_mixin.py:95}} INFO - [2019-10-05 05:12:51,182] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:07:51.182388+00:00
[2019-10-05 05:12:51,191] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.286 seconds
[2019-10-05 05:13:02,221] {{logging_mixin.py:95}} INFO - [2019-10-05 05:13:02,221] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:13:02,227] {{jobs.py:386}} INFO - Started process (PID=6436) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:13:02,230] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:13:02,232] {{logging_mixin.py:95}} INFO - [2019-10-05 05:13:02,231] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:13:02,278] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:13:02,511] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:13:02,516] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:13:02,525] {{logging_mixin.py:95}} INFO - [2019-10-05 05:13:02,524] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:13:02,525] {{logging_mixin.py:95}} INFO - [2019-10-05 05:13:02,525] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:08:02.525246+00:00
[2019-10-05 05:13:02,533] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.306 seconds
[2019-10-05 05:13:13,676] {{logging_mixin.py:95}} INFO - [2019-10-05 05:13:13,676] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:13:13,679] {{jobs.py:386}} INFO - Started process (PID=6445) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:13:13,685] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:13:13,686] {{logging_mixin.py:95}} INFO - [2019-10-05 05:13:13,686] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:13:13,712] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:13:14,540] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:13:14,550] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:13:14,565] {{logging_mixin.py:95}} INFO - [2019-10-05 05:13:14,564] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:13:14,567] {{logging_mixin.py:95}} INFO - [2019-10-05 05:13:14,566] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:08:14.566306+00:00
[2019-10-05 05:13:14,579] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.900 seconds
[2019-10-05 05:13:25,816] {{logging_mixin.py:95}} INFO - [2019-10-05 05:13:25,816] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:13:26,003] {{jobs.py:386}} INFO - Started process (PID=6449) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:13:26,349] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:13:26,350] {{logging_mixin.py:95}} INFO - [2019-10-05 05:13:26,350] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:13:28,491] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:13:35,435] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:13:35,536] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:13:35,546] {{logging_mixin.py:95}} INFO - [2019-10-05 05:13:35,546] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:13:35,547] {{logging_mixin.py:95}} INFO - [2019-10-05 05:13:35,546] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:08:35.546915+00:00
[2019-10-05 05:13:35,554] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 9.552 seconds
[2019-10-05 05:13:46,518] {{logging_mixin.py:95}} INFO - [2019-10-05 05:13:46,518] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:13:46,527] {{jobs.py:386}} INFO - Started process (PID=6458) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:13:46,530] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:13:46,531] {{logging_mixin.py:95}} INFO - [2019-10-05 05:13:46,531] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:13:46,564] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:13:46,980] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:13:46,996] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:13:47,008] {{logging_mixin.py:95}} INFO - [2019-10-05 05:13:47,008] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:13:47,009] {{logging_mixin.py:95}} INFO - [2019-10-05 05:13:47,008] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:08:47.008593+00:00
[2019-10-05 05:13:47,021] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.494 seconds
[2019-10-05 05:13:58,396] {{logging_mixin.py:95}} INFO - [2019-10-05 05:13:58,396] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:13:58,626] {{jobs.py:386}} INFO - Started process (PID=6462) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:13:58,672] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:13:58,679] {{logging_mixin.py:95}} INFO - [2019-10-05 05:13:58,678] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:13:59,904] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:14:10,670] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:14:11,103] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:14:11,204] {{logging_mixin.py:95}} INFO - [2019-10-05 05:14:11,204] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:14:11,206] {{logging_mixin.py:95}} INFO - [2019-10-05 05:14:11,205] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:09:11.205217+00:00
[2019-10-05 05:14:11,933] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 13.307 seconds
[2019-10-05 05:14:23,163] {{logging_mixin.py:95}} INFO - [2019-10-05 05:14:23,163] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:14:23,192] {{jobs.py:386}} INFO - Started process (PID=6466) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:14:24,136] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:14:24,137] {{logging_mixin.py:95}} INFO - [2019-10-05 05:14:24,137] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:14:26,774] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:14:30,054] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:14:30,084] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:14:30,094] {{logging_mixin.py:95}} INFO - [2019-10-05 05:14:30,093] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:14:30,095] {{logging_mixin.py:95}} INFO - [2019-10-05 05:14:30,094] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:09:30.094799+00:00
[2019-10-05 05:14:30,103] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 6.911 seconds
[2019-10-05 05:14:41,449] {{logging_mixin.py:95}} INFO - [2019-10-05 05:14:41,401] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:14:41,489] {{jobs.py:386}} INFO - Started process (PID=6475) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:14:42,000] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:14:42,008] {{logging_mixin.py:95}} INFO - [2019-10-05 05:14:42,008] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:14:43,877] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:14:58,056] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:14:58,366] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:14:58,377] {{logging_mixin.py:95}} INFO - [2019-10-05 05:14:58,376] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:14:58,378] {{logging_mixin.py:95}} INFO - [2019-10-05 05:14:58,377] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:09:58.377714+00:00
[2019-10-05 05:15:00,469] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 18.979 seconds
[2019-10-05 05:15:12,287] {{logging_mixin.py:95}} INFO - [2019-10-05 05:15:12,286] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:15:12,373] {{jobs.py:386}} INFO - Started process (PID=6479) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:15:12,902] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:15:12,904] {{logging_mixin.py:95}} INFO - [2019-10-05 05:15:12,904] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:15:13,285] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:15:13,742] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:15:13,748] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:15:13,757] {{logging_mixin.py:95}} INFO - [2019-10-05 05:15:13,757] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:15:13,758] {{logging_mixin.py:95}} INFO - [2019-10-05 05:15:13,758] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:10:13.758313+00:00
[2019-10-05 05:15:13,767] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.394 seconds
[2019-10-05 05:15:24,576] {{logging_mixin.py:95}} INFO - [2019-10-05 05:15:24,576] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:15:24,596] {{jobs.py:386}} INFO - Started process (PID=6491) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:15:24,602] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:15:24,603] {{logging_mixin.py:95}} INFO - [2019-10-05 05:15:24,603] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:15:24,644] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:15:24,959] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:15:24,968] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:15:24,983] {{logging_mixin.py:95}} INFO - [2019-10-05 05:15:24,983] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:15:24,985] {{logging_mixin.py:95}} INFO - [2019-10-05 05:15:24,984] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:10:24.984353+00:00
[2019-10-05 05:15:24,999] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.403 seconds
[2019-10-05 05:15:36,014] {{logging_mixin.py:95}} INFO - [2019-10-05 05:15:36,014] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:15:36,017] {{jobs.py:386}} INFO - Started process (PID=6495) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:15:36,020] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:15:36,021] {{logging_mixin.py:95}} INFO - [2019-10-05 05:15:36,021] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:15:36,043] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:15:36,683] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:15:36,690] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:15:36,698] {{logging_mixin.py:95}} INFO - [2019-10-05 05:15:36,698] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:15:36,699] {{logging_mixin.py:95}} INFO - [2019-10-05 05:15:36,698] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:10:36.698874+00:00
[2019-10-05 05:15:36,705] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.688 seconds
[2019-10-05 05:15:47,819] {{logging_mixin.py:95}} INFO - [2019-10-05 05:15:47,819] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:15:47,823] {{jobs.py:386}} INFO - Started process (PID=6499) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:15:48,070] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:15:48,071] {{logging_mixin.py:95}} INFO - [2019-10-05 05:15:48,071] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:15:48,920] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:15:49,576] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:15:49,583] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:15:49,601] {{logging_mixin.py:95}} INFO - [2019-10-05 05:15:49,601] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:15:49,602] {{logging_mixin.py:95}} INFO - [2019-10-05 05:15:49,602] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:10:49.602119+00:00
[2019-10-05 05:15:49,723] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.900 seconds
[2019-10-05 05:16:01,360] {{logging_mixin.py:95}} INFO - [2019-10-05 05:16:01,360] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:16:01,365] {{jobs.py:386}} INFO - Started process (PID=6508) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:16:01,367] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:16:01,369] {{logging_mixin.py:95}} INFO - [2019-10-05 05:16:01,368] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:16:01,397] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:16:01,507] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:16:01,533] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:16:01,540] {{logging_mixin.py:95}} INFO - [2019-10-05 05:16:01,540] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:16:01,541] {{logging_mixin.py:95}} INFO - [2019-10-05 05:16:01,540] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:11:01.540896+00:00
[2019-10-05 05:16:01,548] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.184 seconds
[2019-10-05 05:16:15,204] {{logging_mixin.py:95}} INFO - [2019-10-05 05:16:15,126] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:16:15,277] {{jobs.py:386}} INFO - Started process (PID=6512) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:16:16,491] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:16:16,491] {{logging_mixin.py:95}} INFO - [2019-10-05 05:16:16,491] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:16:18,509] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:16:31,602] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:16:31,836] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:16:31,850] {{logging_mixin.py:95}} INFO - [2019-10-05 05:16:31,850] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:16:31,852] {{logging_mixin.py:95}} INFO - [2019-10-05 05:16:31,851] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:11:31.851390+00:00
[2019-10-05 05:16:32,045] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 16.768 seconds
[2019-10-05 05:16:43,829] {{logging_mixin.py:95}} INFO - [2019-10-05 05:16:43,829] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:16:43,862] {{jobs.py:386}} INFO - Started process (PID=6521) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:16:44,280] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:16:44,281] {{logging_mixin.py:95}} INFO - [2019-10-05 05:16:44,281] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:16:46,464] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:16:58,362] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:16:58,754] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:16:58,774] {{logging_mixin.py:95}} INFO - [2019-10-05 05:16:58,774] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:16:58,777] {{logging_mixin.py:95}} INFO - [2019-10-05 05:16:58,775] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:11:58.775771+00:00
[2019-10-05 05:16:59,586] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 15.724 seconds
[2019-10-05 05:17:12,091] {{logging_mixin.py:95}} INFO - [2019-10-05 05:17:12,091] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:17:12,200] {{jobs.py:386}} INFO - Started process (PID=6536) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:17:12,783] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:17:12,785] {{logging_mixin.py:95}} INFO - [2019-10-05 05:17:12,784] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:17:14,965] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:17:20,777] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:17:20,791] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:17:20,808] {{logging_mixin.py:95}} INFO - [2019-10-05 05:17:20,807] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:17:20,810] {{logging_mixin.py:95}} INFO - [2019-10-05 05:17:20,809] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:12:20.809314+00:00
[2019-10-05 05:17:20,829] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 8.629 seconds
[2019-10-05 05:17:32,050] {{logging_mixin.py:95}} INFO - [2019-10-05 05:17:32,049] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:17:32,053] {{jobs.py:386}} INFO - Started process (PID=6540) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:17:32,055] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:17:32,055] {{logging_mixin.py:95}} INFO - [2019-10-05 05:17:32,055] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:17:32,076] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:17:32,231] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:17:32,237] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:17:32,245] {{logging_mixin.py:95}} INFO - [2019-10-05 05:17:32,245] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:17:32,246] {{logging_mixin.py:95}} INFO - [2019-10-05 05:17:32,245] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:12:32.245560+00:00
[2019-10-05 05:17:32,252] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.199 seconds
[2019-10-05 05:17:43,479] {{logging_mixin.py:95}} INFO - [2019-10-05 05:17:43,479] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:17:43,485] {{jobs.py:386}} INFO - Started process (PID=6544) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:17:43,489] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:17:43,492] {{logging_mixin.py:95}} INFO - [2019-10-05 05:17:43,492] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:17:43,562] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:17:44,097] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:17:44,109] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:17:44,138] {{logging_mixin.py:95}} INFO - [2019-10-05 05:17:44,138] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:17:44,142] {{logging_mixin.py:95}} INFO - [2019-10-05 05:17:44,140] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:12:44.140542+00:00
[2019-10-05 05:17:44,160] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.676 seconds
[2019-10-05 05:17:55,221] {{logging_mixin.py:95}} INFO - [2019-10-05 05:17:55,221] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:17:55,325] {{jobs.py:386}} INFO - Started process (PID=6548) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:17:55,531] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:17:55,575] {{logging_mixin.py:95}} INFO - [2019-10-05 05:17:55,575] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:17:55,995] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:17:57,720] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:17:57,766] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:17:57,775] {{logging_mixin.py:95}} INFO - [2019-10-05 05:17:57,775] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:17:57,776] {{logging_mixin.py:95}} INFO - [2019-10-05 05:17:57,776] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:12:57.776140+00:00
[2019-10-05 05:17:57,792] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.466 seconds
[2019-10-05 05:18:08,643] {{logging_mixin.py:95}} INFO - [2019-10-05 05:18:08,643] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:18:08,647] {{jobs.py:386}} INFO - Started process (PID=6559) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:18:08,650] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:18:08,651] {{logging_mixin.py:95}} INFO - [2019-10-05 05:18:08,651] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:18:08,686] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:18:08,975] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:18:08,981] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:18:08,989] {{logging_mixin.py:95}} INFO - [2019-10-05 05:18:08,989] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:18:08,991] {{logging_mixin.py:95}} INFO - [2019-10-05 05:18:08,990] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:13:08.990476+00:00
[2019-10-05 05:18:08,997] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.350 seconds
[2019-10-05 05:18:20,171] {{logging_mixin.py:95}} INFO - [2019-10-05 05:18:20,170] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:18:20,249] {{jobs.py:386}} INFO - Started process (PID=6563) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:18:20,293] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:18:20,338] {{logging_mixin.py:95}} INFO - [2019-10-05 05:18:20,337] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:18:20,420] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:18:21,020] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:18:21,025] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:18:21,033] {{logging_mixin.py:95}} INFO - [2019-10-05 05:18:21,033] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:18:21,034] {{logging_mixin.py:95}} INFO - [2019-10-05 05:18:21,033] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:13:21.033904+00:00
[2019-10-05 05:18:21,041] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.792 seconds
[2019-10-05 05:18:32,601] {{logging_mixin.py:95}} INFO - [2019-10-05 05:18:32,601] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:18:32,688] {{jobs.py:386}} INFO - Started process (PID=6567) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:18:33,473] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:18:33,474] {{logging_mixin.py:95}} INFO - [2019-10-05 05:18:33,474] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:18:33,869] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:18:46,007] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:18:46,121] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:18:46,129] {{logging_mixin.py:95}} INFO - [2019-10-05 05:18:46,129] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:18:46,130] {{logging_mixin.py:95}} INFO - [2019-10-05 05:18:46,130] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:13:46.130103+00:00
[2019-10-05 05:18:46,137] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 13.449 seconds
[2019-10-05 05:19:01,119] {{logging_mixin.py:95}} INFO - [2019-10-05 05:19:00,766] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:19:01,544] {{jobs.py:386}} INFO - Started process (PID=6581) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:19:02,769] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:19:02,771] {{logging_mixin.py:95}} INFO - [2019-10-05 05:19:02,770] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:19:05,091] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:19:18,707] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 05:19:36,505] {{logging_mixin.py:95}} INFO - [2019-10-05 05:19:36,505] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:19:37,284] {{jobs.py:386}} INFO - Started process (PID=6583) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:19:38,796] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:19:38,797] {{logging_mixin.py:95}} INFO - [2019-10-05 05:19:38,797] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:19:41,252] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:20:04,953] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 05:20:25,214] {{logging_mixin.py:95}} INFO - [2019-10-05 05:20:25,213] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:20:25,866] {{jobs.py:386}} INFO - Started process (PID=6585) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:20:28,547] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:20:28,548] {{logging_mixin.py:95}} INFO - [2019-10-05 05:20:28,548] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:20:30,179] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:20:39,028] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:20:39,110] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:20:39,121] {{logging_mixin.py:95}} INFO - [2019-10-05 05:20:39,121] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:20:39,122] {{logging_mixin.py:95}} INFO - [2019-10-05 05:20:39,121] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:15:39.121838+00:00
[2019-10-05 05:20:39,170] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 13.304 seconds
[2019-10-05 05:20:52,632] {{logging_mixin.py:95}} INFO - [2019-10-05 05:20:52,632] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:20:52,757] {{jobs.py:386}} INFO - Started process (PID=6589) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:20:53,729] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:20:53,730] {{logging_mixin.py:95}} INFO - [2019-10-05 05:20:53,729] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:20:55,886] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:20:56,068] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:20:56,074] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:20:56,082] {{logging_mixin.py:95}} INFO - [2019-10-05 05:20:56,082] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:20:56,085] {{logging_mixin.py:95}} INFO - [2019-10-05 05:20:56,084] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:15:56.084266+00:00
[2019-10-05 05:20:56,093] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.336 seconds
[2019-10-05 05:21:06,507] {{logging_mixin.py:95}} INFO - [2019-10-05 05:21:06,506] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:21:06,510] {{jobs.py:386}} INFO - Started process (PID=6599) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:21:06,515] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:21:06,516] {{logging_mixin.py:95}} INFO - [2019-10-05 05:21:06,516] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:21:06,532] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:21:06,681] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:21:06,685] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:21:06,692] {{logging_mixin.py:95}} INFO - [2019-10-05 05:21:06,692] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:21:06,694] {{logging_mixin.py:95}} INFO - [2019-10-05 05:21:06,693] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:16:06.693551+00:00
[2019-10-05 05:21:06,700] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.190 seconds
[2019-10-05 05:21:17,897] {{logging_mixin.py:95}} INFO - [2019-10-05 05:21:17,772] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:21:18,027] {{jobs.py:386}} INFO - Started process (PID=6603) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:21:18,103] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:21:18,103] {{logging_mixin.py:95}} INFO - [2019-10-05 05:21:18,103] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:21:18,435] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:21:19,746] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:21:19,776] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:21:19,795] {{logging_mixin.py:95}} INFO - [2019-10-05 05:21:19,794] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:21:19,796] {{logging_mixin.py:95}} INFO - [2019-10-05 05:21:19,795] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:16:19.795383+00:00
[2019-10-05 05:21:19,808] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.781 seconds
[2019-10-05 05:21:30,419] {{logging_mixin.py:95}} INFO - [2019-10-05 05:21:30,419] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:21:30,424] {{jobs.py:386}} INFO - Started process (PID=6607) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:21:30,492] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:21:30,494] {{logging_mixin.py:95}} INFO - [2019-10-05 05:21:30,494] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:21:30,538] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:21:31,091] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:21:31,097] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:21:31,105] {{logging_mixin.py:95}} INFO - [2019-10-05 05:21:31,105] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:21:31,106] {{logging_mixin.py:95}} INFO - [2019-10-05 05:21:31,105] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:16:31.105957+00:00
[2019-10-05 05:21:31,113] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.689 seconds
[2019-10-05 05:21:42,990] {{logging_mixin.py:95}} INFO - [2019-10-05 05:21:42,990] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:21:43,038] {{jobs.py:386}} INFO - Started process (PID=6617) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:21:43,204] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:21:43,205] {{logging_mixin.py:95}} INFO - [2019-10-05 05:21:43,205] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:21:43,603] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:21:44,610] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:21:44,614] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:21:44,624] {{logging_mixin.py:95}} INFO - [2019-10-05 05:21:44,624] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:21:44,625] {{logging_mixin.py:95}} INFO - [2019-10-05 05:21:44,624] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:16:44.624885+00:00
[2019-10-05 05:21:44,631] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.593 seconds
[2019-10-05 05:21:58,011] {{logging_mixin.py:95}} INFO - [2019-10-05 05:21:57,944] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:21:58,154] {{jobs.py:386}} INFO - Started process (PID=6621) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:21:58,894] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:21:58,895] {{logging_mixin.py:95}} INFO - [2019-10-05 05:21:58,894] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:21:59,892] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:22:01,015] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:22:01,033] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:22:01,040] {{logging_mixin.py:95}} INFO - [2019-10-05 05:22:01,040] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:22:01,041] {{logging_mixin.py:95}} INFO - [2019-10-05 05:22:01,041] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:17:01.040987+00:00
[2019-10-05 05:22:01,049] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.895 seconds
[2019-10-05 05:22:11,751] {{logging_mixin.py:95}} INFO - [2019-10-05 05:22:11,751] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:22:11,820] {{jobs.py:386}} INFO - Started process (PID=6630) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:22:11,869] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:22:11,871] {{logging_mixin.py:95}} INFO - [2019-10-05 05:22:11,871] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:22:12,072] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:22:13,733] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:22:13,742] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:22:13,752] {{logging_mixin.py:95}} INFO - [2019-10-05 05:22:13,752] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:22:13,753] {{logging_mixin.py:95}} INFO - [2019-10-05 05:22:13,753] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:17:13.753228+00:00
[2019-10-05 05:22:13,860] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.039 seconds
[2019-10-05 05:22:25,860] {{logging_mixin.py:95}} INFO - [2019-10-05 05:22:25,859] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:22:26,009] {{jobs.py:386}} INFO - Started process (PID=6634) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:22:26,419] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:22:26,421] {{logging_mixin.py:95}} INFO - [2019-10-05 05:22:26,421] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:22:26,463] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:22:27,730] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:22:27,818] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:22:27,827] {{logging_mixin.py:95}} INFO - [2019-10-05 05:22:27,827] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:22:27,829] {{logging_mixin.py:95}} INFO - [2019-10-05 05:22:27,828] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:17:27.828629+00:00
[2019-10-05 05:22:27,837] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.828 seconds
[2019-10-05 05:22:42,070] {{logging_mixin.py:95}} INFO - [2019-10-05 05:22:42,069] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:22:42,369] {{jobs.py:386}} INFO - Started process (PID=6638) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:22:44,032] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:22:44,034] {{logging_mixin.py:95}} INFO - [2019-10-05 05:22:44,033] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:22:48,867] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:23:01,735] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:23:01,839] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:23:01,854] {{logging_mixin.py:95}} INFO - [2019-10-05 05:23:01,854] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:23:01,871] {{logging_mixin.py:95}} INFO - [2019-10-05 05:23:01,871] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:18:01.871132+00:00
[2019-10-05 05:23:02,382] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 20.014 seconds
[2019-10-05 05:23:14,526] {{logging_mixin.py:95}} INFO - [2019-10-05 05:23:14,526] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:23:14,602] {{jobs.py:386}} INFO - Started process (PID=6652) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:23:15,415] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:23:15,417] {{logging_mixin.py:95}} INFO - [2019-10-05 05:23:15,416] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:23:17,436] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:23:30,126] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:23:30,469] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:23:30,479] {{logging_mixin.py:95}} INFO - [2019-10-05 05:23:30,479] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:23:30,481] {{logging_mixin.py:95}} INFO - [2019-10-05 05:23:30,479] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:18:30.479969+00:00
[2019-10-05 05:23:30,652] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 16.049 seconds
[2019-10-05 05:23:41,892] {{logging_mixin.py:95}} INFO - [2019-10-05 05:23:41,892] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:23:41,896] {{jobs.py:386}} INFO - Started process (PID=6656) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:23:42,581] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:23:42,582] {{logging_mixin.py:95}} INFO - [2019-10-05 05:23:42,582] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:23:43,172] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:23:43,419] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:23:43,426] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:23:43,435] {{logging_mixin.py:95}} INFO - [2019-10-05 05:23:43,435] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:23:43,436] {{logging_mixin.py:95}} INFO - [2019-10-05 05:23:43,436] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:18:43.436186+00:00
[2019-10-05 05:23:43,446] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.550 seconds
[2019-10-05 05:23:54,201] {{logging_mixin.py:95}} INFO - [2019-10-05 05:23:54,201] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:23:54,205] {{jobs.py:386}} INFO - Started process (PID=6660) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:23:54,208] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:23:54,209] {{logging_mixin.py:95}} INFO - [2019-10-05 05:23:54,209] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:23:54,239] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:23:54,552] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:23:54,558] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:23:54,569] {{logging_mixin.py:95}} INFO - [2019-10-05 05:23:54,568] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:23:54,570] {{logging_mixin.py:95}} INFO - [2019-10-05 05:23:54,569] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:18:54.569790+00:00
[2019-10-05 05:23:54,577] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.373 seconds
[2019-10-05 05:24:06,262] {{logging_mixin.py:95}} INFO - [2019-10-05 05:24:06,262] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:24:06,289] {{jobs.py:386}} INFO - Started process (PID=6669) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:24:06,472] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:24:06,473] {{logging_mixin.py:95}} INFO - [2019-10-05 05:24:06,473] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:24:06,609] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:24:07,029] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:24:07,036] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:24:07,048] {{logging_mixin.py:95}} INFO - [2019-10-05 05:24:07,048] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:24:07,049] {{logging_mixin.py:95}} INFO - [2019-10-05 05:24:07,049] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:19:07.049134+00:00
[2019-10-05 05:24:07,060] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.771 seconds
[2019-10-05 05:24:18,137] {{logging_mixin.py:95}} INFO - [2019-10-05 05:24:18,137] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:24:18,263] {{jobs.py:386}} INFO - Started process (PID=6673) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:24:18,495] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:24:18,496] {{logging_mixin.py:95}} INFO - [2019-10-05 05:24:18,496] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:24:18,526] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:24:23,672] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:24:23,818] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:24:23,955] {{logging_mixin.py:95}} INFO - [2019-10-05 05:24:23,955] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:24:23,957] {{logging_mixin.py:95}} INFO - [2019-10-05 05:24:23,956] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:19:23.956865+00:00
[2019-10-05 05:24:24,151] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.888 seconds
[2019-10-05 05:24:35,814] {{logging_mixin.py:95}} INFO - [2019-10-05 05:24:35,761] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:24:35,839] {{jobs.py:386}} INFO - Started process (PID=6682) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:24:36,378] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:24:36,379] {{logging_mixin.py:95}} INFO - [2019-10-05 05:24:36,379] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:24:36,918] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:24:39,989] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:24:39,995] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:24:40,004] {{logging_mixin.py:95}} INFO - [2019-10-05 05:24:40,004] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:24:40,005] {{logging_mixin.py:95}} INFO - [2019-10-05 05:24:40,004] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:19:40.004774+00:00
[2019-10-05 05:24:40,027] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.188 seconds
[2019-10-05 05:24:51,109] {{logging_mixin.py:95}} INFO - [2019-10-05 05:24:51,109] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:24:51,113] {{jobs.py:386}} INFO - Started process (PID=6686) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:24:51,115] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:24:51,117] {{logging_mixin.py:95}} INFO - [2019-10-05 05:24:51,117] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:24:51,151] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:24:51,395] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:24:51,423] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:24:51,437] {{logging_mixin.py:95}} INFO - [2019-10-05 05:24:51,437] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:24:51,439] {{logging_mixin.py:95}} INFO - [2019-10-05 05:24:51,438] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:19:51.438480+00:00
[2019-10-05 05:24:51,445] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.333 seconds
[2019-10-05 05:25:03,511] {{logging_mixin.py:95}} INFO - [2019-10-05 05:25:03,458] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:25:03,640] {{jobs.py:386}} INFO - Started process (PID=6690) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:25:03,927] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:25:03,930] {{logging_mixin.py:95}} INFO - [2019-10-05 05:25:03,930] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:25:08,157] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:25:23,654] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:25:23,940] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:25:23,957] {{logging_mixin.py:95}} INFO - [2019-10-05 05:25:23,956] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:25:23,959] {{logging_mixin.py:95}} INFO - [2019-10-05 05:25:23,958] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:20:23.958023+00:00
[2019-10-05 05:25:24,756] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 21.116 seconds
[2019-10-05 05:25:39,777] {{logging_mixin.py:95}} INFO - [2019-10-05 05:25:39,777] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:25:40,135] {{jobs.py:386}} INFO - Started process (PID=6700) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:25:42,096] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:25:42,097] {{logging_mixin.py:95}} INFO - [2019-10-05 05:25:42,097] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:25:43,808] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:25:56,810] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:25:57,162] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:25:57,171] {{logging_mixin.py:95}} INFO - [2019-10-05 05:25:57,171] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:25:57,172] {{logging_mixin.py:95}} INFO - [2019-10-05 05:25:57,172] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:20:57.172416+00:00
[2019-10-05 05:25:58,509] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 18.374 seconds
[2019-10-05 05:26:13,058] {{logging_mixin.py:95}} INFO - [2019-10-05 05:26:12,383] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:26:13,234] {{jobs.py:386}} INFO - Started process (PID=6704) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:26:14,908] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:26:14,910] {{logging_mixin.py:95}} INFO - [2019-10-05 05:26:14,910] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:26:17,472] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:26:40,527] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 05:26:58,125] {{logging_mixin.py:95}} INFO - [2019-10-05 05:26:58,125] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:26:58,315] {{jobs.py:386}} INFO - Started process (PID=6706) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:26:58,615] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:26:58,619] {{logging_mixin.py:95}} INFO - [2019-10-05 05:26:58,618] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:26:59,005] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:27:00,719] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:27:00,788] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:27:00,795] {{logging_mixin.py:95}} INFO - [2019-10-05 05:27:00,795] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:27:00,796] {{logging_mixin.py:95}} INFO - [2019-10-05 05:27:00,796] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:22:00.796379+00:00
[2019-10-05 05:27:00,853] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.538 seconds
[2019-10-05 05:27:12,668] {{logging_mixin.py:95}} INFO - [2019-10-05 05:27:12,668] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:27:12,672] {{jobs.py:386}} INFO - Started process (PID=6710) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:27:12,676] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:27:12,679] {{logging_mixin.py:95}} INFO - [2019-10-05 05:27:12,679] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:27:12,704] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:27:12,985] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:27:12,995] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:27:13,010] {{logging_mixin.py:95}} INFO - [2019-10-05 05:27:13,010] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:27:13,012] {{logging_mixin.py:95}} INFO - [2019-10-05 05:27:13,011] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:22:13.011677+00:00
[2019-10-05 05:27:13,025] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.353 seconds
[2019-10-05 05:27:24,033] {{logging_mixin.py:95}} INFO - [2019-10-05 05:27:24,033] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:27:24,036] {{jobs.py:386}} INFO - Started process (PID=6714) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:27:24,039] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:27:24,040] {{logging_mixin.py:95}} INFO - [2019-10-05 05:27:24,039] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:27:24,063] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:27:24,296] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:27:24,304] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:27:24,311] {{logging_mixin.py:95}} INFO - [2019-10-05 05:27:24,311] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:27:24,312] {{logging_mixin.py:95}} INFO - [2019-10-05 05:27:24,312] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:22:24.312297+00:00
[2019-10-05 05:27:24,319] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.283 seconds
[2019-10-05 05:27:35,447] {{logging_mixin.py:95}} INFO - [2019-10-05 05:27:35,447] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:27:35,454] {{jobs.py:386}} INFO - Started process (PID=6724) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:27:35,578] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:27:35,579] {{logging_mixin.py:95}} INFO - [2019-10-05 05:27:35,579] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:27:35,604] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:27:38,113] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:27:38,196] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:27:38,205] {{logging_mixin.py:95}} INFO - [2019-10-05 05:27:38,205] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:27:38,206] {{logging_mixin.py:95}} INFO - [2019-10-05 05:27:38,206] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:22:38.206101+00:00
[2019-10-05 05:27:38,215] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.761 seconds
[2019-10-05 05:27:49,048] {{logging_mixin.py:95}} INFO - [2019-10-05 05:27:49,048] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:27:49,051] {{jobs.py:386}} INFO - Started process (PID=6728) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:27:49,057] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:27:49,058] {{logging_mixin.py:95}} INFO - [2019-10-05 05:27:49,058] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:27:49,079] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:27:49,301] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:27:49,307] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:27:49,316] {{logging_mixin.py:95}} INFO - [2019-10-05 05:27:49,316] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:27:49,317] {{logging_mixin.py:95}} INFO - [2019-10-05 05:27:49,316] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:22:49.316744+00:00
[2019-10-05 05:27:49,444] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.393 seconds
[2019-10-05 05:28:00,479] {{logging_mixin.py:95}} INFO - [2019-10-05 05:28:00,479] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:28:00,483] {{jobs.py:386}} INFO - Started process (PID=6732) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:28:00,485] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:28:00,487] {{logging_mixin.py:95}} INFO - [2019-10-05 05:28:00,487] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:28:00,539] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:28:00,807] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:28:00,813] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:28:00,820] {{logging_mixin.py:95}} INFO - [2019-10-05 05:28:00,820] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:28:00,822] {{logging_mixin.py:95}} INFO - [2019-10-05 05:28:00,821] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:23:00.821699+00:00
[2019-10-05 05:28:00,828] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.346 seconds
[2019-10-05 05:28:12,115] {{logging_mixin.py:95}} INFO - [2019-10-05 05:28:12,115] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:28:12,146] {{jobs.py:386}} INFO - Started process (PID=6741) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:28:12,470] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:28:12,472] {{logging_mixin.py:95}} INFO - [2019-10-05 05:28:12,472] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:28:12,911] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:28:28,861] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:28:29,466] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:28:29,483] {{logging_mixin.py:95}} INFO - [2019-10-05 05:28:29,483] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:28:29,486] {{logging_mixin.py:95}} INFO - [2019-10-05 05:28:29,484] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:23:29.484838+00:00
[2019-10-05 05:28:30,300] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 18.154 seconds
[2019-10-05 05:28:43,185] {{logging_mixin.py:95}} INFO - [2019-10-05 05:28:43,184] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:28:43,327] {{jobs.py:386}} INFO - Started process (PID=6754) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:28:43,567] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:28:43,567] {{logging_mixin.py:95}} INFO - [2019-10-05 05:28:43,567] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:28:44,823] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:28:55,386] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:28:55,747] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:28:55,818] {{logging_mixin.py:95}} INFO - [2019-10-05 05:28:55,818] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:28:55,819] {{logging_mixin.py:95}} INFO - [2019-10-05 05:28:55,818] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:23:55.818654+00:00
[2019-10-05 05:28:57,257] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 13.930 seconds
[2019-10-05 05:29:09,121] {{logging_mixin.py:95}} INFO - [2019-10-05 05:29:09,120] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:29:09,169] {{jobs.py:386}} INFO - Started process (PID=6758) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:29:11,052] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:29:11,055] {{logging_mixin.py:95}} INFO - [2019-10-05 05:29:11,055] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:29:13,398] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:29:32,967] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:29:33,596] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:29:33,602] {{logging_mixin.py:95}} INFO - [2019-10-05 05:29:33,602] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:29:33,604] {{logging_mixin.py:95}} INFO - [2019-10-05 05:29:33,603] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:24:33.603768+00:00
[2019-10-05 05:29:35,417] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 26.247 seconds
[2019-10-05 05:29:49,174] {{logging_mixin.py:95}} INFO - [2019-10-05 05:29:49,174] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:29:49,266] {{jobs.py:386}} INFO - Started process (PID=6762) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:29:51,482] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:29:51,483] {{logging_mixin.py:95}} INFO - [2019-10-05 05:29:51,483] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:29:54,007] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:30:12,567] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 05:30:34,570] {{logging_mixin.py:95}} INFO - [2019-10-05 05:30:34,570] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:30:34,672] {{jobs.py:386}} INFO - Started process (PID=6764) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:30:34,995] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:30:35,013] {{logging_mixin.py:95}} INFO - [2019-10-05 05:30:35,013] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:30:36,463] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:30:40,877] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:30:40,884] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:30:40,895] {{logging_mixin.py:95}} INFO - [2019-10-05 05:30:40,895] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:30:40,896] {{logging_mixin.py:95}} INFO - [2019-10-05 05:30:40,895] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:25:40.895886+00:00
[2019-10-05 05:30:40,905] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 6.233 seconds
[2019-10-05 05:30:51,663] {{logging_mixin.py:95}} INFO - [2019-10-05 05:30:51,662] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:30:51,688] {{jobs.py:386}} INFO - Started process (PID=6776) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:30:51,704] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:30:51,709] {{logging_mixin.py:95}} INFO - [2019-10-05 05:30:51,708] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:30:51,735] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:30:52,166] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:30:52,218] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:30:52,235] {{logging_mixin.py:95}} INFO - [2019-10-05 05:30:52,235] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:30:52,237] {{logging_mixin.py:95}} INFO - [2019-10-05 05:30:52,235] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:25:52.235721+00:00
[2019-10-05 05:30:52,250] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.562 seconds
[2019-10-05 05:31:03,218] {{logging_mixin.py:95}} INFO - [2019-10-05 05:31:03,218] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:31:03,338] {{jobs.py:386}} INFO - Started process (PID=6780) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:31:03,796] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:31:03,797] {{logging_mixin.py:95}} INFO - [2019-10-05 05:31:03,797] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:31:04,247] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:31:06,420] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:31:06,456] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:31:06,466] {{logging_mixin.py:95}} INFO - [2019-10-05 05:31:06,465] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:31:06,467] {{logging_mixin.py:95}} INFO - [2019-10-05 05:31:06,466] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:26:06.466722+00:00
[2019-10-05 05:31:06,482] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.145 seconds
[2019-10-05 05:31:17,713] {{logging_mixin.py:95}} INFO - [2019-10-05 05:31:17,712] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:31:17,734] {{jobs.py:386}} INFO - Started process (PID=6784) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:31:17,772] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:31:17,775] {{logging_mixin.py:95}} INFO - [2019-10-05 05:31:17,775] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:31:17,862] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:31:18,130] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:31:18,157] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:31:18,278] {{logging_mixin.py:95}} INFO - [2019-10-05 05:31:18,278] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:31:18,422] {{logging_mixin.py:95}} INFO - [2019-10-05 05:31:18,422] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:26:18.422261+00:00
[2019-10-05 05:31:18,430] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.696 seconds
[2019-10-05 05:31:30,129] {{logging_mixin.py:95}} INFO - [2019-10-05 05:31:30,073] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:31:30,420] {{jobs.py:386}} INFO - Started process (PID=6796) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:31:31,352] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:31:31,355] {{logging_mixin.py:95}} INFO - [2019-10-05 05:31:31,354] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:31:32,308] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:31:40,883] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:31:41,030] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:31:41,039] {{logging_mixin.py:95}} INFO - [2019-10-05 05:31:41,039] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:31:41,040] {{logging_mixin.py:95}} INFO - [2019-10-05 05:31:41,039] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:26:41.039931+00:00
[2019-10-05 05:31:41,786] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 11.367 seconds
[2019-10-05 05:31:53,927] {{logging_mixin.py:95}} INFO - [2019-10-05 05:31:53,927] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:31:53,933] {{jobs.py:386}} INFO - Started process (PID=6800) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:31:53,975] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:31:53,976] {{logging_mixin.py:95}} INFO - [2019-10-05 05:31:53,976] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:31:54,007] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:31:54,175] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:31:54,179] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:31:54,187] {{logging_mixin.py:95}} INFO - [2019-10-05 05:31:54,187] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:31:54,188] {{logging_mixin.py:95}} INFO - [2019-10-05 05:31:54,187] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:26:54.187946+00:00
[2019-10-05 05:31:54,199] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.266 seconds
[2019-10-05 05:32:05,753] {{logging_mixin.py:95}} INFO - [2019-10-05 05:32:05,688] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:32:05,810] {{jobs.py:386}} INFO - Started process (PID=6809) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:32:06,249] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:32:06,250] {{logging_mixin.py:95}} INFO - [2019-10-05 05:32:06,250] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:32:07,432] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:32:22,245] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:32:22,412] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:32:22,428] {{logging_mixin.py:95}} INFO - [2019-10-05 05:32:22,428] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:32:22,433] {{logging_mixin.py:95}} INFO - [2019-10-05 05:32:22,432] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:27:22.432480+00:00
[2019-10-05 05:32:22,589] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 16.780 seconds
[2019-10-05 05:32:35,666] {{logging_mixin.py:95}} INFO - [2019-10-05 05:32:35,666] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:32:36,125] {{jobs.py:386}} INFO - Started process (PID=6820) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:32:36,633] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:32:36,638] {{logging_mixin.py:95}} INFO - [2019-10-05 05:32:36,638] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:32:37,846] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:32:49,667] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:32:50,237] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:32:50,254] {{logging_mixin.py:95}} INFO - [2019-10-05 05:32:50,254] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:32:50,257] {{logging_mixin.py:95}} INFO - [2019-10-05 05:32:50,256] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:27:50.256165+00:00
[2019-10-05 05:32:51,788] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 15.663 seconds
[2019-10-05 05:33:05,108] {{logging_mixin.py:95}} INFO - [2019-10-05 05:33:05,093] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:33:05,266] {{jobs.py:386}} INFO - Started process (PID=6824) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:33:05,947] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:33:05,949] {{logging_mixin.py:95}} INFO - [2019-10-05 05:33:05,949] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:33:08,871] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:33:20,206] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:33:20,292] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:33:20,302] {{logging_mixin.py:95}} INFO - [2019-10-05 05:33:20,302] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:33:20,304] {{logging_mixin.py:95}} INFO - [2019-10-05 05:33:20,303] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:28:20.303763+00:00
[2019-10-05 05:33:20,937] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 15.671 seconds
[2019-10-05 05:33:32,703] {{logging_mixin.py:95}} INFO - [2019-10-05 05:33:32,702] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:33:32,765] {{jobs.py:386}} INFO - Started process (PID=6834) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:33:32,807] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:33:32,808] {{logging_mixin.py:95}} INFO - [2019-10-05 05:33:32,808] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:33:32,873] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:33:33,095] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:33:33,100] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:33:33,115] {{logging_mixin.py:95}} INFO - [2019-10-05 05:33:33,114] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:33:33,116] {{logging_mixin.py:95}} INFO - [2019-10-05 05:33:33,115] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:28:33.115629+00:00
[2019-10-05 05:33:33,122] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.357 seconds
[2019-10-05 05:33:44,152] {{logging_mixin.py:95}} INFO - [2019-10-05 05:33:44,151] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:33:44,196] {{jobs.py:386}} INFO - Started process (PID=6838) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:33:44,217] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:33:44,220] {{logging_mixin.py:95}} INFO - [2019-10-05 05:33:44,219] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:33:44,263] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:33:44,881] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:33:44,885] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:33:44,892] {{logging_mixin.py:95}} INFO - [2019-10-05 05:33:44,892] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:33:44,892] {{logging_mixin.py:95}} INFO - [2019-10-05 05:33:44,892] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:28:44.892320+00:00
[2019-10-05 05:33:44,900] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.704 seconds
[2019-10-05 05:33:55,977] {{logging_mixin.py:95}} INFO - [2019-10-05 05:33:55,976] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:33:56,013] {{jobs.py:386}} INFO - Started process (PID=6842) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:33:56,115] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:33:56,118] {{logging_mixin.py:95}} INFO - [2019-10-05 05:33:56,118] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:33:56,299] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:33:56,635] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:33:56,642] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:33:56,652] {{logging_mixin.py:95}} INFO - [2019-10-05 05:33:56,652] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:33:56,653] {{logging_mixin.py:95}} INFO - [2019-10-05 05:33:56,653] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:28:56.653146+00:00
[2019-10-05 05:33:56,661] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.648 seconds
[2019-10-05 05:34:08,433] {{logging_mixin.py:95}} INFO - [2019-10-05 05:34:08,433] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:34:08,469] {{jobs.py:386}} INFO - Started process (PID=6851) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:34:08,643] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:34:08,645] {{logging_mixin.py:95}} INFO - [2019-10-05 05:34:08,645] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:34:08,852] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:34:11,141] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:34:11,148] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:34:11,158] {{logging_mixin.py:95}} INFO - [2019-10-05 05:34:11,158] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:34:11,160] {{logging_mixin.py:95}} INFO - [2019-10-05 05:34:11,159] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:29:11.159617+00:00
[2019-10-05 05:34:11,168] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.699 seconds
[2019-10-05 05:34:22,720] {{logging_mixin.py:95}} INFO - [2019-10-05 05:34:22,654] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:34:22,794] {{jobs.py:386}} INFO - Started process (PID=6855) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:34:23,227] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:34:23,229] {{logging_mixin.py:95}} INFO - [2019-10-05 05:34:23,229] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:34:24,991] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:34:27,608] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:34:27,798] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:34:27,818] {{logging_mixin.py:95}} INFO - [2019-10-05 05:34:27,817] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:34:27,819] {{logging_mixin.py:95}} INFO - [2019-10-05 05:34:27,818] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:29:27.818257+00:00
[2019-10-05 05:34:27,828] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.035 seconds
[2019-10-05 05:34:38,407] {{logging_mixin.py:95}} INFO - [2019-10-05 05:34:38,406] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:34:38,411] {{jobs.py:386}} INFO - Started process (PID=6866) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:34:38,414] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:34:38,415] {{logging_mixin.py:95}} INFO - [2019-10-05 05:34:38,415] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:34:38,429] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:34:38,863] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:34:39,015] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:34:39,032] {{logging_mixin.py:95}} INFO - [2019-10-05 05:34:39,031] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:34:39,035] {{logging_mixin.py:95}} INFO - [2019-10-05 05:34:39,033] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:29:39.033692+00:00
[2019-10-05 05:34:39,048] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.637 seconds
[2019-10-05 05:34:50,683] {{logging_mixin.py:95}} INFO - [2019-10-05 05:34:50,683] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:34:50,786] {{jobs.py:386}} INFO - Started process (PID=6870) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:34:51,010] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:34:51,011] {{logging_mixin.py:95}} INFO - [2019-10-05 05:34:51,011] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:34:52,808] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:35:03,023] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:35:03,188] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:35:03,198] {{logging_mixin.py:95}} INFO - [2019-10-05 05:35:03,198] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:35:03,200] {{logging_mixin.py:95}} INFO - [2019-10-05 05:35:03,199] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:30:03.199531+00:00
[2019-10-05 05:35:03,206] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 12.420 seconds
[2019-10-05 05:35:16,182] {{logging_mixin.py:95}} INFO - [2019-10-05 05:35:16,182] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:35:16,222] {{jobs.py:386}} INFO - Started process (PID=6874) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:35:17,132] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:35:17,133] {{logging_mixin.py:95}} INFO - [2019-10-05 05:35:17,132] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:35:19,883] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:35:39,288] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:35:39,954] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:35:39,964] {{logging_mixin.py:95}} INFO - [2019-10-05 05:35:39,963] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:35:39,965] {{logging_mixin.py:95}} INFO - [2019-10-05 05:35:39,964] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:30:39.964727+00:00
[2019-10-05 05:35:41,079] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 24.857 seconds
[2019-10-05 05:35:53,643] {{logging_mixin.py:95}} INFO - [2019-10-05 05:35:53,643] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:35:53,667] {{jobs.py:386}} INFO - Started process (PID=6883) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:35:54,389] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:35:54,391] {{logging_mixin.py:95}} INFO - [2019-10-05 05:35:54,391] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:35:55,696] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:35:57,041] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:35:57,055] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:35:57,062] {{logging_mixin.py:95}} INFO - [2019-10-05 05:35:57,062] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:35:57,064] {{logging_mixin.py:95}} INFO - [2019-10-05 05:35:57,063] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:30:57.063321+00:00
[2019-10-05 05:35:57,070] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.403 seconds
[2019-10-05 05:36:07,755] {{logging_mixin.py:95}} INFO - [2019-10-05 05:36:07,755] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:36:07,763] {{jobs.py:386}} INFO - Started process (PID=6887) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:36:07,768] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:36:07,769] {{logging_mixin.py:95}} INFO - [2019-10-05 05:36:07,769] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:36:07,836] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:36:07,952] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:36:07,958] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:36:07,966] {{logging_mixin.py:95}} INFO - [2019-10-05 05:36:07,965] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:36:07,967] {{logging_mixin.py:95}} INFO - [2019-10-05 05:36:07,966] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:31:07.966646+00:00
[2019-10-05 05:36:07,973] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.210 seconds
[2019-10-05 05:36:19,450] {{logging_mixin.py:95}} INFO - [2019-10-05 05:36:19,415] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:36:19,473] {{jobs.py:386}} INFO - Started process (PID=6896) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:36:19,497] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:36:19,503] {{logging_mixin.py:95}} INFO - [2019-10-05 05:36:19,501] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:36:19,640] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:36:21,425] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:36:21,436] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:36:21,452] {{logging_mixin.py:95}} INFO - [2019-10-05 05:36:21,451] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:36:21,453] {{logging_mixin.py:95}} INFO - [2019-10-05 05:36:21,452] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:31:21.452438+00:00
[2019-10-05 05:36:21,488] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.015 seconds
[2019-10-05 05:36:33,363] {{logging_mixin.py:95}} INFO - [2019-10-05 05:36:33,362] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:36:33,367] {{jobs.py:386}} INFO - Started process (PID=6900) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:36:33,371] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:36:33,393] {{logging_mixin.py:95}} INFO - [2019-10-05 05:36:33,393] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:36:33,721] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:36:37,699] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:36:37,706] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:36:37,719] {{logging_mixin.py:95}} INFO - [2019-10-05 05:36:37,719] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:36:37,721] {{logging_mixin.py:95}} INFO - [2019-10-05 05:36:37,720] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:31:37.720432+00:00
[2019-10-05 05:36:37,729] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.362 seconds
[2019-10-05 05:36:49,097] {{logging_mixin.py:95}} INFO - [2019-10-05 05:36:49,096] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:36:49,157] {{jobs.py:386}} INFO - Started process (PID=6909) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:36:49,223] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:36:49,225] {{logging_mixin.py:95}} INFO - [2019-10-05 05:36:49,225] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:36:49,374] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:36:49,953] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:36:49,991] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:36:50,000] {{logging_mixin.py:95}} INFO - [2019-10-05 05:36:50,000] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:36:50,001] {{logging_mixin.py:95}} INFO - [2019-10-05 05:36:50,001] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:31:50.001190+00:00
[2019-10-05 05:36:50,009] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.852 seconds
[2019-10-05 05:37:01,677] {{logging_mixin.py:95}} INFO - [2019-10-05 05:37:01,677] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:37:01,680] {{jobs.py:386}} INFO - Started process (PID=6914) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:37:02,053] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:37:02,054] {{logging_mixin.py:95}} INFO - [2019-10-05 05:37:02,054] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:37:04,160] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:37:13,678] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:37:14,023] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:37:14,033] {{logging_mixin.py:95}} INFO - [2019-10-05 05:37:14,032] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:37:14,034] {{logging_mixin.py:95}} INFO - [2019-10-05 05:37:14,033] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:32:14.033760+00:00
[2019-10-05 05:37:14,351] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 12.671 seconds
[2019-10-05 05:37:27,945] {{logging_mixin.py:95}} INFO - [2019-10-05 05:37:27,943] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:37:27,990] {{jobs.py:386}} INFO - Started process (PID=6928) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:37:28,817] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:37:28,820] {{logging_mixin.py:95}} INFO - [2019-10-05 05:37:28,820] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:37:38,729] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:37:49,414] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:37:49,564] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:37:49,639] {{logging_mixin.py:95}} INFO - [2019-10-05 05:37:49,639] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:37:49,641] {{logging_mixin.py:95}} INFO - [2019-10-05 05:37:49,640] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:32:49.640549+00:00
[2019-10-05 05:37:50,998] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 23.008 seconds
[2019-10-05 05:38:05,913] {{logging_mixin.py:95}} INFO - [2019-10-05 05:38:05,913] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:38:06,078] {{jobs.py:386}} INFO - Started process (PID=6932) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:38:07,172] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:38:07,174] {{logging_mixin.py:95}} INFO - [2019-10-05 05:38:07,173] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:38:09,152] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:38:26,269] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:38:26,405] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:38:26,420] {{logging_mixin.py:95}} INFO - [2019-10-05 05:38:26,420] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:38:26,422] {{logging_mixin.py:95}} INFO - [2019-10-05 05:38:26,421] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:33:26.421706+00:00
[2019-10-05 05:38:26,838] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 20.761 seconds
[2019-10-05 05:38:38,016] {{logging_mixin.py:95}} INFO - [2019-10-05 05:38:38,016] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:38:38,019] {{jobs.py:386}} INFO - Started process (PID=6941) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:38:38,029] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:38:38,030] {{logging_mixin.py:95}} INFO - [2019-10-05 05:38:38,030] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:38:38,063] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:38:38,441] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:38:38,480] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:38:38,488] {{logging_mixin.py:95}} INFO - [2019-10-05 05:38:38,488] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:38:38,490] {{logging_mixin.py:95}} INFO - [2019-10-05 05:38:38,490] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:33:38.490342+00:00
[2019-10-05 05:38:38,499] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.480 seconds
[2019-10-05 05:38:49,526] {{logging_mixin.py:95}} INFO - [2019-10-05 05:38:49,526] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:38:49,531] {{jobs.py:386}} INFO - Started process (PID=6945) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:38:49,857] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:38:49,858] {{logging_mixin.py:95}} INFO - [2019-10-05 05:38:49,858] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:38:50,213] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:38:52,273] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:38:52,278] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:38:52,286] {{logging_mixin.py:95}} INFO - [2019-10-05 05:38:52,286] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:38:52,287] {{logging_mixin.py:95}} INFO - [2019-10-05 05:38:52,286] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:33:52.286917+00:00
[2019-10-05 05:38:52,295] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.765 seconds
[2019-10-05 05:39:03,369] {{logging_mixin.py:95}} INFO - [2019-10-05 05:39:03,368] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:39:03,385] {{jobs.py:386}} INFO - Started process (PID=6949) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:39:03,425] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:39:03,428] {{logging_mixin.py:95}} INFO - [2019-10-05 05:39:03,428] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:39:03,709] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:39:05,751] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:39:05,831] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:39:05,839] {{logging_mixin.py:95}} INFO - [2019-10-05 05:39:05,839] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:39:05,841] {{logging_mixin.py:95}} INFO - [2019-10-05 05:39:05,840] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:34:05.840665+00:00
[2019-10-05 05:39:05,847] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.462 seconds
[2019-10-05 05:39:16,967] {{logging_mixin.py:95}} INFO - [2019-10-05 05:39:16,967] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:39:16,970] {{jobs.py:386}} INFO - Started process (PID=6958) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:39:16,975] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:39:16,978] {{logging_mixin.py:95}} INFO - [2019-10-05 05:39:16,978] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:39:17,001] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:39:17,612] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:39:17,619] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:39:17,628] {{logging_mixin.py:95}} INFO - [2019-10-05 05:39:17,628] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:39:17,629] {{logging_mixin.py:95}} INFO - [2019-10-05 05:39:17,629] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:34:17.629082+00:00
[2019-10-05 05:39:17,785] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.815 seconds
[2019-10-05 05:39:28,378] {{logging_mixin.py:95}} INFO - [2019-10-05 05:39:28,378] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:39:28,380] {{jobs.py:386}} INFO - Started process (PID=6962) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:39:28,382] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:39:28,383] {{logging_mixin.py:95}} INFO - [2019-10-05 05:39:28,383] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:39:28,406] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:39:28,674] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:39:28,680] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:39:28,691] {{logging_mixin.py:95}} INFO - [2019-10-05 05:39:28,691] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:39:28,692] {{logging_mixin.py:95}} INFO - [2019-10-05 05:39:28,692] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:34:28.692091+00:00
[2019-10-05 05:39:28,700] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.320 seconds
[2019-10-05 05:39:40,233] {{logging_mixin.py:95}} INFO - [2019-10-05 05:39:40,233] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:39:40,328] {{jobs.py:386}} INFO - Started process (PID=6966) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:39:40,562] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:39:40,563] {{logging_mixin.py:95}} INFO - [2019-10-05 05:39:40,563] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:39:41,270] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:39:47,859] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:39:48,083] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:39:48,097] {{logging_mixin.py:95}} INFO - [2019-10-05 05:39:48,097] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:39:48,105] {{logging_mixin.py:95}} INFO - [2019-10-05 05:39:48,101] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:34:48.101918+00:00
[2019-10-05 05:39:48,136] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 7.808 seconds
[2019-10-05 05:39:59,208] {{logging_mixin.py:95}} INFO - [2019-10-05 05:39:59,207] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:39:59,219] {{jobs.py:386}} INFO - Started process (PID=6975) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:39:59,227] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:39:59,228] {{logging_mixin.py:95}} INFO - [2019-10-05 05:39:59,228] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:39:59,278] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:39:59,408] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:39:59,419] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:39:59,434] {{logging_mixin.py:95}} INFO - [2019-10-05 05:39:59,434] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:39:59,439] {{logging_mixin.py:95}} INFO - [2019-10-05 05:39:59,437] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:34:59.437045+00:00
[2019-10-05 05:39:59,473] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.255 seconds
[2019-10-05 05:40:12,654] {{logging_mixin.py:95}} INFO - [2019-10-05 05:40:12,559] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:40:12,709] {{jobs.py:386}} INFO - Started process (PID=6979) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:40:13,515] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:40:13,517] {{logging_mixin.py:95}} INFO - [2019-10-05 05:40:13,517] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:40:16,736] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:40:33,830] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:40:34,266] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:40:34,274] {{logging_mixin.py:95}} INFO - [2019-10-05 05:40:34,274] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:40:34,275] {{logging_mixin.py:95}} INFO - [2019-10-05 05:40:34,274] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:35:34.274859+00:00
[2019-10-05 05:40:35,299] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 22.590 seconds
[2019-10-05 05:40:49,813] {{logging_mixin.py:95}} INFO - [2019-10-05 05:40:49,636] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:40:50,045] {{jobs.py:386}} INFO - Started process (PID=6988) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:40:52,331] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:40:52,333] {{logging_mixin.py:95}} INFO - [2019-10-05 05:40:52,333] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:40:55,907] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:41:10,424] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 05:41:28,436] {{logging_mixin.py:95}} INFO - [2019-10-05 05:41:28,365] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:41:28,485] {{jobs.py:386}} INFO - Started process (PID=6990) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:41:29,274] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:41:29,277] {{logging_mixin.py:95}} INFO - [2019-10-05 05:41:29,276] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:41:31,082] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:41:39,009] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:41:39,095] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:41:39,312] {{logging_mixin.py:95}} INFO - [2019-10-05 05:41:39,312] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:41:39,314] {{logging_mixin.py:95}} INFO - [2019-10-05 05:41:39,313] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:36:39.313364+00:00
[2019-10-05 05:41:41,729] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 13.244 seconds
[2019-10-05 05:41:53,456] {{logging_mixin.py:95}} INFO - [2019-10-05 05:41:53,455] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:41:53,484] {{jobs.py:386}} INFO - Started process (PID=6999) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:41:53,883] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:41:53,885] {{logging_mixin.py:95}} INFO - [2019-10-05 05:41:53,885] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:41:54,363] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:41:54,807] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:41:54,819] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:41:54,839] {{logging_mixin.py:95}} INFO - [2019-10-05 05:41:54,839] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:41:54,842] {{logging_mixin.py:95}} INFO - [2019-10-05 05:41:54,841] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:36:54.840971+00:00
[2019-10-05 05:41:54,858] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.373 seconds
[2019-10-05 05:42:05,323] {{logging_mixin.py:95}} INFO - [2019-10-05 05:42:05,322] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:42:05,330] {{jobs.py:386}} INFO - Started process (PID=7003) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:42:05,337] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:42:05,339] {{logging_mixin.py:95}} INFO - [2019-10-05 05:42:05,339] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:42:05,370] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:42:05,734] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:42:05,740] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:42:05,749] {{logging_mixin.py:95}} INFO - [2019-10-05 05:42:05,749] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:42:05,751] {{logging_mixin.py:95}} INFO - [2019-10-05 05:42:05,750] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:37:05.750401+00:00
[2019-10-05 05:42:05,759] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.429 seconds
[2019-10-05 05:42:16,852] {{logging_mixin.py:95}} INFO - [2019-10-05 05:42:16,852] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:42:16,924] {{jobs.py:386}} INFO - Started process (PID=7007) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:42:17,014] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:42:17,015] {{logging_mixin.py:95}} INFO - [2019-10-05 05:42:17,015] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:42:17,130] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:42:18,618] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:42:18,651] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:42:18,670] {{logging_mixin.py:95}} INFO - [2019-10-05 05:42:18,670] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:42:18,678] {{logging_mixin.py:95}} INFO - [2019-10-05 05:42:18,674] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:37:18.673620+00:00
[2019-10-05 05:42:18,727] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.803 seconds
[2019-10-05 05:42:30,007] {{logging_mixin.py:95}} INFO - [2019-10-05 05:42:29,900] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:42:30,011] {{jobs.py:386}} INFO - Started process (PID=7020) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:42:30,058] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:42:30,060] {{logging_mixin.py:95}} INFO - [2019-10-05 05:42:30,059] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:42:30,423] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:42:33,852] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:42:33,968] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:42:33,976] {{logging_mixin.py:95}} INFO - [2019-10-05 05:42:33,976] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:42:33,978] {{logging_mixin.py:95}} INFO - [2019-10-05 05:42:33,977] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:37:33.977694+00:00
[2019-10-05 05:42:33,985] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.974 seconds
[2019-10-05 05:42:45,547] {{logging_mixin.py:95}} INFO - [2019-10-05 05:42:45,547] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:42:45,554] {{jobs.py:386}} INFO - Started process (PID=7024) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:42:45,560] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:42:45,561] {{logging_mixin.py:95}} INFO - [2019-10-05 05:42:45,561] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:42:45,590] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:42:45,777] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:42:45,783] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:42:45,790] {{logging_mixin.py:95}} INFO - [2019-10-05 05:42:45,790] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:42:45,792] {{logging_mixin.py:95}} INFO - [2019-10-05 05:42:45,791] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:37:45.791604+00:00
[2019-10-05 05:42:45,801] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.247 seconds
[2019-10-05 05:42:57,022] {{logging_mixin.py:95}} INFO - [2019-10-05 05:42:57,022] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:42:57,034] {{jobs.py:386}} INFO - Started process (PID=7028) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:42:57,199] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:42:57,300] {{logging_mixin.py:95}} INFO - [2019-10-05 05:42:57,300] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:42:57,924] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:42:59,320] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:42:59,400] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:42:59,409] {{logging_mixin.py:95}} INFO - [2019-10-05 05:42:59,409] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:42:59,410] {{logging_mixin.py:95}} INFO - [2019-10-05 05:42:59,409] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:37:59.409601+00:00
[2019-10-05 05:42:59,416] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.382 seconds
[2019-10-05 05:43:10,908] {{logging_mixin.py:95}} INFO - [2019-10-05 05:43:10,907] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:43:10,956] {{jobs.py:386}} INFO - Started process (PID=7032) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:43:11,195] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:43:11,196] {{logging_mixin.py:95}} INFO - [2019-10-05 05:43:11,196] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:43:11,312] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:43:12,309] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:43:12,329] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:43:12,361] {{logging_mixin.py:95}} INFO - [2019-10-05 05:43:12,360] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:43:12,365] {{logging_mixin.py:95}} INFO - [2019-10-05 05:43:12,364] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:38:12.364147+00:00
[2019-10-05 05:43:12,380] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.424 seconds
[2019-10-05 05:43:24,811] {{logging_mixin.py:95}} INFO - [2019-10-05 05:43:24,811] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:43:24,880] {{jobs.py:386}} INFO - Started process (PID=7042) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:43:25,296] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:43:25,297] {{logging_mixin.py:95}} INFO - [2019-10-05 05:43:25,297] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:43:28,068] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:43:33,660] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:43:33,699] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:43:33,745] {{logging_mixin.py:95}} INFO - [2019-10-05 05:43:33,745] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:43:33,753] {{logging_mixin.py:95}} INFO - [2019-10-05 05:43:33,752] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:38:33.752488+00:00
[2019-10-05 05:43:34,445] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 9.565 seconds
[2019-10-05 05:43:47,399] {{logging_mixin.py:95}} INFO - [2019-10-05 05:43:47,399] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:43:47,521] {{jobs.py:386}} INFO - Started process (PID=7046) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:43:49,198] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:43:49,199] {{logging_mixin.py:95}} INFO - [2019-10-05 05:43:49,199] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:43:51,750] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:43:52,558] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:43:52,564] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:43:52,573] {{logging_mixin.py:95}} INFO - [2019-10-05 05:43:52,573] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:43:52,574] {{logging_mixin.py:95}} INFO - [2019-10-05 05:43:52,573] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:38:52.573791+00:00
[2019-10-05 05:43:52,583] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.062 seconds
[2019-10-05 05:44:03,209] {{logging_mixin.py:95}} INFO - [2019-10-05 05:44:03,208] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:44:03,212] {{jobs.py:386}} INFO - Started process (PID=7060) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:44:03,581] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:44:03,583] {{logging_mixin.py:95}} INFO - [2019-10-05 05:44:03,583] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:44:04,379] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:44:14,085] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:44:14,224] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:44:14,241] {{logging_mixin.py:95}} INFO - [2019-10-05 05:44:14,241] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:44:14,244] {{logging_mixin.py:95}} INFO - [2019-10-05 05:44:14,243] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:39:14.243008+00:00
[2019-10-05 05:44:14,808] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 11.597 seconds
[2019-10-05 05:44:26,095] {{logging_mixin.py:95}} INFO - [2019-10-05 05:44:26,095] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:44:26,236] {{jobs.py:386}} INFO - Started process (PID=7064) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:44:27,175] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:44:27,177] {{logging_mixin.py:95}} INFO - [2019-10-05 05:44:27,177] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:44:27,882] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:44:29,136] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:44:29,143] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:44:29,154] {{logging_mixin.py:95}} INFO - [2019-10-05 05:44:29,154] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:44:29,155] {{logging_mixin.py:95}} INFO - [2019-10-05 05:44:29,155] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:39:29.155036+00:00
[2019-10-05 05:44:29,164] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.928 seconds
[2019-10-05 05:44:40,322] {{logging_mixin.py:95}} INFO - [2019-10-05 05:44:40,321] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:44:40,386] {{jobs.py:386}} INFO - Started process (PID=7073) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:44:40,390] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:44:40,393] {{logging_mixin.py:95}} INFO - [2019-10-05 05:44:40,393] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:44:40,417] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:44:40,640] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:44:40,644] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:44:40,652] {{logging_mixin.py:95}} INFO - [2019-10-05 05:44:40,652] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:44:40,653] {{logging_mixin.py:95}} INFO - [2019-10-05 05:44:40,652] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:39:40.652489+00:00
[2019-10-05 05:44:40,662] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.276 seconds
[2019-10-05 05:44:52,246] {{logging_mixin.py:95}} INFO - [2019-10-05 05:44:52,246] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:44:52,249] {{jobs.py:386}} INFO - Started process (PID=7077) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:44:52,266] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:44:52,304] {{logging_mixin.py:95}} INFO - [2019-10-05 05:44:52,304] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:44:52,376] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:44:52,861] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:44:52,872] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:44:52,880] {{logging_mixin.py:95}} INFO - [2019-10-05 05:44:52,880] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:44:52,881] {{logging_mixin.py:95}} INFO - [2019-10-05 05:44:52,881] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:39:52.881212+00:00
[2019-10-05 05:44:52,887] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.638 seconds
[2019-10-05 05:45:03,765] {{logging_mixin.py:95}} INFO - [2019-10-05 05:45:03,765] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:45:03,775] {{jobs.py:386}} INFO - Started process (PID=7081) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:45:03,956] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:45:03,958] {{logging_mixin.py:95}} INFO - [2019-10-05 05:45:03,958] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:45:04,209] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:45:04,613] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:45:04,617] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:45:04,625] {{logging_mixin.py:95}} INFO - [2019-10-05 05:45:04,625] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:45:04,626] {{logging_mixin.py:95}} INFO - [2019-10-05 05:45:04,626] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:40:04.626329+00:00
[2019-10-05 05:45:04,686] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.911 seconds
[2019-10-05 05:45:16,754] {{logging_mixin.py:95}} INFO - [2019-10-05 05:45:16,754] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:45:16,933] {{jobs.py:386}} INFO - Started process (PID=7090) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:45:17,333] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:45:17,335] {{logging_mixin.py:95}} INFO - [2019-10-05 05:45:17,334] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:45:18,456] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:45:21,642] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:45:21,827] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:45:21,835] {{logging_mixin.py:95}} INFO - [2019-10-05 05:45:21,835] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:45:21,836] {{logging_mixin.py:95}} INFO - [2019-10-05 05:45:21,836] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:40:21.836026+00:00
[2019-10-05 05:45:21,844] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.911 seconds
[2019-10-05 05:45:33,264] {{logging_mixin.py:95}} INFO - [2019-10-05 05:45:33,264] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:45:33,276] {{jobs.py:386}} INFO - Started process (PID=7094) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:45:33,282] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:45:33,284] {{logging_mixin.py:95}} INFO - [2019-10-05 05:45:33,284] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:45:33,319] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:45:33,589] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:45:33,594] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:45:33,603] {{logging_mixin.py:95}} INFO - [2019-10-05 05:45:33,603] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:45:33,605] {{logging_mixin.py:95}} INFO - [2019-10-05 05:45:33,604] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:40:33.604814+00:00
[2019-10-05 05:45:33,613] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.339 seconds
[2019-10-05 05:45:45,186] {{logging_mixin.py:95}} INFO - [2019-10-05 05:45:45,186] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:45:45,267] {{jobs.py:386}} INFO - Started process (PID=7098) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:45:45,731] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:45:45,733] {{logging_mixin.py:95}} INFO - [2019-10-05 05:45:45,733] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:45:50,386] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:45:57,463] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:45:57,478] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:45:57,488] {{logging_mixin.py:95}} INFO - [2019-10-05 05:45:57,487] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:45:57,489] {{logging_mixin.py:95}} INFO - [2019-10-05 05:45:57,488] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:40:57.488618+00:00
[2019-10-05 05:45:57,497] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 12.230 seconds
[2019-10-05 05:46:10,107] {{logging_mixin.py:95}} INFO - [2019-10-05 05:46:09,879] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:46:10,448] {{jobs.py:386}} INFO - Started process (PID=7107) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:46:11,298] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:46:11,302] {{logging_mixin.py:95}} INFO - [2019-10-05 05:46:11,301] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:46:13,231] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:46:30,719] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 05:46:46,491] {{logging_mixin.py:95}} INFO - [2019-10-05 05:46:46,490] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:46:46,849] {{jobs.py:386}} INFO - Started process (PID=7109) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:46:47,503] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:46:47,505] {{logging_mixin.py:95}} INFO - [2019-10-05 05:46:47,505] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:46:50,476] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:47:02,448] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 05:47:24,152] {{logging_mixin.py:95}} INFO - [2019-10-05 05:47:24,098] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:47:24,344] {{jobs.py:386}} INFO - Started process (PID=7111) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:47:25,831] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:47:25,833] {{logging_mixin.py:95}} INFO - [2019-10-05 05:47:25,833] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:47:27,685] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:47:41,017] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:47:42,256] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:47:42,275] {{logging_mixin.py:95}} INFO - [2019-10-05 05:47:42,275] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:47:42,277] {{logging_mixin.py:95}} INFO - [2019-10-05 05:47:42,276] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:42:42.276221+00:00
[2019-10-05 05:47:43,235] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 18.891 seconds
[2019-10-05 05:47:56,101] {{logging_mixin.py:95}} INFO - [2019-10-05 05:47:56,100] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:47:56,402] {{jobs.py:386}} INFO - Started process (PID=7120) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:47:57,284] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:47:57,285] {{logging_mixin.py:95}} INFO - [2019-10-05 05:47:57,285] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:47:59,507] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:48:02,131] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:48:02,137] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:48:02,152] {{logging_mixin.py:95}} INFO - [2019-10-05 05:48:02,152] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:48:02,153] {{logging_mixin.py:95}} INFO - [2019-10-05 05:48:02,153] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:43:02.153427+00:00
[2019-10-05 05:48:02,212] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.810 seconds
[2019-10-05 05:48:13,518] {{logging_mixin.py:95}} INFO - [2019-10-05 05:48:13,518] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:48:13,521] {{jobs.py:386}} INFO - Started process (PID=7124) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:48:13,523] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:48:13,525] {{logging_mixin.py:95}} INFO - [2019-10-05 05:48:13,525] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:48:13,580] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:48:13,874] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:48:13,879] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:48:13,887] {{logging_mixin.py:95}} INFO - [2019-10-05 05:48:13,887] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:48:13,890] {{logging_mixin.py:95}} INFO - [2019-10-05 05:48:13,889] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:43:13.889514+00:00
[2019-10-05 05:48:13,896] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.376 seconds
[2019-10-05 05:48:25,045] {{logging_mixin.py:95}} INFO - [2019-10-05 05:48:25,045] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:48:25,049] {{jobs.py:386}} INFO - Started process (PID=7128) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:48:25,325] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:48:25,326] {{logging_mixin.py:95}} INFO - [2019-10-05 05:48:25,326] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:48:25,557] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:48:26,412] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:48:26,416] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:48:26,423] {{logging_mixin.py:95}} INFO - [2019-10-05 05:48:26,423] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:48:26,424] {{logging_mixin.py:95}} INFO - [2019-10-05 05:48:26,424] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:43:26.424035+00:00
[2019-10-05 05:48:26,430] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.381 seconds
[2019-10-05 05:48:37,845] {{logging_mixin.py:95}} INFO - [2019-10-05 05:48:37,845] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:48:37,848] {{jobs.py:386}} INFO - Started process (PID=7138) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:48:37,922] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:48:37,925] {{logging_mixin.py:95}} INFO - [2019-10-05 05:48:37,925] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:48:37,949] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:48:38,164] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:48:38,285] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:48:38,294] {{logging_mixin.py:95}} INFO - [2019-10-05 05:48:38,294] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:48:38,296] {{logging_mixin.py:95}} INFO - [2019-10-05 05:48:38,295] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:43:38.295544+00:00
[2019-10-05 05:48:38,305] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.457 seconds
[2019-10-05 05:48:48,975] {{logging_mixin.py:95}} INFO - [2019-10-05 05:48:48,975] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:48:48,978] {{jobs.py:386}} INFO - Started process (PID=7142) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:48:48,983] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:48:48,984] {{logging_mixin.py:95}} INFO - [2019-10-05 05:48:48,984] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:48:49,011] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:48:49,220] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:48:49,225] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:48:49,234] {{logging_mixin.py:95}} INFO - [2019-10-05 05:48:49,234] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:48:49,235] {{logging_mixin.py:95}} INFO - [2019-10-05 05:48:49,235] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:43:49.235215+00:00
[2019-10-05 05:48:49,242] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.265 seconds
[2019-10-05 05:49:01,380] {{logging_mixin.py:95}} INFO - [2019-10-05 05:49:01,380] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:49:01,582] {{jobs.py:386}} INFO - Started process (PID=7146) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:49:02,008] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:49:02,009] {{logging_mixin.py:95}} INFO - [2019-10-05 05:49:02,009] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:49:02,336] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:49:04,739] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:49:04,768] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:49:04,774] {{logging_mixin.py:95}} INFO - [2019-10-05 05:49:04,774] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:49:04,778] {{logging_mixin.py:95}} INFO - [2019-10-05 05:49:04,777] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:44:04.774463+00:00
[2019-10-05 05:49:04,789] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.206 seconds
[2019-10-05 05:49:15,460] {{logging_mixin.py:95}} INFO - [2019-10-05 05:49:15,460] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:49:15,464] {{jobs.py:386}} INFO - Started process (PID=7155) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:49:15,643] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:49:15,644] {{logging_mixin.py:95}} INFO - [2019-10-05 05:49:15,644] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:49:15,676] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:49:16,104] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:49:16,110] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:49:16,118] {{logging_mixin.py:95}} INFO - [2019-10-05 05:49:16,118] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:49:16,119] {{logging_mixin.py:95}} INFO - [2019-10-05 05:49:16,119] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:44:16.118946+00:00
[2019-10-05 05:49:16,126] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.662 seconds
[2019-10-05 05:49:27,072] {{logging_mixin.py:95}} INFO - [2019-10-05 05:49:27,072] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:49:27,079] {{jobs.py:386}} INFO - Started process (PID=7159) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:49:27,082] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:49:27,083] {{logging_mixin.py:95}} INFO - [2019-10-05 05:49:27,083] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:49:27,108] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:49:27,240] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:49:27,333] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:49:27,344] {{logging_mixin.py:95}} INFO - [2019-10-05 05:49:27,344] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:49:27,345] {{logging_mixin.py:95}} INFO - [2019-10-05 05:49:27,345] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:44:27.345048+00:00
[2019-10-05 05:49:27,365] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.286 seconds
[2019-10-05 05:49:39,579] {{logging_mixin.py:95}} INFO - [2019-10-05 05:49:39,483] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:49:39,738] {{jobs.py:386}} INFO - Started process (PID=7163) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:49:39,936] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:49:39,937] {{logging_mixin.py:95}} INFO - [2019-10-05 05:49:39,937] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:49:40,576] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:49:45,891] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:49:45,897] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:49:45,906] {{logging_mixin.py:95}} INFO - [2019-10-05 05:49:45,906] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:49:45,907] {{logging_mixin.py:95}} INFO - [2019-10-05 05:49:45,906] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:44:45.906948+00:00
[2019-10-05 05:49:45,999] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 6.261 seconds
[2019-10-05 05:50:00,268] {{logging_mixin.py:95}} INFO - [2019-10-05 05:50:00,268] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:50:00,539] {{jobs.py:386}} INFO - Started process (PID=7176) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:50:02,244] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:50:02,249] {{logging_mixin.py:95}} INFO - [2019-10-05 05:50:02,249] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:50:05,483] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:50:14,659] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:50:14,739] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:50:14,749] {{logging_mixin.py:95}} INFO - [2019-10-05 05:50:14,747] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:50:14,750] {{logging_mixin.py:95}} INFO - [2019-10-05 05:50:14,750] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:45:14.750460+00:00
[2019-10-05 05:50:15,533] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 14.995 seconds
[2019-10-05 05:50:29,612] {{logging_mixin.py:95}} INFO - [2019-10-05 05:50:29,436] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:50:30,052] {{jobs.py:386}} INFO - Started process (PID=7180) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:50:31,759] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:50:31,761] {{logging_mixin.py:95}} INFO - [2019-10-05 05:50:31,761] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:50:33,145] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:50:50,875] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:50:51,814] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:50:51,821] {{logging_mixin.py:95}} INFO - [2019-10-05 05:50:51,821] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:50:51,822] {{logging_mixin.py:95}} INFO - [2019-10-05 05:50:51,822] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:45:51.822297+00:00
[2019-10-05 05:50:53,838] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 23.785 seconds
[2019-10-05 05:51:06,268] {{logging_mixin.py:95}} INFO - [2019-10-05 05:51:06,268] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:51:06,360] {{jobs.py:386}} INFO - Started process (PID=7190) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:51:06,718] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:51:06,720] {{logging_mixin.py:95}} INFO - [2019-10-05 05:51:06,720] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:51:07,380] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:51:07,688] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:51:07,691] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:51:07,698] {{logging_mixin.py:95}} INFO - [2019-10-05 05:51:07,698] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:51:07,698] {{logging_mixin.py:95}} INFO - [2019-10-05 05:51:07,698] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:46:07.698361+00:00
[2019-10-05 05:51:07,704] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.344 seconds
[2019-10-05 05:51:19,076] {{logging_mixin.py:95}} INFO - [2019-10-05 05:51:18,972] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:51:19,159] {{jobs.py:386}} INFO - Started process (PID=7194) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:51:19,573] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:51:19,573] {{logging_mixin.py:95}} INFO - [2019-10-05 05:51:19,573] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:51:19,900] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:51:21,556] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:51:21,574] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:51:21,588] {{logging_mixin.py:95}} INFO - [2019-10-05 05:51:21,587] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:51:21,589] {{logging_mixin.py:95}} INFO - [2019-10-05 05:51:21,588] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:46:21.588710+00:00
[2019-10-05 05:51:21,597] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.439 seconds
[2019-10-05 05:51:32,571] {{logging_mixin.py:95}} INFO - [2019-10-05 05:51:32,570] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:51:32,689] {{jobs.py:386}} INFO - Started process (PID=7203) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:51:32,872] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:51:32,873] {{logging_mixin.py:95}} INFO - [2019-10-05 05:51:32,873] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:51:32,962] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:51:37,196] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:51:37,510] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:51:37,518] {{logging_mixin.py:95}} INFO - [2019-10-05 05:51:37,518] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:51:37,519] {{logging_mixin.py:95}} INFO - [2019-10-05 05:51:37,519] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:46:37.519293+00:00
[2019-10-05 05:51:37,808] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.119 seconds
[2019-10-05 05:51:49,580] {{logging_mixin.py:95}} INFO - [2019-10-05 05:51:49,580] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:51:49,583] {{jobs.py:386}} INFO - Started process (PID=7207) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:51:49,588] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:51:49,589] {{logging_mixin.py:95}} INFO - [2019-10-05 05:51:49,589] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:51:49,616] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:51:49,880] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:51:49,926] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:51:49,934] {{logging_mixin.py:95}} INFO - [2019-10-05 05:51:49,934] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:51:49,935] {{logging_mixin.py:95}} INFO - [2019-10-05 05:51:49,934] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:46:49.934838+00:00
[2019-10-05 05:51:49,944] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.360 seconds
[2019-10-05 05:52:01,857] {{logging_mixin.py:95}} INFO - [2019-10-05 05:52:01,857] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:52:01,982] {{jobs.py:386}} INFO - Started process (PID=7211) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:52:02,218] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:52:02,223] {{logging_mixin.py:95}} INFO - [2019-10-05 05:52:02,223] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:52:02,681] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:52:02,899] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:52:02,913] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:52:02,921] {{logging_mixin.py:95}} INFO - [2019-10-05 05:52:02,921] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:52:02,922] {{logging_mixin.py:95}} INFO - [2019-10-05 05:52:02,922] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:47:02.922228+00:00
[2019-10-05 05:52:03,070] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.088 seconds
[2019-10-05 05:52:15,374] {{logging_mixin.py:95}} INFO - [2019-10-05 05:52:14,958] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:52:15,673] {{jobs.py:386}} INFO - Started process (PID=7223) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:52:16,053] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:52:16,071] {{logging_mixin.py:95}} INFO - [2019-10-05 05:52:16,071] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:52:16,306] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:52:18,588] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:52:18,890] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:52:18,900] {{logging_mixin.py:95}} INFO - [2019-10-05 05:52:18,899] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:52:18,901] {{logging_mixin.py:95}} INFO - [2019-10-05 05:52:18,900] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:47:18.900611+00:00
[2019-10-05 05:52:18,912] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.238 seconds
[2019-10-05 05:52:30,312] {{logging_mixin.py:95}} INFO - [2019-10-05 05:52:30,311] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:52:30,316] {{jobs.py:386}} INFO - Started process (PID=7229) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:52:30,317] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:52:30,318] {{logging_mixin.py:95}} INFO - [2019-10-05 05:52:30,318] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:52:30,378] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:52:30,510] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:52:30,516] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:52:30,523] {{logging_mixin.py:95}} INFO - [2019-10-05 05:52:30,523] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:52:30,524] {{logging_mixin.py:95}} INFO - [2019-10-05 05:52:30,523] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:47:30.523304+00:00
[2019-10-05 05:52:30,530] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.214 seconds
[2019-10-05 05:52:41,671] {{logging_mixin.py:95}} INFO - [2019-10-05 05:52:41,670] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:52:41,673] {{jobs.py:386}} INFO - Started process (PID=7233) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:52:41,676] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:52:41,678] {{logging_mixin.py:95}} INFO - [2019-10-05 05:52:41,678] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:52:41,701] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:52:41,873] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:52:41,879] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:52:41,889] {{logging_mixin.py:95}} INFO - [2019-10-05 05:52:41,889] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:52:41,891] {{logging_mixin.py:95}} INFO - [2019-10-05 05:52:41,890] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:47:41.890553+00:00
[2019-10-05 05:52:41,897] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.223 seconds
[2019-10-05 05:52:56,001] {{logging_mixin.py:95}} INFO - [2019-10-05 05:52:56,001] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:52:56,004] {{jobs.py:386}} INFO - Started process (PID=7236) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:52:56,444] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:52:56,445] {{logging_mixin.py:95}} INFO - [2019-10-05 05:52:56,445] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:52:58,288] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:53:02,158] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:53:02,348] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:53:02,356] {{logging_mixin.py:95}} INFO - [2019-10-05 05:53:02,356] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:53:02,357] {{logging_mixin.py:95}} INFO - [2019-10-05 05:53:02,356] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:48:02.356920+00:00
[2019-10-05 05:53:02,365] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 6.361 seconds
[2019-10-05 05:53:16,734] {{logging_mixin.py:95}} INFO - [2019-10-05 05:53:16,734] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:53:16,821] {{jobs.py:386}} INFO - Started process (PID=7245) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:53:17,910] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:53:17,911] {{logging_mixin.py:95}} INFO - [2019-10-05 05:53:17,910] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:53:19,624] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:53:27,123] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:53:27,222] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:53:27,404] {{logging_mixin.py:95}} INFO - [2019-10-05 05:53:27,404] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:53:27,406] {{logging_mixin.py:95}} INFO - [2019-10-05 05:53:27,405] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:48:27.405562+00:00
[2019-10-05 05:53:28,373] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 11.552 seconds
[2019-10-05 05:53:41,442] {{logging_mixin.py:95}} INFO - [2019-10-05 05:53:41,442] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:53:41,586] {{jobs.py:386}} INFO - Started process (PID=7249) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:53:42,600] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:53:42,602] {{logging_mixin.py:95}} INFO - [2019-10-05 05:53:42,602] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:53:44,376] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:53:56,191] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:53:57,923] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:53:57,931] {{logging_mixin.py:95}} INFO - [2019-10-05 05:53:57,931] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:53:57,933] {{logging_mixin.py:95}} INFO - [2019-10-05 05:53:57,932] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:48:57.932188+00:00
[2019-10-05 05:53:59,499] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 17.913 seconds
[2019-10-05 05:54:11,879] {{logging_mixin.py:95}} INFO - [2019-10-05 05:54:11,879] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:54:12,134] {{jobs.py:386}} INFO - Started process (PID=7253) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:54:13,208] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:54:13,209] {{logging_mixin.py:95}} INFO - [2019-10-05 05:54:13,209] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:54:14,258] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:54:24,137] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:54:24,236] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:54:24,251] {{logging_mixin.py:95}} INFO - [2019-10-05 05:54:24,251] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:54:24,253] {{logging_mixin.py:95}} INFO - [2019-10-05 05:54:24,252] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:49:24.252490+00:00
[2019-10-05 05:54:24,836] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 12.702 seconds
[2019-10-05 05:54:35,942] {{logging_mixin.py:95}} INFO - [2019-10-05 05:54:35,942] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:54:35,945] {{jobs.py:386}} INFO - Started process (PID=7257) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:54:36,027] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:54:36,028] {{logging_mixin.py:95}} INFO - [2019-10-05 05:54:36,028] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:54:36,060] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:54:36,387] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:54:36,393] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:54:36,402] {{logging_mixin.py:95}} INFO - [2019-10-05 05:54:36,402] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:54:36,404] {{logging_mixin.py:95}} INFO - [2019-10-05 05:54:36,403] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:49:36.403528+00:00
[2019-10-05 05:54:36,412] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.467 seconds
[2019-10-05 05:54:47,382] {{logging_mixin.py:95}} INFO - [2019-10-05 05:54:47,382] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:54:47,386] {{jobs.py:386}} INFO - Started process (PID=7261) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:54:47,444] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:54:47,445] {{logging_mixin.py:95}} INFO - [2019-10-05 05:54:47,445] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:54:48,069] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:54:50,171] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:54:50,176] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:54:50,193] {{logging_mixin.py:95}} INFO - [2019-10-05 05:54:50,193] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:54:50,194] {{logging_mixin.py:95}} INFO - [2019-10-05 05:54:50,194] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:49:50.194154+00:00
[2019-10-05 05:54:50,201] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.816 seconds
[2019-10-05 05:55:00,934] {{logging_mixin.py:95}} INFO - [2019-10-05 05:55:00,934] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:55:01,087] {{jobs.py:386}} INFO - Started process (PID=7271) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:55:01,441] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:55:01,442] {{logging_mixin.py:95}} INFO - [2019-10-05 05:55:01,442] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:55:01,577] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:55:03,437] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:55:03,506] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:55:03,560] {{logging_mixin.py:95}} INFO - [2019-10-05 05:55:03,560] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:55:03,563] {{logging_mixin.py:95}} INFO - [2019-10-05 05:55:03,562] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:50:03.562833+00:00
[2019-10-05 05:55:03,568] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.481 seconds
[2019-10-05 05:55:14,289] {{logging_mixin.py:95}} INFO - [2019-10-05 05:55:14,289] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:55:14,294] {{jobs.py:386}} INFO - Started process (PID=7275) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:55:14,300] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:55:14,300] {{logging_mixin.py:95}} INFO - [2019-10-05 05:55:14,300] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:55:14,324] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:55:14,798] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:55:14,804] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:55:14,814] {{logging_mixin.py:95}} INFO - [2019-10-05 05:55:14,814] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:55:14,815] {{logging_mixin.py:95}} INFO - [2019-10-05 05:55:14,815] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:50:14.815244+00:00
[2019-10-05 05:55:14,822] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.528 seconds
[2019-10-05 05:55:26,699] {{logging_mixin.py:95}} INFO - [2019-10-05 05:55:26,699] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:55:26,936] {{jobs.py:386}} INFO - Started process (PID=7279) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:55:27,438] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:55:27,440] {{logging_mixin.py:95}} INFO - [2019-10-05 05:55:27,440] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:55:28,378] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:55:32,088] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:55:32,093] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:55:32,102] {{logging_mixin.py:95}} INFO - [2019-10-05 05:55:32,102] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:55:32,103] {{logging_mixin.py:95}} INFO - [2019-10-05 05:55:32,103] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:50:32.103001+00:00
[2019-10-05 05:55:32,267] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.331 seconds
[2019-10-05 05:55:43,688] {{logging_mixin.py:95}} INFO - [2019-10-05 05:55:43,688] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:55:43,694] {{jobs.py:386}} INFO - Started process (PID=7283) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:55:43,698] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:55:43,699] {{logging_mixin.py:95}} INFO - [2019-10-05 05:55:43,699] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:55:43,727] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:55:43,875] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:55:43,881] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:55:43,890] {{logging_mixin.py:95}} INFO - [2019-10-05 05:55:43,889] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:55:43,891] {{logging_mixin.py:95}} INFO - [2019-10-05 05:55:43,890] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:50:43.890862+00:00
[2019-10-05 05:55:43,898] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.204 seconds
[2019-10-05 05:55:57,446] {{logging_mixin.py:95}} INFO - [2019-10-05 05:55:57,313] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:55:57,596] {{jobs.py:386}} INFO - Started process (PID=7292) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:55:57,878] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:55:57,879] {{logging_mixin.py:95}} INFO - [2019-10-05 05:55:57,879] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:55:58,993] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:56:10,153] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:56:10,278] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:56:10,289] {{logging_mixin.py:95}} INFO - [2019-10-05 05:56:10,289] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:56:10,290] {{logging_mixin.py:95}} INFO - [2019-10-05 05:56:10,289] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:51:10.289941+00:00
[2019-10-05 05:56:10,751] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 13.155 seconds
[2019-10-05 05:56:23,217] {{logging_mixin.py:95}} INFO - [2019-10-05 05:56:23,217] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:56:23,263] {{jobs.py:386}} INFO - Started process (PID=7301) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:56:23,607] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:56:23,608] {{logging_mixin.py:95}} INFO - [2019-10-05 05:56:23,608] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:56:27,076] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:56:40,654] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:56:40,766] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:56:40,774] {{logging_mixin.py:95}} INFO - [2019-10-05 05:56:40,774] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:56:40,775] {{logging_mixin.py:95}} INFO - [2019-10-05 05:56:40,775] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:51:40.775237+00:00
[2019-10-05 05:56:41,749] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 18.487 seconds
[2019-10-05 05:56:54,910] {{logging_mixin.py:95}} INFO - [2019-10-05 05:56:54,836] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:56:54,987] {{jobs.py:386}} INFO - Started process (PID=7305) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:56:56,075] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:56:56,076] {{logging_mixin.py:95}} INFO - [2019-10-05 05:56:56,076] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:56:58,216] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:57:09,611] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:57:10,079] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:57:10,089] {{logging_mixin.py:95}} INFO - [2019-10-05 05:57:10,089] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:57:10,090] {{logging_mixin.py:95}} INFO - [2019-10-05 05:57:10,090] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:52:10.090156+00:00
[2019-10-05 05:57:11,470] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 16.483 seconds
[2019-10-05 05:57:25,017] {{logging_mixin.py:95}} INFO - [2019-10-05 05:57:24,911] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:57:25,509] {{jobs.py:386}} INFO - Started process (PID=7309) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:57:25,971] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:57:25,973] {{logging_mixin.py:95}} INFO - [2019-10-05 05:57:25,973] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:57:27,792] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:57:49,792] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 05:58:07,703] {{logging_mixin.py:95}} INFO - [2019-10-05 05:58:07,703] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:58:07,783] {{jobs.py:386}} INFO - Started process (PID=7318) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:58:07,983] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:58:07,984] {{logging_mixin.py:95}} INFO - [2019-10-05 05:58:07,984] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:58:08,946] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:58:09,328] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:58:09,385] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:58:09,392] {{logging_mixin.py:95}} INFO - [2019-10-05 05:58:09,392] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:58:09,395] {{logging_mixin.py:95}} INFO - [2019-10-05 05:58:09,393] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:53:09.393322+00:00
[2019-10-05 05:58:09,410] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.627 seconds
[2019-10-05 05:58:19,772] {{logging_mixin.py:95}} INFO - [2019-10-05 05:58:19,772] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:58:19,775] {{jobs.py:386}} INFO - Started process (PID=7322) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:58:19,858] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:58:19,859] {{logging_mixin.py:95}} INFO - [2019-10-05 05:58:19,859] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:58:19,953] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:58:20,154] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:58:20,310] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:58:20,319] {{logging_mixin.py:95}} INFO - [2019-10-05 05:58:20,319] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:58:20,321] {{logging_mixin.py:95}} INFO - [2019-10-05 05:58:20,320] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:53:20.320436+00:00
[2019-10-05 05:58:20,330] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.556 seconds
[2019-10-05 05:58:31,249] {{logging_mixin.py:95}} INFO - [2019-10-05 05:58:31,249] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:58:31,252] {{jobs.py:386}} INFO - Started process (PID=7334) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:58:31,256] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:58:31,266] {{logging_mixin.py:95}} INFO - [2019-10-05 05:58:31,266] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:58:31,302] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:58:31,675] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:58:31,682] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:58:31,704] {{logging_mixin.py:95}} INFO - [2019-10-05 05:58:31,704] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:58:31,749] {{logging_mixin.py:95}} INFO - [2019-10-05 05:58:31,748] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:53:31.748896+00:00
[2019-10-05 05:58:31,754] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.502 seconds
[2019-10-05 05:58:43,465] {{logging_mixin.py:95}} INFO - [2019-10-05 05:58:43,190] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:58:43,472] {{jobs.py:386}} INFO - Started process (PID=7338) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:58:43,817] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:58:43,849] {{logging_mixin.py:95}} INFO - [2019-10-05 05:58:43,848] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:58:44,481] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:58:47,170] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:58:47,176] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:58:47,186] {{logging_mixin.py:95}} INFO - [2019-10-05 05:58:47,186] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:58:47,188] {{logging_mixin.py:95}} INFO - [2019-10-05 05:58:47,187] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:53:47.187853+00:00
[2019-10-05 05:58:47,196] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.724 seconds
[2019-10-05 05:58:58,527] {{logging_mixin.py:95}} INFO - [2019-10-05 05:58:58,527] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:58:58,564] {{jobs.py:386}} INFO - Started process (PID=7342) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:58:58,700] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:58:58,702] {{logging_mixin.py:95}} INFO - [2019-10-05 05:58:58,702] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:58:58,726] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:58:59,058] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:58:59,064] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:58:59,070] {{logging_mixin.py:95}} INFO - [2019-10-05 05:58:59,070] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:58:59,071] {{logging_mixin.py:95}} INFO - [2019-10-05 05:58:59,071] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:53:59.071171+00:00
[2019-10-05 05:58:59,078] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.514 seconds
[2019-10-05 05:59:10,346] {{logging_mixin.py:95}} INFO - [2019-10-05 05:59:10,346] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:59:10,463] {{jobs.py:386}} INFO - Started process (PID=7351) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:59:10,844] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:59:10,846] {{logging_mixin.py:95}} INFO - [2019-10-05 05:59:10,846] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:59:12,112] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:59:13,548] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:59:13,590] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:59:13,597] {{logging_mixin.py:95}} INFO - [2019-10-05 05:59:13,597] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:59:13,600] {{logging_mixin.py:95}} INFO - [2019-10-05 05:59:13,597] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:54:13.597939+00:00
[2019-10-05 05:59:13,607] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.143 seconds
[2019-10-05 05:59:25,465] {{logging_mixin.py:95}} INFO - [2019-10-05 05:59:25,464] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:59:25,468] {{jobs.py:386}} INFO - Started process (PID=7355) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:59:25,985] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:59:25,986] {{logging_mixin.py:95}} INFO - [2019-10-05 05:59:25,986] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:59:27,125] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:59:29,882] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 05:59:29,889] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 05:59:29,906] {{logging_mixin.py:95}} INFO - [2019-10-05 05:59:29,906] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 05:59:29,908] {{logging_mixin.py:95}} INFO - [2019-10-05 05:59:29,907] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:54:29.907396+00:00
[2019-10-05 05:59:29,940] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.472 seconds
[2019-10-05 05:59:43,965] {{logging_mixin.py:95}} INFO - [2019-10-05 05:59:43,862] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 05:59:44,003] {{jobs.py:386}} INFO - Started process (PID=7359) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:59:44,718] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 05:59:44,719] {{logging_mixin.py:95}} INFO - [2019-10-05 05:59:44,719] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 05:59:45,717] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:00:01,819] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:00:02,015] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:00:02,023] {{logging_mixin.py:95}} INFO - [2019-10-05 06:00:02,023] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:00:02,024] {{logging_mixin.py:95}} INFO - [2019-10-05 06:00:02,024] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:55:02.024142+00:00
[2019-10-05 06:00:02,281] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 18.278 seconds
[2019-10-05 06:00:14,158] {{logging_mixin.py:95}} INFO - [2019-10-05 06:00:14,157] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:00:14,336] {{jobs.py:386}} INFO - Started process (PID=7368) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:00:15,017] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:00:15,018] {{logging_mixin.py:95}} INFO - [2019-10-05 06:00:15,018] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:00:19,374] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:00:28,804] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:00:28,829] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:00:28,839] {{logging_mixin.py:95}} INFO - [2019-10-05 06:00:28,839] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:00:28,840] {{logging_mixin.py:95}} INFO - [2019-10-05 06:00:28,840] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:55:28.840144+00:00
[2019-10-05 06:00:30,416] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 16.080 seconds
[2019-10-05 06:00:43,125] {{logging_mixin.py:95}} INFO - [2019-10-05 06:00:43,125] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:00:43,151] {{jobs.py:386}} INFO - Started process (PID=7372) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:00:43,759] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:00:43,760] {{logging_mixin.py:95}} INFO - [2019-10-05 06:00:43,760] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:00:45,813] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:00:47,332] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:00:47,337] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:00:47,345] {{logging_mixin.py:95}} INFO - [2019-10-05 06:00:47,345] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:00:47,346] {{logging_mixin.py:95}} INFO - [2019-10-05 06:00:47,345] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:55:47.345861+00:00
[2019-10-05 06:00:47,353] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.202 seconds
[2019-10-05 06:00:58,441] {{logging_mixin.py:95}} INFO - [2019-10-05 06:00:58,440] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:00:58,444] {{jobs.py:386}} INFO - Started process (PID=7381) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:00:58,450] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:00:58,453] {{logging_mixin.py:95}} INFO - [2019-10-05 06:00:58,453] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:00:58,478] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:00:58,669] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:00:58,674] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:00:58,681] {{logging_mixin.py:95}} INFO - [2019-10-05 06:00:58,681] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:00:58,682] {{logging_mixin.py:95}} INFO - [2019-10-05 06:00:58,682] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:55:58.682374+00:00
[2019-10-05 06:00:58,689] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.246 seconds
[2019-10-05 06:01:10,447] {{logging_mixin.py:95}} INFO - [2019-10-05 06:01:10,447] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:01:10,492] {{jobs.py:386}} INFO - Started process (PID=7385) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:01:11,022] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:01:11,028] {{logging_mixin.py:95}} INFO - [2019-10-05 06:01:11,028] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:01:11,656] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:01:13,369] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:01:13,617] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:01:13,625] {{logging_mixin.py:95}} INFO - [2019-10-05 06:01:13,625] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:01:13,626] {{logging_mixin.py:95}} INFO - [2019-10-05 06:01:13,626] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:56:13.626092+00:00
[2019-10-05 06:01:13,846] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.354 seconds
[2019-10-05 06:01:25,257] {{logging_mixin.py:95}} INFO - [2019-10-05 06:01:25,256] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:01:25,357] {{jobs.py:386}} INFO - Started process (PID=7394) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:01:25,538] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:01:25,539] {{logging_mixin.py:95}} INFO - [2019-10-05 06:01:25,539] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:01:25,745] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:01:28,131] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:01:28,234] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:01:28,243] {{logging_mixin.py:95}} INFO - [2019-10-05 06:01:28,242] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:01:28,244] {{logging_mixin.py:95}} INFO - [2019-10-05 06:01:28,243] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:56:28.243846+00:00
[2019-10-05 06:01:28,252] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.895 seconds
[2019-10-05 06:01:39,642] {{logging_mixin.py:95}} INFO - [2019-10-05 06:01:39,641] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:01:39,645] {{jobs.py:386}} INFO - Started process (PID=7399) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:01:39,905] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:01:39,906] {{logging_mixin.py:95}} INFO - [2019-10-05 06:01:39,906] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:01:40,971] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:01:44,814] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:01:44,892] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:01:44,901] {{logging_mixin.py:95}} INFO - [2019-10-05 06:01:44,901] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:01:44,902] {{logging_mixin.py:95}} INFO - [2019-10-05 06:01:44,902] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:56:44.902174+00:00
[2019-10-05 06:01:44,962] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.317 seconds
[2019-10-05 06:01:57,140] {{logging_mixin.py:95}} INFO - [2019-10-05 06:01:57,120] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:01:57,306] {{jobs.py:386}} INFO - Started process (PID=7402) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:01:58,180] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:01:58,181] {{logging_mixin.py:95}} INFO - [2019-10-05 06:01:58,181] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:01:59,361] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:02:04,311] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:02:04,441] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:02:04,449] {{logging_mixin.py:95}} INFO - [2019-10-05 06:02:04,448] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:02:04,450] {{logging_mixin.py:95}} INFO - [2019-10-05 06:02:04,449] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:57:04.449217+00:00
[2019-10-05 06:02:04,457] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 7.151 seconds
[2019-10-05 06:02:15,173] {{logging_mixin.py:95}} INFO - [2019-10-05 06:02:15,172] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:02:15,176] {{jobs.py:386}} INFO - Started process (PID=7412) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:02:15,180] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:02:15,181] {{logging_mixin.py:95}} INFO - [2019-10-05 06:02:15,181] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:02:15,718] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:02:18,743] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:02:19,169] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:02:19,180] {{logging_mixin.py:95}} INFO - [2019-10-05 06:02:19,179] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:02:19,181] {{logging_mixin.py:95}} INFO - [2019-10-05 06:02:19,180] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:57:19.180793+00:00
[2019-10-05 06:02:19,188] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.012 seconds
[2019-10-05 06:02:31,095] {{logging_mixin.py:95}} INFO - [2019-10-05 06:02:31,083] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:02:31,114] {{jobs.py:386}} INFO - Started process (PID=7416) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:02:31,632] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:02:31,633] {{logging_mixin.py:95}} INFO - [2019-10-05 06:02:31,633] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:02:32,848] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:02:39,338] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:02:39,374] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:02:39,384] {{logging_mixin.py:95}} INFO - [2019-10-05 06:02:39,384] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:02:39,386] {{logging_mixin.py:95}} INFO - [2019-10-05 06:02:39,385] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:57:39.385809+00:00
[2019-10-05 06:02:39,834] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 8.720 seconds
[2019-10-05 06:02:51,144] {{logging_mixin.py:95}} INFO - [2019-10-05 06:02:51,144] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:02:51,149] {{jobs.py:386}} INFO - Started process (PID=7420) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:02:51,452] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:02:51,453] {{logging_mixin.py:95}} INFO - [2019-10-05 06:02:51,453] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:02:51,502] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:02:51,768] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:02:51,773] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:02:51,781] {{logging_mixin.py:95}} INFO - [2019-10-05 06:02:51,781] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:02:51,782] {{logging_mixin.py:95}} INFO - [2019-10-05 06:02:51,781] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:57:51.781455+00:00
[2019-10-05 06:02:51,787] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.638 seconds
[2019-10-05 06:03:02,312] {{logging_mixin.py:95}} INFO - [2019-10-05 06:03:02,312] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:03:02,316] {{jobs.py:386}} INFO - Started process (PID=7430) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:03:02,318] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:03:02,320] {{logging_mixin.py:95}} INFO - [2019-10-05 06:03:02,319] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:03:02,382] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:03:06,035] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:03:06,042] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:03:06,052] {{logging_mixin.py:95}} INFO - [2019-10-05 06:03:06,052] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:03:06,054] {{logging_mixin.py:95}} INFO - [2019-10-05 06:03:06,053] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:58:06.053306+00:00
[2019-10-05 06:03:06,062] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.746 seconds
[2019-10-05 06:03:18,610] {{logging_mixin.py:95}} INFO - [2019-10-05 06:03:18,610] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:03:18,902] {{jobs.py:386}} INFO - Started process (PID=7434) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:03:19,160] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:03:19,161] {{logging_mixin.py:95}} INFO - [2019-10-05 06:03:19,161] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:03:21,324] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:03:30,593] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:03:30,998] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:03:31,007] {{logging_mixin.py:95}} INFO - [2019-10-05 06:03:31,007] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:03:31,009] {{logging_mixin.py:95}} INFO - [2019-10-05 06:03:31,008] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:58:31.008404+00:00
[2019-10-05 06:03:32,961] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 14.059 seconds
[2019-10-05 06:03:46,525] {{logging_mixin.py:95}} INFO - [2019-10-05 06:03:46,525] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:03:46,717] {{jobs.py:386}} INFO - Started process (PID=7438) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:03:47,675] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:03:47,675] {{logging_mixin.py:95}} INFO - [2019-10-05 06:03:47,675] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:03:49,347] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:03:56,611] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:03:57,395] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:03:57,402] {{logging_mixin.py:95}} INFO - [2019-10-05 06:03:57,402] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:03:57,404] {{logging_mixin.py:95}} INFO - [2019-10-05 06:03:57,403] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:58:57.403447+00:00
[2019-10-05 06:03:58,474] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 11.757 seconds
[2019-10-05 06:04:14,990] {{logging_mixin.py:95}} INFO - [2019-10-05 06:04:14,990] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:04:15,325] {{jobs.py:386}} INFO - Started process (PID=7448) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:04:16,714] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:04:16,715] {{logging_mixin.py:95}} INFO - [2019-10-05 06:04:16,715] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:04:19,123] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:04:29,779] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:04:30,019] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:04:30,039] {{logging_mixin.py:95}} INFO - [2019-10-05 06:04:30,039] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:04:30,040] {{logging_mixin.py:95}} INFO - [2019-10-05 06:04:30,040] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:59:30.040006+00:00
[2019-10-05 06:04:30,918] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 15.594 seconds
[2019-10-05 06:04:42,068] {{logging_mixin.py:95}} INFO - [2019-10-05 06:04:42,068] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:04:42,107] {{jobs.py:386}} INFO - Started process (PID=7458) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:04:42,190] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:04:42,191] {{logging_mixin.py:95}} INFO - [2019-10-05 06:04:42,191] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:04:42,484] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:04:43,122] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:04:43,176] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:04:43,184] {{logging_mixin.py:95}} INFO - [2019-10-05 06:04:43,184] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:04:43,185] {{logging_mixin.py:95}} INFO - [2019-10-05 06:04:43,185] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:59:43.185339+00:00
[2019-10-05 06:04:43,193] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.085 seconds
[2019-10-05 06:04:54,339] {{logging_mixin.py:95}} INFO - [2019-10-05 06:04:54,339] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:04:54,375] {{jobs.py:386}} INFO - Started process (PID=7462) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:04:54,376] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:04:54,377] {{logging_mixin.py:95}} INFO - [2019-10-05 06:04:54,377] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:04:54,391] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:04:56,602] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:04:56,607] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:04:56,615] {{logging_mixin.py:95}} INFO - [2019-10-05 06:04:56,615] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:04:56,616] {{logging_mixin.py:95}} INFO - [2019-10-05 06:04:56,615] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 05:59:56.615802+00:00
[2019-10-05 06:04:56,626] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.251 seconds
[2019-10-05 06:05:07,846] {{logging_mixin.py:95}} INFO - [2019-10-05 06:05:07,846] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:05:07,850] {{jobs.py:386}} INFO - Started process (PID=7466) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:05:08,008] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:05:08,009] {{logging_mixin.py:95}} INFO - [2019-10-05 06:05:08,009] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:05:08,029] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:05:08,246] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:05:08,252] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:05:08,261] {{logging_mixin.py:95}} INFO - [2019-10-05 06:05:08,260] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:05:08,262] {{logging_mixin.py:95}} INFO - [2019-10-05 06:05:08,261] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:00:08.261829+00:00
[2019-10-05 06:05:08,270] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.420 seconds
[2019-10-05 06:05:19,721] {{logging_mixin.py:95}} INFO - [2019-10-05 06:05:19,720] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:05:19,724] {{jobs.py:386}} INFO - Started process (PID=7475) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:05:19,771] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:05:19,772] {{logging_mixin.py:95}} INFO - [2019-10-05 06:05:19,771] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:05:20,045] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:05:24,017] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:05:24,174] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:05:24,182] {{logging_mixin.py:95}} INFO - [2019-10-05 06:05:24,182] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:05:24,183] {{logging_mixin.py:95}} INFO - [2019-10-05 06:05:24,183] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:00:24.183038+00:00
[2019-10-05 06:05:24,189] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.465 seconds
[2019-10-05 06:05:35,384] {{logging_mixin.py:95}} INFO - [2019-10-05 06:05:35,382] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:05:35,399] {{jobs.py:386}} INFO - Started process (PID=7479) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:05:35,402] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:05:35,404] {{logging_mixin.py:95}} INFO - [2019-10-05 06:05:35,404] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:05:35,427] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:05:35,562] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:05:35,570] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:05:35,601] {{logging_mixin.py:95}} INFO - [2019-10-05 06:05:35,601] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:05:35,793] {{logging_mixin.py:95}} INFO - [2019-10-05 06:05:35,792] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:00:35.792927+00:00
[2019-10-05 06:05:35,800] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.401 seconds
[2019-10-05 06:05:46,813] {{logging_mixin.py:95}} INFO - [2019-10-05 06:05:46,813] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:05:46,816] {{jobs.py:386}} INFO - Started process (PID=7483) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:05:46,821] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:05:46,822] {{logging_mixin.py:95}} INFO - [2019-10-05 06:05:46,822] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:05:46,868] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:05:48,007] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:05:48,013] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:05:48,089] {{logging_mixin.py:95}} INFO - [2019-10-05 06:05:48,089] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:05:48,091] {{logging_mixin.py:95}} INFO - [2019-10-05 06:05:48,090] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:00:48.090770+00:00
[2019-10-05 06:05:48,099] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.283 seconds
[2019-10-05 06:05:59,319] {{logging_mixin.py:95}} INFO - [2019-10-05 06:05:59,318] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:05:59,429] {{jobs.py:386}} INFO - Started process (PID=7492) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:05:59,498] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:05:59,499] {{logging_mixin.py:95}} INFO - [2019-10-05 06:05:59,499] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:05:59,589] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:05:59,783] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:05:59,789] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:05:59,798] {{logging_mixin.py:95}} INFO - [2019-10-05 06:05:59,798] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:05:59,800] {{logging_mixin.py:95}} INFO - [2019-10-05 06:05:59,799] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:00:59.799153+00:00
[2019-10-05 06:05:59,809] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.379 seconds
[2019-10-05 06:06:12,075] {{logging_mixin.py:95}} INFO - [2019-10-05 06:06:12,075] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:06:12,161] {{jobs.py:386}} INFO - Started process (PID=7496) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:06:13,443] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:06:13,444] {{logging_mixin.py:95}} INFO - [2019-10-05 06:06:13,444] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:06:15,216] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:06:22,518] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:06:22,539] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:06:22,548] {{logging_mixin.py:95}} INFO - [2019-10-05 06:06:22,548] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:06:22,550] {{logging_mixin.py:95}} INFO - [2019-10-05 06:06:22,549] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:01:22.549608+00:00
[2019-10-05 06:06:23,316] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 11.155 seconds
[2019-10-05 06:06:35,234] {{logging_mixin.py:95}} INFO - [2019-10-05 06:06:35,233] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:06:35,327] {{jobs.py:386}} INFO - Started process (PID=7505) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:06:35,425] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:06:35,426] {{logging_mixin.py:95}} INFO - [2019-10-05 06:06:35,426] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:06:35,516] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:06:35,661] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:06:35,667] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:06:35,674] {{logging_mixin.py:95}} INFO - [2019-10-05 06:06:35,673] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:06:35,676] {{logging_mixin.py:95}} INFO - [2019-10-05 06:06:35,674] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:01:35.674900+00:00
[2019-10-05 06:06:35,683] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.356 seconds
[2019-10-05 06:06:46,905] {{logging_mixin.py:95}} INFO - [2019-10-05 06:06:46,902] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:06:47,085] {{jobs.py:386}} INFO - Started process (PID=7509) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:06:47,102] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:06:47,103] {{logging_mixin.py:95}} INFO - [2019-10-05 06:06:47,103] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:06:47,322] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:06:49,041] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:06:49,047] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:06:49,083] {{logging_mixin.py:95}} INFO - [2019-10-05 06:06:49,083] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:06:49,084] {{logging_mixin.py:95}} INFO - [2019-10-05 06:06:49,084] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:01:49.084181+00:00
[2019-10-05 06:06:49,196] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.111 seconds
[2019-10-05 06:07:00,744] {{logging_mixin.py:95}} INFO - [2019-10-05 06:07:00,743] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:07:00,894] {{jobs.py:386}} INFO - Started process (PID=7513) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:07:00,896] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:07:00,898] {{logging_mixin.py:95}} INFO - [2019-10-05 06:07:00,898] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:07:01,298] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:07:02,569] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:07:02,577] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:07:02,586] {{logging_mixin.py:95}} INFO - [2019-10-05 06:07:02,586] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:07:02,588] {{logging_mixin.py:95}} INFO - [2019-10-05 06:07:02,587] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:02:02.587672+00:00
[2019-10-05 06:07:02,597] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.703 seconds
[2019-10-05 06:07:15,282] {{logging_mixin.py:95}} INFO - [2019-10-05 06:07:15,082] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:07:15,542] {{jobs.py:386}} INFO - Started process (PID=7522) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:07:15,861] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:07:15,862] {{logging_mixin.py:95}} INFO - [2019-10-05 06:07:15,862] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:07:16,546] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:07:29,614] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:07:30,462] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:07:30,471] {{logging_mixin.py:95}} INFO - [2019-10-05 06:07:30,471] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:07:30,472] {{logging_mixin.py:95}} INFO - [2019-10-05 06:07:30,471] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:02:30.471827+00:00
[2019-10-05 06:07:31,030] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 15.489 seconds
[2019-10-05 06:07:42,633] {{logging_mixin.py:95}} INFO - [2019-10-05 06:07:42,632] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:07:42,809] {{jobs.py:386}} INFO - Started process (PID=7526) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:07:43,472] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:07:43,473] {{logging_mixin.py:95}} INFO - [2019-10-05 06:07:43,473] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:07:45,032] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:07:48,530] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:07:48,693] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:07:48,702] {{logging_mixin.py:95}} INFO - [2019-10-05 06:07:48,702] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:07:48,703] {{logging_mixin.py:95}} INFO - [2019-10-05 06:07:48,702] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:02:48.702673+00:00
[2019-10-05 06:07:48,710] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.901 seconds
[2019-10-05 06:08:00,626] {{logging_mixin.py:95}} INFO - [2019-10-05 06:08:00,609] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:08:00,666] {{jobs.py:386}} INFO - Started process (PID=7531) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:08:01,842] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:08:01,843] {{logging_mixin.py:95}} INFO - [2019-10-05 06:08:01,843] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:08:04,094] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:08:08,572] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:08:08,667] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:08:08,676] {{logging_mixin.py:95}} INFO - [2019-10-05 06:08:08,676] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:08:08,677] {{logging_mixin.py:95}} INFO - [2019-10-05 06:08:08,677] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:03:08.677403+00:00
[2019-10-05 06:08:08,685] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 8.018 seconds
[2019-10-05 06:08:20,447] {{logging_mixin.py:95}} INFO - [2019-10-05 06:08:20,447] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:08:20,606] {{jobs.py:386}} INFO - Started process (PID=7534) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:08:21,037] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:08:21,037] {{logging_mixin.py:95}} INFO - [2019-10-05 06:08:21,037] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:08:24,293] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:08:33,563] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:08:33,575] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:08:33,584] {{logging_mixin.py:95}} INFO - [2019-10-05 06:08:33,584] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:08:33,586] {{logging_mixin.py:95}} INFO - [2019-10-05 06:08:33,585] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:03:33.585306+00:00
[2019-10-05 06:08:33,593] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 12.988 seconds
[2019-10-05 06:08:45,041] {{logging_mixin.py:95}} INFO - [2019-10-05 06:08:45,041] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:08:45,045] {{jobs.py:386}} INFO - Started process (PID=7547) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:08:45,048] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:08:45,054] {{logging_mixin.py:95}} INFO - [2019-10-05 06:08:45,053] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:08:45,081] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:08:45,466] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:08:45,472] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:08:45,480] {{logging_mixin.py:95}} INFO - [2019-10-05 06:08:45,480] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:08:45,481] {{logging_mixin.py:95}} INFO - [2019-10-05 06:08:45,480] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:03:45.480762+00:00
[2019-10-05 06:08:45,488] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.443 seconds
[2019-10-05 06:08:56,576] {{logging_mixin.py:95}} INFO - [2019-10-05 06:08:56,576] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:08:56,581] {{jobs.py:386}} INFO - Started process (PID=7551) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:08:56,696] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:08:56,697] {{logging_mixin.py:95}} INFO - [2019-10-05 06:08:56,697] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:08:57,494] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:08:58,207] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:08:58,214] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:08:58,235] {{logging_mixin.py:95}} INFO - [2019-10-05 06:08:58,235] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:08:58,236] {{logging_mixin.py:95}} INFO - [2019-10-05 06:08:58,236] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:03:58.236289+00:00
[2019-10-05 06:08:58,252] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.671 seconds
[2019-10-05 06:09:08,826] {{logging_mixin.py:95}} INFO - [2019-10-05 06:09:08,826] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:09:08,829] {{jobs.py:386}} INFO - Started process (PID=7560) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:09:08,837] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:09:08,840] {{logging_mixin.py:95}} INFO - [2019-10-05 06:09:08,840] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:09:08,871] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:09:10,639] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:09:10,739] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:09:10,748] {{logging_mixin.py:95}} INFO - [2019-10-05 06:09:10,748] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:09:10,749] {{logging_mixin.py:95}} INFO - [2019-10-05 06:09:10,748] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:04:10.748828+00:00
[2019-10-05 06:09:10,756] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.927 seconds
[2019-10-05 06:09:22,586] {{logging_mixin.py:95}} INFO - [2019-10-05 06:09:22,585] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:09:22,713] {{jobs.py:386}} INFO - Started process (PID=7564) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:09:22,986] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:09:22,987] {{logging_mixin.py:95}} INFO - [2019-10-05 06:09:22,987] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:09:24,218] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:09:28,492] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:09:28,498] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:09:28,505] {{logging_mixin.py:95}} INFO - [2019-10-05 06:09:28,505] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:09:28,506] {{logging_mixin.py:95}} INFO - [2019-10-05 06:09:28,505] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:04:28.505651+00:00
[2019-10-05 06:09:28,647] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.934 seconds
[2019-10-05 06:09:39,882] {{logging_mixin.py:95}} INFO - [2019-10-05 06:09:39,882] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:09:39,921] {{jobs.py:386}} INFO - Started process (PID=7568) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:09:39,948] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:09:39,949] {{logging_mixin.py:95}} INFO - [2019-10-05 06:09:39,949] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:09:39,991] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:09:40,096] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:09:40,127] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:09:40,136] {{logging_mixin.py:95}} INFO - [2019-10-05 06:09:40,136] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:09:40,137] {{logging_mixin.py:95}} INFO - [2019-10-05 06:09:40,137] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:04:40.137283+00:00
[2019-10-05 06:09:40,147] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.227 seconds
[2019-10-05 06:09:52,593] {{logging_mixin.py:95}} INFO - [2019-10-05 06:09:52,553] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:09:52,741] {{jobs.py:386}} INFO - Started process (PID=7577) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:09:53,349] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:09:53,351] {{logging_mixin.py:95}} INFO - [2019-10-05 06:09:53,350] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:09:55,965] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:09:58,055] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:09:58,128] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:09:58,137] {{logging_mixin.py:95}} INFO - [2019-10-05 06:09:58,137] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:09:58,139] {{logging_mixin.py:95}} INFO - [2019-10-05 06:09:58,139] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:04:58.138992+00:00
[2019-10-05 06:09:58,145] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.404 seconds
[2019-10-05 06:10:09,754] {{logging_mixin.py:95}} INFO - [2019-10-05 06:10:09,754] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:10:09,893] {{jobs.py:386}} INFO - Started process (PID=7581) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:10:10,432] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:10:10,436] {{logging_mixin.py:95}} INFO - [2019-10-05 06:10:10,434] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:10:10,863] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:10:12,754] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:10:12,853] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:10:12,864] {{logging_mixin.py:95}} INFO - [2019-10-05 06:10:12,864] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:10:12,865] {{logging_mixin.py:95}} INFO - [2019-10-05 06:10:12,864] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:05:12.864957+00:00
[2019-10-05 06:10:12,874] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.981 seconds
[2019-10-05 06:10:25,028] {{logging_mixin.py:95}} INFO - [2019-10-05 06:10:25,028] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:10:25,105] {{jobs.py:386}} INFO - Started process (PID=7585) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:10:25,694] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:10:25,695] {{logging_mixin.py:95}} INFO - [2019-10-05 06:10:25,695] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:10:29,213] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:10:46,921] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 06:11:10,447] {{logging_mixin.py:95}} INFO - [2019-10-05 06:11:10,290] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:11:10,665] {{jobs.py:386}} INFO - Started process (PID=7592) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:11:11,275] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:11:11,277] {{logging_mixin.py:95}} INFO - [2019-10-05 06:11:11,277] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:11:14,655] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:11:28,966] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 06:11:52,463] {{logging_mixin.py:95}} INFO - [2019-10-05 06:11:52,463] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:11:52,630] {{jobs.py:386}} INFO - Started process (PID=7594) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:11:53,279] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:11:53,280] {{logging_mixin.py:95}} INFO - [2019-10-05 06:11:53,280] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:11:55,252] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:12:23,641] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:12:24,468] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:12:24,478] {{logging_mixin.py:95}} INFO - [2019-10-05 06:12:24,477] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:12:24,480] {{logging_mixin.py:95}} INFO - [2019-10-05 06:12:24,479] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:07:24.478970+00:00
[2019-10-05 06:12:25,298] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 32.668 seconds
[2019-10-05 06:12:39,294] {{logging_mixin.py:95}} INFO - [2019-10-05 06:12:39,204] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:12:39,611] {{jobs.py:386}} INFO - Started process (PID=7598) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:12:41,088] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:12:41,089] {{logging_mixin.py:95}} INFO - [2019-10-05 06:12:41,089] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:12:43,869] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:13:02,088] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:13:03,537] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:13:03,578] {{logging_mixin.py:95}} INFO - [2019-10-05 06:13:03,578] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:13:03,580] {{logging_mixin.py:95}} INFO - [2019-10-05 06:13:03,579] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:08:03.579522+00:00
[2019-10-05 06:13:06,140] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 26.529 seconds
[2019-10-05 06:13:27,261] {{logging_mixin.py:95}} INFO - [2019-10-05 06:13:26,442] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:13:28,155] {{jobs.py:386}} INFO - Started process (PID=7602) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:13:30,815] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:13:30,816] {{logging_mixin.py:95}} INFO - [2019-10-05 06:13:30,816] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:13:35,355] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:13:39,095] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:13:39,102] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:13:39,111] {{logging_mixin.py:95}} INFO - [2019-10-05 06:13:39,111] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:13:39,112] {{logging_mixin.py:95}} INFO - [2019-10-05 06:13:39,112] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:08:39.112101+00:00
[2019-10-05 06:13:39,119] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 10.963 seconds
[2019-10-05 06:13:50,691] {{logging_mixin.py:95}} INFO - [2019-10-05 06:13:50,690] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:13:50,694] {{jobs.py:386}} INFO - Started process (PID=7606) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:13:50,699] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:13:50,701] {{logging_mixin.py:95}} INFO - [2019-10-05 06:13:50,701] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:13:50,730] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:13:50,961] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:13:50,966] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:13:50,977] {{logging_mixin.py:95}} INFO - [2019-10-05 06:13:50,977] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:13:50,978] {{logging_mixin.py:95}} INFO - [2019-10-05 06:13:50,978] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:08:50.978110+00:00
[2019-10-05 06:13:50,986] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.293 seconds
[2019-10-05 06:14:02,563] {{logging_mixin.py:95}} INFO - [2019-10-05 06:14:02,563] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:14:02,566] {{jobs.py:386}} INFO - Started process (PID=7610) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:14:02,568] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:14:02,569] {{logging_mixin.py:95}} INFO - [2019-10-05 06:14:02,569] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:14:02,594] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:14:03,157] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:14:03,164] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:14:03,172] {{logging_mixin.py:95}} INFO - [2019-10-05 06:14:03,172] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:14:03,174] {{logging_mixin.py:95}} INFO - [2019-10-05 06:14:03,174] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:09:03.174210+00:00
[2019-10-05 06:14:03,180] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.614 seconds
[2019-10-05 06:14:13,915] {{logging_mixin.py:95}} INFO - [2019-10-05 06:14:13,915] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:14:13,974] {{jobs.py:386}} INFO - Started process (PID=7619) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:14:14,043] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:14:14,045] {{logging_mixin.py:95}} INFO - [2019-10-05 06:14:14,045] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:14:14,396] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:14:15,500] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:14:15,569] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:14:15,577] {{logging_mixin.py:95}} INFO - [2019-10-05 06:14:15,577] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:14:15,578] {{logging_mixin.py:95}} INFO - [2019-10-05 06:14:15,577] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:09:15.577577+00:00
[2019-10-05 06:14:15,588] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.614 seconds
[2019-10-05 06:14:26,546] {{logging_mixin.py:95}} INFO - [2019-10-05 06:14:26,546] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:14:26,550] {{jobs.py:386}} INFO - Started process (PID=7623) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:14:26,816] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:14:26,817] {{logging_mixin.py:95}} INFO - [2019-10-05 06:14:26,817] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:14:27,028] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:14:31,069] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:14:31,217] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:14:31,226] {{logging_mixin.py:95}} INFO - [2019-10-05 06:14:31,226] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:14:31,228] {{logging_mixin.py:95}} INFO - [2019-10-05 06:14:31,227] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:09:31.227548+00:00
[2019-10-05 06:14:31,235] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.685 seconds
[2019-10-05 06:14:42,266] {{logging_mixin.py:95}} INFO - [2019-10-05 06:14:42,266] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:14:42,270] {{jobs.py:386}} INFO - Started process (PID=7632) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:14:42,276] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:14:42,277] {{logging_mixin.py:95}} INFO - [2019-10-05 06:14:42,277] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:14:42,303] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:14:42,551] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:14:42,558] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:14:42,568] {{logging_mixin.py:95}} INFO - [2019-10-05 06:14:42,568] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:14:42,569] {{logging_mixin.py:95}} INFO - [2019-10-05 06:14:42,569] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:09:42.569144+00:00
[2019-10-05 06:14:42,578] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.308 seconds
[2019-10-05 06:14:53,849] {{logging_mixin.py:95}} INFO - [2019-10-05 06:14:53,848] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:14:53,872] {{jobs.py:386}} INFO - Started process (PID=7636) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:14:54,578] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:14:54,579] {{logging_mixin.py:95}} INFO - [2019-10-05 06:14:54,578] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:14:56,424] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:14:58,855] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:14:59,024] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:14:59,031] {{logging_mixin.py:95}} INFO - [2019-10-05 06:14:59,031] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:14:59,032] {{logging_mixin.py:95}} INFO - [2019-10-05 06:14:59,032] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:09:59.032069+00:00
[2019-10-05 06:14:59,040] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.168 seconds
[2019-10-05 06:15:13,014] {{logging_mixin.py:95}} INFO - [2019-10-05 06:15:12,933] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:15:13,046] {{jobs.py:386}} INFO - Started process (PID=7640) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:15:13,560] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:15:13,561] {{logging_mixin.py:95}} INFO - [2019-10-05 06:15:13,561] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:15:15,601] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:15:21,679] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:15:21,831] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:15:21,986] {{logging_mixin.py:95}} INFO - [2019-10-05 06:15:21,986] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:15:21,987] {{logging_mixin.py:95}} INFO - [2019-10-05 06:15:21,987] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:10:21.987011+00:00
[2019-10-05 06:15:21,994] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 8.948 seconds
[2019-10-05 06:15:35,119] {{logging_mixin.py:95}} INFO - [2019-10-05 06:15:34,903] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:15:35,268] {{jobs.py:386}} INFO - Started process (PID=7649) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:15:37,143] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:15:37,144] {{logging_mixin.py:95}} INFO - [2019-10-05 06:15:37,144] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:15:39,657] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:15:52,676] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:15:52,705] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:15:52,714] {{logging_mixin.py:95}} INFO - [2019-10-05 06:15:52,714] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:15:52,716] {{logging_mixin.py:95}} INFO - [2019-10-05 06:15:52,715] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:10:52.715790+00:00
[2019-10-05 06:15:53,272] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 18.003 seconds
[2019-10-05 06:16:06,379] {{logging_mixin.py:95}} INFO - [2019-10-05 06:16:06,215] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:16:07,011] {{jobs.py:386}} INFO - Started process (PID=7658) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:16:07,965] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:16:07,967] {{logging_mixin.py:95}} INFO - [2019-10-05 06:16:07,967] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:16:13,806] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:16:37,449] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:16:38,229] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:16:38,240] {{logging_mixin.py:95}} INFO - [2019-10-05 06:16:38,240] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:16:38,241] {{logging_mixin.py:95}} INFO - [2019-10-05 06:16:38,241] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:11:38.241262+00:00
[2019-10-05 06:16:38,656] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 31.645 seconds
[2019-10-05 06:16:50,135] {{logging_mixin.py:95}} INFO - [2019-10-05 06:16:50,134] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:16:50,217] {{jobs.py:386}} INFO - Started process (PID=7662) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:16:50,467] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:16:50,468] {{logging_mixin.py:95}} INFO - [2019-10-05 06:16:50,468] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:16:51,450] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:16:53,744] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:16:53,843] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:16:53,849] {{logging_mixin.py:95}} INFO - [2019-10-05 06:16:53,849] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:16:53,851] {{logging_mixin.py:95}} INFO - [2019-10-05 06:16:53,850] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:11:53.850918+00:00
[2019-10-05 06:16:53,858] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.641 seconds
[2019-10-05 06:17:04,524] {{logging_mixin.py:95}} INFO - [2019-10-05 06:17:04,523] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:17:04,528] {{jobs.py:386}} INFO - Started process (PID=7671) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:17:04,534] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:17:04,538] {{logging_mixin.py:95}} INFO - [2019-10-05 06:17:04,535] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:17:04,575] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:17:04,663] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:17:04,669] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:17:04,681] {{logging_mixin.py:95}} INFO - [2019-10-05 06:17:04,681] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:17:04,683] {{logging_mixin.py:95}} INFO - [2019-10-05 06:17:04,682] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:12:04.682293+00:00
[2019-10-05 06:17:04,693] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.165 seconds
[2019-10-05 06:17:15,936] {{logging_mixin.py:95}} INFO - [2019-10-05 06:17:15,936] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:17:16,041] {{jobs.py:386}} INFO - Started process (PID=7675) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:17:16,249] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:17:16,250] {{logging_mixin.py:95}} INFO - [2019-10-05 06:17:16,250] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:17:16,423] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:17:18,225] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:17:18,307] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:17:18,325] {{logging_mixin.py:95}} INFO - [2019-10-05 06:17:18,325] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:17:18,326] {{logging_mixin.py:95}} INFO - [2019-10-05 06:17:18,325] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:12:18.325924+00:00
[2019-10-05 06:17:18,332] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.291 seconds
[2019-10-05 06:17:29,321] {{logging_mixin.py:95}} INFO - [2019-10-05 06:17:29,321] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:17:29,325] {{jobs.py:386}} INFO - Started process (PID=7679) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:17:29,328] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:17:29,329] {{logging_mixin.py:95}} INFO - [2019-10-05 06:17:29,329] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:17:29,369] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:17:30,002] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:17:30,008] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:17:30,019] {{logging_mixin.py:95}} INFO - [2019-10-05 06:17:30,018] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:17:30,020] {{logging_mixin.py:95}} INFO - [2019-10-05 06:17:30,020] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:12:30.020107+00:00
[2019-10-05 06:17:30,028] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.703 seconds
[2019-10-05 06:17:41,444] {{logging_mixin.py:95}} INFO - [2019-10-05 06:17:41,444] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:17:41,515] {{jobs.py:386}} INFO - Started process (PID=7691) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:17:42,131] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:17:42,133] {{logging_mixin.py:95}} INFO - [2019-10-05 06:17:42,133] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:17:43,119] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:17:48,165] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:17:48,200] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:17:48,208] {{logging_mixin.py:95}} INFO - [2019-10-05 06:17:48,208] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:17:48,209] {{logging_mixin.py:95}} INFO - [2019-10-05 06:17:48,208] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:12:48.208901+00:00
[2019-10-05 06:17:48,217] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 6.702 seconds
[2019-10-05 06:17:58,822] {{logging_mixin.py:95}} INFO - [2019-10-05 06:17:58,822] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:17:58,872] {{jobs.py:386}} INFO - Started process (PID=7695) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:17:58,879] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:17:58,880] {{logging_mixin.py:95}} INFO - [2019-10-05 06:17:58,879] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:17:58,911] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:17:59,402] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:17:59,407] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:17:59,418] {{logging_mixin.py:95}} INFO - [2019-10-05 06:17:59,417] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:17:59,418] {{logging_mixin.py:95}} INFO - [2019-10-05 06:17:59,418] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:12:59.418318+00:00
[2019-10-05 06:17:59,427] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.555 seconds
[2019-10-05 06:18:10,100] {{logging_mixin.py:95}} INFO - [2019-10-05 06:18:10,100] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:18:10,103] {{jobs.py:386}} INFO - Started process (PID=7704) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:18:10,140] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:18:10,141] {{logging_mixin.py:95}} INFO - [2019-10-05 06:18:10,141] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:18:10,160] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:18:11,346] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:18:11,400] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:18:11,408] {{logging_mixin.py:95}} INFO - [2019-10-05 06:18:11,408] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:18:11,409] {{logging_mixin.py:95}} INFO - [2019-10-05 06:18:11,409] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:13:11.409070+00:00
[2019-10-05 06:18:11,478] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.374 seconds
[2019-10-05 06:18:23,081] {{logging_mixin.py:95}} INFO - [2019-10-05 06:18:23,080] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:18:23,179] {{jobs.py:386}} INFO - Started process (PID=7708) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:18:24,177] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:18:24,178] {{logging_mixin.py:95}} INFO - [2019-10-05 06:18:24,178] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:18:25,977] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:18:34,091] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:18:34,164] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:18:34,251] {{logging_mixin.py:95}} INFO - [2019-10-05 06:18:34,251] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:18:34,252] {{logging_mixin.py:95}} INFO - [2019-10-05 06:18:34,251] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:13:34.251848+00:00
[2019-10-05 06:18:34,306] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 11.127 seconds
[2019-10-05 06:18:46,613] {{logging_mixin.py:95}} INFO - [2019-10-05 06:18:46,613] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:18:46,661] {{jobs.py:386}} INFO - Started process (PID=7718) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:18:46,877] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:18:46,877] {{logging_mixin.py:95}} INFO - [2019-10-05 06:18:46,877] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:18:46,999] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:18:48,603] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:18:48,611] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:18:48,620] {{logging_mixin.py:95}} INFO - [2019-10-05 06:18:48,620] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:18:48,620] {{logging_mixin.py:95}} INFO - [2019-10-05 06:18:48,620] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:13:48.620474+00:00
[2019-10-05 06:18:48,631] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.970 seconds
[2019-10-05 06:19:00,354] {{logging_mixin.py:95}} INFO - [2019-10-05 06:19:00,354] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:19:00,358] {{jobs.py:386}} INFO - Started process (PID=7722) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:19:00,900] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:19:00,904] {{logging_mixin.py:95}} INFO - [2019-10-05 06:19:00,904] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:19:01,393] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:19:01,784] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:19:02,021] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:19:02,031] {{logging_mixin.py:95}} INFO - [2019-10-05 06:19:02,031] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:19:02,033] {{logging_mixin.py:95}} INFO - [2019-10-05 06:19:02,032] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:14:02.032474+00:00
[2019-10-05 06:19:02,039] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.681 seconds
[2019-10-05 06:19:15,618] {{logging_mixin.py:95}} INFO - [2019-10-05 06:19:15,454] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:19:15,802] {{jobs.py:386}} INFO - Started process (PID=7726) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:19:16,833] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:19:16,834] {{logging_mixin.py:95}} INFO - [2019-10-05 06:19:16,834] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:19:19,599] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:19:34,036] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:19:35,147] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:19:35,229] {{logging_mixin.py:95}} INFO - [2019-10-05 06:19:35,229] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:19:35,231] {{logging_mixin.py:95}} INFO - [2019-10-05 06:19:35,230] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:14:35.230650+00:00
[2019-10-05 06:19:36,297] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 20.495 seconds
[2019-10-05 06:19:50,483] {{logging_mixin.py:95}} INFO - [2019-10-05 06:19:50,483] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:19:50,850] {{jobs.py:386}} INFO - Started process (PID=7735) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:19:51,678] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:19:51,680] {{logging_mixin.py:95}} INFO - [2019-10-05 06:19:51,680] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:19:53,863] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:20:14,868] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 06:20:55,481] {{logging_mixin.py:95}} INFO - [2019-10-05 06:20:55,480] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:20:55,681] {{jobs.py:386}} INFO - Started process (PID=7737) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:20:56,437] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:20:56,437] {{logging_mixin.py:95}} INFO - [2019-10-05 06:20:56,437] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:20:58,653] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:21:00,364] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:21:00,397] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:21:00,405] {{logging_mixin.py:95}} INFO - [2019-10-05 06:21:00,405] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:21:00,406] {{logging_mixin.py:95}} INFO - [2019-10-05 06:21:00,405] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:16:00.405617+00:00
[2019-10-05 06:21:00,508] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.826 seconds
[2019-10-05 06:21:12,284] {{logging_mixin.py:95}} INFO - [2019-10-05 06:21:12,284] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:21:12,288] {{jobs.py:386}} INFO - Started process (PID=7741) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:21:12,579] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:21:12,580] {{logging_mixin.py:95}} INFO - [2019-10-05 06:21:12,580] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:21:12,786] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:21:14,384] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:21:14,392] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:21:14,410] {{logging_mixin.py:95}} INFO - [2019-10-05 06:21:14,409] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:21:14,411] {{logging_mixin.py:95}} INFO - [2019-10-05 06:21:14,410] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:16:14.410715+00:00
[2019-10-05 06:21:14,422] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.134 seconds
[2019-10-05 06:21:26,243] {{logging_mixin.py:95}} INFO - [2019-10-05 06:21:26,243] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:21:26,272] {{jobs.py:386}} INFO - Started process (PID=7750) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:21:26,419] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:21:26,420] {{logging_mixin.py:95}} INFO - [2019-10-05 06:21:26,420] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:21:26,931] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:21:32,315] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:21:32,415] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:21:32,422] {{logging_mixin.py:95}} INFO - [2019-10-05 06:21:32,422] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:21:32,424] {{logging_mixin.py:95}} INFO - [2019-10-05 06:21:32,423] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:16:32.423585+00:00
[2019-10-05 06:21:32,431] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 6.159 seconds
[2019-10-05 06:21:43,725] {{logging_mixin.py:95}} INFO - [2019-10-05 06:21:43,656] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:21:43,812] {{jobs.py:386}} INFO - Started process (PID=7754) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:21:44,552] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:21:44,553] {{logging_mixin.py:95}} INFO - [2019-10-05 06:21:44,553] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:21:45,831] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:21:48,430] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:21:48,495] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:21:48,527] {{logging_mixin.py:95}} INFO - [2019-10-05 06:21:48,527] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:21:48,527] {{logging_mixin.py:95}} INFO - [2019-10-05 06:21:48,527] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:16:48.527317+00:00
[2019-10-05 06:21:48,558] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.746 seconds
[2019-10-05 06:21:59,711] {{logging_mixin.py:95}} INFO - [2019-10-05 06:21:59,710] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:21:59,715] {{jobs.py:386}} INFO - Started process (PID=7763) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:21:59,717] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:21:59,721] {{logging_mixin.py:95}} INFO - [2019-10-05 06:21:59,720] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:21:59,759] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:22:00,157] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:22:00,162] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:22:00,171] {{logging_mixin.py:95}} INFO - [2019-10-05 06:22:00,171] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:22:00,172] {{logging_mixin.py:95}} INFO - [2019-10-05 06:22:00,172] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:17:00.172310+00:00
[2019-10-05 06:22:00,180] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.465 seconds
[2019-10-05 06:22:12,303] {{logging_mixin.py:95}} INFO - [2019-10-05 06:22:12,256] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:22:12,419] {{jobs.py:386}} INFO - Started process (PID=7767) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:22:12,733] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:22:12,734] {{logging_mixin.py:95}} INFO - [2019-10-05 06:22:12,734] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:22:14,196] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:22:22,236] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:22:22,289] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:22:22,297] {{logging_mixin.py:95}} INFO - [2019-10-05 06:22:22,297] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:22:22,298] {{logging_mixin.py:95}} INFO - [2019-10-05 06:22:22,298] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:17:22.298294+00:00
[2019-10-05 06:22:22,315] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 9.896 seconds
[2019-10-05 06:22:33,233] {{logging_mixin.py:95}} INFO - [2019-10-05 06:22:33,232] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:22:33,269] {{jobs.py:386}} INFO - Started process (PID=7782) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:22:33,532] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:22:33,534] {{logging_mixin.py:95}} INFO - [2019-10-05 06:22:33,533] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:22:36,514] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:22:52,471] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:22:52,613] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:22:52,621] {{logging_mixin.py:95}} INFO - [2019-10-05 06:22:52,621] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:22:52,622] {{logging_mixin.py:95}} INFO - [2019-10-05 06:22:52,622] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:17:52.622186+00:00
[2019-10-05 06:22:53,122] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 19.853 seconds
[2019-10-05 06:23:05,880] {{logging_mixin.py:95}} INFO - [2019-10-05 06:23:05,880] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:23:06,400] {{jobs.py:386}} INFO - Started process (PID=7791) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:23:06,675] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:23:06,677] {{logging_mixin.py:95}} INFO - [2019-10-05 06:23:06,677] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:23:08,738] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:23:15,540] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:23:16,018] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:23:16,025] {{logging_mixin.py:95}} INFO - [2019-10-05 06:23:16,025] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:23:16,027] {{logging_mixin.py:95}} INFO - [2019-10-05 06:23:16,026] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:18:16.026227+00:00
[2019-10-05 06:23:16,034] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 9.634 seconds
[2019-10-05 06:23:26,624] {{logging_mixin.py:95}} INFO - [2019-10-05 06:23:26,624] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:23:26,636] {{jobs.py:386}} INFO - Started process (PID=7795) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:23:27,230] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:23:27,231] {{logging_mixin.py:95}} INFO - [2019-10-05 06:23:27,231] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:23:28,345] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:23:32,149] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:23:32,299] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:23:32,307] {{logging_mixin.py:95}} INFO - [2019-10-05 06:23:32,307] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:23:32,309] {{logging_mixin.py:95}} INFO - [2019-10-05 06:23:32,308] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:18:32.308487+00:00
[2019-10-05 06:23:32,317] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.681 seconds
[2019-10-05 06:23:43,152] {{logging_mixin.py:95}} INFO - [2019-10-05 06:23:43,152] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:23:43,155] {{jobs.py:386}} INFO - Started process (PID=7799) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:23:43,159] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:23:43,160] {{logging_mixin.py:95}} INFO - [2019-10-05 06:23:43,160] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:23:43,187] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:23:43,355] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:23:43,365] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:23:43,375] {{logging_mixin.py:95}} INFO - [2019-10-05 06:23:43,375] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:23:43,376] {{logging_mixin.py:95}} INFO - [2019-10-05 06:23:43,376] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:18:43.376450+00:00
[2019-10-05 06:23:43,392] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.237 seconds
[2019-10-05 06:23:54,775] {{logging_mixin.py:95}} INFO - [2019-10-05 06:23:54,775] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:23:54,779] {{jobs.py:386}} INFO - Started process (PID=7803) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:23:55,040] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:23:55,040] {{logging_mixin.py:95}} INFO - [2019-10-05 06:23:55,040] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:23:55,795] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:23:57,564] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:23:57,699] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:23:57,707] {{logging_mixin.py:95}} INFO - [2019-10-05 06:23:57,706] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:23:57,709] {{logging_mixin.py:95}} INFO - [2019-10-05 06:23:57,708] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:18:57.708658+00:00
[2019-10-05 06:23:57,717] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.938 seconds
[2019-10-05 06:24:08,606] {{logging_mixin.py:95}} INFO - [2019-10-05 06:24:08,606] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:24:08,614] {{jobs.py:386}} INFO - Started process (PID=7812) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:24:08,616] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:24:08,618] {{logging_mixin.py:95}} INFO - [2019-10-05 06:24:08,618] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:24:08,684] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:24:08,948] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:24:08,953] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:24:08,961] {{logging_mixin.py:95}} INFO - [2019-10-05 06:24:08,960] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:24:08,962] {{logging_mixin.py:95}} INFO - [2019-10-05 06:24:08,961] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:19:08.961781+00:00
[2019-10-05 06:24:08,971] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.357 seconds
[2019-10-05 06:24:22,035] {{logging_mixin.py:95}} INFO - [2019-10-05 06:24:22,035] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:24:22,130] {{jobs.py:386}} INFO - Started process (PID=7816) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:24:23,108] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:24:23,165] {{logging_mixin.py:95}} INFO - [2019-10-05 06:24:23,164] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:24:24,930] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:24:29,406] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:24:29,456] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:24:29,466] {{logging_mixin.py:95}} INFO - [2019-10-05 06:24:29,466] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:24:29,468] {{logging_mixin.py:95}} INFO - [2019-10-05 06:24:29,467] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:19:29.467734+00:00
[2019-10-05 06:24:29,476] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 7.346 seconds
[2019-10-05 06:24:40,745] {{logging_mixin.py:95}} INFO - [2019-10-05 06:24:40,745] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:24:40,748] {{jobs.py:386}} INFO - Started process (PID=7827) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:24:40,751] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:24:40,752] {{logging_mixin.py:95}} INFO - [2019-10-05 06:24:40,752] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:24:40,769] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:24:40,923] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:24:41,089] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:24:41,096] {{logging_mixin.py:95}} INFO - [2019-10-05 06:24:41,096] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:24:41,098] {{logging_mixin.py:95}} INFO - [2019-10-05 06:24:41,097] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:19:41.097353+00:00
[2019-10-05 06:24:41,104] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.356 seconds
[2019-10-05 06:24:52,382] {{logging_mixin.py:95}} INFO - [2019-10-05 06:24:52,382] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:24:52,385] {{jobs.py:386}} INFO - Started process (PID=7830) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:24:52,397] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:24:52,398] {{logging_mixin.py:95}} INFO - [2019-10-05 06:24:52,398] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:24:52,418] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:25:02,452] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:25:02,467] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:25:02,606] {{logging_mixin.py:95}} INFO - [2019-10-05 06:25:02,606] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:25:02,607] {{logging_mixin.py:95}} INFO - [2019-10-05 06:25:02,606] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:20:02.606965+00:00
[2019-10-05 06:25:02,854] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 10.468 seconds
[2019-10-05 06:25:14,928] {{logging_mixin.py:95}} INFO - [2019-10-05 06:25:14,927] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:25:14,995] {{jobs.py:386}} INFO - Started process (PID=7833) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:25:16,305] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:25:16,306] {{logging_mixin.py:95}} INFO - [2019-10-05 06:25:16,306] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:25:19,237] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:25:34,391] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:25:35,423] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:25:35,429] {{logging_mixin.py:95}} INFO - [2019-10-05 06:25:35,429] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:25:35,431] {{logging_mixin.py:95}} INFO - [2019-10-05 06:25:35,431] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:20:35.430985+00:00
[2019-10-05 06:25:36,349] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 21.354 seconds
[2019-10-05 06:25:48,850] {{logging_mixin.py:95}} INFO - [2019-10-05 06:25:48,741] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:25:48,945] {{jobs.py:386}} INFO - Started process (PID=7842) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:25:49,642] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:25:49,643] {{logging_mixin.py:95}} INFO - [2019-10-05 06:25:49,643] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:25:50,625] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:26:13,906] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 06:26:36,074] {{logging_mixin.py:95}} INFO - [2019-10-05 06:26:35,968] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:26:36,208] {{jobs.py:386}} INFO - Started process (PID=7844) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:26:37,739] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:26:37,740] {{logging_mixin.py:95}} INFO - [2019-10-05 06:26:37,740] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:26:40,471] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:26:58,500] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 06:27:25,923] {{logging_mixin.py:95}} INFO - [2019-10-05 06:27:25,872] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:27:26,214] {{jobs.py:386}} INFO - Started process (PID=7853) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:27:26,894] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:27:26,895] {{logging_mixin.py:95}} INFO - [2019-10-05 06:27:26,895] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:27:27,900] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:27:43,697] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:27:43,774] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:27:43,781] {{logging_mixin.py:95}} INFO - [2019-10-05 06:27:43,781] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:27:43,782] {{logging_mixin.py:95}} INFO - [2019-10-05 06:27:43,782] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:22:43.782275+00:00
[2019-10-05 06:27:43,791] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 17.576 seconds
[2019-10-05 06:27:54,859] {{logging_mixin.py:95}} INFO - [2019-10-05 06:27:54,859] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:27:54,862] {{jobs.py:386}} INFO - Started process (PID=7857) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:27:55,209] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:27:55,211] {{logging_mixin.py:95}} INFO - [2019-10-05 06:27:55,211] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:27:56,025] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:27:57,799] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:27:57,997] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:27:58,003] {{logging_mixin.py:95}} INFO - [2019-10-05 06:27:58,003] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:27:58,004] {{logging_mixin.py:95}} INFO - [2019-10-05 06:27:58,003] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:22:58.003823+00:00
[2019-10-05 06:27:58,009] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.147 seconds
[2019-10-05 06:28:09,764] {{logging_mixin.py:95}} INFO - [2019-10-05 06:28:09,764] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:28:09,767] {{jobs.py:386}} INFO - Started process (PID=7862) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:28:09,770] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:28:09,771] {{logging_mixin.py:95}} INFO - [2019-10-05 06:28:09,771] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:28:09,837] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:28:21,006] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:28:21,114] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:28:21,121] {{logging_mixin.py:95}} INFO - [2019-10-05 06:28:21,121] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:28:21,122] {{logging_mixin.py:95}} INFO - [2019-10-05 06:28:21,121] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:23:21.121846+00:00
[2019-10-05 06:28:21,147] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 11.380 seconds
[2019-10-05 06:28:32,781] {{logging_mixin.py:95}} INFO - [2019-10-05 06:28:32,781] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:28:32,811] {{jobs.py:386}} INFO - Started process (PID=7870) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:28:32,935] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:28:32,937] {{logging_mixin.py:95}} INFO - [2019-10-05 06:28:32,937] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:28:33,385] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:28:34,110] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:28:34,221] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:28:34,228] {{logging_mixin.py:95}} INFO - [2019-10-05 06:28:34,228] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:28:34,229] {{logging_mixin.py:95}} INFO - [2019-10-05 06:28:34,229] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:23:34.229405+00:00
[2019-10-05 06:28:34,239] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.428 seconds
[2019-10-05 06:28:45,751] {{logging_mixin.py:95}} INFO - [2019-10-05 06:28:45,732] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:28:45,785] {{jobs.py:386}} INFO - Started process (PID=7874) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:28:46,216] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:28:46,217] {{logging_mixin.py:95}} INFO - [2019-10-05 06:28:46,217] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:28:48,289] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:28:54,232] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:28:54,345] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:28:54,352] {{logging_mixin.py:95}} INFO - [2019-10-05 06:28:54,352] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:28:54,354] {{logging_mixin.py:95}} INFO - [2019-10-05 06:28:54,353] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:23:54.353681+00:00
[2019-10-05 06:28:54,362] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 8.577 seconds
[2019-10-05 06:29:05,466] {{logging_mixin.py:95}} INFO - [2019-10-05 06:29:05,466] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:29:05,469] {{jobs.py:386}} INFO - Started process (PID=7884) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:29:05,471] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:29:05,472] {{logging_mixin.py:95}} INFO - [2019-10-05 06:29:05,472] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:29:05,509] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:29:05,833] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:29:05,936] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:29:05,944] {{logging_mixin.py:95}} INFO - [2019-10-05 06:29:05,944] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:29:05,945] {{logging_mixin.py:95}} INFO - [2019-10-05 06:29:05,944] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:24:05.944943+00:00
[2019-10-05 06:29:05,953] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.484 seconds
[2019-10-05 06:29:17,555] {{logging_mixin.py:95}} INFO - [2019-10-05 06:29:17,555] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:29:17,558] {{jobs.py:386}} INFO - Started process (PID=7888) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:29:17,731] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:29:17,732] {{logging_mixin.py:95}} INFO - [2019-10-05 06:29:17,732] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:29:18,756] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:29:23,392] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:29:23,485] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:29:23,586] {{logging_mixin.py:95}} INFO - [2019-10-05 06:29:23,586] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:29:23,588] {{logging_mixin.py:95}} INFO - [2019-10-05 06:29:23,587] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:24:23.587530+00:00
[2019-10-05 06:29:23,927] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 6.370 seconds
[2019-10-05 06:29:36,620] {{logging_mixin.py:95}} INFO - [2019-10-05 06:29:36,620] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:29:36,627] {{jobs.py:386}} INFO - Started process (PID=7892) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:29:36,634] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:29:36,636] {{logging_mixin.py:95}} INFO - [2019-10-05 06:29:36,635] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:29:36,663] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:29:37,555] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:29:37,802] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:29:37,809] {{logging_mixin.py:95}} INFO - [2019-10-05 06:29:37,809] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:29:37,811] {{logging_mixin.py:95}} INFO - [2019-10-05 06:29:37,810] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:24:37.810584+00:00
[2019-10-05 06:29:37,816] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.190 seconds
[2019-10-05 06:29:50,249] {{logging_mixin.py:95}} INFO - [2019-10-05 06:29:50,214] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:29:50,350] {{jobs.py:386}} INFO - Started process (PID=7901) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:29:51,001] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:29:51,002] {{logging_mixin.py:95}} INFO - [2019-10-05 06:29:51,002] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:29:54,765] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:30:03,812] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:30:03,942] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:30:03,950] {{logging_mixin.py:95}} INFO - [2019-10-05 06:30:03,950] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:30:03,951] {{logging_mixin.py:95}} INFO - [2019-10-05 06:30:03,951] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:25:03.951420+00:00
[2019-10-05 06:30:05,770] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 15.420 seconds
[2019-10-05 06:30:17,322] {{logging_mixin.py:95}} INFO - [2019-10-05 06:30:17,288] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:30:17,432] {{jobs.py:386}} INFO - Started process (PID=7905) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:30:18,979] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:30:18,980] {{logging_mixin.py:95}} INFO - [2019-10-05 06:30:18,980] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:30:19,976] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:30:32,052] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:30:32,310] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:30:32,318] {{logging_mixin.py:95}} INFO - [2019-10-05 06:30:32,318] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:30:32,319] {{logging_mixin.py:95}} INFO - [2019-10-05 06:30:32,319] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:25:32.318984+00:00
[2019-10-05 06:30:32,777] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 15.346 seconds
[2019-10-05 06:30:49,537] {{logging_mixin.py:95}} INFO - [2019-10-05 06:30:49,407] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:30:49,771] {{jobs.py:386}} INFO - Started process (PID=7914) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:30:51,316] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:30:51,317] {{logging_mixin.py:95}} INFO - [2019-10-05 06:30:51,317] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:30:53,295] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:31:12,642] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 06:31:39,435] {{logging_mixin.py:95}} INFO - [2019-10-05 06:31:39,127] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:31:39,869] {{jobs.py:386}} INFO - Started process (PID=7916) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:31:44,076] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:31:44,077] {{logging_mixin.py:95}} INFO - [2019-10-05 06:31:44,077] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:31:52,190] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:31:58,618] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:31:58,623] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:31:58,631] {{logging_mixin.py:95}} INFO - [2019-10-05 06:31:58,631] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:31:58,633] {{logging_mixin.py:95}} INFO - [2019-10-05 06:31:58,632] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:26:58.632582+00:00
[2019-10-05 06:31:58,829] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 18.961 seconds
[2019-10-05 06:32:11,600] {{logging_mixin.py:95}} INFO - [2019-10-05 06:32:11,453] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:32:11,893] {{jobs.py:386}} INFO - Started process (PID=7920) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:32:12,457] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:32:12,462] {{logging_mixin.py:95}} INFO - [2019-10-05 06:32:12,462] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:32:13,584] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:32:18,732] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:32:18,870] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:32:18,877] {{logging_mixin.py:95}} INFO - [2019-10-05 06:32:18,877] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:32:18,878] {{logging_mixin.py:95}} INFO - [2019-10-05 06:32:18,878] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:27:18.878018+00:00
[2019-10-05 06:32:19,220] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 7.327 seconds
[2019-10-05 06:32:30,607] {{logging_mixin.py:95}} INFO - [2019-10-05 06:32:30,607] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:32:30,611] {{jobs.py:386}} INFO - Started process (PID=7930) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:32:30,616] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:32:30,620] {{logging_mixin.py:95}} INFO - [2019-10-05 06:32:30,620] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:32:30,770] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:32:31,274] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:32:31,378] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:32:31,386] {{logging_mixin.py:95}} INFO - [2019-10-05 06:32:31,386] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:32:31,388] {{logging_mixin.py:95}} INFO - [2019-10-05 06:32:31,387] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:27:31.387691+00:00
[2019-10-05 06:32:31,396] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.785 seconds
[2019-10-05 06:32:42,784] {{logging_mixin.py:95}} INFO - [2019-10-05 06:32:42,654] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:32:42,892] {{jobs.py:386}} INFO - Started process (PID=7934) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:32:43,389] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:32:43,390] {{logging_mixin.py:95}} INFO - [2019-10-05 06:32:43,390] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:32:43,662] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:32:49,377] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:32:49,423] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:32:49,467] {{logging_mixin.py:95}} INFO - [2019-10-05 06:32:49,467] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:32:49,471] {{logging_mixin.py:95}} INFO - [2019-10-05 06:32:49,470] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:27:49.470692+00:00
[2019-10-05 06:32:49,746] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 6.854 seconds
[2019-10-05 06:33:02,299] {{logging_mixin.py:95}} INFO - [2019-10-05 06:33:02,299] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:33:02,383] {{jobs.py:386}} INFO - Started process (PID=7938) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:33:02,765] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:33:02,766] {{logging_mixin.py:95}} INFO - [2019-10-05 06:33:02,766] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:33:04,488] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:33:04,874] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:33:04,992] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:33:05,000] {{logging_mixin.py:95}} INFO - [2019-10-05 06:33:04,999] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:33:05,001] {{logging_mixin.py:95}} INFO - [2019-10-05 06:33:05,000] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:28:05.000910+00:00
[2019-10-05 06:33:05,007] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.625 seconds
[2019-10-05 06:33:16,692] {{logging_mixin.py:95}} INFO - [2019-10-05 06:33:16,692] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:33:16,695] {{jobs.py:386}} INFO - Started process (PID=7947) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:33:16,709] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:33:16,710] {{logging_mixin.py:95}} INFO - [2019-10-05 06:33:16,710] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:33:16,742] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:33:19,610] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:33:19,630] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:33:19,670] {{logging_mixin.py:95}} INFO - [2019-10-05 06:33:19,670] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:33:19,672] {{logging_mixin.py:95}} INFO - [2019-10-05 06:33:19,671] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:28:19.671561+00:00
[2019-10-05 06:33:19,678] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.983 seconds
[2019-10-05 06:33:31,047] {{logging_mixin.py:95}} INFO - [2019-10-05 06:33:31,047] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:33:31,051] {{jobs.py:386}} INFO - Started process (PID=7951) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:33:31,188] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:33:31,190] {{logging_mixin.py:95}} INFO - [2019-10-05 06:33:31,190] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:33:31,223] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:33:31,747] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:33:31,753] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:33:31,765] {{logging_mixin.py:95}} INFO - [2019-10-05 06:33:31,764] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:33:31,766] {{logging_mixin.py:95}} INFO - [2019-10-05 06:33:31,766] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:28:31.766047+00:00
[2019-10-05 06:33:31,772] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.722 seconds
[2019-10-05 06:33:44,431] {{logging_mixin.py:95}} INFO - [2019-10-05 06:33:44,289] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:33:44,489] {{jobs.py:386}} INFO - Started process (PID=7955) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:33:44,720] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:33:44,722] {{logging_mixin.py:95}} INFO - [2019-10-05 06:33:44,722] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:33:46,235] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:33:56,527] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:33:57,326] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:33:57,334] {{logging_mixin.py:95}} INFO - [2019-10-05 06:33:57,334] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:33:57,335] {{logging_mixin.py:95}} INFO - [2019-10-05 06:33:57,334] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:28:57.334844+00:00
[2019-10-05 06:33:58,216] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 13.728 seconds
[2019-10-05 06:34:10,155] {{logging_mixin.py:95}} INFO - [2019-10-05 06:34:10,154] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:34:10,280] {{jobs.py:386}} INFO - Started process (PID=7967) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:34:10,810] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:34:10,811] {{logging_mixin.py:95}} INFO - [2019-10-05 06:34:10,811] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:34:11,425] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:34:13,082] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:34:13,556] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:34:13,564] {{logging_mixin.py:95}} INFO - [2019-10-05 06:34:13,564] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:34:13,566] {{logging_mixin.py:95}} INFO - [2019-10-05 06:34:13,566] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:29:13.566215+00:00
[2019-10-05 06:34:13,573] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.294 seconds
[2019-10-05 06:34:25,411] {{logging_mixin.py:95}} INFO - [2019-10-05 06:34:25,411] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:34:25,453] {{jobs.py:386}} INFO - Started process (PID=7971) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:34:25,876] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:34:25,877] {{logging_mixin.py:95}} INFO - [2019-10-05 06:34:25,877] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:34:27,169] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:34:29,588] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:34:29,681] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:34:29,690] {{logging_mixin.py:95}} INFO - [2019-10-05 06:34:29,690] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:34:29,691] {{logging_mixin.py:95}} INFO - [2019-10-05 06:34:29,690] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:29:29.690630+00:00
[2019-10-05 06:34:29,698] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.245 seconds
[2019-10-05 06:34:40,630] {{logging_mixin.py:95}} INFO - [2019-10-05 06:34:40,630] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:34:40,633] {{jobs.py:386}} INFO - Started process (PID=7975) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:34:40,776] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:34:40,777] {{logging_mixin.py:95}} INFO - [2019-10-05 06:34:40,777] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:34:41,327] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:35:04,412] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:35:05,903] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:35:06,196] {{logging_mixin.py:95}} INFO - [2019-10-05 06:35:06,196] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:35:06,198] {{logging_mixin.py:95}} INFO - [2019-10-05 06:35:06,197] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:30:06.197411+00:00
[2019-10-05 06:35:07,007] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 26.374 seconds
[2019-10-05 06:35:24,584] {{logging_mixin.py:95}} INFO - [2019-10-05 06:35:24,584] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:35:25,314] {{jobs.py:386}} INFO - Started process (PID=7985) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:35:26,663] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:35:26,664] {{logging_mixin.py:95}} INFO - [2019-10-05 06:35:26,664] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:35:29,439] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:35:58,689] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:36:00,337] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:36:00,346] {{logging_mixin.py:95}} INFO - [2019-10-05 06:36:00,345] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:36:00,347] {{logging_mixin.py:95}} INFO - [2019-10-05 06:36:00,346] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:31:00.346949+00:00
[2019-10-05 06:36:01,163] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 35.848 seconds
[2019-10-05 06:36:14,233] {{logging_mixin.py:95}} INFO - [2019-10-05 06:36:14,233] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:36:14,328] {{jobs.py:386}} INFO - Started process (PID=7989) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:36:16,018] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:36:16,019] {{logging_mixin.py:95}} INFO - [2019-10-05 06:36:16,019] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:36:18,702] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:36:38,138] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:36:38,866] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:36:38,874] {{logging_mixin.py:95}} INFO - [2019-10-05 06:36:38,874] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:36:38,875] {{logging_mixin.py:95}} INFO - [2019-10-05 06:36:38,875] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:31:38.875290+00:00
[2019-10-05 06:36:39,759] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 25.431 seconds
[2019-10-05 06:36:54,035] {{logging_mixin.py:95}} INFO - [2019-10-05 06:36:54,035] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:36:54,256] {{jobs.py:386}} INFO - Started process (PID=7993) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:36:55,720] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:36:55,721] {{logging_mixin.py:95}} INFO - [2019-10-05 06:36:55,721] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:36:58,768] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:37:01,359] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:37:01,365] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:37:01,377] {{logging_mixin.py:95}} INFO - [2019-10-05 06:37:01,376] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:37:01,378] {{logging_mixin.py:95}} INFO - [2019-10-05 06:37:01,378] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:32:01.378050+00:00
[2019-10-05 06:37:01,387] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 7.131 seconds
[2019-10-05 06:37:12,487] {{logging_mixin.py:95}} INFO - [2019-10-05 06:37:12,486] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:37:12,492] {{jobs.py:386}} INFO - Started process (PID=8002) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:37:12,496] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:37:12,497] {{logging_mixin.py:95}} INFO - [2019-10-05 06:37:12,497] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:37:12,527] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:37:15,582] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:37:15,856] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:37:15,864] {{logging_mixin.py:95}} INFO - [2019-10-05 06:37:15,864] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:37:15,881] {{logging_mixin.py:95}} INFO - [2019-10-05 06:37:15,880] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:32:15.880799+00:00
[2019-10-05 06:37:15,924] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.431 seconds
[2019-10-05 06:37:27,247] {{logging_mixin.py:95}} INFO - [2019-10-05 06:37:27,246] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:37:27,250] {{jobs.py:386}} INFO - Started process (PID=8006) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:37:27,275] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:37:27,276] {{logging_mixin.py:95}} INFO - [2019-10-05 06:37:27,276] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:37:27,338] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:37:29,354] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:37:29,359] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:37:29,539] {{logging_mixin.py:95}} INFO - [2019-10-05 06:37:29,539] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:37:29,540] {{logging_mixin.py:95}} INFO - [2019-10-05 06:37:29,540] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:32:29.540271+00:00
[2019-10-05 06:37:29,548] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.297 seconds
[2019-10-05 06:37:41,648] {{logging_mixin.py:95}} INFO - [2019-10-05 06:37:41,648] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:37:41,655] {{jobs.py:386}} INFO - Started process (PID=8015) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:37:42,843] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:37:42,844] {{logging_mixin.py:95}} INFO - [2019-10-05 06:37:42,844] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:37:43,414] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:37:49,746] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:37:49,905] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:37:49,913] {{logging_mixin.py:95}} INFO - [2019-10-05 06:37:49,913] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:37:49,915] {{logging_mixin.py:95}} INFO - [2019-10-05 06:37:49,914] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:32:49.914604+00:00
[2019-10-05 06:37:50,825] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 9.170 seconds
[2019-10-05 06:38:02,125] {{logging_mixin.py:95}} INFO - [2019-10-05 06:38:02,125] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:38:02,170] {{jobs.py:386}} INFO - Started process (PID=8019) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:38:02,333] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:38:02,335] {{logging_mixin.py:95}} INFO - [2019-10-05 06:38:02,335] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:38:02,710] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:38:03,298] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:38:03,488] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:38:03,497] {{logging_mixin.py:95}} INFO - [2019-10-05 06:38:03,497] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:38:03,499] {{logging_mixin.py:95}} INFO - [2019-10-05 06:38:03,498] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:33:03.498695+00:00
[2019-10-05 06:38:03,506] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.336 seconds
[2019-10-05 06:38:15,995] {{logging_mixin.py:95}} INFO - [2019-10-05 06:38:15,995] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:38:16,341] {{jobs.py:386}} INFO - Started process (PID=8023) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:38:17,168] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:38:17,170] {{logging_mixin.py:95}} INFO - [2019-10-05 06:38:17,170] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:38:17,708] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:38:22,981] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:38:23,137] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:38:23,145] {{logging_mixin.py:95}} INFO - [2019-10-05 06:38:23,145] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:38:23,146] {{logging_mixin.py:95}} INFO - [2019-10-05 06:38:23,146] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:33:23.146048+00:00
[2019-10-05 06:38:23,174] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 6.833 seconds
[2019-10-05 06:38:34,821] {{logging_mixin.py:95}} INFO - [2019-10-05 06:38:34,821] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:38:34,824] {{jobs.py:386}} INFO - Started process (PID=8032) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:38:34,827] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:38:34,828] {{logging_mixin.py:95}} INFO - [2019-10-05 06:38:34,828] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:38:35,362] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:38:35,555] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:38:35,560] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:38:35,568] {{logging_mixin.py:95}} INFO - [2019-10-05 06:38:35,568] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:38:35,570] {{logging_mixin.py:95}} INFO - [2019-10-05 06:38:35,569] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:33:35.569529+00:00
[2019-10-05 06:38:35,577] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.753 seconds
[2019-10-05 06:38:47,268] {{logging_mixin.py:95}} INFO - [2019-10-05 06:38:47,132] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:38:47,487] {{jobs.py:386}} INFO - Started process (PID=8036) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:38:47,858] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:38:47,859] {{logging_mixin.py:95}} INFO - [2019-10-05 06:38:47,859] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:38:48,656] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:38:51,893] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:38:52,062] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:38:52,071] {{logging_mixin.py:95}} INFO - [2019-10-05 06:38:52,071] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:38:52,073] {{logging_mixin.py:95}} INFO - [2019-10-05 06:38:52,072] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:33:52.072584+00:00
[2019-10-05 06:38:52,739] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.252 seconds
[2019-10-05 06:39:05,054] {{logging_mixin.py:95}} INFO - [2019-10-05 06:39:05,054] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:39:05,075] {{jobs.py:386}} INFO - Started process (PID=8040) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:39:05,218] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:39:05,218] {{logging_mixin.py:95}} INFO - [2019-10-05 06:39:05,218] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:39:06,565] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:39:06,831] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:39:06,837] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:39:06,849] {{logging_mixin.py:95}} INFO - [2019-10-05 06:39:06,849] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:39:06,850] {{logging_mixin.py:95}} INFO - [2019-10-05 06:39:06,849] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:34:06.849940+00:00
[2019-10-05 06:39:06,856] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.781 seconds
[2019-10-05 06:39:19,283] {{logging_mixin.py:95}} INFO - [2019-10-05 06:39:19,156] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:39:19,400] {{jobs.py:386}} INFO - Started process (PID=8049) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:39:19,507] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:39:19,508] {{logging_mixin.py:95}} INFO - [2019-10-05 06:39:19,508] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:39:20,362] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:39:25,500] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:39:25,717] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:39:25,726] {{logging_mixin.py:95}} INFO - [2019-10-05 06:39:25,726] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:39:25,728] {{logging_mixin.py:95}} INFO - [2019-10-05 06:39:25,727] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:34:25.727442+00:00
[2019-10-05 06:39:25,736] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 6.336 seconds
[2019-10-05 06:39:37,612] {{logging_mixin.py:95}} INFO - [2019-10-05 06:39:37,612] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:39:37,649] {{jobs.py:386}} INFO - Started process (PID=8053) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:39:38,513] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:39:38,514] {{logging_mixin.py:95}} INFO - [2019-10-05 06:39:38,514] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:39:40,928] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:39:50,794] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:39:51,400] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:39:51,409] {{logging_mixin.py:95}} INFO - [2019-10-05 06:39:51,409] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:39:51,411] {{logging_mixin.py:95}} INFO - [2019-10-05 06:39:51,410] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:34:51.410745+00:00
[2019-10-05 06:39:52,994] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 15.346 seconds
[2019-10-05 06:40:11,796] {{logging_mixin.py:95}} INFO - [2019-10-05 06:40:11,341] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:40:11,930] {{jobs.py:386}} INFO - Started process (PID=8057) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:40:12,571] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:40:12,571] {{logging_mixin.py:95}} INFO - [2019-10-05 06:40:12,571] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:40:16,857] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:40:26,291] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:40:26,524] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:40:26,638] {{logging_mixin.py:95}} INFO - [2019-10-05 06:40:26,637] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:40:26,639] {{logging_mixin.py:95}} INFO - [2019-10-05 06:40:26,638] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:35:26.638675+00:00
[2019-10-05 06:40:29,193] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 17.263 seconds
[2019-10-05 06:40:45,277] {{logging_mixin.py:95}} INFO - [2019-10-05 06:40:45,277] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:40:45,320] {{jobs.py:386}} INFO - Started process (PID=8066) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:40:46,337] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:40:46,422] {{logging_mixin.py:95}} INFO - [2019-10-05 06:40:46,422] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:40:48,036] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:40:51,527] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:40:51,545] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:40:51,553] {{logging_mixin.py:95}} INFO - [2019-10-05 06:40:51,553] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:40:51,555] {{logging_mixin.py:95}} INFO - [2019-10-05 06:40:51,554] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:35:51.554250+00:00
[2019-10-05 06:40:51,560] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 6.240 seconds
[2019-10-05 06:41:03,143] {{logging_mixin.py:95}} INFO - [2019-10-05 06:41:03,143] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:41:03,147] {{jobs.py:386}} INFO - Started process (PID=8070) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:41:03,268] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:41:03,270] {{logging_mixin.py:95}} INFO - [2019-10-05 06:41:03,269] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:41:03,442] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:41:05,495] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:41:05,555] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:41:05,564] {{logging_mixin.py:95}} INFO - [2019-10-05 06:41:05,563] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:41:05,565] {{logging_mixin.py:95}} INFO - [2019-10-05 06:41:05,565] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:36:05.565488+00:00
[2019-10-05 06:41:05,572] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.425 seconds
[2019-10-05 06:41:16,466] {{logging_mixin.py:95}} INFO - [2019-10-05 06:41:16,466] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:41:16,470] {{jobs.py:386}} INFO - Started process (PID=8079) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:41:16,473] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:41:16,473] {{logging_mixin.py:95}} INFO - [2019-10-05 06:41:16,473] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:41:16,493] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:41:17,766] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:41:17,772] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:41:17,779] {{logging_mixin.py:95}} INFO - [2019-10-05 06:41:17,779] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:41:17,780] {{logging_mixin.py:95}} INFO - [2019-10-05 06:41:17,779] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:36:17.779501+00:00
[2019-10-05 06:41:17,786] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.316 seconds
[2019-10-05 06:41:28,537] {{logging_mixin.py:95}} INFO - [2019-10-05 06:41:28,447] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:41:28,885] {{jobs.py:386}} INFO - Started process (PID=8083) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:41:29,400] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:41:29,401] {{logging_mixin.py:95}} INFO - [2019-10-05 06:41:29,401] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:41:30,559] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:41:34,446] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:41:34,457] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:41:34,465] {{logging_mixin.py:95}} INFO - [2019-10-05 06:41:34,465] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:41:34,467] {{logging_mixin.py:95}} INFO - [2019-10-05 06:41:34,466] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:36:34.466698+00:00
[2019-10-05 06:41:34,477] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.592 seconds
[2019-10-05 06:41:46,225] {{logging_mixin.py:95}} INFO - [2019-10-05 06:41:46,225] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:41:46,231] {{jobs.py:386}} INFO - Started process (PID=8087) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:41:46,235] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:41:46,236] {{logging_mixin.py:95}} INFO - [2019-10-05 06:41:46,236] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:41:46,257] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:41:46,719] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:41:46,724] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:41:46,732] {{logging_mixin.py:95}} INFO - [2019-10-05 06:41:46,732] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:41:46,733] {{logging_mixin.py:95}} INFO - [2019-10-05 06:41:46,733] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:36:46.733044+00:00
[2019-10-05 06:41:46,742] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.511 seconds
[2019-10-05 06:41:58,389] {{logging_mixin.py:95}} INFO - [2019-10-05 06:41:58,389] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:41:58,659] {{jobs.py:386}} INFO - Started process (PID=8096) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:41:59,173] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:41:59,175] {{logging_mixin.py:95}} INFO - [2019-10-05 06:41:59,174] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:42:01,971] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:42:08,960] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:42:09,469] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:42:09,476] {{logging_mixin.py:95}} INFO - [2019-10-05 06:42:09,476] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:42:09,477] {{logging_mixin.py:95}} INFO - [2019-10-05 06:42:09,477] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:37:09.477132+00:00
[2019-10-05 06:42:10,836] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 12.178 seconds
[2019-10-05 06:42:23,285] {{logging_mixin.py:95}} INFO - [2019-10-05 06:42:23,285] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:42:23,325] {{jobs.py:386}} INFO - Started process (PID=8100) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:42:24,490] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:42:24,491] {{logging_mixin.py:95}} INFO - [2019-10-05 06:42:24,491] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:42:25,489] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:42:27,303] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:42:27,352] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:42:27,360] {{logging_mixin.py:95}} INFO - [2019-10-05 06:42:27,360] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:42:27,362] {{logging_mixin.py:95}} INFO - [2019-10-05 06:42:27,361] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:37:27.361637+00:00
[2019-10-05 06:42:27,370] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.045 seconds
[2019-10-05 06:42:39,749] {{logging_mixin.py:95}} INFO - [2019-10-05 06:42:39,729] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:42:39,807] {{jobs.py:386}} INFO - Started process (PID=8115) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:42:40,417] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:42:40,418] {{logging_mixin.py:95}} INFO - [2019-10-05 06:42:40,418] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:42:41,603] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:42:52,709] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:42:52,758] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:42:52,767] {{logging_mixin.py:95}} INFO - [2019-10-05 06:42:52,766] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:42:52,768] {{logging_mixin.py:95}} INFO - [2019-10-05 06:42:52,767] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:37:52.767852+00:00
[2019-10-05 06:42:52,890] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 13.083 seconds
[2019-10-05 06:43:07,665] {{logging_mixin.py:95}} INFO - [2019-10-05 06:43:07,518] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:43:07,922] {{jobs.py:386}} INFO - Started process (PID=8119) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:43:09,019] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:43:09,020] {{logging_mixin.py:95}} INFO - [2019-10-05 06:43:09,020] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:43:10,660] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:43:20,599] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:43:20,799] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:43:20,806] {{logging_mixin.py:95}} INFO - [2019-10-05 06:43:20,806] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:43:20,807] {{logging_mixin.py:95}} INFO - [2019-10-05 06:43:20,807] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:38:20.807393+00:00
[2019-10-05 06:43:21,797] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 13.875 seconds
[2019-10-05 06:43:33,685] {{logging_mixin.py:95}} INFO - [2019-10-05 06:43:33,685] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:43:33,730] {{jobs.py:386}} INFO - Started process (PID=8128) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:43:34,161] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:43:34,167] {{logging_mixin.py:95}} INFO - [2019-10-05 06:43:34,167] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:43:35,356] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:43:38,273] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:43:38,298] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:43:38,306] {{logging_mixin.py:95}} INFO - [2019-10-05 06:43:38,305] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:43:38,307] {{logging_mixin.py:95}} INFO - [2019-10-05 06:43:38,306] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:38:38.306632+00:00
[2019-10-05 06:43:38,313] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.583 seconds
[2019-10-05 06:43:50,143] {{logging_mixin.py:95}} INFO - [2019-10-05 06:43:50,142] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:43:50,147] {{jobs.py:386}} INFO - Started process (PID=8132) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:43:50,745] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:43:50,745] {{logging_mixin.py:95}} INFO - [2019-10-05 06:43:50,745] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:43:53,100] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:44:02,072] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:44:02,239] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:44:02,246] {{logging_mixin.py:95}} INFO - [2019-10-05 06:44:02,245] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:44:02,247] {{logging_mixin.py:95}} INFO - [2019-10-05 06:44:02,246] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:39:02.246689+00:00
[2019-10-05 06:44:03,197] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 13.051 seconds
[2019-10-05 06:44:14,883] {{logging_mixin.py:95}} INFO - [2019-10-05 06:44:14,883] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:44:14,886] {{jobs.py:386}} INFO - Started process (PID=8143) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:44:15,209] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:44:15,216] {{logging_mixin.py:95}} INFO - [2019-10-05 06:44:15,216] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:44:19,665] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:44:42,542] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-05 06:45:01,710] {{logging_mixin.py:95}} INFO - [2019-10-05 06:45:01,596] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:45:02,864] {{jobs.py:386}} INFO - Started process (PID=8155) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:45:04,334] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:45:04,334] {{logging_mixin.py:95}} INFO - [2019-10-05 06:45:04,334] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:45:07,872] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:45:12,379] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:45:12,553] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:45:12,561] {{logging_mixin.py:95}} INFO - [2019-10-05 06:45:12,561] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:45:12,562] {{logging_mixin.py:95}} INFO - [2019-10-05 06:45:12,562] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:40:12.562470+00:00
[2019-10-05 06:45:12,720] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 9.856 seconds
[2019-10-05 06:45:24,782] {{logging_mixin.py:95}} INFO - [2019-10-05 06:45:24,782] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:45:24,785] {{jobs.py:386}} INFO - Started process (PID=8159) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:45:25,115] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:45:25,180] {{logging_mixin.py:95}} INFO - [2019-10-05 06:45:25,180] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:45:25,209] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:45:26,270] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:45:26,275] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:45:26,282] {{logging_mixin.py:95}} INFO - [2019-10-05 06:45:26,282] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:45:26,283] {{logging_mixin.py:95}} INFO - [2019-10-05 06:45:26,283] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:40:26.283150+00:00
[2019-10-05 06:45:26,289] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.504 seconds
[2019-10-05 06:45:37,031] {{logging_mixin.py:95}} INFO - [2019-10-05 06:45:37,031] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:45:37,037] {{jobs.py:386}} INFO - Started process (PID=8163) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:45:37,045] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:45:37,047] {{logging_mixin.py:95}} INFO - [2019-10-05 06:45:37,047] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:45:37,112] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:45:37,532] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:45:37,537] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:45:37,544] {{logging_mixin.py:95}} INFO - [2019-10-05 06:45:37,544] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:45:37,545] {{logging_mixin.py:95}} INFO - [2019-10-05 06:45:37,545] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:40:37.545350+00:00
[2019-10-05 06:45:37,551] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.514 seconds
[2019-10-05 06:45:49,360] {{logging_mixin.py:95}} INFO - [2019-10-05 06:45:49,359] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:45:49,465] {{jobs.py:386}} INFO - Started process (PID=8167) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:45:49,621] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:45:49,622] {{logging_mixin.py:95}} INFO - [2019-10-05 06:45:49,622] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:45:49,957] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:45:51,867] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:45:51,875] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:45:51,883] {{logging_mixin.py:95}} INFO - [2019-10-05 06:45:51,883] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:45:51,884] {{logging_mixin.py:95}} INFO - [2019-10-05 06:45:51,884] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:40:51.884072+00:00
[2019-10-05 06:45:51,901] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.436 seconds
[2019-10-05 06:46:03,894] {{logging_mixin.py:95}} INFO - [2019-10-05 06:46:03,893] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:46:04,112] {{jobs.py:386}} INFO - Started process (PID=8176) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:46:04,249] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:46:04,253] {{logging_mixin.py:95}} INFO - [2019-10-05 06:46:04,253] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:46:07,561] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:46:11,948] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:46:11,955] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:46:11,968] {{logging_mixin.py:95}} INFO - [2019-10-05 06:46:11,968] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:46:11,970] {{logging_mixin.py:95}} INFO - [2019-10-05 06:46:11,969] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:41:11.969514+00:00
[2019-10-05 06:46:12,091] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 7.979 seconds
[2019-10-05 06:46:23,658] {{logging_mixin.py:95}} INFO - [2019-10-05 06:46:23,658] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:46:23,662] {{jobs.py:386}} INFO - Started process (PID=8180) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:46:23,664] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:46:23,665] {{logging_mixin.py:95}} INFO - [2019-10-05 06:46:23,665] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:46:23,769] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:46:23,999] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:46:24,100] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:46:24,143] {{logging_mixin.py:95}} INFO - [2019-10-05 06:46:24,143] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:46:24,144] {{logging_mixin.py:95}} INFO - [2019-10-05 06:46:24,144] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:41:24.144071+00:00
[2019-10-05 06:46:24,152] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.490 seconds
[2019-10-05 06:46:35,443] {{logging_mixin.py:95}} INFO - [2019-10-05 06:46:35,443] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:46:35,655] {{jobs.py:386}} INFO - Started process (PID=8184) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:46:35,739] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:46:35,740] {{logging_mixin.py:95}} INFO - [2019-10-05 06:46:35,740] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:46:36,917] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:46:40,624] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:46:40,629] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:46:40,639] {{logging_mixin.py:95}} INFO - [2019-10-05 06:46:40,639] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:46:40,641] {{logging_mixin.py:95}} INFO - [2019-10-05 06:46:40,639] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:41:40.639932+00:00
[2019-10-05 06:46:40,707] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.052 seconds
[2019-10-05 06:46:52,690] {{logging_mixin.py:95}} INFO - [2019-10-05 06:46:52,690] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:46:52,721] {{jobs.py:386}} INFO - Started process (PID=8193) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:46:53,136] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:46:53,137] {{logging_mixin.py:95}} INFO - [2019-10-05 06:46:53,137] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:46:55,037] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:47:02,463] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:47:02,631] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:47:02,638] {{logging_mixin.py:95}} INFO - [2019-10-05 06:47:02,638] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:47:02,640] {{logging_mixin.py:95}} INFO - [2019-10-05 06:47:02,639] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:42:02.639530+00:00
[2019-10-05 06:47:03,226] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 10.505 seconds
[2019-10-05 06:47:17,406] {{logging_mixin.py:95}} INFO - [2019-10-05 06:47:17,402] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:47:17,620] {{jobs.py:386}} INFO - Started process (PID=8197) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:47:19,161] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:47:19,162] {{logging_mixin.py:95}} INFO - [2019-10-05 06:47:19,162] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:47:22,324] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:47:38,473] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:47:39,056] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:47:39,065] {{logging_mixin.py:95}} INFO - [2019-10-05 06:47:39,065] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:47:39,066] {{logging_mixin.py:95}} INFO - [2019-10-05 06:47:39,066] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:42:39.065981+00:00
[2019-10-05 06:47:39,907] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 22.287 seconds
[2019-10-05 06:47:53,226] {{logging_mixin.py:95}} INFO - [2019-10-05 06:47:53,226] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:47:53,943] {{jobs.py:386}} INFO - Started process (PID=8206) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:47:54,516] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:47:54,517] {{logging_mixin.py:95}} INFO - [2019-10-05 06:47:54,517] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:47:59,417] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:48:11,997] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:48:16,380] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:48:16,488] {{logging_mixin.py:95}} INFO - [2019-10-05 06:48:16,487] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:48:16,489] {{logging_mixin.py:95}} INFO - [2019-10-05 06:48:16,488] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:43:16.488721+00:00
[2019-10-05 06:48:21,780] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 27.838 seconds
[2019-10-05 06:48:34,832] {{logging_mixin.py:95}} INFO - [2019-10-05 06:48:34,832] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:48:34,927] {{jobs.py:386}} INFO - Started process (PID=8210) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:48:36,097] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:48:36,099] {{logging_mixin.py:95}} INFO - [2019-10-05 06:48:36,099] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:48:37,839] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:48:40,104] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:48:40,109] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:48:40,117] {{logging_mixin.py:95}} INFO - [2019-10-05 06:48:40,117] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:48:40,119] {{logging_mixin.py:95}} INFO - [2019-10-05 06:48:40,118] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:43:40.118713+00:00
[2019-10-05 06:48:40,125] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.198 seconds
[2019-10-05 06:48:51,450] {{logging_mixin.py:95}} INFO - [2019-10-05 06:48:51,449] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:48:51,453] {{jobs.py:386}} INFO - Started process (PID=8214) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:48:51,455] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:48:51,456] {{logging_mixin.py:95}} INFO - [2019-10-05 06:48:51,456] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:48:51,507] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:48:52,501] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:48:52,506] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:48:52,512] {{logging_mixin.py:95}} INFO - [2019-10-05 06:48:52,512] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:48:52,512] {{logging_mixin.py:95}} INFO - [2019-10-05 06:48:52,512] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:43:52.512444+00:00
[2019-10-05 06:48:52,518] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.066 seconds
[2019-10-05 06:49:03,632] {{logging_mixin.py:95}} INFO - [2019-10-05 06:49:03,632] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:49:03,635] {{jobs.py:386}} INFO - Started process (PID=8219) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:49:04,595] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:49:04,596] {{logging_mixin.py:95}} INFO - [2019-10-05 06:49:04,596] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:49:05,412] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:49:06,369] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:49:06,387] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:49:06,398] {{logging_mixin.py:95}} INFO - [2019-10-05 06:49:06,394] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:49:06,400] {{logging_mixin.py:95}} INFO - [2019-10-05 06:49:06,399] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:44:06.399611+00:00
[2019-10-05 06:49:06,408] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.773 seconds
[2019-10-05 06:49:18,540] {{logging_mixin.py:95}} INFO - [2019-10-05 06:49:18,411] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:49:18,623] {{jobs.py:386}} INFO - Started process (PID=8227) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:49:19,204] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:49:19,205] {{logging_mixin.py:95}} INFO - [2019-10-05 06:49:19,205] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:49:20,602] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:49:27,053] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:49:27,240] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:49:27,251] {{logging_mixin.py:95}} INFO - [2019-10-05 06:49:27,251] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:49:27,252] {{logging_mixin.py:95}} INFO - [2019-10-05 06:49:27,252] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:44:27.252006+00:00
[2019-10-05 06:49:27,260] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 8.637 seconds
[2019-10-05 06:49:38,690] {{logging_mixin.py:95}} INFO - [2019-10-05 06:49:38,690] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:49:38,693] {{jobs.py:386}} INFO - Started process (PID=8231) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:49:38,697] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:49:38,698] {{logging_mixin.py:95}} INFO - [2019-10-05 06:49:38,698] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:49:38,722] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:49:38,879] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:49:38,885] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:49:38,893] {{logging_mixin.py:95}} INFO - [2019-10-05 06:49:38,893] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:49:38,894] {{logging_mixin.py:95}} INFO - [2019-10-05 06:49:38,894] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:44:38.894055+00:00
[2019-10-05 06:49:38,900] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.207 seconds
[2019-10-05 06:49:50,265] {{logging_mixin.py:95}} INFO - [2019-10-05 06:49:50,265] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:49:50,393] {{jobs.py:386}} INFO - Started process (PID=8240) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:49:51,236] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:49:51,354] {{logging_mixin.py:95}} INFO - [2019-10-05 06:49:51,354] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:49:53,135] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:49:56,078] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:49:56,084] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:49:56,093] {{logging_mixin.py:95}} INFO - [2019-10-05 06:49:56,092] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:49:56,094] {{logging_mixin.py:95}} INFO - [2019-10-05 06:49:56,094] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:44:56.094387+00:00
[2019-10-05 06:49:56,113] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.721 seconds
[2019-10-05 06:50:07,322] {{logging_mixin.py:95}} INFO - [2019-10-05 06:50:07,322] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:50:07,327] {{jobs.py:386}} INFO - Started process (PID=8244) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:50:07,652] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:50:07,653] {{logging_mixin.py:95}} INFO - [2019-10-05 06:50:07,653] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:50:09,836] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:50:24,545] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:50:25,249] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:50:25,259] {{logging_mixin.py:95}} INFO - [2019-10-05 06:50:25,259] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:50:25,260] {{logging_mixin.py:95}} INFO - [2019-10-05 06:50:25,260] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:45:25.260358+00:00
[2019-10-05 06:50:27,357] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 20.030 seconds
[2019-10-05 06:50:42,737] {{logging_mixin.py:95}} INFO - [2019-10-05 06:50:42,562] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:50:43,269] {{jobs.py:386}} INFO - Started process (PID=8253) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:50:44,409] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:50:44,410] {{logging_mixin.py:95}} INFO - [2019-10-05 06:50:44,410] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:50:47,015] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:51:04,994] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-05 06:51:05,080] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-05 06:51:05,087] {{logging_mixin.py:95}} INFO - [2019-10-05 06:51:05,087] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-05 06:51:05,088] {{logging_mixin.py:95}} INFO - [2019-10-05 06:51:05,088] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-05 06:46:05.088393+00:00
[2019-10-05 06:51:06,688] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 23.419 seconds
[2019-10-05 06:51:24,079] {{logging_mixin.py:95}} INFO - [2019-10-05 06:51:23,609] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-05 06:51:24,359] {{jobs.py:386}} INFO - Started process (PID=8257) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:51:26,108] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-05 06:51:26,109] {{logging_mixin.py:95}} INFO - [2019-10-05 06:51:26,109] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:51:32,655] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-05 06:51:57,364] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

