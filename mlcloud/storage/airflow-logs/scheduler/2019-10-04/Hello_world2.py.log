[2019-10-04 08:46:09,401] {{logging_mixin.py:95}} INFO - [2019-10-04 08:46:09,401] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:46:09,403] {{jobs.py:386}} INFO - Started process (PID=307) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:46:09,407] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:46:09,408] {{logging_mixin.py:95}} INFO - [2019-10-04 08:46:09,407] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:46:09,457] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:46:09,686] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:46:09,693] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:46:09,988] {{logging_mixin.py:95}} INFO - [2019-10-04 08:46:09,988] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:46:09,988] {{logging_mixin.py:95}} INFO - [2019-10-04 08:46:09,988] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:41:09.988399+00:00
[2019-10-04 08:46:10,043] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.640 seconds
[2019-10-04 08:46:22,062] {{logging_mixin.py:95}} INFO - [2019-10-04 08:46:22,062] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:46:22,163] {{jobs.py:386}} INFO - Started process (PID=322) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:46:22,347] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:46:22,349] {{logging_mixin.py:95}} INFO - [2019-10-04 08:46:22,349] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:46:25,283] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:46:25,934] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:46:25,939] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:46:25,949] {{logging_mixin.py:95}} INFO - [2019-10-04 08:46:25,949] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:46:25,950] {{logging_mixin.py:95}} INFO - [2019-10-04 08:46:25,950] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:41:25.950158+00:00
[2019-10-04 08:46:26,388] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.225 seconds
[2019-10-04 08:46:38,982] {{logging_mixin.py:95}} INFO - [2019-10-04 08:46:38,921] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:46:39,114] {{jobs.py:386}} INFO - Started process (PID=335) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:46:39,119] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:46:39,121] {{logging_mixin.py:95}} INFO - [2019-10-04 08:46:39,121] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:46:39,403] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:46:39,762] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:46:39,769] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:46:39,786] {{logging_mixin.py:95}} INFO - [2019-10-04 08:46:39,785] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:46:39,788] {{logging_mixin.py:95}} INFO - [2019-10-04 08:46:39,787] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:41:39.787371+00:00
[2019-10-04 08:46:39,797] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.683 seconds
[2019-10-04 08:46:51,110] {{logging_mixin.py:95}} INFO - [2019-10-04 08:46:51,109] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:46:51,113] {{jobs.py:386}} INFO - Started process (PID=340) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:46:51,115] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:46:51,116] {{logging_mixin.py:95}} INFO - [2019-10-04 08:46:51,116] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:46:51,135] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:46:51,355] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:46:51,362] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:46:51,370] {{logging_mixin.py:95}} INFO - [2019-10-04 08:46:51,370] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:46:51,372] {{logging_mixin.py:95}} INFO - [2019-10-04 08:46:51,371] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:41:51.371680+00:00
[2019-10-04 08:46:51,380] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.267 seconds
[2019-10-04 08:47:02,749] {{logging_mixin.py:95}} INFO - [2019-10-04 08:47:02,749] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:47:02,752] {{jobs.py:386}} INFO - Started process (PID=344) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:47:02,754] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:47:02,755] {{logging_mixin.py:95}} INFO - [2019-10-04 08:47:02,755] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:47:02,773] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:47:03,001] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:47:03,008] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:47:03,016] {{logging_mixin.py:95}} INFO - [2019-10-04 08:47:03,016] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:47:03,018] {{logging_mixin.py:95}} INFO - [2019-10-04 08:47:03,017] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:42:03.017874+00:00
[2019-10-04 08:47:03,025] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.273 seconds
[2019-10-04 08:47:14,541] {{logging_mixin.py:95}} INFO - [2019-10-04 08:47:14,541] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:47:16,788] {{jobs.py:386}} INFO - Started process (PID=352) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:47:16,796] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:47:16,797] {{logging_mixin.py:95}} INFO - [2019-10-04 08:47:16,797] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:47:19,944] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:47:26,282] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:47:26,427] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:47:26,441] {{logging_mixin.py:95}} INFO - [2019-10-04 08:47:26,441] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:47:26,475] {{logging_mixin.py:95}} INFO - [2019-10-04 08:47:26,474] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:42:26.474572+00:00
[2019-10-04 08:47:26,489] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 9.701 seconds
[2019-10-04 08:47:37,817] {{logging_mixin.py:95}} INFO - [2019-10-04 08:47:37,817] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:47:40,623] {{jobs.py:386}} INFO - Started process (PID=362) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:47:42,186] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:47:42,187] {{logging_mixin.py:95}} INFO - [2019-10-04 08:47:42,187] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:47:42,329] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:47:44,782] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:47:45,213] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:47:45,223] {{logging_mixin.py:95}} INFO - [2019-10-04 08:47:45,223] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:47:45,226] {{logging_mixin.py:95}} INFO - [2019-10-04 08:47:45,224] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:42:45.224337+00:00
[2019-10-04 08:47:45,233] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.611 seconds
[2019-10-04 08:47:57,460] {{logging_mixin.py:95}} INFO - [2019-10-04 08:47:57,460] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:47:57,542] {{jobs.py:386}} INFO - Started process (PID=365) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:47:57,547] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:47:57,549] {{logging_mixin.py:95}} INFO - [2019-10-04 08:47:57,548] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:47:57,619] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:47:57,989] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:47:57,998] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:47:58,009] {{logging_mixin.py:95}} INFO - [2019-10-04 08:47:58,009] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:47:58,010] {{logging_mixin.py:95}} INFO - [2019-10-04 08:47:58,010] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:42:58.010023+00:00
[2019-10-04 08:47:58,049] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.507 seconds
[2019-10-04 08:48:09,614] {{logging_mixin.py:95}} INFO - [2019-10-04 08:48:09,614] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:48:10,737] {{jobs.py:386}} INFO - Started process (PID=369) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:48:11,598] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:48:11,607] {{logging_mixin.py:95}} INFO - [2019-10-04 08:48:11,607] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:48:13,439] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:48:14,313] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:48:14,603] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:48:15,203] {{logging_mixin.py:95}} INFO - [2019-10-04 08:48:15,203] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:48:15,204] {{logging_mixin.py:95}} INFO - [2019-10-04 08:48:15,204] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:43:15.204285+00:00
[2019-10-04 08:48:15,999] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.262 seconds
[2019-10-04 08:48:28,292] {{logging_mixin.py:95}} INFO - [2019-10-04 08:48:28,292] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:48:28,296] {{jobs.py:386}} INFO - Started process (PID=378) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:48:28,300] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:48:28,301] {{logging_mixin.py:95}} INFO - [2019-10-04 08:48:28,300] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:48:28,332] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:48:28,735] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:48:28,743] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:48:28,756] {{logging_mixin.py:95}} INFO - [2019-10-04 08:48:28,756] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:48:28,758] {{logging_mixin.py:95}} INFO - [2019-10-04 08:48:28,757] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:43:28.757660+00:00
[2019-10-04 08:48:28,765] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.469 seconds
[2019-10-04 08:48:39,658] {{logging_mixin.py:95}} INFO - [2019-10-04 08:48:39,658] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:48:39,662] {{jobs.py:386}} INFO - Started process (PID=382) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:48:39,665] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:48:39,666] {{logging_mixin.py:95}} INFO - [2019-10-04 08:48:39,666] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:48:39,699] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:48:40,111] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:48:40,117] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:48:40,126] {{logging_mixin.py:95}} INFO - [2019-10-04 08:48:40,126] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:48:40,128] {{logging_mixin.py:95}} INFO - [2019-10-04 08:48:40,127] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:43:40.127775+00:00
[2019-10-04 08:48:40,136] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.474 seconds
[2019-10-04 08:48:51,253] {{logging_mixin.py:95}} INFO - [2019-10-04 08:48:51,252] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:48:51,256] {{jobs.py:386}} INFO - Started process (PID=391) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:48:51,259] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:48:51,260] {{logging_mixin.py:95}} INFO - [2019-10-04 08:48:51,260] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:48:51,292] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:48:51,556] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:48:51,562] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:48:51,571] {{logging_mixin.py:95}} INFO - [2019-10-04 08:48:51,571] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:48:51,571] {{logging_mixin.py:95}} INFO - [2019-10-04 08:48:51,571] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:43:51.571465+00:00
[2019-10-04 08:48:51,580] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.324 seconds
[2019-10-04 08:49:02,761] {{logging_mixin.py:95}} INFO - [2019-10-04 08:49:02,761] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:49:02,765] {{jobs.py:386}} INFO - Started process (PID=395) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:49:02,773] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:49:02,777] {{logging_mixin.py:95}} INFO - [2019-10-04 08:49:02,777] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:49:02,805] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:49:02,966] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:49:02,971] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:49:02,984] {{logging_mixin.py:95}} INFO - [2019-10-04 08:49:02,984] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:49:02,985] {{logging_mixin.py:95}} INFO - [2019-10-04 08:49:02,985] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:44:02.985157+00:00
[2019-10-04 08:49:02,993] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.228 seconds
[2019-10-04 08:49:14,322] {{logging_mixin.py:95}} INFO - [2019-10-04 08:49:14,322] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:49:14,334] {{jobs.py:386}} INFO - Started process (PID=405) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:49:14,336] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:49:14,337] {{logging_mixin.py:95}} INFO - [2019-10-04 08:49:14,337] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:49:14,374] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:49:14,815] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:49:14,827] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:49:14,842] {{logging_mixin.py:95}} INFO - [2019-10-04 08:49:14,841] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:49:14,846] {{logging_mixin.py:95}} INFO - [2019-10-04 08:49:14,843] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:44:14.843028+00:00
[2019-10-04 08:49:14,856] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.522 seconds
[2019-10-04 08:49:25,938] {{logging_mixin.py:95}} INFO - [2019-10-04 08:49:25,937] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:49:25,941] {{jobs.py:386}} INFO - Started process (PID=409) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:49:25,953] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:49:25,961] {{logging_mixin.py:95}} INFO - [2019-10-04 08:49:25,961] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:49:25,998] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:49:26,627] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:49:26,633] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:49:26,644] {{logging_mixin.py:95}} INFO - [2019-10-04 08:49:26,644] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:49:26,645] {{logging_mixin.py:95}} INFO - [2019-10-04 08:49:26,645] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:44:26.644990+00:00
[2019-10-04 08:49:26,651] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.710 seconds
[2019-10-04 08:49:37,934] {{logging_mixin.py:95}} INFO - [2019-10-04 08:49:37,933] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:49:38,466] {{jobs.py:386}} INFO - Started process (PID=413) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:49:38,875] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:49:38,968] {{logging_mixin.py:95}} INFO - [2019-10-04 08:49:38,968] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:49:41,979] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:49:44,246] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:49:44,709] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:49:44,886] {{logging_mixin.py:95}} INFO - [2019-10-04 08:49:44,886] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:49:44,888] {{logging_mixin.py:95}} INFO - [2019-10-04 08:49:44,887] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:44:44.887329+00:00
[2019-10-04 08:49:44,994] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 6.528 seconds
[2019-10-04 08:49:55,538] {{logging_mixin.py:95}} INFO - [2019-10-04 08:49:55,538] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:49:55,879] {{jobs.py:386}} INFO - Started process (PID=424) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:49:56,098] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:49:56,100] {{logging_mixin.py:95}} INFO - [2019-10-04 08:49:56,100] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:49:56,363] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:49:56,689] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:49:56,751] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:49:56,759] {{logging_mixin.py:95}} INFO - [2019-10-04 08:49:56,759] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:49:56,761] {{logging_mixin.py:95}} INFO - [2019-10-04 08:49:56,760] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:44:56.760660+00:00
[2019-10-04 08:49:56,768] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.889 seconds
[2019-10-04 08:50:08,450] {{logging_mixin.py:95}} INFO - [2019-10-04 08:50:08,450] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:50:08,454] {{jobs.py:386}} INFO - Started process (PID=428) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:50:08,457] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:50:08,460] {{logging_mixin.py:95}} INFO - [2019-10-04 08:50:08,460] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:50:08,480] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:50:10,069] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:50:10,263] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:50:10,272] {{logging_mixin.py:95}} INFO - [2019-10-04 08:50:10,272] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:50:10,274] {{logging_mixin.py:95}} INFO - [2019-10-04 08:50:10,273] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:45:10.272993+00:00
[2019-10-04 08:50:10,317] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.863 seconds
[2019-10-04 08:50:20,879] {{logging_mixin.py:95}} INFO - [2019-10-04 08:50:20,879] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:50:20,882] {{jobs.py:386}} INFO - Started process (PID=437) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:50:20,885] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:50:20,886] {{logging_mixin.py:95}} INFO - [2019-10-04 08:50:20,886] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:50:20,906] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:50:21,324] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:50:21,329] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:50:21,491] {{logging_mixin.py:95}} INFO - [2019-10-04 08:50:21,491] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:50:21,493] {{logging_mixin.py:95}} INFO - [2019-10-04 08:50:21,492] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:45:21.492648+00:00
[2019-10-04 08:50:21,564] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.681 seconds
[2019-10-04 08:50:32,122] {{logging_mixin.py:95}} INFO - [2019-10-04 08:50:32,122] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:50:32,126] {{jobs.py:386}} INFO - Started process (PID=441) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:50:32,129] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:50:32,130] {{logging_mixin.py:95}} INFO - [2019-10-04 08:50:32,130] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:50:32,151] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:50:32,813] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:50:32,821] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:50:32,836] {{logging_mixin.py:95}} INFO - [2019-10-04 08:50:32,836] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:50:32,839] {{logging_mixin.py:95}} INFO - [2019-10-04 08:50:32,837] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:45:32.837902+00:00
[2019-10-04 08:50:33,208] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.081 seconds
[2019-10-04 08:50:44,568] {{logging_mixin.py:95}} INFO - [2019-10-04 08:50:44,567] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:50:44,573] {{jobs.py:386}} INFO - Started process (PID=445) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:50:44,576] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:50:44,579] {{logging_mixin.py:95}} INFO - [2019-10-04 08:50:44,579] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:50:44,623] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:50:45,690] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:50:45,694] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:50:46,280] {{logging_mixin.py:95}} INFO - [2019-10-04 08:50:45,774] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:50:46,281] {{logging_mixin.py:95}} INFO - [2019-10-04 08:50:46,280] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:45:46.280503+00:00
[2019-10-04 08:50:46,408] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.835 seconds
[2019-10-04 08:50:57,789] {{logging_mixin.py:95}} INFO - [2019-10-04 08:50:57,789] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:50:57,792] {{jobs.py:386}} INFO - Started process (PID=460) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:50:57,794] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:50:57,795] {{logging_mixin.py:95}} INFO - [2019-10-04 08:50:57,795] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:50:57,816] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:50:58,039] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:50:58,050] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:50:58,061] {{logging_mixin.py:95}} INFO - [2019-10-04 08:50:58,061] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:50:58,063] {{logging_mixin.py:95}} INFO - [2019-10-04 08:50:58,062] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:45:58.062554+00:00
[2019-10-04 08:50:58,072] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.280 seconds
[2019-10-04 08:51:09,028] {{logging_mixin.py:95}} INFO - [2019-10-04 08:51:09,028] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:51:09,031] {{jobs.py:386}} INFO - Started process (PID=464) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:51:09,034] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:51:09,035] {{logging_mixin.py:95}} INFO - [2019-10-04 08:51:09,035] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:51:09,057] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:51:09,798] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:51:09,805] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:51:09,814] {{logging_mixin.py:95}} INFO - [2019-10-04 08:51:09,814] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:51:09,816] {{logging_mixin.py:95}} INFO - [2019-10-04 08:51:09,815] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:46:09.815735+00:00
[2019-10-04 08:51:09,826] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.795 seconds
[2019-10-04 08:51:20,669] {{logging_mixin.py:95}} INFO - [2019-10-04 08:51:20,668] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:51:20,683] {{jobs.py:386}} INFO - Started process (PID=474) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:51:20,686] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:51:20,687] {{logging_mixin.py:95}} INFO - [2019-10-04 08:51:20,687] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:51:20,706] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:51:20,948] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:51:20,954] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:51:20,966] {{logging_mixin.py:95}} INFO - [2019-10-04 08:51:20,965] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:51:20,967] {{logging_mixin.py:95}} INFO - [2019-10-04 08:51:20,966] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:46:20.966567+00:00
[2019-10-04 08:51:20,978] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.295 seconds
[2019-10-04 08:51:32,042] {{logging_mixin.py:95}} INFO - [2019-10-04 08:51:32,041] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:51:32,045] {{jobs.py:386}} INFO - Started process (PID=478) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:51:32,048] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:51:32,049] {{logging_mixin.py:95}} INFO - [2019-10-04 08:51:32,049] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:51:32,067] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:51:32,399] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:51:32,404] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:51:32,416] {{logging_mixin.py:95}} INFO - [2019-10-04 08:51:32,415] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:51:32,418] {{logging_mixin.py:95}} INFO - [2019-10-04 08:51:32,418] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:46:32.418089+00:00
[2019-10-04 08:51:32,426] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.381 seconds
[2019-10-04 08:51:43,785] {{logging_mixin.py:95}} INFO - [2019-10-04 08:51:43,784] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:51:43,874] {{jobs.py:386}} INFO - Started process (PID=482) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:51:43,918] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:51:44,039] {{logging_mixin.py:95}} INFO - [2019-10-04 08:51:44,038] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:51:44,055] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:51:44,200] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:51:44,204] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:51:44,214] {{logging_mixin.py:95}} INFO - [2019-10-04 08:51:44,214] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:51:44,216] {{logging_mixin.py:95}} INFO - [2019-10-04 08:51:44,215] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:46:44.215388+00:00
[2019-10-04 08:51:44,229] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.355 seconds
[2019-10-04 08:51:55,678] {{logging_mixin.py:95}} INFO - [2019-10-04 08:51:55,678] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:51:55,681] {{jobs.py:386}} INFO - Started process (PID=491) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:51:55,684] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:51:55,685] {{logging_mixin.py:95}} INFO - [2019-10-04 08:51:55,684] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:51:55,715] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:51:55,926] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:51:55,931] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:51:55,938] {{logging_mixin.py:95}} INFO - [2019-10-04 08:51:55,938] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:51:55,938] {{logging_mixin.py:95}} INFO - [2019-10-04 08:51:55,938] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:46:55.938301+00:00
[2019-10-04 08:51:55,946] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.265 seconds
[2019-10-04 08:52:07,302] {{logging_mixin.py:95}} INFO - [2019-10-04 08:52:07,302] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:52:07,305] {{jobs.py:386}} INFO - Started process (PID=495) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:52:07,415] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:52:07,417] {{logging_mixin.py:95}} INFO - [2019-10-04 08:52:07,417] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:52:07,713] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:52:09,599] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:52:09,611] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:52:09,632] {{logging_mixin.py:95}} INFO - [2019-10-04 08:52:09,632] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:52:09,638] {{logging_mixin.py:95}} INFO - [2019-10-04 08:52:09,637] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:47:09.637827+00:00
[2019-10-04 08:52:09,648] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.343 seconds
[2019-10-04 08:52:20,911] {{logging_mixin.py:95}} INFO - [2019-10-04 08:52:20,911] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:52:21,274] {{jobs.py:386}} INFO - Started process (PID=499) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:52:21,278] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:52:21,279] {{logging_mixin.py:95}} INFO - [2019-10-04 08:52:21,279] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:52:21,779] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:52:23,061] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:52:23,068] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:52:23,078] {{logging_mixin.py:95}} INFO - [2019-10-04 08:52:23,077] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:52:23,079] {{logging_mixin.py:95}} INFO - [2019-10-04 08:52:23,079] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:47:23.079027+00:00
[2019-10-04 08:52:23,087] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.813 seconds
[2019-10-04 08:52:34,062] {{logging_mixin.py:95}} INFO - [2019-10-04 08:52:34,062] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:52:34,137] {{jobs.py:386}} INFO - Started process (PID=508) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:52:34,139] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:52:34,139] {{logging_mixin.py:95}} INFO - [2019-10-04 08:52:34,139] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:52:34,162] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:52:34,682] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:52:34,687] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:52:34,694] {{logging_mixin.py:95}} INFO - [2019-10-04 08:52:34,694] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:52:34,695] {{logging_mixin.py:95}} INFO - [2019-10-04 08:52:34,694] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:47:34.694899+00:00
[2019-10-04 08:52:34,702] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.565 seconds
[2019-10-04 08:52:45,277] {{logging_mixin.py:95}} INFO - [2019-10-04 08:52:45,276] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:52:45,280] {{jobs.py:386}} INFO - Started process (PID=512) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:52:45,283] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:52:45,284] {{logging_mixin.py:95}} INFO - [2019-10-04 08:52:45,284] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:52:45,316] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:52:45,564] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:52:45,570] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:52:45,582] {{logging_mixin.py:95}} INFO - [2019-10-04 08:52:45,582] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:52:45,584] {{logging_mixin.py:95}} INFO - [2019-10-04 08:52:45,583] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:47:45.583724+00:00
[2019-10-04 08:52:45,592] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.312 seconds
[2019-10-04 08:52:56,760] {{logging_mixin.py:95}} INFO - [2019-10-04 08:52:56,760] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:52:56,763] {{jobs.py:386}} INFO - Started process (PID=516) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:52:56,766] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:52:56,767] {{logging_mixin.py:95}} INFO - [2019-10-04 08:52:56,766] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:52:56,787] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:52:57,032] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:52:57,037] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:52:57,048] {{logging_mixin.py:95}} INFO - [2019-10-04 08:52:57,048] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:52:57,050] {{logging_mixin.py:95}} INFO - [2019-10-04 08:52:57,049] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:47:57.049488+00:00
[2019-10-04 08:52:57,058] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.295 seconds
[2019-10-04 08:53:08,800] {{logging_mixin.py:95}} INFO - [2019-10-04 08:53:08,800] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:53:08,803] {{jobs.py:386}} INFO - Started process (PID=525) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:53:08,808] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:53:08,808] {{logging_mixin.py:95}} INFO - [2019-10-04 08:53:08,808] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:53:08,852] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:53:09,061] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:53:09,065] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:53:09,077] {{logging_mixin.py:95}} INFO - [2019-10-04 08:53:09,077] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:53:09,078] {{logging_mixin.py:95}} INFO - [2019-10-04 08:53:09,077] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:48:09.077712+00:00
[2019-10-04 08:53:09,084] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.282 seconds
[2019-10-04 08:53:20,298] {{logging_mixin.py:95}} INFO - [2019-10-04 08:53:20,298] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:53:20,302] {{jobs.py:386}} INFO - Started process (PID=529) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:53:20,459] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:53:20,503] {{logging_mixin.py:95}} INFO - [2019-10-04 08:53:20,502] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:53:21,020] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:53:21,744] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:53:21,749] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:53:21,764] {{logging_mixin.py:95}} INFO - [2019-10-04 08:53:21,764] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:53:21,765] {{logging_mixin.py:95}} INFO - [2019-10-04 08:53:21,765] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:48:21.765374+00:00
[2019-10-04 08:53:21,776] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.474 seconds
[2019-10-04 08:53:33,318] {{logging_mixin.py:95}} INFO - [2019-10-04 08:53:33,318] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:53:33,464] {{jobs.py:386}} INFO - Started process (PID=542) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:53:33,643] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:53:33,922] {{logging_mixin.py:95}} INFO - [2019-10-04 08:53:33,922] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:53:34,531] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:53:35,457] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:53:35,464] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:53:35,474] {{logging_mixin.py:95}} INFO - [2019-10-04 08:53:35,474] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:53:35,475] {{logging_mixin.py:95}} INFO - [2019-10-04 08:53:35,475] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:48:35.475242+00:00
[2019-10-04 08:53:35,482] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.019 seconds
[2019-10-04 08:53:46,121] {{logging_mixin.py:95}} INFO - [2019-10-04 08:53:46,120] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:53:46,128] {{jobs.py:386}} INFO - Started process (PID=546) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:53:46,134] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:53:46,135] {{logging_mixin.py:95}} INFO - [2019-10-04 08:53:46,135] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:53:46,174] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:53:46,318] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:53:46,325] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:53:46,334] {{logging_mixin.py:95}} INFO - [2019-10-04 08:53:46,334] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:53:46,335] {{logging_mixin.py:95}} INFO - [2019-10-04 08:53:46,335] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:48:46.335044+00:00
[2019-10-04 08:53:46,344] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.216 seconds
[2019-10-04 08:53:57,429] {{logging_mixin.py:95}} INFO - [2019-10-04 08:53:57,429] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:53:57,433] {{jobs.py:386}} INFO - Started process (PID=550) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:53:57,437] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:53:57,438] {{logging_mixin.py:95}} INFO - [2019-10-04 08:53:57,438] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:53:57,480] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:53:57,612] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:53:57,618] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:53:57,628] {{logging_mixin.py:95}} INFO - [2019-10-04 08:53:57,627] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:53:57,629] {{logging_mixin.py:95}} INFO - [2019-10-04 08:53:57,628] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:48:57.628914+00:00
[2019-10-04 08:53:57,636] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.204 seconds
[2019-10-04 08:54:08,784] {{logging_mixin.py:95}} INFO - [2019-10-04 08:54:08,783] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:54:08,788] {{jobs.py:386}} INFO - Started process (PID=562) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:54:08,799] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:54:08,800] {{logging_mixin.py:95}} INFO - [2019-10-04 08:54:08,800] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:54:08,827] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:54:09,901] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:54:09,907] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:54:09,917] {{logging_mixin.py:95}} INFO - [2019-10-04 08:54:09,917] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:54:09,919] {{logging_mixin.py:95}} INFO - [2019-10-04 08:54:09,918] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:49:09.918690+00:00
[2019-10-04 08:54:09,926] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.137 seconds
[2019-10-04 08:54:22,017] {{logging_mixin.py:95}} INFO - [2019-10-04 08:54:22,016] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:54:22,021] {{jobs.py:386}} INFO - Started process (PID=566) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:54:22,024] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:54:22,026] {{logging_mixin.py:95}} INFO - [2019-10-04 08:54:22,025] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:54:22,058] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:54:22,337] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:54:22,341] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:54:22,352] {{logging_mixin.py:95}} INFO - [2019-10-04 08:54:22,352] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:54:22,353] {{logging_mixin.py:95}} INFO - [2019-10-04 08:54:22,353] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:49:22.353286+00:00
[2019-10-04 08:54:22,361] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.340 seconds
[2019-10-04 08:54:33,561] {{logging_mixin.py:95}} INFO - [2019-10-04 08:54:33,561] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:54:33,566] {{jobs.py:386}} INFO - Started process (PID=575) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:54:33,569] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:54:33,571] {{logging_mixin.py:95}} INFO - [2019-10-04 08:54:33,571] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:54:33,596] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:54:33,885] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:54:33,892] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:54:33,903] {{logging_mixin.py:95}} INFO - [2019-10-04 08:54:33,902] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:54:33,905] {{logging_mixin.py:95}} INFO - [2019-10-04 08:54:33,905] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:49:33.905066+00:00
[2019-10-04 08:54:33,916] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.350 seconds
[2019-10-04 08:54:45,047] {{logging_mixin.py:95}} INFO - [2019-10-04 08:54:45,047] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:54:45,054] {{jobs.py:386}} INFO - Started process (PID=579) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:54:45,060] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:54:45,061] {{logging_mixin.py:95}} INFO - [2019-10-04 08:54:45,061] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:54:45,098] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:54:45,366] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:54:45,371] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:54:45,379] {{logging_mixin.py:95}} INFO - [2019-10-04 08:54:45,379] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:54:45,380] {{logging_mixin.py:95}} INFO - [2019-10-04 08:54:45,380] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:49:45.380057+00:00
[2019-10-04 08:54:45,387] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.333 seconds
[2019-10-04 08:54:56,624] {{logging_mixin.py:95}} INFO - [2019-10-04 08:54:56,624] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:54:56,629] {{jobs.py:386}} INFO - Started process (PID=583) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:54:56,633] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:54:56,634] {{logging_mixin.py:95}} INFO - [2019-10-04 08:54:56,634] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:54:56,729] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:54:56,876] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:54:56,882] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:54:56,891] {{logging_mixin.py:95}} INFO - [2019-10-04 08:54:56,891] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:54:56,894] {{logging_mixin.py:95}} INFO - [2019-10-04 08:54:56,892] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:49:56.892542+00:00
[2019-10-04 08:54:56,902] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.273 seconds
[2019-10-04 08:55:08,017] {{logging_mixin.py:95}} INFO - [2019-10-04 08:55:08,017] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:55:08,020] {{jobs.py:386}} INFO - Started process (PID=593) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:55:08,024] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:55:08,031] {{logging_mixin.py:95}} INFO - [2019-10-04 08:55:08,031] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:55:08,052] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:55:08,619] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:55:08,624] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:55:08,633] {{logging_mixin.py:95}} INFO - [2019-10-04 08:55:08,633] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:55:08,635] {{logging_mixin.py:95}} INFO - [2019-10-04 08:55:08,634] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:50:08.634590+00:00
[2019-10-04 08:55:08,644] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.624 seconds
[2019-10-04 08:55:19,915] {{logging_mixin.py:95}} INFO - [2019-10-04 08:55:19,914] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:55:19,918] {{jobs.py:386}} INFO - Started process (PID=597) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:55:19,923] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:55:19,925] {{logging_mixin.py:95}} INFO - [2019-10-04 08:55:19,925] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:55:19,958] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:55:20,291] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:55:20,296] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:55:20,305] {{logging_mixin.py:95}} INFO - [2019-10-04 08:55:20,305] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:55:20,306] {{logging_mixin.py:95}} INFO - [2019-10-04 08:55:20,306] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:50:20.306000+00:00
[2019-10-04 08:55:20,314] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.396 seconds
[2019-10-04 08:55:31,356] {{logging_mixin.py:95}} INFO - [2019-10-04 08:55:31,356] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:55:31,360] {{jobs.py:386}} INFO - Started process (PID=601) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:55:31,363] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:55:31,364] {{logging_mixin.py:95}} INFO - [2019-10-04 08:55:31,364] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:55:31,394] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:55:31,953] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:55:31,960] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:55:31,973] {{logging_mixin.py:95}} INFO - [2019-10-04 08:55:31,973] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:55:31,978] {{logging_mixin.py:95}} INFO - [2019-10-04 08:55:31,977] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:50:31.977571+00:00
[2019-10-04 08:55:31,987] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.627 seconds
[2019-10-04 08:55:42,584] {{logging_mixin.py:95}} INFO - [2019-10-04 08:55:42,584] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:55:42,587] {{jobs.py:386}} INFO - Started process (PID=612) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:55:42,591] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:55:42,592] {{logging_mixin.py:95}} INFO - [2019-10-04 08:55:42,592] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:55:42,623] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:55:42,813] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:55:42,819] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:55:42,828] {{logging_mixin.py:95}} INFO - [2019-10-04 08:55:42,827] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:55:42,829] {{logging_mixin.py:95}} INFO - [2019-10-04 08:55:42,829] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:50:42.829014+00:00
[2019-10-04 08:55:42,838] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.251 seconds
[2019-10-04 08:55:54,382] {{logging_mixin.py:95}} INFO - [2019-10-04 08:55:54,382] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:55:54,385] {{jobs.py:386}} INFO - Started process (PID=616) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:55:54,387] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:55:54,388] {{logging_mixin.py:95}} INFO - [2019-10-04 08:55:54,388] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:55:54,411] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:55:55,083] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:55:55,088] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:55:55,096] {{logging_mixin.py:95}} INFO - [2019-10-04 08:55:55,096] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:55:55,097] {{logging_mixin.py:95}} INFO - [2019-10-04 08:55:55,096] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:50:55.096547+00:00
[2019-10-04 08:55:55,103] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.718 seconds
[2019-10-04 08:56:05,846] {{logging_mixin.py:95}} INFO - [2019-10-04 08:56:05,845] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:56:05,849] {{jobs.py:386}} INFO - Started process (PID=620) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:56:05,852] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:56:05,853] {{logging_mixin.py:95}} INFO - [2019-10-04 08:56:05,853] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:56:05,872] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:56:06,129] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:56:06,169] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:56:06,247] {{logging_mixin.py:95}} INFO - [2019-10-04 08:56:06,247] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:56:06,249] {{logging_mixin.py:95}} INFO - [2019-10-04 08:56:06,248] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:51:06.248775+00:00
[2019-10-04 08:56:06,256] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.407 seconds
[2019-10-04 08:56:17,320] {{logging_mixin.py:95}} INFO - [2019-10-04 08:56:17,320] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:56:17,323] {{jobs.py:386}} INFO - Started process (PID=631) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:56:17,325] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:56:17,326] {{logging_mixin.py:95}} INFO - [2019-10-04 08:56:17,326] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:56:17,348] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:56:17,740] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:56:17,746] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:56:17,754] {{logging_mixin.py:95}} INFO - [2019-10-04 08:56:17,754] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:56:17,756] {{logging_mixin.py:95}} INFO - [2019-10-04 08:56:17,755] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:51:17.755884+00:00
[2019-10-04 08:56:17,764] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.442 seconds
[2019-10-04 08:56:29,123] {{logging_mixin.py:95}} INFO - [2019-10-04 08:56:29,123] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:56:29,126] {{jobs.py:386}} INFO - Started process (PID=635) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:56:29,129] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:56:29,130] {{logging_mixin.py:95}} INFO - [2019-10-04 08:56:29,129] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:56:29,147] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:56:29,415] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:56:29,419] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:56:29,428] {{logging_mixin.py:95}} INFO - [2019-10-04 08:56:29,428] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:56:29,429] {{logging_mixin.py:95}} INFO - [2019-10-04 08:56:29,428] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:51:29.428635+00:00
[2019-10-04 08:56:29,435] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.309 seconds
[2019-10-04 08:56:40,531] {{logging_mixin.py:95}} INFO - [2019-10-04 08:56:40,530] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:56:40,534] {{jobs.py:386}} INFO - Started process (PID=645) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:56:40,543] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:56:40,544] {{logging_mixin.py:95}} INFO - [2019-10-04 08:56:40,544] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:56:40,569] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:56:40,769] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:56:40,775] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:56:40,784] {{logging_mixin.py:95}} INFO - [2019-10-04 08:56:40,784] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:56:40,786] {{logging_mixin.py:95}} INFO - [2019-10-04 08:56:40,786] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:51:40.786193+00:00
[2019-10-04 08:56:40,794] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.260 seconds
[2019-10-04 08:56:51,994] {{logging_mixin.py:95}} INFO - [2019-10-04 08:56:51,993] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:56:51,997] {{jobs.py:386}} INFO - Started process (PID=649) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:56:51,999] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:56:52,000] {{logging_mixin.py:95}} INFO - [2019-10-04 08:56:52,000] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:56:52,021] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:56:52,120] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:56:52,127] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:56:52,135] {{logging_mixin.py:95}} INFO - [2019-10-04 08:56:52,135] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:56:52,137] {{logging_mixin.py:95}} INFO - [2019-10-04 08:56:52,136] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:51:52.136159+00:00
[2019-10-04 08:56:52,145] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.148 seconds
[2019-10-04 08:57:03,593] {{logging_mixin.py:95}} INFO - [2019-10-04 08:57:03,593] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:57:03,596] {{jobs.py:386}} INFO - Started process (PID=653) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:57:03,599] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:57:03,600] {{logging_mixin.py:95}} INFO - [2019-10-04 08:57:03,600] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:57:03,620] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:57:03,783] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:57:03,787] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:57:03,796] {{logging_mixin.py:95}} INFO - [2019-10-04 08:57:03,796] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:57:03,797] {{logging_mixin.py:95}} INFO - [2019-10-04 08:57:03,796] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:52:03.796844+00:00
[2019-10-04 08:57:03,806] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.210 seconds
[2019-10-04 08:57:15,301] {{logging_mixin.py:95}} INFO - [2019-10-04 08:57:15,301] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:57:15,304] {{jobs.py:386}} INFO - Started process (PID=662) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:57:15,307] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:57:15,308] {{logging_mixin.py:95}} INFO - [2019-10-04 08:57:15,308] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:57:15,329] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:57:15,743] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:57:15,749] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:57:15,760] {{logging_mixin.py:95}} INFO - [2019-10-04 08:57:15,760] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:57:15,763] {{logging_mixin.py:95}} INFO - [2019-10-04 08:57:15,762] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:52:15.762526+00:00
[2019-10-04 08:57:15,772] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.468 seconds
[2019-10-04 08:57:27,585] {{logging_mixin.py:95}} INFO - [2019-10-04 08:57:27,585] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:57:27,588] {{jobs.py:386}} INFO - Started process (PID=666) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:57:27,591] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:57:27,591] {{logging_mixin.py:95}} INFO - [2019-10-04 08:57:27,591] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:57:27,612] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:57:27,731] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:57:27,736] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:57:27,744] {{logging_mixin.py:95}} INFO - [2019-10-04 08:57:27,744] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:57:27,745] {{logging_mixin.py:95}} INFO - [2019-10-04 08:57:27,745] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:52:27.745014+00:00
[2019-10-04 08:57:27,751] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.163 seconds
[2019-10-04 08:57:38,903] {{logging_mixin.py:95}} INFO - [2019-10-04 08:57:38,903] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:57:38,906] {{jobs.py:386}} INFO - Started process (PID=670) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:57:38,909] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:57:38,911] {{logging_mixin.py:95}} INFO - [2019-10-04 08:57:38,911] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:57:38,949] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:57:39,258] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:57:39,264] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:57:39,273] {{logging_mixin.py:95}} INFO - [2019-10-04 08:57:39,273] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:57:39,274] {{logging_mixin.py:95}} INFO - [2019-10-04 08:57:39,273] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:52:39.273912+00:00
[2019-10-04 08:57:39,281] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.374 seconds
[2019-10-04 08:57:50,770] {{logging_mixin.py:95}} INFO - [2019-10-04 08:57:50,770] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:57:50,773] {{jobs.py:386}} INFO - Started process (PID=681) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:57:50,775] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:57:50,776] {{logging_mixin.py:95}} INFO - [2019-10-04 08:57:50,776] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:57:50,799] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:57:51,044] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:57:51,050] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:57:51,057] {{logging_mixin.py:95}} INFO - [2019-10-04 08:57:51,057] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:57:51,059] {{logging_mixin.py:95}} INFO - [2019-10-04 08:57:51,058] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:52:51.058912+00:00
[2019-10-04 08:57:51,066] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.293 seconds
[2019-10-04 08:58:02,158] {{logging_mixin.py:95}} INFO - [2019-10-04 08:58:02,158] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:58:02,162] {{jobs.py:386}} INFO - Started process (PID=685) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:58:02,164] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:58:02,165] {{logging_mixin.py:95}} INFO - [2019-10-04 08:58:02,165] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:58:02,187] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:58:02,374] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:58:02,379] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:58:02,388] {{logging_mixin.py:95}} INFO - [2019-10-04 08:58:02,387] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:58:02,389] {{logging_mixin.py:95}} INFO - [2019-10-04 08:58:02,388] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:53:02.388828+00:00
[2019-10-04 08:58:02,396] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.234 seconds
[2019-10-04 08:58:13,539] {{logging_mixin.py:95}} INFO - [2019-10-04 08:58:13,538] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:58:13,541] {{jobs.py:386}} INFO - Started process (PID=694) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:58:13,543] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:58:13,544] {{logging_mixin.py:95}} INFO - [2019-10-04 08:58:13,544] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:58:13,602] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:58:13,810] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:58:13,815] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:58:13,824] {{logging_mixin.py:95}} INFO - [2019-10-04 08:58:13,824] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:58:13,825] {{logging_mixin.py:95}} INFO - [2019-10-04 08:58:13,824] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:53:13.824810+00:00
[2019-10-04 08:58:13,832] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.291 seconds
[2019-10-04 08:58:25,151] {{logging_mixin.py:95}} INFO - [2019-10-04 08:58:25,149] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:58:25,159] {{jobs.py:386}} INFO - Started process (PID=698) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:58:25,161] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:58:25,163] {{logging_mixin.py:95}} INFO - [2019-10-04 08:58:25,163] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:58:25,196] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:58:25,411] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:58:25,415] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:58:25,422] {{logging_mixin.py:95}} INFO - [2019-10-04 08:58:25,422] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:58:25,423] {{logging_mixin.py:95}} INFO - [2019-10-04 08:58:25,423] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:53:25.423263+00:00
[2019-10-04 08:58:25,439] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.280 seconds
[2019-10-04 08:58:36,895] {{logging_mixin.py:95}} INFO - [2019-10-04 08:58:36,895] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:58:36,898] {{jobs.py:386}} INFO - Started process (PID=702) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:58:36,945] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:58:36,946] {{logging_mixin.py:95}} INFO - [2019-10-04 08:58:36,946] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:58:37,563] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:58:39,663] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:58:39,856] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:58:39,864] {{logging_mixin.py:95}} INFO - [2019-10-04 08:58:39,864] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:58:39,866] {{logging_mixin.py:95}} INFO - [2019-10-04 08:58:39,865] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:53:39.865129+00:00
[2019-10-04 08:58:39,880] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.981 seconds
[2019-10-04 08:58:51,475] {{logging_mixin.py:95}} INFO - [2019-10-04 08:58:51,474] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:58:51,479] {{jobs.py:386}} INFO - Started process (PID=711) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:58:51,483] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:58:51,483] {{logging_mixin.py:95}} INFO - [2019-10-04 08:58:51,483] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:58:52,312] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:58:52,968] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:58:52,973] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:58:52,983] {{logging_mixin.py:95}} INFO - [2019-10-04 08:58:52,983] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:58:52,984] {{logging_mixin.py:95}} INFO - [2019-10-04 08:58:52,983] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:53:52.983704+00:00
[2019-10-04 08:58:52,990] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.511 seconds
[2019-10-04 08:59:04,041] {{logging_mixin.py:95}} INFO - [2019-10-04 08:59:04,041] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:59:04,044] {{jobs.py:386}} INFO - Started process (PID=715) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:59:04,047] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:59:04,048] {{logging_mixin.py:95}} INFO - [2019-10-04 08:59:04,048] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:59:04,091] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:59:04,562] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:59:04,568] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:59:04,575] {{logging_mixin.py:95}} INFO - [2019-10-04 08:59:04,575] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:59:04,577] {{logging_mixin.py:95}} INFO - [2019-10-04 08:59:04,576] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:54:04.576491+00:00
[2019-10-04 08:59:04,583] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.538 seconds
[2019-10-04 08:59:15,500] {{logging_mixin.py:95}} INFO - [2019-10-04 08:59:15,500] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:59:15,504] {{jobs.py:386}} INFO - Started process (PID=729) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:59:15,506] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:59:15,509] {{logging_mixin.py:95}} INFO - [2019-10-04 08:59:15,509] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:59:15,539] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:59:15,738] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:59:15,744] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:59:15,751] {{logging_mixin.py:95}} INFO - [2019-10-04 08:59:15,751] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:59:15,752] {{logging_mixin.py:95}} INFO - [2019-10-04 08:59:15,752] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:54:15.752498+00:00
[2019-10-04 08:59:15,759] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.255 seconds
[2019-10-04 08:59:26,852] {{logging_mixin.py:95}} INFO - [2019-10-04 08:59:26,852] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:59:26,855] {{jobs.py:386}} INFO - Started process (PID=733) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:59:26,859] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:59:26,860] {{logging_mixin.py:95}} INFO - [2019-10-04 08:59:26,860] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:59:26,888] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:59:27,350] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:59:27,365] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:59:27,381] {{logging_mixin.py:95}} INFO - [2019-10-04 08:59:27,380] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:59:27,381] {{logging_mixin.py:95}} INFO - [2019-10-04 08:59:27,381] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:54:27.381176+00:00
[2019-10-04 08:59:27,397] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.543 seconds
[2019-10-04 08:59:39,361] {{logging_mixin.py:95}} INFO - [2019-10-04 08:59:39,361] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:59:39,367] {{jobs.py:386}} INFO - Started process (PID=737) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:59:39,373] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:59:39,376] {{logging_mixin.py:95}} INFO - [2019-10-04 08:59:39,375] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:59:39,419] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:59:39,736] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:59:39,742] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:59:39,752] {{logging_mixin.py:95}} INFO - [2019-10-04 08:59:39,752] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:59:39,759] {{logging_mixin.py:95}} INFO - [2019-10-04 08:59:39,756] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:54:39.756963+00:00
[2019-10-04 08:59:39,765] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.398 seconds
[2019-10-04 08:59:50,820] {{logging_mixin.py:95}} INFO - [2019-10-04 08:59:50,820] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 08:59:50,823] {{jobs.py:386}} INFO - Started process (PID=746) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:59:50,827] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 08:59:50,832] {{logging_mixin.py:95}} INFO - [2019-10-04 08:59:50,832] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:59:50,878] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 08:59:51,163] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 08:59:51,169] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 08:59:51,179] {{logging_mixin.py:95}} INFO - [2019-10-04 08:59:51,178] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 08:59:51,180] {{logging_mixin.py:95}} INFO - [2019-10-04 08:59:51,180] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:54:51.179968+00:00
[2019-10-04 08:59:51,187] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.363 seconds
[2019-10-04 09:00:02,612] {{logging_mixin.py:95}} INFO - [2019-10-04 09:00:02,612] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:00:02,617] {{jobs.py:386}} INFO - Started process (PID=750) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:00:02,623] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:00:02,624] {{logging_mixin.py:95}} INFO - [2019-10-04 09:00:02,624] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:00:02,662] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:00:02,882] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:00:02,888] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:00:02,903] {{logging_mixin.py:95}} INFO - [2019-10-04 09:00:02,903] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:00:02,905] {{logging_mixin.py:95}} INFO - [2019-10-04 09:00:02,904] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:55:02.904481+00:00
[2019-10-04 09:00:02,916] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.299 seconds
[2019-10-04 09:00:14,177] {{logging_mixin.py:95}} INFO - [2019-10-04 09:00:14,177] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:00:14,180] {{jobs.py:386}} INFO - Started process (PID=754) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:00:14,183] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:00:14,184] {{logging_mixin.py:95}} INFO - [2019-10-04 09:00:14,184] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:00:14,221] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:00:15,328] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:00:15,334] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:00:15,347] {{logging_mixin.py:95}} INFO - [2019-10-04 09:00:15,347] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:00:15,349] {{logging_mixin.py:95}} INFO - [2019-10-04 09:00:15,348] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:55:15.348665+00:00
[2019-10-04 09:00:15,356] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.176 seconds
[2019-10-04 09:00:27,461] {{logging_mixin.py:95}} INFO - [2019-10-04 09:00:27,461] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:00:27,465] {{jobs.py:386}} INFO - Started process (PID=763) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:00:27,467] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:00:27,469] {{logging_mixin.py:95}} INFO - [2019-10-04 09:00:27,468] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:00:27,508] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:00:27,759] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:00:27,765] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:00:27,774] {{logging_mixin.py:95}} INFO - [2019-10-04 09:00:27,774] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:00:27,776] {{logging_mixin.py:95}} INFO - [2019-10-04 09:00:27,775] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:55:27.775477+00:00
[2019-10-04 09:00:27,783] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.318 seconds
[2019-10-04 09:00:38,897] {{logging_mixin.py:95}} INFO - [2019-10-04 09:00:38,896] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:00:38,900] {{jobs.py:386}} INFO - Started process (PID=767) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:00:38,903] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:00:38,904] {{logging_mixin.py:95}} INFO - [2019-10-04 09:00:38,904] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:00:38,941] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:00:39,234] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:00:39,240] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:00:39,248] {{logging_mixin.py:95}} INFO - [2019-10-04 09:00:39,247] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:00:39,316] {{logging_mixin.py:95}} INFO - [2019-10-04 09:00:39,316] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:55:39.316165+00:00
[2019-10-04 09:00:39,366] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.466 seconds
[2019-10-04 09:00:50,463] {{logging_mixin.py:95}} INFO - [2019-10-04 09:00:50,463] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:00:50,470] {{jobs.py:386}} INFO - Started process (PID=777) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:00:50,474] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:00:50,476] {{logging_mixin.py:95}} INFO - [2019-10-04 09:00:50,476] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:00:50,609] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:00:52,023] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:00:52,029] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:00:52,037] {{logging_mixin.py:95}} INFO - [2019-10-04 09:00:52,037] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:00:52,039] {{logging_mixin.py:95}} INFO - [2019-10-04 09:00:52,038] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:55:52.038620+00:00
[2019-10-04 09:00:52,046] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.576 seconds
[2019-10-04 09:01:03,146] {{logging_mixin.py:95}} INFO - [2019-10-04 09:01:03,146] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:01:03,149] {{jobs.py:386}} INFO - Started process (PID=783) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:01:03,153] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:01:03,154] {{logging_mixin.py:95}} INFO - [2019-10-04 09:01:03,153] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:01:03,170] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:01:03,484] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:01:03,517] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:01:03,526] {{logging_mixin.py:95}} INFO - [2019-10-04 09:01:03,526] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:01:03,527] {{logging_mixin.py:95}} INFO - [2019-10-04 09:01:03,527] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:56:03.527124+00:00
[2019-10-04 09:01:03,533] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.384 seconds
[2019-10-04 09:01:15,296] {{logging_mixin.py:95}} INFO - [2019-10-04 09:01:15,295] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:01:15,299] {{jobs.py:386}} INFO - Started process (PID=786) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:01:15,304] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:01:15,307] {{logging_mixin.py:95}} INFO - [2019-10-04 09:01:15,307] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:01:15,323] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:01:16,430] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:01:16,435] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:01:16,658] {{logging_mixin.py:95}} INFO - [2019-10-04 09:01:16,658] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:01:16,661] {{logging_mixin.py:95}} INFO - [2019-10-04 09:01:16,660] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:56:16.660548+00:00
[2019-10-04 09:01:16,883] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.584 seconds
[2019-10-04 09:01:27,681] {{logging_mixin.py:95}} INFO - [2019-10-04 09:01:27,681] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:01:27,694] {{jobs.py:386}} INFO - Started process (PID=795) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:01:27,698] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:01:27,700] {{logging_mixin.py:95}} INFO - [2019-10-04 09:01:27,700] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:01:27,718] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:01:28,424] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:01:28,430] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:01:28,531] {{logging_mixin.py:95}} INFO - [2019-10-04 09:01:28,531] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:01:28,532] {{logging_mixin.py:95}} INFO - [2019-10-04 09:01:28,532] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:56:28.532153+00:00
[2019-10-04 09:01:28,539] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.846 seconds
[2019-10-04 09:01:39,350] {{logging_mixin.py:95}} INFO - [2019-10-04 09:01:39,350] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:01:39,358] {{jobs.py:386}} INFO - Started process (PID=799) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:01:39,366] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:01:39,367] {{logging_mixin.py:95}} INFO - [2019-10-04 09:01:39,367] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:01:39,390] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:01:40,706] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:01:40,714] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:01:40,735] {{logging_mixin.py:95}} INFO - [2019-10-04 09:01:40,734] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:01:40,735] {{logging_mixin.py:95}} INFO - [2019-10-04 09:01:40,735] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:56:40.735161+00:00
[2019-10-04 09:01:40,743] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.384 seconds
[2019-10-04 09:01:53,427] {{logging_mixin.py:95}} INFO - [2019-10-04 09:01:53,427] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:01:53,431] {{jobs.py:386}} INFO - Started process (PID=811) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:01:53,437] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:01:53,438] {{logging_mixin.py:95}} INFO - [2019-10-04 09:01:53,438] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:01:53,470] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:01:53,720] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:01:53,726] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:01:53,735] {{logging_mixin.py:95}} INFO - [2019-10-04 09:01:53,735] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:01:53,736] {{logging_mixin.py:95}} INFO - [2019-10-04 09:01:53,736] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:56:53.736249+00:00
[2019-10-04 09:01:53,744] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.313 seconds
[2019-10-04 09:02:04,976] {{logging_mixin.py:95}} INFO - [2019-10-04 09:02:04,976] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:02:04,980] {{jobs.py:386}} INFO - Started process (PID=815) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:02:04,982] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:02:04,983] {{logging_mixin.py:95}} INFO - [2019-10-04 09:02:04,983] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:02:05,017] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:02:05,179] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:02:05,185] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:02:05,193] {{logging_mixin.py:95}} INFO - [2019-10-04 09:02:05,193] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:02:05,194] {{logging_mixin.py:95}} INFO - [2019-10-04 09:02:05,194] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:57:05.194162+00:00
[2019-10-04 09:02:05,202] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.222 seconds
[2019-10-04 09:02:16,536] {{logging_mixin.py:95}} INFO - [2019-10-04 09:02:16,536] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:02:16,542] {{jobs.py:386}} INFO - Started process (PID=819) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:02:16,548] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:02:16,551] {{logging_mixin.py:95}} INFO - [2019-10-04 09:02:16,550] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:02:16,588] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:02:16,995] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:02:17,000] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:02:17,008] {{logging_mixin.py:95}} INFO - [2019-10-04 09:02:17,008] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:02:17,008] {{logging_mixin.py:95}} INFO - [2019-10-04 09:02:17,008] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:57:17.008487+00:00
[2019-10-04 09:02:17,014] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.472 seconds
[2019-10-04 09:02:28,325] {{logging_mixin.py:95}} INFO - [2019-10-04 09:02:28,325] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:02:28,329] {{jobs.py:386}} INFO - Started process (PID=828) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:02:28,331] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:02:28,332] {{logging_mixin.py:95}} INFO - [2019-10-04 09:02:28,332] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:02:28,363] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:02:28,632] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:02:28,637] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:02:28,645] {{logging_mixin.py:95}} INFO - [2019-10-04 09:02:28,645] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:02:28,647] {{logging_mixin.py:95}} INFO - [2019-10-04 09:02:28,646] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:57:28.646466+00:00
[2019-10-04 09:02:28,654] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.326 seconds
[2019-10-04 09:02:39,936] {{logging_mixin.py:95}} INFO - [2019-10-04 09:02:39,935] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:02:39,946] {{jobs.py:386}} INFO - Started process (PID=832) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:02:39,949] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:02:39,951] {{logging_mixin.py:95}} INFO - [2019-10-04 09:02:39,951] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:02:39,989] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:02:40,261] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:02:40,270] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:02:40,283] {{logging_mixin.py:95}} INFO - [2019-10-04 09:02:40,283] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:02:40,284] {{logging_mixin.py:95}} INFO - [2019-10-04 09:02:40,284] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:57:40.284026+00:00
[2019-10-04 09:02:40,291] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.346 seconds
[2019-10-04 09:02:51,467] {{logging_mixin.py:95}} INFO - [2019-10-04 09:02:51,467] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:02:51,472] {{jobs.py:386}} INFO - Started process (PID=836) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:02:51,475] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:02:51,480] {{logging_mixin.py:95}} INFO - [2019-10-04 09:02:51,480] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:02:51,516] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:02:51,702] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:02:51,707] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:02:51,716] {{logging_mixin.py:95}} INFO - [2019-10-04 09:02:51,716] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:02:51,717] {{logging_mixin.py:95}} INFO - [2019-10-04 09:02:51,716] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:57:51.716630+00:00
[2019-10-04 09:02:51,724] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.252 seconds
[2019-10-04 09:03:02,876] {{logging_mixin.py:95}} INFO - [2019-10-04 09:03:02,876] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:03:02,880] {{jobs.py:386}} INFO - Started process (PID=845) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:03:02,884] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:03:02,887] {{logging_mixin.py:95}} INFO - [2019-10-04 09:03:02,887] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:03:02,924] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:03:03,268] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:03:03,274] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:03:03,282] {{logging_mixin.py:95}} INFO - [2019-10-04 09:03:03,282] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:03:03,284] {{logging_mixin.py:95}} INFO - [2019-10-04 09:03:03,283] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:58:03.283639+00:00
[2019-10-04 09:03:03,321] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.441 seconds
[2019-10-04 09:03:14,065] {{logging_mixin.py:95}} INFO - [2019-10-04 09:03:14,065] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:03:14,069] {{jobs.py:386}} INFO - Started process (PID=849) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:03:14,074] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:03:14,076] {{logging_mixin.py:95}} INFO - [2019-10-04 09:03:14,075] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:03:14,109] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:03:14,225] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:03:14,230] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:03:14,238] {{logging_mixin.py:95}} INFO - [2019-10-04 09:03:14,238] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:03:14,239] {{logging_mixin.py:95}} INFO - [2019-10-04 09:03:14,239] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:58:14.239212+00:00
[2019-10-04 09:03:14,245] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.176 seconds
[2019-10-04 09:03:25,427] {{logging_mixin.py:95}} INFO - [2019-10-04 09:03:25,427] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:03:25,430] {{jobs.py:386}} INFO - Started process (PID=853) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:03:25,435] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:03:25,436] {{logging_mixin.py:95}} INFO - [2019-10-04 09:03:25,436] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:03:25,486] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:03:25,837] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:03:25,873] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:03:25,881] {{logging_mixin.py:95}} INFO - [2019-10-04 09:03:25,881] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:03:25,882] {{logging_mixin.py:95}} INFO - [2019-10-04 09:03:25,882] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:58:25.882014+00:00
[2019-10-04 09:03:25,887] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.457 seconds
[2019-10-04 09:03:36,847] {{logging_mixin.py:95}} INFO - [2019-10-04 09:03:36,847] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:03:36,852] {{jobs.py:386}} INFO - Started process (PID=862) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:03:36,857] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:03:36,858] {{logging_mixin.py:95}} INFO - [2019-10-04 09:03:36,858] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:03:36,882] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:03:37,237] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:03:37,254] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:03:37,278] {{logging_mixin.py:95}} INFO - [2019-10-04 09:03:37,277] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:03:37,280] {{logging_mixin.py:95}} INFO - [2019-10-04 09:03:37,279] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:58:37.279483+00:00
[2019-10-04 09:03:37,290] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.438 seconds
[2019-10-04 09:03:48,336] {{logging_mixin.py:95}} INFO - [2019-10-04 09:03:48,336] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:03:48,340] {{jobs.py:386}} INFO - Started process (PID=866) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:03:48,343] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:03:48,344] {{logging_mixin.py:95}} INFO - [2019-10-04 09:03:48,344] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:03:48,379] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:03:48,575] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:03:48,581] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:03:48,589] {{logging_mixin.py:95}} INFO - [2019-10-04 09:03:48,589] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:03:48,591] {{logging_mixin.py:95}} INFO - [2019-10-04 09:03:48,590] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:58:48.590584+00:00
[2019-10-04 09:03:48,597] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.257 seconds
[2019-10-04 09:03:59,862] {{logging_mixin.py:95}} INFO - [2019-10-04 09:03:59,862] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:03:59,865] {{jobs.py:386}} INFO - Started process (PID=876) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:03:59,867] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:03:59,869] {{logging_mixin.py:95}} INFO - [2019-10-04 09:03:59,868] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:03:59,911] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:04:00,345] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:04:00,350] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:04:00,357] {{logging_mixin.py:95}} INFO - [2019-10-04 09:04:00,357] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:04:00,358] {{logging_mixin.py:95}} INFO - [2019-10-04 09:04:00,357] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:59:00.357560+00:00
[2019-10-04 09:04:00,364] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.499 seconds
[2019-10-04 09:04:11,570] {{logging_mixin.py:95}} INFO - [2019-10-04 09:04:11,570] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:04:11,574] {{jobs.py:386}} INFO - Started process (PID=880) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:04:11,578] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:04:11,580] {{logging_mixin.py:95}} INFO - [2019-10-04 09:04:11,580] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:04:11,610] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:04:12,089] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:04:12,096] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:04:12,106] {{logging_mixin.py:95}} INFO - [2019-10-04 09:04:12,106] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:04:12,107] {{logging_mixin.py:95}} INFO - [2019-10-04 09:04:12,107] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:59:12.107169+00:00
[2019-10-04 09:04:12,115] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.540 seconds
[2019-10-04 09:04:23,011] {{logging_mixin.py:95}} INFO - [2019-10-04 09:04:23,010] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:04:23,014] {{jobs.py:386}} INFO - Started process (PID=884) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:04:23,026] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:04:23,028] {{logging_mixin.py:95}} INFO - [2019-10-04 09:04:23,028] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:04:23,051] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:04:23,563] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:04:23,568] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:04:23,576] {{logging_mixin.py:95}} INFO - [2019-10-04 09:04:23,576] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:04:23,578] {{logging_mixin.py:95}} INFO - [2019-10-04 09:04:23,577] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:59:23.577751+00:00
[2019-10-04 09:04:23,584] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.570 seconds
[2019-10-04 09:04:34,838] {{logging_mixin.py:95}} INFO - [2019-10-04 09:04:34,683] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:04:34,841] {{jobs.py:386}} INFO - Started process (PID=897) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:04:35,429] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:04:35,429] {{logging_mixin.py:95}} INFO - [2019-10-04 09:04:35,429] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:04:36,361] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:04:38,714] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:04:39,013] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:04:39,021] {{logging_mixin.py:95}} INFO - [2019-10-04 09:04:39,021] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:04:39,021] {{logging_mixin.py:95}} INFO - [2019-10-04 09:04:39,021] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:59:39.021339+00:00
[2019-10-04 09:04:39,029] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.187 seconds
[2019-10-04 09:04:50,223] {{logging_mixin.py:95}} INFO - [2019-10-04 09:04:50,223] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:04:50,234] {{jobs.py:386}} INFO - Started process (PID=901) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:04:50,237] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:04:50,238] {{logging_mixin.py:95}} INFO - [2019-10-04 09:04:50,238] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:04:50,265] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:04:50,536] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:04:50,541] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:04:50,549] {{logging_mixin.py:95}} INFO - [2019-10-04 09:04:50,549] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:04:50,552] {{logging_mixin.py:95}} INFO - [2019-10-04 09:04:50,551] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 08:59:50.551587+00:00
[2019-10-04 09:04:50,561] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.327 seconds
[2019-10-04 09:05:01,823] {{logging_mixin.py:95}} INFO - [2019-10-04 09:05:01,823] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:05:01,827] {{jobs.py:386}} INFO - Started process (PID=916) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:05:01,834] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:05:01,840] {{logging_mixin.py:95}} INFO - [2019-10-04 09:05:01,838] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:05:01,873] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:05:02,307] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:05:02,438] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:05:02,446] {{logging_mixin.py:95}} INFO - [2019-10-04 09:05:02,446] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:05:02,447] {{logging_mixin.py:95}} INFO - [2019-10-04 09:05:02,447] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:00:02.447378+00:00
[2019-10-04 09:05:02,454] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.627 seconds
[2019-10-04 09:05:13,197] {{logging_mixin.py:95}} INFO - [2019-10-04 09:05:13,196] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:05:13,230] {{jobs.py:386}} INFO - Started process (PID=920) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:05:13,232] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:05:13,233] {{logging_mixin.py:95}} INFO - [2019-10-04 09:05:13,232] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:05:13,265] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:05:13,813] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:05:13,818] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:05:13,827] {{logging_mixin.py:95}} INFO - [2019-10-04 09:05:13,827] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:05:13,828] {{logging_mixin.py:95}} INFO - [2019-10-04 09:05:13,828] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:00:13.827986+00:00
[2019-10-04 09:05:13,835] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.605 seconds
[2019-10-04 09:05:24,756] {{logging_mixin.py:95}} INFO - [2019-10-04 09:05:24,756] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:05:24,760] {{jobs.py:386}} INFO - Started process (PID=924) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:05:24,763] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:05:24,765] {{logging_mixin.py:95}} INFO - [2019-10-04 09:05:24,765] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:05:24,792] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:05:25,099] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:05:25,104] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:05:25,111] {{logging_mixin.py:95}} INFO - [2019-10-04 09:05:25,111] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:05:25,112] {{logging_mixin.py:95}} INFO - [2019-10-04 09:05:25,112] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:00:25.112251+00:00
[2019-10-04 09:05:25,129] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.368 seconds
[2019-10-04 09:05:36,193] {{logging_mixin.py:95}} INFO - [2019-10-04 09:05:36,193] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:05:36,196] {{jobs.py:386}} INFO - Started process (PID=933) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:05:36,198] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:05:36,199] {{logging_mixin.py:95}} INFO - [2019-10-04 09:05:36,199] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:05:36,221] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:05:36,474] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:05:36,480] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:05:36,487] {{logging_mixin.py:95}} INFO - [2019-10-04 09:05:36,487] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:05:36,489] {{logging_mixin.py:95}} INFO - [2019-10-04 09:05:36,488] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:00:36.488361+00:00
[2019-10-04 09:05:36,496] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.300 seconds
[2019-10-04 09:05:47,832] {{logging_mixin.py:95}} INFO - [2019-10-04 09:05:47,831] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:05:47,842] {{jobs.py:386}} INFO - Started process (PID=937) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:05:47,854] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:05:47,854] {{logging_mixin.py:95}} INFO - [2019-10-04 09:05:47,854] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:05:47,913] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:05:48,233] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:05:48,239] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:05:48,259] {{logging_mixin.py:95}} INFO - [2019-10-04 09:05:48,259] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:05:48,260] {{logging_mixin.py:95}} INFO - [2019-10-04 09:05:48,259] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:00:48.259819+00:00
[2019-10-04 09:05:48,266] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.424 seconds
[2019-10-04 09:05:59,938] {{logging_mixin.py:95}} INFO - [2019-10-04 09:05:59,938] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:05:59,941] {{jobs.py:386}} INFO - Started process (PID=941) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:05:59,944] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:05:59,945] {{logging_mixin.py:95}} INFO - [2019-10-04 09:05:59,945] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:05:59,962] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:06:00,207] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:06:00,214] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:06:00,227] {{logging_mixin.py:95}} INFO - [2019-10-04 09:06:00,227] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:06:00,229] {{logging_mixin.py:95}} INFO - [2019-10-04 09:06:00,228] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:01:00.228725+00:00
[2019-10-04 09:06:00,237] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.296 seconds
[2019-10-04 09:06:11,418] {{logging_mixin.py:95}} INFO - [2019-10-04 09:06:11,417] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:06:11,422] {{jobs.py:386}} INFO - Started process (PID=950) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:06:11,425] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:06:11,426] {{logging_mixin.py:95}} INFO - [2019-10-04 09:06:11,426] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:06:11,447] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:06:11,585] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:06:11,591] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:06:11,600] {{logging_mixin.py:95}} INFO - [2019-10-04 09:06:11,600] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:06:11,601] {{logging_mixin.py:95}} INFO - [2019-10-04 09:06:11,600] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:01:11.600934+00:00
[2019-10-04 09:06:11,608] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.186 seconds
[2019-10-04 09:06:22,523] {{logging_mixin.py:95}} INFO - [2019-10-04 09:06:22,523] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:06:22,538] {{jobs.py:386}} INFO - Started process (PID=954) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:06:22,542] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:06:22,543] {{logging_mixin.py:95}} INFO - [2019-10-04 09:06:22,543] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:06:22,563] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:06:22,701] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:06:22,707] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:06:22,717] {{logging_mixin.py:95}} INFO - [2019-10-04 09:06:22,717] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:06:22,718] {{logging_mixin.py:95}} INFO - [2019-10-04 09:06:22,717] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:01:22.717906+00:00
[2019-10-04 09:06:22,726] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.188 seconds
[2019-10-04 09:06:34,084] {{logging_mixin.py:95}} INFO - [2019-10-04 09:06:34,084] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:06:34,089] {{jobs.py:386}} INFO - Started process (PID=958) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:06:34,091] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:06:34,093] {{logging_mixin.py:95}} INFO - [2019-10-04 09:06:34,093] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:06:34,118] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:06:34,302] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:06:34,364] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:06:34,396] {{logging_mixin.py:95}} INFO - [2019-10-04 09:06:34,395] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:06:34,397] {{logging_mixin.py:95}} INFO - [2019-10-04 09:06:34,397] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:01:34.397089+00:00
[2019-10-04 09:06:34,404] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.316 seconds
[2019-10-04 09:06:45,834] {{logging_mixin.py:95}} INFO - [2019-10-04 09:06:45,834] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:06:45,837] {{jobs.py:386}} INFO - Started process (PID=968) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:06:45,847] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:06:45,847] {{logging_mixin.py:95}} INFO - [2019-10-04 09:06:45,847] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:06:45,864] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:06:46,201] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:06:46,207] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:06:46,216] {{logging_mixin.py:95}} INFO - [2019-10-04 09:06:46,216] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:06:46,218] {{logging_mixin.py:95}} INFO - [2019-10-04 09:06:46,217] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:01:46.217796+00:00
[2019-10-04 09:06:46,227] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.390 seconds
[2019-10-04 09:06:57,809] {{logging_mixin.py:95}} INFO - [2019-10-04 09:06:57,809] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:06:57,812] {{jobs.py:386}} INFO - Started process (PID=972) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:06:57,820] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:06:57,822] {{logging_mixin.py:95}} INFO - [2019-10-04 09:06:57,822] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:06:57,845] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:06:59,122] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:06:59,129] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:06:59,137] {{logging_mixin.py:95}} INFO - [2019-10-04 09:06:59,137] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:06:59,139] {{logging_mixin.py:95}} INFO - [2019-10-04 09:06:59,138] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:01:59.138843+00:00
[2019-10-04 09:06:59,145] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.333 seconds
[2019-10-04 09:07:11,931] {{logging_mixin.py:95}} INFO - [2019-10-04 09:07:11,931] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:07:11,936] {{jobs.py:386}} INFO - Started process (PID=984) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:07:11,939] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:07:11,941] {{logging_mixin.py:95}} INFO - [2019-10-04 09:07:11,941] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:07:12,160] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:07:12,569] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:07:12,575] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:07:12,582] {{logging_mixin.py:95}} INFO - [2019-10-04 09:07:12,582] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:07:12,584] {{logging_mixin.py:95}} INFO - [2019-10-04 09:07:12,584] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:02:12.584001+00:00
[2019-10-04 09:07:12,590] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.654 seconds
[2019-10-04 09:07:23,747] {{logging_mixin.py:95}} INFO - [2019-10-04 09:07:23,746] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:07:23,752] {{jobs.py:386}} INFO - Started process (PID=988) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:07:23,755] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:07:23,757] {{logging_mixin.py:95}} INFO - [2019-10-04 09:07:23,757] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:07:23,796] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:07:24,517] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:07:24,527] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:07:24,544] {{logging_mixin.py:95}} INFO - [2019-10-04 09:07:24,544] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:07:24,546] {{logging_mixin.py:95}} INFO - [2019-10-04 09:07:24,545] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:02:24.545627+00:00
[2019-10-04 09:07:24,554] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.802 seconds
[2019-10-04 09:07:35,280] {{logging_mixin.py:95}} INFO - [2019-10-04 09:07:35,280] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:07:35,284] {{jobs.py:386}} INFO - Started process (PID=992) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:07:35,294] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:07:35,299] {{logging_mixin.py:95}} INFO - [2019-10-04 09:07:35,298] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:07:35,329] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:07:36,572] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:07:36,630] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:07:36,642] {{logging_mixin.py:95}} INFO - [2019-10-04 09:07:36,642] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:07:36,643] {{logging_mixin.py:95}} INFO - [2019-10-04 09:07:36,643] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:02:36.643209+00:00
[2019-10-04 09:07:36,652] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.368 seconds
[2019-10-04 09:07:47,496] {{logging_mixin.py:95}} INFO - [2019-10-04 09:07:47,496] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:07:47,500] {{jobs.py:386}} INFO - Started process (PID=1001) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:07:47,556] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:07:47,557] {{logging_mixin.py:95}} INFO - [2019-10-04 09:07:47,557] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:07:47,792] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:07:48,331] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:07:48,497] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:07:48,506] {{logging_mixin.py:95}} INFO - [2019-10-04 09:07:48,506] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:07:48,508] {{logging_mixin.py:95}} INFO - [2019-10-04 09:07:48,507] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:02:48.507698+00:00
[2019-10-04 09:07:48,515] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.015 seconds
[2019-10-04 09:07:59,803] {{logging_mixin.py:95}} INFO - [2019-10-04 09:07:59,803] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:07:59,807] {{jobs.py:386}} INFO - Started process (PID=1005) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:07:59,817] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:07:59,819] {{logging_mixin.py:95}} INFO - [2019-10-04 09:07:59,819] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:07:59,877] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:08:00,235] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:08:00,242] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:08:00,250] {{logging_mixin.py:95}} INFO - [2019-10-04 09:08:00,250] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:08:00,250] {{logging_mixin.py:95}} INFO - [2019-10-04 09:08:00,250] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:03:00.250484+00:00
[2019-10-04 09:08:00,258] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.451 seconds
[2019-10-04 09:08:11,030] {{logging_mixin.py:95}} INFO - [2019-10-04 09:08:11,030] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:08:11,049] {{jobs.py:386}} INFO - Started process (PID=1014) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:08:11,053] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:08:11,055] {{logging_mixin.py:95}} INFO - [2019-10-04 09:08:11,055] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:08:11,108] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:08:11,515] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:08:11,525] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:08:11,540] {{logging_mixin.py:95}} INFO - [2019-10-04 09:08:11,540] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:08:11,541] {{logging_mixin.py:95}} INFO - [2019-10-04 09:08:11,541] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:03:11.541145+00:00
[2019-10-04 09:08:11,548] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.499 seconds
[2019-10-04 09:08:22,422] {{logging_mixin.py:95}} INFO - [2019-10-04 09:08:22,422] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:08:22,426] {{jobs.py:386}} INFO - Started process (PID=1018) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:08:22,428] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:08:22,429] {{logging_mixin.py:95}} INFO - [2019-10-04 09:08:22,429] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:08:22,451] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:08:22,934] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:08:22,943] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:08:22,960] {{logging_mixin.py:95}} INFO - [2019-10-04 09:08:22,960] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:08:22,962] {{logging_mixin.py:95}} INFO - [2019-10-04 09:08:22,961] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:03:22.961627+00:00
[2019-10-04 09:08:22,974] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.548 seconds
[2019-10-04 09:08:33,872] {{logging_mixin.py:95}} INFO - [2019-10-04 09:08:33,871] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:08:33,875] {{jobs.py:386}} INFO - Started process (PID=1022) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:08:33,878] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:08:33,879] {{logging_mixin.py:95}} INFO - [2019-10-04 09:08:33,878] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:08:33,899] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:08:34,144] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:08:34,151] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:08:34,159] {{logging_mixin.py:95}} INFO - [2019-10-04 09:08:34,159] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:08:34,159] {{logging_mixin.py:95}} INFO - [2019-10-04 09:08:34,159] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:03:34.159444+00:00
[2019-10-04 09:08:34,167] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.291 seconds
[2019-10-04 09:08:45,672] {{logging_mixin.py:95}} INFO - [2019-10-04 09:08:45,672] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:08:45,676] {{jobs.py:386}} INFO - Started process (PID=1031) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:08:45,679] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:08:45,680] {{logging_mixin.py:95}} INFO - [2019-10-04 09:08:45,680] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:08:45,699] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:08:46,918] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:08:47,194] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:08:47,203] {{logging_mixin.py:95}} INFO - [2019-10-04 09:08:47,203] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:08:47,204] {{logging_mixin.py:95}} INFO - [2019-10-04 09:08:47,203] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:03:47.203933+00:00
[2019-10-04 09:08:47,211] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.534 seconds
[2019-10-04 09:08:58,379] {{logging_mixin.py:95}} INFO - [2019-10-04 09:08:58,379] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:08:58,382] {{jobs.py:386}} INFO - Started process (PID=1035) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:08:58,387] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:08:58,395] {{logging_mixin.py:95}} INFO - [2019-10-04 09:08:58,395] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:08:58,430] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:08:58,871] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:08:58,876] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:08:58,886] {{logging_mixin.py:95}} INFO - [2019-10-04 09:08:58,886] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:08:58,888] {{logging_mixin.py:95}} INFO - [2019-10-04 09:08:58,887] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:03:58.887418+00:00
[2019-10-04 09:08:58,894] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.512 seconds
[2019-10-04 09:09:10,041] {{logging_mixin.py:95}} INFO - [2019-10-04 09:09:10,040] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:09:10,044] {{jobs.py:386}} INFO - Started process (PID=1039) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:09:10,047] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:09:10,049] {{logging_mixin.py:95}} INFO - [2019-10-04 09:09:10,049] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:09:10,077] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:09:10,783] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:09:10,790] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:09:10,798] {{logging_mixin.py:95}} INFO - [2019-10-04 09:09:10,797] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:09:10,798] {{logging_mixin.py:95}} INFO - [2019-10-04 09:09:10,798] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:04:10.798199+00:00
[2019-10-04 09:09:10,804] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.760 seconds
[2019-10-04 09:09:21,754] {{logging_mixin.py:95}} INFO - [2019-10-04 09:09:21,754] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:09:22,052] {{jobs.py:386}} INFO - Started process (PID=1049) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:09:22,055] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:09:22,056] {{logging_mixin.py:95}} INFO - [2019-10-04 09:09:22,056] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:09:22,088] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:09:22,801] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:09:22,813] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:09:22,820] {{logging_mixin.py:95}} INFO - [2019-10-04 09:09:22,820] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:09:22,821] {{logging_mixin.py:95}} INFO - [2019-10-04 09:09:22,821] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:04:22.821271+00:00
[2019-10-04 09:09:22,828] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.776 seconds
[2019-10-04 09:09:34,396] {{logging_mixin.py:95}} INFO - [2019-10-04 09:09:34,396] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:09:34,399] {{jobs.py:386}} INFO - Started process (PID=1055) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:09:34,402] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:09:34,403] {{logging_mixin.py:95}} INFO - [2019-10-04 09:09:34,403] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:09:34,418] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:09:34,615] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:09:34,621] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:09:34,628] {{logging_mixin.py:95}} INFO - [2019-10-04 09:09:34,628] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:09:34,630] {{logging_mixin.py:95}} INFO - [2019-10-04 09:09:34,629] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:04:34.629754+00:00
[2019-10-04 09:09:34,636] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.237 seconds
[2019-10-04 09:09:45,887] {{logging_mixin.py:95}} INFO - [2019-10-04 09:09:45,887] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:09:45,891] {{jobs.py:386}} INFO - Started process (PID=1059) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:09:45,894] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:09:45,910] {{logging_mixin.py:95}} INFO - [2019-10-04 09:09:45,910] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:09:45,935] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:09:46,257] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:09:46,265] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:09:46,273] {{logging_mixin.py:95}} INFO - [2019-10-04 09:09:46,272] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:09:46,273] {{logging_mixin.py:95}} INFO - [2019-10-04 09:09:46,273] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:04:46.273182+00:00
[2019-10-04 09:09:46,279] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.388 seconds
[2019-10-04 09:09:56,915] {{logging_mixin.py:95}} INFO - [2019-10-04 09:09:56,915] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:09:56,918] {{jobs.py:386}} INFO - Started process (PID=1072) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:09:56,921] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:09:56,922] {{logging_mixin.py:95}} INFO - [2019-10-04 09:09:56,922] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:09:56,941] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:09:57,193] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:09:57,200] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:09:57,209] {{logging_mixin.py:95}} INFO - [2019-10-04 09:09:57,209] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:09:57,210] {{logging_mixin.py:95}} INFO - [2019-10-04 09:09:57,210] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:04:57.210284+00:00
[2019-10-04 09:09:57,218] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.299 seconds
[2019-10-04 09:10:08,276] {{logging_mixin.py:95}} INFO - [2019-10-04 09:10:08,276] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:10:08,279] {{jobs.py:386}} INFO - Started process (PID=1076) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:10:08,281] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:10:08,282] {{logging_mixin.py:95}} INFO - [2019-10-04 09:10:08,282] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:10:08,300] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:10:08,769] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:10:08,775] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:10:08,784] {{logging_mixin.py:95}} INFO - [2019-10-04 09:10:08,784] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:10:08,785] {{logging_mixin.py:95}} INFO - [2019-10-04 09:10:08,785] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:05:08.785404+00:00
[2019-10-04 09:10:08,793] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.514 seconds
[2019-10-04 09:10:20,376] {{logging_mixin.py:95}} INFO - [2019-10-04 09:10:20,376] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:10:20,384] {{jobs.py:386}} INFO - Started process (PID=1080) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:10:20,387] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:10:20,388] {{logging_mixin.py:95}} INFO - [2019-10-04 09:10:20,388] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:10:20,412] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:10:20,667] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:10:20,672] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:10:20,679] {{logging_mixin.py:95}} INFO - [2019-10-04 09:10:20,679] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:10:20,679] {{logging_mixin.py:95}} INFO - [2019-10-04 09:10:20,679] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:05:20.679467+00:00
[2019-10-04 09:13:34,378] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 193.994 seconds
[2019-10-04 09:13:45,670] {{logging_mixin.py:95}} INFO - [2019-10-04 09:13:45,669] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:13:45,852] {{jobs.py:386}} INFO - Started process (PID=1158) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:13:46,390] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:13:46,392] {{logging_mixin.py:95}} INFO - [2019-10-04 09:13:46,392] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:13:46,941] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:13:47,483] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:13:47,506] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:13:47,516] {{logging_mixin.py:95}} INFO - [2019-10-04 09:13:47,516] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:13:47,517] {{logging_mixin.py:95}} INFO - [2019-10-04 09:13:47,516] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:08:47.516865+00:00
[2019-10-04 09:13:47,562] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.710 seconds
[2019-10-04 09:13:58,218] {{logging_mixin.py:95}} INFO - [2019-10-04 09:13:58,218] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:13:58,223] {{jobs.py:386}} INFO - Started process (PID=1162) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:13:58,228] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:13:58,230] {{logging_mixin.py:95}} INFO - [2019-10-04 09:13:58,230] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:13:58,833] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:13:59,085] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:13:59,122] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:13:59,325] {{logging_mixin.py:95}} INFO - [2019-10-04 09:13:59,325] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:13:59,326] {{logging_mixin.py:95}} INFO - [2019-10-04 09:13:59,326] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:08:59.326283+00:00
[2019-10-04 09:13:59,333] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.110 seconds
[2019-10-04 09:14:10,614] {{logging_mixin.py:95}} INFO - [2019-10-04 09:14:10,614] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:14:10,617] {{jobs.py:386}} INFO - Started process (PID=1171) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:14:10,619] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:14:10,620] {{logging_mixin.py:95}} INFO - [2019-10-04 09:14:10,620] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:14:10,641] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:14:11,251] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:14:11,259] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:14:11,272] {{logging_mixin.py:95}} INFO - [2019-10-04 09:14:11,272] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:14:11,273] {{logging_mixin.py:95}} INFO - [2019-10-04 09:14:11,272] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:09:11.272762+00:00
[2019-10-04 09:14:11,279] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.662 seconds
[2019-10-04 09:14:22,264] {{logging_mixin.py:95}} INFO - [2019-10-04 09:14:22,264] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:14:22,268] {{jobs.py:386}} INFO - Started process (PID=1175) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:14:22,271] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:14:22,272] {{logging_mixin.py:95}} INFO - [2019-10-04 09:14:22,272] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:14:22,293] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:14:22,664] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:14:22,670] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:14:22,678] {{logging_mixin.py:95}} INFO - [2019-10-04 09:14:22,677] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:14:22,679] {{logging_mixin.py:95}} INFO - [2019-10-04 09:14:22,678] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:09:22.678813+00:00
[2019-10-04 09:14:22,686] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.417 seconds
[2019-10-04 09:14:33,903] {{logging_mixin.py:95}} INFO - [2019-10-04 09:14:33,903] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:14:33,906] {{jobs.py:386}} INFO - Started process (PID=1179) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:14:33,910] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:14:33,910] {{logging_mixin.py:95}} INFO - [2019-10-04 09:14:33,910] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:14:33,958] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:14:34,085] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:14:34,092] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:14:34,132] {{logging_mixin.py:95}} INFO - [2019-10-04 09:14:34,132] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:14:34,134] {{logging_mixin.py:95}} INFO - [2019-10-04 09:14:34,133] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:09:34.133681+00:00
[2019-10-04 09:14:34,142] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.236 seconds
[2019-10-04 09:14:45,400] {{logging_mixin.py:95}} INFO - [2019-10-04 09:14:45,400] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:14:45,403] {{jobs.py:386}} INFO - Started process (PID=1188) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:14:45,405] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:14:45,405] {{logging_mixin.py:95}} INFO - [2019-10-04 09:14:45,405] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:14:45,427] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:14:45,779] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:14:45,783] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:14:45,796] {{logging_mixin.py:95}} INFO - [2019-10-04 09:14:45,796] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:14:45,797] {{logging_mixin.py:95}} INFO - [2019-10-04 09:14:45,796] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:09:45.796605+00:00
[2019-10-04 09:14:45,803] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.400 seconds
[2019-10-04 09:14:56,994] {{logging_mixin.py:95}} INFO - [2019-10-04 09:14:56,994] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:14:56,998] {{jobs.py:386}} INFO - Started process (PID=1192) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:14:57,001] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:14:57,002] {{logging_mixin.py:95}} INFO - [2019-10-04 09:14:57,002] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:14:57,022] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:14:57,236] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:14:57,242] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:14:57,251] {{logging_mixin.py:95}} INFO - [2019-10-04 09:14:57,251] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:14:57,252] {{logging_mixin.py:95}} INFO - [2019-10-04 09:14:57,252] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:09:57.252324+00:00
[2019-10-04 09:14:57,260] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.262 seconds
[2019-10-04 09:15:08,632] {{logging_mixin.py:95}} INFO - [2019-10-04 09:15:08,631] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:15:10,326] {{jobs.py:386}} INFO - Started process (PID=1196) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:15:10,427] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:15:10,428] {{logging_mixin.py:95}} INFO - [2019-10-04 09:15:10,428] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:15:11,642] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:15:13,585] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:15:13,688] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:15:13,846] {{logging_mixin.py:95}} INFO - [2019-10-04 09:15:13,845] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:15:13,856] {{logging_mixin.py:95}} INFO - [2019-10-04 09:15:13,851] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:10:13.851310+00:00
[2019-10-04 09:15:13,875] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.549 seconds
[2019-10-04 09:15:25,419] {{logging_mixin.py:95}} INFO - [2019-10-04 09:15:25,419] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:15:25,425] {{jobs.py:386}} INFO - Started process (PID=1205) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:15:25,431] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:15:25,433] {{logging_mixin.py:95}} INFO - [2019-10-04 09:15:25,433] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:15:25,473] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:15:25,744] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:15:25,750] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:15:26,087] {{logging_mixin.py:95}} INFO - [2019-10-04 09:15:26,087] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:15:26,088] {{logging_mixin.py:95}} INFO - [2019-10-04 09:15:26,088] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:10:26.088348+00:00
[2019-10-04 09:15:31,275] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.849 seconds
[2019-10-04 09:15:42,123] {{logging_mixin.py:95}} INFO - [2019-10-04 09:15:42,123] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:15:42,126] {{jobs.py:386}} INFO - Started process (PID=1216) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:15:42,129] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:15:42,133] {{logging_mixin.py:95}} INFO - [2019-10-04 09:15:42,133] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:15:42,209] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:15:42,296] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:15:42,301] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:15:42,308] {{logging_mixin.py:95}} INFO - [2019-10-04 09:15:42,308] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:15:42,310] {{logging_mixin.py:95}} INFO - [2019-10-04 09:15:42,309] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:10:42.309429+00:00
[2019-10-04 09:15:42,317] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.191 seconds
[2019-10-04 09:15:53,920] {{logging_mixin.py:95}} INFO - [2019-10-04 09:15:53,920] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:15:53,923] {{jobs.py:386}} INFO - Started process (PID=1220) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:15:53,925] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:15:53,926] {{logging_mixin.py:95}} INFO - [2019-10-04 09:15:53,926] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:15:53,942] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:15:54,070] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:15:54,077] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:15:54,087] {{logging_mixin.py:95}} INFO - [2019-10-04 09:15:54,086] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:15:54,088] {{logging_mixin.py:95}} INFO - [2019-10-04 09:15:54,087] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:10:54.087853+00:00
[2019-10-04 09:15:54,096] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.173 seconds
[2019-10-04 09:16:05,537] {{logging_mixin.py:95}} INFO - [2019-10-04 09:16:05,537] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:16:05,543] {{jobs.py:386}} INFO - Started process (PID=1224) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:16:05,551] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:16:05,552] {{logging_mixin.py:95}} INFO - [2019-10-04 09:16:05,552] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:16:05,571] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:16:05,758] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:16:05,770] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:16:05,784] {{logging_mixin.py:95}} INFO - [2019-10-04 09:16:05,784] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:16:05,786] {{logging_mixin.py:95}} INFO - [2019-10-04 09:16:05,785] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:11:05.785434+00:00
[2019-10-04 09:16:05,793] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.250 seconds
[2019-10-04 09:16:16,795] {{logging_mixin.py:95}} INFO - [2019-10-04 09:16:16,794] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:16:16,798] {{jobs.py:386}} INFO - Started process (PID=1234) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:16:16,801] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:16:16,802] {{logging_mixin.py:95}} INFO - [2019-10-04 09:16:16,802] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:16:16,823] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:16:17,383] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:16:17,390] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:16:17,398] {{logging_mixin.py:95}} INFO - [2019-10-04 09:16:17,398] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:16:17,401] {{logging_mixin.py:95}} INFO - [2019-10-04 09:16:17,399] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:11:17.399921+00:00
[2019-10-04 09:16:17,409] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.611 seconds
[2019-10-04 09:16:28,272] {{logging_mixin.py:95}} INFO - [2019-10-04 09:16:28,271] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:16:28,275] {{jobs.py:386}} INFO - Started process (PID=1238) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:16:28,277] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:16:28,278] {{logging_mixin.py:95}} INFO - [2019-10-04 09:16:28,278] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:16:28,294] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:16:28,453] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:16:28,459] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:16:28,467] {{logging_mixin.py:95}} INFO - [2019-10-04 09:16:28,467] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:16:28,469] {{logging_mixin.py:95}} INFO - [2019-10-04 09:16:28,468] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:11:28.468888+00:00
[2019-10-04 09:16:28,476] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.202 seconds
[2019-10-04 09:16:39,578] {{logging_mixin.py:95}} INFO - [2019-10-04 09:16:39,577] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:16:39,582] {{jobs.py:386}} INFO - Started process (PID=1242) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:16:39,585] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:16:39,586] {{logging_mixin.py:95}} INFO - [2019-10-04 09:16:39,586] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:16:39,606] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:16:39,699] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:16:39,705] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:16:39,714] {{logging_mixin.py:95}} INFO - [2019-10-04 09:16:39,714] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:16:39,715] {{logging_mixin.py:95}} INFO - [2019-10-04 09:16:39,715] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:11:39.715267+00:00
[2019-10-04 09:16:39,722] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.140 seconds
[2019-10-04 09:16:51,279] {{logging_mixin.py:95}} INFO - [2019-10-04 09:16:51,279] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:16:51,284] {{jobs.py:386}} INFO - Started process (PID=1252) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:16:51,286] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:16:51,287] {{logging_mixin.py:95}} INFO - [2019-10-04 09:16:51,287] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:16:51,309] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:16:51,461] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:16:51,466] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:16:51,475] {{logging_mixin.py:95}} INFO - [2019-10-04 09:16:51,474] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:16:51,476] {{logging_mixin.py:95}} INFO - [2019-10-04 09:16:51,475] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:11:51.475892+00:00
[2019-10-04 09:16:51,483] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.199 seconds
[2019-10-04 09:17:02,562] {{logging_mixin.py:95}} INFO - [2019-10-04 09:17:02,562] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:17:02,588] {{jobs.py:386}} INFO - Started process (PID=1256) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:17:02,591] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:17:02,592] {{logging_mixin.py:95}} INFO - [2019-10-04 09:17:02,592] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:17:02,611] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:17:02,824] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:17:02,829] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:17:02,837] {{logging_mixin.py:95}} INFO - [2019-10-04 09:17:02,837] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:17:02,839] {{logging_mixin.py:95}} INFO - [2019-10-04 09:17:02,838] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:12:02.838692+00:00
[2019-10-04 09:17:02,845] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.257 seconds
[2019-10-04 09:17:13,910] {{logging_mixin.py:95}} INFO - [2019-10-04 09:17:13,910] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:17:13,913] {{jobs.py:386}} INFO - Started process (PID=1260) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:17:13,916] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:17:13,917] {{logging_mixin.py:95}} INFO - [2019-10-04 09:17:13,917] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:17:13,934] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:17:14,173] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:17:14,178] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:17:14,187] {{logging_mixin.py:95}} INFO - [2019-10-04 09:17:14,187] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:17:14,188] {{logging_mixin.py:95}} INFO - [2019-10-04 09:17:14,187] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:12:14.187951+00:00
[2019-10-04 09:17:14,198] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.285 seconds
[2019-10-04 09:17:25,233] {{logging_mixin.py:95}} INFO - [2019-10-04 09:17:25,233] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:17:25,236] {{jobs.py:386}} INFO - Started process (PID=1269) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:17:25,239] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:17:25,240] {{logging_mixin.py:95}} INFO - [2019-10-04 09:17:25,240] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:17:25,258] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:17:25,728] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:17:25,770] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:17:25,778] {{logging_mixin.py:95}} INFO - [2019-10-04 09:17:25,778] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:17:25,780] {{logging_mixin.py:95}} INFO - [2019-10-04 09:17:25,779] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:12:25.779772+00:00
[2019-10-04 09:17:25,787] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.551 seconds
[2019-10-04 09:17:36,648] {{logging_mixin.py:95}} INFO - [2019-10-04 09:17:36,648] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:17:36,651] {{jobs.py:386}} INFO - Started process (PID=1273) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:17:36,663] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:17:36,664] {{logging_mixin.py:95}} INFO - [2019-10-04 09:17:36,664] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:17:36,682] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:17:37,413] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:17:37,419] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:17:37,429] {{logging_mixin.py:95}} INFO - [2019-10-04 09:17:37,429] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:17:37,429] {{logging_mixin.py:95}} INFO - [2019-10-04 09:17:37,429] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:12:37.429386+00:00
[2019-10-04 09:17:37,437] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.786 seconds
[2019-10-04 09:17:49,256] {{logging_mixin.py:95}} INFO - [2019-10-04 09:17:49,256] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:17:49,338] {{jobs.py:386}} INFO - Started process (PID=1282) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:17:49,820] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:17:49,822] {{logging_mixin.py:95}} INFO - [2019-10-04 09:17:49,822] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:17:51,783] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:17:53,047] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:17:53,056] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:17:53,620] {{logging_mixin.py:95}} INFO - [2019-10-04 09:17:53,471] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:17:53,621] {{logging_mixin.py:95}} INFO - [2019-10-04 09:17:53,621] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:12:53.621212+00:00
[2019-10-04 09:17:53,808] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.470 seconds
[2019-10-04 09:18:06,058] {{logging_mixin.py:95}} INFO - [2019-10-04 09:18:06,057] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:18:06,528] {{jobs.py:386}} INFO - Started process (PID=1285) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:18:06,547] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:18:06,549] {{logging_mixin.py:95}} INFO - [2019-10-04 09:18:06,549] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:18:06,617] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:18:06,904] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:18:06,917] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:18:06,975] {{logging_mixin.py:95}} INFO - [2019-10-04 09:18:06,975] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:18:06,977] {{logging_mixin.py:95}} INFO - [2019-10-04 09:18:06,976] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:13:06.976583+00:00
[2019-10-04 09:18:07,271] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.743 seconds
[2019-10-04 09:18:17,691] {{logging_mixin.py:95}} INFO - [2019-10-04 09:18:17,690] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:18:17,695] {{jobs.py:386}} INFO - Started process (PID=1293) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:18:17,699] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:18:17,701] {{logging_mixin.py:95}} INFO - [2019-10-04 09:18:17,701] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:18:17,732] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:18:18,102] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:18:18,106] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:18:18,114] {{logging_mixin.py:95}} INFO - [2019-10-04 09:18:18,114] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:18:18,115] {{logging_mixin.py:95}} INFO - [2019-10-04 09:18:18,114] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:13:18.114522+00:00
[2019-10-04 09:18:18,123] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.428 seconds
[2019-10-04 09:18:29,248] {{logging_mixin.py:95}} INFO - [2019-10-04 09:18:29,247] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:18:29,250] {{jobs.py:386}} INFO - Started process (PID=1297) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:18:29,253] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:18:29,257] {{logging_mixin.py:95}} INFO - [2019-10-04 09:18:29,257] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:18:29,288] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:18:29,637] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:18:29,643] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:18:29,651] {{logging_mixin.py:95}} INFO - [2019-10-04 09:18:29,651] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:18:29,653] {{logging_mixin.py:95}} INFO - [2019-10-04 09:18:29,652] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:13:29.652750+00:00
[2019-10-04 09:18:29,659] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.409 seconds
[2019-10-04 09:18:41,103] {{logging_mixin.py:95}} INFO - [2019-10-04 09:18:41,103] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:18:41,106] {{jobs.py:386}} INFO - Started process (PID=1301) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:18:41,108] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:18:41,109] {{logging_mixin.py:95}} INFO - [2019-10-04 09:18:41,109] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:18:41,144] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:18:41,566] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:18:41,574] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:18:41,582] {{logging_mixin.py:95}} INFO - [2019-10-04 09:18:41,581] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:18:41,583] {{logging_mixin.py:95}} INFO - [2019-10-04 09:18:41,582] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:13:41.582683+00:00
[2019-10-04 09:18:41,591] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.485 seconds
[2019-10-04 09:18:52,645] {{logging_mixin.py:95}} INFO - [2019-10-04 09:18:52,645] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:18:52,648] {{jobs.py:386}} INFO - Started process (PID=1312) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:18:52,651] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:18:52,652] {{logging_mixin.py:95}} INFO - [2019-10-04 09:18:52,652] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:18:52,679] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:18:53,108] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:18:53,112] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:18:53,422] {{logging_mixin.py:95}} INFO - [2019-10-04 09:18:53,422] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:18:53,423] {{logging_mixin.py:95}} INFO - [2019-10-04 09:18:53,422] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:13:53.422620+00:00
[2019-10-04 09:18:53,545] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.896 seconds
[2019-10-04 09:19:04,372] {{logging_mixin.py:95}} INFO - [2019-10-04 09:19:04,372] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:19:05,426] {{jobs.py:386}} INFO - Started process (PID=1316) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:19:06,353] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:19:06,474] {{logging_mixin.py:95}} INFO - [2019-10-04 09:19:06,474] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:19:08,266] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:19:08,665] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:19:08,708] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:19:08,723] {{logging_mixin.py:95}} INFO - [2019-10-04 09:19:08,723] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:19:08,725] {{logging_mixin.py:95}} INFO - [2019-10-04 09:19:08,724] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:14:08.724777+00:00
[2019-10-04 09:19:08,837] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.411 seconds
[2019-10-04 09:19:19,959] {{logging_mixin.py:95}} INFO - [2019-10-04 09:19:19,959] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:19:19,963] {{jobs.py:386}} INFO - Started process (PID=1320) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:19:19,968] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:19:19,971] {{logging_mixin.py:95}} INFO - [2019-10-04 09:19:19,971] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:19:20,002] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:19:20,322] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:19:20,330] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:19:20,344] {{logging_mixin.py:95}} INFO - [2019-10-04 09:19:20,344] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:19:20,349] {{logging_mixin.py:95}} INFO - [2019-10-04 09:19:20,345] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:14:20.345551+00:00
[2019-10-04 09:19:20,363] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.400 seconds
[2019-10-04 09:19:31,545] {{logging_mixin.py:95}} INFO - [2019-10-04 09:19:31,545] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:19:31,549] {{jobs.py:386}} INFO - Started process (PID=1329) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:19:31,571] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:19:31,572] {{logging_mixin.py:95}} INFO - [2019-10-04 09:19:31,572] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:19:31,604] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:19:31,911] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:19:31,916] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:19:31,924] {{logging_mixin.py:95}} INFO - [2019-10-04 09:19:31,924] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:19:31,925] {{logging_mixin.py:95}} INFO - [2019-10-04 09:19:31,924] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:14:31.924481+00:00
[2019-10-04 09:19:31,930] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.381 seconds
[2019-10-04 09:19:42,932] {{logging_mixin.py:95}} INFO - [2019-10-04 09:19:42,931] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:19:42,936] {{jobs.py:386}} INFO - Started process (PID=1333) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:19:42,941] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:19:42,942] {{logging_mixin.py:95}} INFO - [2019-10-04 09:19:42,942] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:19:42,972] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:19:43,446] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:19:43,471] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:19:43,479] {{logging_mixin.py:95}} INFO - [2019-10-04 09:19:43,479] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:19:43,481] {{logging_mixin.py:95}} INFO - [2019-10-04 09:19:43,480] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:14:43.480674+00:00
[2019-10-04 09:19:43,488] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.552 seconds
[2019-10-04 09:19:54,468] {{logging_mixin.py:95}} INFO - [2019-10-04 09:19:54,468] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:19:54,471] {{jobs.py:386}} INFO - Started process (PID=1342) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:19:54,474] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:19:54,475] {{logging_mixin.py:95}} INFO - [2019-10-04 09:19:54,475] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:19:54,507] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:19:55,498] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:19:55,505] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:19:55,565] {{logging_mixin.py:95}} INFO - [2019-10-04 09:19:55,565] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:19:55,566] {{logging_mixin.py:95}} INFO - [2019-10-04 09:19:55,565] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:14:55.565959+00:00
[2019-10-04 09:19:55,573] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.101 seconds
[2019-10-04 09:20:07,303] {{logging_mixin.py:95}} INFO - [2019-10-04 09:20:07,303] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:20:07,312] {{jobs.py:386}} INFO - Started process (PID=1346) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:20:07,316] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:20:07,317] {{logging_mixin.py:95}} INFO - [2019-10-04 09:20:07,317] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:20:07,348] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:20:08,001] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:20:08,006] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:20:08,015] {{logging_mixin.py:95}} INFO - [2019-10-04 09:20:08,014] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:20:08,015] {{logging_mixin.py:95}} INFO - [2019-10-04 09:20:08,015] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:15:08.015181+00:00
[2019-10-04 09:20:08,080] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.767 seconds
[2019-10-04 09:20:18,700] {{logging_mixin.py:95}} INFO - [2019-10-04 09:20:18,699] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:20:18,703] {{jobs.py:386}} INFO - Started process (PID=1350) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:20:18,705] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:20:18,713] {{logging_mixin.py:95}} INFO - [2019-10-04 09:20:18,713] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:20:18,740] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:20:21,160] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:20:21,165] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:20:21,177] {{logging_mixin.py:95}} INFO - [2019-10-04 09:20:21,176] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:20:21,178] {{logging_mixin.py:95}} INFO - [2019-10-04 09:20:21,177] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:15:21.177803+00:00
[2019-10-04 09:20:21,197] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.494 seconds
[2019-10-04 09:20:32,372] {{logging_mixin.py:95}} INFO - [2019-10-04 09:20:32,372] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:20:32,376] {{jobs.py:386}} INFO - Started process (PID=1359) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:20:32,379] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:20:32,380] {{logging_mixin.py:95}} INFO - [2019-10-04 09:20:32,380] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:20:32,413] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:20:32,681] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:20:32,687] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:20:32,695] {{logging_mixin.py:95}} INFO - [2019-10-04 09:20:32,695] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:20:32,696] {{logging_mixin.py:95}} INFO - [2019-10-04 09:20:32,696] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:15:32.696371+00:00
[2019-10-04 09:20:32,703] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.327 seconds
[2019-10-04 09:20:43,786] {{logging_mixin.py:95}} INFO - [2019-10-04 09:20:43,785] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:20:43,789] {{jobs.py:386}} INFO - Started process (PID=1363) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:20:43,793] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:20:43,793] {{logging_mixin.py:95}} INFO - [2019-10-04 09:20:43,793] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:20:43,824] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:20:43,945] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:20:43,950] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:20:43,958] {{logging_mixin.py:95}} INFO - [2019-10-04 09:20:43,958] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:20:43,959] {{logging_mixin.py:95}} INFO - [2019-10-04 09:20:43,959] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:15:43.958996+00:00
[2019-10-04 09:20:43,967] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.177 seconds
[2019-10-04 09:20:55,174] {{logging_mixin.py:95}} INFO - [2019-10-04 09:20:55,174] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:20:55,177] {{jobs.py:386}} INFO - Started process (PID=1372) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:20:55,180] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:20:55,181] {{logging_mixin.py:95}} INFO - [2019-10-04 09:20:55,181] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:20:55,209] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:20:56,108] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:20:56,112] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:20:56,121] {{logging_mixin.py:95}} INFO - [2019-10-04 09:20:56,121] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:20:56,123] {{logging_mixin.py:95}} INFO - [2019-10-04 09:20:56,122] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:15:56.122574+00:00
[2019-10-04 09:20:56,158] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.981 seconds
[2019-10-04 09:21:07,872] {{logging_mixin.py:95}} INFO - [2019-10-04 09:21:07,871] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:21:07,874] {{jobs.py:386}} INFO - Started process (PID=1378) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:21:07,878] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:21:07,879] {{logging_mixin.py:95}} INFO - [2019-10-04 09:21:07,878] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:21:07,899] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:21:08,166] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:21:08,172] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:21:08,181] {{logging_mixin.py:95}} INFO - [2019-10-04 09:21:08,180] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:21:08,182] {{logging_mixin.py:95}} INFO - [2019-10-04 09:21:08,181] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:16:08.181929+00:00
[2019-10-04 09:21:08,189] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.314 seconds
[2019-10-04 09:21:19,504] {{logging_mixin.py:95}} INFO - [2019-10-04 09:21:19,503] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:21:19,507] {{jobs.py:386}} INFO - Started process (PID=1382) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:21:19,509] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:21:19,509] {{logging_mixin.py:95}} INFO - [2019-10-04 09:21:19,509] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:21:19,524] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:21:20,046] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:21:20,050] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:21:20,057] {{logging_mixin.py:95}} INFO - [2019-10-04 09:21:20,057] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:21:20,058] {{logging_mixin.py:95}} INFO - [2019-10-04 09:21:20,057] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:16:20.057821+00:00
[2019-10-04 09:21:20,063] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.556 seconds
[2019-10-04 09:21:31,296] {{logging_mixin.py:95}} INFO - [2019-10-04 09:21:31,295] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:21:31,299] {{jobs.py:386}} INFO - Started process (PID=1391) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:21:31,301] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:21:31,302] {{logging_mixin.py:95}} INFO - [2019-10-04 09:21:31,302] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:21:31,321] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:21:31,639] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:21:31,648] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:21:31,659] {{logging_mixin.py:95}} INFO - [2019-10-04 09:21:31,659] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:21:31,660] {{logging_mixin.py:95}} INFO - [2019-10-04 09:21:31,659] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:16:31.659816+00:00
[2019-10-04 09:21:31,666] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.368 seconds
[2019-10-04 09:21:42,743] {{logging_mixin.py:95}} INFO - [2019-10-04 09:21:42,743] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:21:42,746] {{jobs.py:386}} INFO - Started process (PID=1395) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:21:42,749] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:21:42,750] {{logging_mixin.py:95}} INFO - [2019-10-04 09:21:42,750] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:21:42,774] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:21:42,930] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:21:42,935] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:21:42,947] {{logging_mixin.py:95}} INFO - [2019-10-04 09:21:42,947] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:21:42,948] {{logging_mixin.py:95}} INFO - [2019-10-04 09:21:42,948] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:16:42.948352+00:00
[2019-10-04 09:21:43,107] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.361 seconds
[2019-10-04 09:21:54,095] {{logging_mixin.py:95}} INFO - [2019-10-04 09:21:54,095] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:21:54,098] {{jobs.py:386}} INFO - Started process (PID=1399) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:21:54,101] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:21:54,102] {{logging_mixin.py:95}} INFO - [2019-10-04 09:21:54,102] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:21:54,125] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:21:54,350] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:21:54,355] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:21:54,363] {{logging_mixin.py:95}} INFO - [2019-10-04 09:21:54,363] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:21:54,364] {{logging_mixin.py:95}} INFO - [2019-10-04 09:21:54,364] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:16:54.364275+00:00
[2019-10-04 09:21:54,489] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.391 seconds
[2019-10-04 09:22:05,706] {{logging_mixin.py:95}} INFO - [2019-10-04 09:22:05,706] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:22:05,710] {{jobs.py:386}} INFO - Started process (PID=1408) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:22:05,712] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:22:05,713] {{logging_mixin.py:95}} INFO - [2019-10-04 09:22:05,713] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:22:05,730] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:22:06,704] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:22:06,709] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:22:06,717] {{logging_mixin.py:95}} INFO - [2019-10-04 09:22:06,717] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:22:06,719] {{logging_mixin.py:95}} INFO - [2019-10-04 09:22:06,718] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:17:06.718436+00:00
[2019-10-04 09:22:06,862] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.152 seconds
[2019-10-04 09:22:18,449] {{logging_mixin.py:95}} INFO - [2019-10-04 09:22:18,448] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:22:18,452] {{jobs.py:386}} INFO - Started process (PID=1411) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:22:18,456] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:22:18,458] {{logging_mixin.py:95}} INFO - [2019-10-04 09:22:18,458] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:22:18,567] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:22:19,251] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:22:19,258] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:22:19,265] {{logging_mixin.py:95}} INFO - [2019-10-04 09:22:19,265] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:22:19,267] {{logging_mixin.py:95}} INFO - [2019-10-04 09:22:19,266] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:17:19.266686+00:00
[2019-10-04 09:22:19,273] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.822 seconds
[2019-10-04 09:22:30,358] {{logging_mixin.py:95}} INFO - [2019-10-04 09:22:30,358] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:22:30,362] {{jobs.py:386}} INFO - Started process (PID=1420) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:22:30,364] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:22:30,365] {{logging_mixin.py:95}} INFO - [2019-10-04 09:22:30,365] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:22:30,391] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:22:30,627] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:22:30,632] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:22:30,649] {{logging_mixin.py:95}} INFO - [2019-10-04 09:22:30,649] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:22:30,651] {{logging_mixin.py:95}} INFO - [2019-10-04 09:22:30,650] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:17:30.650626+00:00
[2019-10-04 09:22:30,659] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.298 seconds
[2019-10-04 09:22:41,482] {{logging_mixin.py:95}} INFO - [2019-10-04 09:22:41,482] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:22:41,485] {{jobs.py:386}} INFO - Started process (PID=1424) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:22:41,488] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:22:41,489] {{logging_mixin.py:95}} INFO - [2019-10-04 09:22:41,488] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:22:41,553] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:22:41,724] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:22:41,733] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:22:41,748] {{logging_mixin.py:95}} INFO - [2019-10-04 09:22:41,748] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:22:41,753] {{logging_mixin.py:95}} INFO - [2019-10-04 09:22:41,753] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:17:41.753158+00:00
[2019-10-04 09:22:41,764] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.279 seconds
[2019-10-04 09:22:52,904] {{logging_mixin.py:95}} INFO - [2019-10-04 09:22:52,904] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:22:52,910] {{jobs.py:386}} INFO - Started process (PID=1428) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:22:52,929] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:22:52,934] {{logging_mixin.py:95}} INFO - [2019-10-04 09:22:52,933] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:22:52,974] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:22:53,458] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:22:53,465] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:22:53,486] {{logging_mixin.py:95}} INFO - [2019-10-04 09:22:53,486] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:22:53,487] {{logging_mixin.py:95}} INFO - [2019-10-04 09:22:53,487] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:17:53.486985+00:00
[2019-10-04 09:22:53,493] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.582 seconds
[2019-10-04 09:23:04,187] {{logging_mixin.py:95}} INFO - [2019-10-04 09:23:04,187] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:23:04,194] {{jobs.py:386}} INFO - Started process (PID=1439) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:23:04,198] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:23:04,201] {{logging_mixin.py:95}} INFO - [2019-10-04 09:23:04,201] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:23:04,253] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:23:04,619] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:23:04,624] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:23:04,639] {{logging_mixin.py:95}} INFO - [2019-10-04 09:23:04,639] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:23:04,641] {{logging_mixin.py:95}} INFO - [2019-10-04 09:23:04,640] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:18:04.640496+00:00
[2019-10-04 09:23:04,649] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.455 seconds
[2019-10-04 09:23:15,437] {{logging_mixin.py:95}} INFO - [2019-10-04 09:23:15,437] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:23:15,442] {{jobs.py:386}} INFO - Started process (PID=1443) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:23:15,446] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:23:15,453] {{logging_mixin.py:95}} INFO - [2019-10-04 09:23:15,449] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:23:15,523] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:23:16,354] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:23:16,359] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:23:16,370] {{logging_mixin.py:95}} INFO - [2019-10-04 09:23:16,370] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:23:16,507] {{logging_mixin.py:95}} INFO - [2019-10-04 09:23:16,371] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:18:16.371784+00:00
[2019-10-04 09:23:16,514] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.073 seconds
[2019-10-04 09:23:27,860] {{logging_mixin.py:95}} INFO - [2019-10-04 09:23:27,860] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:23:27,863] {{jobs.py:386}} INFO - Started process (PID=1449) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:23:27,865] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:23:27,867] {{logging_mixin.py:95}} INFO - [2019-10-04 09:23:27,867] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:23:27,886] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:23:28,012] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:23:28,018] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:23:28,027] {{logging_mixin.py:95}} INFO - [2019-10-04 09:23:28,026] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:23:28,029] {{logging_mixin.py:95}} INFO - [2019-10-04 09:23:28,028] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:18:28.028687+00:00
[2019-10-04 09:23:28,035] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.172 seconds
[2019-10-04 09:23:39,166] {{logging_mixin.py:95}} INFO - [2019-10-04 09:23:39,165] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:23:39,168] {{jobs.py:386}} INFO - Started process (PID=1457) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:23:39,171] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:23:39,172] {{logging_mixin.py:95}} INFO - [2019-10-04 09:23:39,172] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:23:39,190] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:23:39,832] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:23:39,837] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:23:39,845] {{logging_mixin.py:95}} INFO - [2019-10-04 09:23:39,845] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:23:39,847] {{logging_mixin.py:95}} INFO - [2019-10-04 09:23:39,846] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:18:39.846255+00:00
[2019-10-04 09:23:39,854] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.686 seconds
[2019-10-04 09:23:50,658] {{logging_mixin.py:95}} INFO - [2019-10-04 09:23:50,658] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:23:50,661] {{jobs.py:386}} INFO - Started process (PID=1460) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:23:50,665] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:23:50,668] {{logging_mixin.py:95}} INFO - [2019-10-04 09:23:50,668] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:23:50,773] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:23:51,057] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:23:51,073] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:23:51,117] {{logging_mixin.py:95}} INFO - [2019-10-04 09:23:51,117] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:23:51,131] {{logging_mixin.py:95}} INFO - [2019-10-04 09:23:51,130] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:18:51.130537+00:00
[2019-10-04 09:23:51,157] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.496 seconds
[2019-10-04 09:24:01,987] {{logging_mixin.py:95}} INFO - [2019-10-04 09:24:01,987] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:24:01,991] {{jobs.py:386}} INFO - Started process (PID=1469) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:24:01,993] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:24:01,995] {{logging_mixin.py:95}} INFO - [2019-10-04 09:24:01,995] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:24:02,025] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:24:02,224] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:24:02,229] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:24:02,236] {{logging_mixin.py:95}} INFO - [2019-10-04 09:24:02,236] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:24:02,237] {{logging_mixin.py:95}} INFO - [2019-10-04 09:24:02,237] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:19:02.237146+00:00
[2019-10-04 09:24:02,252] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.261 seconds
[2019-10-04 09:24:13,622] {{logging_mixin.py:95}} INFO - [2019-10-04 09:24:13,622] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:24:13,626] {{jobs.py:386}} INFO - Started process (PID=1473) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:24:13,629] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:24:13,630] {{logging_mixin.py:95}} INFO - [2019-10-04 09:24:13,630] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:24:13,668] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:24:13,901] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:24:13,907] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:24:13,915] {{logging_mixin.py:95}} INFO - [2019-10-04 09:24:13,915] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:24:13,916] {{logging_mixin.py:95}} INFO - [2019-10-04 09:24:13,915] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:19:13.915945+00:00
[2019-10-04 09:24:13,924] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.298 seconds
[2019-10-04 09:24:24,898] {{logging_mixin.py:95}} INFO - [2019-10-04 09:24:24,898] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:24:24,901] {{jobs.py:386}} INFO - Started process (PID=1477) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:24:24,905] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:24:24,906] {{logging_mixin.py:95}} INFO - [2019-10-04 09:24:24,906] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:24:24,936] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:24:25,040] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:24:25,064] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:24:25,080] {{logging_mixin.py:95}} INFO - [2019-10-04 09:24:25,080] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:24:25,081] {{logging_mixin.py:95}} INFO - [2019-10-04 09:24:25,081] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:19:25.081177+00:00
[2019-10-04 09:24:25,095] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.193 seconds
[2019-10-04 09:24:39,105] {{logging_mixin.py:95}} INFO - [2019-10-04 09:24:39,075] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:24:40,938] {{jobs.py:386}} INFO - Started process (PID=1487) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:24:41,469] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:24:41,470] {{logging_mixin.py:95}} INFO - [2019-10-04 09:24:41,470] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:24:45,296] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:24:49,754] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:24:51,975] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:24:52,300] {{logging_mixin.py:95}} INFO - [2019-10-04 09:24:52,300] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:24:52,300] {{logging_mixin.py:95}} INFO - [2019-10-04 09:24:52,300] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:19:52.300350+00:00
[2019-10-04 09:24:52,931] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 11.993 seconds
[2019-10-04 09:25:04,528] {{logging_mixin.py:95}} INFO - [2019-10-04 09:25:04,528] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:25:04,680] {{jobs.py:386}} INFO - Started process (PID=1497) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:25:04,764] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:25:04,765] {{logging_mixin.py:95}} INFO - [2019-10-04 09:25:04,765] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:25:04,796] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:25:04,899] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:25:04,907] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:25:04,914] {{logging_mixin.py:95}} INFO - [2019-10-04 09:25:04,914] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:25:04,915] {{logging_mixin.py:95}} INFO - [2019-10-04 09:25:04,915] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:20:04.915453+00:00
[2019-10-04 09:25:04,923] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.243 seconds
[2019-10-04 09:25:15,855] {{logging_mixin.py:95}} INFO - [2019-10-04 09:25:15,855] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:25:15,859] {{jobs.py:386}} INFO - Started process (PID=1501) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:25:15,862] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:25:15,865] {{logging_mixin.py:95}} INFO - [2019-10-04 09:25:15,865] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:25:15,890] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:25:16,023] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:25:16,029] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:25:16,038] {{logging_mixin.py:95}} INFO - [2019-10-04 09:25:16,038] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:25:16,039] {{logging_mixin.py:95}} INFO - [2019-10-04 09:25:16,039] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:20:16.039219+00:00
[2019-10-04 09:25:16,045] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.186 seconds
[2019-10-04 09:25:27,590] {{logging_mixin.py:95}} INFO - [2019-10-04 09:25:27,590] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:25:27,594] {{jobs.py:386}} INFO - Started process (PID=1505) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:25:27,602] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:25:27,603] {{logging_mixin.py:95}} INFO - [2019-10-04 09:25:27,603] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:25:27,620] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:25:27,924] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:25:27,931] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:25:27,940] {{logging_mixin.py:95}} INFO - [2019-10-04 09:25:27,940] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:25:27,941] {{logging_mixin.py:95}} INFO - [2019-10-04 09:25:27,940] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:20:27.940854+00:00
[2019-10-04 09:25:27,948] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.355 seconds
[2019-10-04 09:25:38,489] {{logging_mixin.py:95}} INFO - [2019-10-04 09:25:38,488] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:25:38,494] {{jobs.py:386}} INFO - Started process (PID=1516) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:25:38,497] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:25:38,511] {{logging_mixin.py:95}} INFO - [2019-10-04 09:25:38,511] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:25:39,004] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:25:39,780] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:25:39,787] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:25:39,795] {{logging_mixin.py:95}} INFO - [2019-10-04 09:25:39,795] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:25:39,797] {{logging_mixin.py:95}} INFO - [2019-10-04 09:25:39,796] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:20:39.796445+00:00
[2019-10-04 09:25:39,804] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.310 seconds
[2019-10-04 09:25:51,520] {{logging_mixin.py:95}} INFO - [2019-10-04 09:25:51,520] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:25:52,359] {{jobs.py:386}} INFO - Started process (PID=1520) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:25:52,744] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:25:52,745] {{logging_mixin.py:95}} INFO - [2019-10-04 09:25:52,745] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:25:53,521] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:25:55,175] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:25:55,286] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:25:55,295] {{logging_mixin.py:95}} INFO - [2019-10-04 09:25:55,295] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:25:55,296] {{logging_mixin.py:95}} INFO - [2019-10-04 09:25:55,296] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:20:55.296302+00:00
[2019-10-04 09:25:55,340] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.982 seconds
[2019-10-04 09:26:06,553] {{logging_mixin.py:95}} INFO - [2019-10-04 09:26:06,553] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:26:06,558] {{jobs.py:386}} INFO - Started process (PID=1530) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:26:06,560] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:26:06,562] {{logging_mixin.py:95}} INFO - [2019-10-04 09:26:06,562] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:26:06,591] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:26:07,017] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:26:07,021] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:26:07,033] {{logging_mixin.py:95}} INFO - [2019-10-04 09:26:07,033] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:26:07,033] {{logging_mixin.py:95}} INFO - [2019-10-04 09:26:07,033] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:21:07.033329+00:00
[2019-10-04 09:26:07,115] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.557 seconds
[2019-10-04 09:26:18,172] {{logging_mixin.py:95}} INFO - [2019-10-04 09:26:18,172] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:26:18,175] {{jobs.py:386}} INFO - Started process (PID=1534) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:26:18,178] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:26:18,179] {{logging_mixin.py:95}} INFO - [2019-10-04 09:26:18,179] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:26:18,552] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:26:18,867] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:26:18,872] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:26:18,885] {{logging_mixin.py:95}} INFO - [2019-10-04 09:26:18,884] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:26:18,886] {{logging_mixin.py:95}} INFO - [2019-10-04 09:26:18,885] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:21:18.885910+00:00
[2019-10-04 09:26:18,894] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.718 seconds
[2019-10-04 09:26:29,413] {{logging_mixin.py:95}} INFO - [2019-10-04 09:26:29,413] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:26:29,427] {{jobs.py:386}} INFO - Started process (PID=1538) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:26:29,431] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:26:29,432] {{logging_mixin.py:95}} INFO - [2019-10-04 09:26:29,432] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:26:29,540] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:26:29,657] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:26:29,667] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:26:29,674] {{logging_mixin.py:95}} INFO - [2019-10-04 09:26:29,674] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:26:29,676] {{logging_mixin.py:95}} INFO - [2019-10-04 09:26:29,675] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:21:29.675527+00:00
[2019-10-04 09:26:29,691] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.264 seconds
[2019-10-04 09:26:40,907] {{logging_mixin.py:95}} INFO - [2019-10-04 09:26:40,906] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:26:40,911] {{jobs.py:386}} INFO - Started process (PID=1548) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:26:41,771] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:26:41,784] {{logging_mixin.py:95}} INFO - [2019-10-04 09:26:41,784] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:26:42,153] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:26:43,917] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:26:44,111] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:26:44,325] {{logging_mixin.py:95}} INFO - [2019-10-04 09:26:44,324] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:26:44,325] {{logging_mixin.py:95}} INFO - [2019-10-04 09:26:44,325] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:21:44.325154+00:00
[2019-10-04 09:26:44,402] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.491 seconds
[2019-10-04 09:26:55,840] {{logging_mixin.py:95}} INFO - [2019-10-04 09:26:55,840] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:26:55,914] {{jobs.py:386}} INFO - Started process (PID=1552) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:26:56,018] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:26:56,019] {{logging_mixin.py:95}} INFO - [2019-10-04 09:26:56,019] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:26:56,137] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:26:56,339] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:26:56,346] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:26:56,368] {{logging_mixin.py:95}} INFO - [2019-10-04 09:26:56,368] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:26:56,370] {{logging_mixin.py:95}} INFO - [2019-10-04 09:26:56,369] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:21:56.369325+00:00
[2019-10-04 09:26:56,377] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.463 seconds
[2019-10-04 09:27:06,985] {{logging_mixin.py:95}} INFO - [2019-10-04 09:27:06,984] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:27:06,989] {{jobs.py:386}} INFO - Started process (PID=1556) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:27:06,995] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:27:06,997] {{logging_mixin.py:95}} INFO - [2019-10-04 09:27:06,997] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:27:07,031] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:27:07,379] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:27:07,393] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:27:07,400] {{logging_mixin.py:95}} INFO - [2019-10-04 09:27:07,400] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:27:07,458] {{logging_mixin.py:95}} INFO - [2019-10-04 09:27:07,401] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:22:07.401788+00:00
[2019-10-04 09:27:07,467] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.478 seconds
[2019-10-04 09:27:18,261] {{logging_mixin.py:95}} INFO - [2019-10-04 09:27:18,260] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:27:18,265] {{jobs.py:386}} INFO - Started process (PID=1566) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:27:18,273] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:27:18,273] {{logging_mixin.py:95}} INFO - [2019-10-04 09:27:18,273] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:27:18,311] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:27:18,507] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:27:18,514] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:27:18,546] {{logging_mixin.py:95}} INFO - [2019-10-04 09:27:18,546] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:27:18,547] {{logging_mixin.py:95}} INFO - [2019-10-04 09:27:18,546] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:22:18.546649+00:00
[2019-10-04 09:27:18,553] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.287 seconds
[2019-10-04 09:27:29,500] {{logging_mixin.py:95}} INFO - [2019-10-04 09:27:29,500] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:27:29,505] {{jobs.py:386}} INFO - Started process (PID=1570) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:27:29,530] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:27:29,535] {{logging_mixin.py:95}} INFO - [2019-10-04 09:27:29,535] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:27:29,563] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:27:30,113] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:27:30,117] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:27:30,126] {{logging_mixin.py:95}} INFO - [2019-10-04 09:27:30,125] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:27:30,127] {{logging_mixin.py:95}} INFO - [2019-10-04 09:27:30,126] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:22:30.126936+00:00
[2019-10-04 09:27:30,134] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.630 seconds
[2019-10-04 09:27:41,466] {{logging_mixin.py:95}} INFO - [2019-10-04 09:27:41,466] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:27:41,478] {{jobs.py:386}} INFO - Started process (PID=1579) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:27:41,487] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:27:41,490] {{logging_mixin.py:95}} INFO - [2019-10-04 09:27:41,490] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:27:41,547] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:27:41,902] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:27:41,908] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:27:41,922] {{logging_mixin.py:95}} INFO - [2019-10-04 09:27:41,922] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:27:41,923] {{logging_mixin.py:95}} INFO - [2019-10-04 09:27:41,922] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:22:41.922890+00:00
[2019-10-04 09:27:41,930] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.453 seconds
[2019-10-04 09:27:53,168] {{logging_mixin.py:95}} INFO - [2019-10-04 09:27:53,168] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:27:53,554] {{jobs.py:386}} INFO - Started process (PID=1583) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:27:53,696] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:27:53,696] {{logging_mixin.py:95}} INFO - [2019-10-04 09:27:53,696] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:27:54,062] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:27:54,848] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:27:54,866] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:27:54,919] {{logging_mixin.py:95}} INFO - [2019-10-04 09:27:54,919] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:27:54,920] {{logging_mixin.py:95}} INFO - [2019-10-04 09:27:54,919] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:22:54.919798+00:00
[2019-10-04 09:27:54,936] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.382 seconds
[2019-10-04 09:28:06,061] {{logging_mixin.py:95}} INFO - [2019-10-04 09:28:06,061] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:28:06,186] {{jobs.py:386}} INFO - Started process (PID=1587) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:28:06,188] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:28:06,190] {{logging_mixin.py:95}} INFO - [2019-10-04 09:28:06,190] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:28:06,236] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:28:06,488] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:28:06,493] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:28:06,502] {{logging_mixin.py:95}} INFO - [2019-10-04 09:28:06,501] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:28:06,503] {{logging_mixin.py:95}} INFO - [2019-10-04 09:28:06,502] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:23:06.502912+00:00
[2019-10-04 09:28:06,511] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.325 seconds
[2019-10-04 09:28:17,307] {{logging_mixin.py:95}} INFO - [2019-10-04 09:28:17,307] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:28:17,311] {{jobs.py:386}} INFO - Started process (PID=1596) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:28:17,317] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:28:17,319] {{logging_mixin.py:95}} INFO - [2019-10-04 09:28:17,319] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:28:17,349] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:28:17,442] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:28:17,448] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:28:17,458] {{logging_mixin.py:95}} INFO - [2019-10-04 09:28:17,457] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:28:17,459] {{logging_mixin.py:95}} INFO - [2019-10-04 09:28:17,458] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:23:17.458752+00:00
[2019-10-04 09:28:17,471] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.160 seconds
[2019-10-04 09:28:28,616] {{logging_mixin.py:95}} INFO - [2019-10-04 09:28:28,616] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:28:28,620] {{jobs.py:386}} INFO - Started process (PID=1600) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:28:28,623] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:28:28,629] {{logging_mixin.py:95}} INFO - [2019-10-04 09:28:28,629] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:28:28,661] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:28:28,839] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:28:28,845] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:28:28,856] {{logging_mixin.py:95}} INFO - [2019-10-04 09:28:28,855] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:28:28,857] {{logging_mixin.py:95}} INFO - [2019-10-04 09:28:28,857] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:23:28.857252+00:00
[2019-10-04 09:28:28,870] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.251 seconds
[2019-10-04 09:28:40,004] {{logging_mixin.py:95}} INFO - [2019-10-04 09:28:40,003] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:28:40,009] {{jobs.py:386}} INFO - Started process (PID=1604) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:28:40,014] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:28:40,020] {{logging_mixin.py:95}} INFO - [2019-10-04 09:28:40,020] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:28:40,057] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:28:40,249] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:28:40,255] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:28:40,271] {{logging_mixin.py:95}} INFO - [2019-10-04 09:28:40,271] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:28:40,273] {{logging_mixin.py:95}} INFO - [2019-10-04 09:28:40,272] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:23:40.272883+00:00
[2019-10-04 09:28:40,283] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.274 seconds
[2019-10-04 09:28:51,371] {{logging_mixin.py:95}} INFO - [2019-10-04 09:28:51,371] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:28:51,374] {{jobs.py:386}} INFO - Started process (PID=1614) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:28:51,377] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:28:51,378] {{logging_mixin.py:95}} INFO - [2019-10-04 09:28:51,378] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:28:51,407] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:28:51,591] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:28:51,597] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:28:51,611] {{logging_mixin.py:95}} INFO - [2019-10-04 09:28:51,611] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:28:51,612] {{logging_mixin.py:95}} INFO - [2019-10-04 09:28:51,611] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:23:51.611967+00:00
[2019-10-04 09:28:51,624] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.250 seconds
[2019-10-04 09:29:02,834] {{logging_mixin.py:95}} INFO - [2019-10-04 09:29:02,834] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:29:02,838] {{jobs.py:386}} INFO - Started process (PID=1618) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:29:02,847] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:29:02,852] {{logging_mixin.py:95}} INFO - [2019-10-04 09:29:02,852] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:29:03,353] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:29:04,529] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:29:04,535] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:29:04,545] {{logging_mixin.py:95}} INFO - [2019-10-04 09:29:04,545] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:29:04,547] {{logging_mixin.py:95}} INFO - [2019-10-04 09:29:04,547] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:24:04.547239+00:00
[2019-10-04 09:29:04,555] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.718 seconds
[2019-10-04 09:29:15,848] {{logging_mixin.py:95}} INFO - [2019-10-04 09:29:15,848] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:29:15,926] {{jobs.py:386}} INFO - Started process (PID=1627) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:29:15,931] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:29:15,933] {{logging_mixin.py:95}} INFO - [2019-10-04 09:29:15,933] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:29:16,027] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:29:16,318] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:29:16,324] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:29:16,333] {{logging_mixin.py:95}} INFO - [2019-10-04 09:29:16,333] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:29:16,335] {{logging_mixin.py:95}} INFO - [2019-10-04 09:29:16,334] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:24:16.334524+00:00
[2019-10-04 09:29:16,342] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.416 seconds
[2019-10-04 09:29:27,193] {{logging_mixin.py:95}} INFO - [2019-10-04 09:29:27,193] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:29:27,197] {{jobs.py:386}} INFO - Started process (PID=1631) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:29:27,203] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:29:27,205] {{logging_mixin.py:95}} INFO - [2019-10-04 09:29:27,205] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:29:27,240] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:29:27,526] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:29:27,539] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:29:27,546] {{logging_mixin.py:95}} INFO - [2019-10-04 09:29:27,546] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:29:27,548] {{logging_mixin.py:95}} INFO - [2019-10-04 09:29:27,547] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:24:27.547838+00:00
[2019-10-04 09:29:27,555] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.358 seconds
[2019-10-04 09:29:38,550] {{logging_mixin.py:95}} INFO - [2019-10-04 09:29:38,549] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:29:38,776] {{jobs.py:386}} INFO - Started process (PID=1635) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:29:39,225] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:29:39,227] {{logging_mixin.py:95}} INFO - [2019-10-04 09:29:39,227] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:29:39,758] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:29:40,693] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:29:40,701] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:29:40,900] {{logging_mixin.py:95}} INFO - [2019-10-04 09:29:40,900] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:29:40,902] {{logging_mixin.py:95}} INFO - [2019-10-04 09:29:40,901] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:24:40.901769+00:00
[2019-10-04 09:29:40,923] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.147 seconds
[2019-10-04 09:29:53,278] {{logging_mixin.py:95}} INFO - [2019-10-04 09:29:53,232] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:29:53,533] {{jobs.py:386}} INFO - Started process (PID=1644) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:29:55,044] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:29:55,067] {{logging_mixin.py:95}} INFO - [2019-10-04 09:29:55,067] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:29:57,405] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:30:01,461] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:30:01,611] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:30:01,619] {{logging_mixin.py:95}} INFO - [2019-10-04 09:30:01,619] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:30:01,620] {{logging_mixin.py:95}} INFO - [2019-10-04 09:30:01,620] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:25:01.620362+00:00
[2019-10-04 09:30:01,692] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 8.159 seconds
[2019-10-04 09:30:14,872] {{logging_mixin.py:95}} INFO - [2019-10-04 09:30:14,872] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:30:15,882] {{jobs.py:386}} INFO - Started process (PID=1648) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:30:17,269] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:30:17,612] {{logging_mixin.py:95}} INFO - [2019-10-04 09:30:17,612] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:30:19,469] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:30:22,816] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:30:22,860] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:30:23,067] {{logging_mixin.py:95}} INFO - [2019-10-04 09:30:23,067] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:30:23,068] {{logging_mixin.py:95}} INFO - [2019-10-04 09:30:23,068] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:25:23.067992+00:00
[2019-10-04 09:30:23,074] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 7.192 seconds
[2019-10-04 09:30:34,829] {{logging_mixin.py:95}} INFO - [2019-10-04 09:30:34,828] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:30:34,832] {{jobs.py:386}} INFO - Started process (PID=1657) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:30:34,835] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:30:34,836] {{logging_mixin.py:95}} INFO - [2019-10-04 09:30:34,836] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:30:34,855] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:30:35,541] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:30:35,546] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:30:35,554] {{logging_mixin.py:95}} INFO - [2019-10-04 09:30:35,554] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:30:35,556] {{logging_mixin.py:95}} INFO - [2019-10-04 09:30:35,555] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:25:35.555717+00:00
[2019-10-04 09:30:35,564] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.732 seconds
[2019-10-04 09:30:46,736] {{logging_mixin.py:95}} INFO - [2019-10-04 09:30:46,736] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:30:46,740] {{jobs.py:386}} INFO - Started process (PID=1661) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:30:46,744] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:30:46,744] {{logging_mixin.py:95}} INFO - [2019-10-04 09:30:46,744] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:30:46,856] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:30:48,821] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:30:48,967] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:30:48,975] {{logging_mixin.py:95}} INFO - [2019-10-04 09:30:48,975] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:30:48,980] {{logging_mixin.py:95}} INFO - [2019-10-04 09:30:48,980] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:25:48.980030+00:00
[2019-10-04 09:30:48,987] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.247 seconds
[2019-10-04 09:31:00,064] {{logging_mixin.py:95}} INFO - [2019-10-04 09:31:00,064] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:31:00,067] {{jobs.py:386}} INFO - Started process (PID=1673) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:31:00,069] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:31:00,072] {{logging_mixin.py:95}} INFO - [2019-10-04 09:31:00,072] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:31:00,091] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:31:01,783] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:31:01,795] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:31:01,983] {{logging_mixin.py:95}} INFO - [2019-10-04 09:31:01,983] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:31:01,984] {{logging_mixin.py:95}} INFO - [2019-10-04 09:31:01,983] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:26:01.983627+00:00
[2019-10-04 09:31:01,990] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.923 seconds
[2019-10-04 09:31:14,337] {{logging_mixin.py:95}} INFO - [2019-10-04 09:31:14,337] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:31:14,351] {{jobs.py:386}} INFO - Started process (PID=1676) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:31:14,425] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:31:14,426] {{logging_mixin.py:95}} INFO - [2019-10-04 09:31:14,426] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:31:15,465] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:31:16,652] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:31:16,972] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:31:16,980] {{logging_mixin.py:95}} INFO - [2019-10-04 09:31:16,980] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:31:16,981] {{logging_mixin.py:95}} INFO - [2019-10-04 09:31:16,981] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:26:16.981392+00:00
[2019-10-04 09:31:17,565] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.214 seconds
[2019-10-04 09:31:29,057] {{logging_mixin.py:95}} INFO - [2019-10-04 09:31:29,057] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:31:29,062] {{jobs.py:386}} INFO - Started process (PID=1685) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:31:29,065] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:31:29,067] {{logging_mixin.py:95}} INFO - [2019-10-04 09:31:29,067] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:31:29,105] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:31:29,397] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:31:29,404] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:31:29,414] {{logging_mixin.py:95}} INFO - [2019-10-04 09:31:29,414] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:31:29,415] {{logging_mixin.py:95}} INFO - [2019-10-04 09:31:29,415] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:26:29.415299+00:00
[2019-10-04 09:31:29,433] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.370 seconds
[2019-10-04 09:31:40,255] {{logging_mixin.py:95}} INFO - [2019-10-04 09:31:40,255] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:31:40,579] {{jobs.py:386}} INFO - Started process (PID=1689) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:31:40,722] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:31:40,724] {{logging_mixin.py:95}} INFO - [2019-10-04 09:31:40,723] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:31:41,620] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:31:43,033] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:31:43,039] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:31:43,075] {{logging_mixin.py:95}} INFO - [2019-10-04 09:31:43,075] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:31:43,076] {{logging_mixin.py:95}} INFO - [2019-10-04 09:31:43,076] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:26:43.076066+00:00
[2019-10-04 09:31:43,374] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.795 seconds
[2019-10-04 09:31:54,965] {{logging_mixin.py:95}} INFO - [2019-10-04 09:31:54,965] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:31:54,970] {{jobs.py:386}} INFO - Started process (PID=1698) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:31:54,974] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:31:55,002] {{logging_mixin.py:95}} INFO - [2019-10-04 09:31:55,002] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:31:55,022] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:31:55,318] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:31:55,323] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:31:55,410] {{logging_mixin.py:95}} INFO - [2019-10-04 09:31:55,410] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:31:55,412] {{logging_mixin.py:95}} INFO - [2019-10-04 09:31:55,411] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:26:55.411757+00:00
[2019-10-04 09:31:55,419] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.449 seconds
[2019-10-04 09:32:06,259] {{logging_mixin.py:95}} INFO - [2019-10-04 09:32:06,259] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:32:06,263] {{jobs.py:386}} INFO - Started process (PID=1702) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:32:06,646] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:32:06,648] {{logging_mixin.py:95}} INFO - [2019-10-04 09:32:06,648] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:32:07,168] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:32:08,765] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:32:08,792] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:32:08,801] {{logging_mixin.py:95}} INFO - [2019-10-04 09:32:08,801] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:32:08,803] {{logging_mixin.py:95}} INFO - [2019-10-04 09:32:08,802] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:27:08.802835+00:00
[2019-10-04 09:32:08,811] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.548 seconds
[2019-10-04 09:32:20,556] {{logging_mixin.py:95}} INFO - [2019-10-04 09:32:20,556] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:32:20,559] {{jobs.py:386}} INFO - Started process (PID=1706) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:32:20,563] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:32:20,564] {{logging_mixin.py:95}} INFO - [2019-10-04 09:32:20,564] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:32:20,687] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:32:22,432] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:32:22,438] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:32:22,597] {{logging_mixin.py:95}} INFO - [2019-10-04 09:32:22,447] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:32:22,598] {{logging_mixin.py:95}} INFO - [2019-10-04 09:32:22,597] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:27:22.597751+00:00
[2019-10-04 09:32:22,687] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.128 seconds
[2019-10-04 09:32:33,902] {{logging_mixin.py:95}} INFO - [2019-10-04 09:32:33,902] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:32:33,907] {{jobs.py:386}} INFO - Started process (PID=1715) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:32:33,910] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:32:33,911] {{logging_mixin.py:95}} INFO - [2019-10-04 09:32:33,910] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:32:33,938] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:32:34,918] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:32:34,938] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:32:34,954] {{logging_mixin.py:95}} INFO - [2019-10-04 09:32:34,954] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:32:34,956] {{logging_mixin.py:95}} INFO - [2019-10-04 09:32:34,955] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:27:34.955438+00:00
[2019-10-04 09:32:34,976] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.069 seconds
[2019-10-04 09:32:46,657] {{logging_mixin.py:95}} INFO - [2019-10-04 09:32:46,657] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:32:47,207] {{jobs.py:386}} INFO - Started process (PID=1719) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:32:48,733] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:32:48,734] {{logging_mixin.py:95}} INFO - [2019-10-04 09:32:48,734] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:32:49,504] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:32:59,068] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:32:59,373] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:32:59,381] {{logging_mixin.py:95}} INFO - [2019-10-04 09:32:59,381] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:32:59,383] {{logging_mixin.py:95}} INFO - [2019-10-04 09:32:59,382] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:27:59.382687+00:00
[2019-10-04 09:32:59,513] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 12.306 seconds
[2019-10-04 09:33:10,084] {{logging_mixin.py:95}} INFO - [2019-10-04 09:33:10,084] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:33:10,170] {{jobs.py:386}} INFO - Started process (PID=1728) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:33:10,173] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:33:10,174] {{logging_mixin.py:95}} INFO - [2019-10-04 09:33:10,174] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:33:10,204] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:33:10,662] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:33:10,666] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:33:10,674] {{logging_mixin.py:95}} INFO - [2019-10-04 09:33:10,673] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:33:10,674] {{logging_mixin.py:95}} INFO - [2019-10-04 09:33:10,674] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:28:10.674137+00:00
[2019-10-04 09:33:11,294] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.124 seconds
[2019-10-04 09:33:22,880] {{logging_mixin.py:95}} INFO - [2019-10-04 09:33:22,879] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:33:22,889] {{jobs.py:386}} INFO - Started process (PID=1734) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:33:22,893] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:33:22,894] {{logging_mixin.py:95}} INFO - [2019-10-04 09:33:22,894] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:33:22,914] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:33:23,162] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:33:23,205] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:33:23,441] {{logging_mixin.py:95}} INFO - [2019-10-04 09:33:23,266] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:33:23,443] {{logging_mixin.py:95}} INFO - [2019-10-04 09:33:23,442] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:28:23.442891+00:00
[2019-10-04 09:33:23,589] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.700 seconds
[2019-10-04 09:33:34,349] {{logging_mixin.py:95}} INFO - [2019-10-04 09:33:34,349] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:33:34,353] {{jobs.py:386}} INFO - Started process (PID=1737) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:33:34,355] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:33:34,357] {{logging_mixin.py:95}} INFO - [2019-10-04 09:33:34,356] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:33:34,375] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:33:36,268] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:33:36,273] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:33:36,294] {{logging_mixin.py:95}} INFO - [2019-10-04 09:33:36,294] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:33:36,296] {{logging_mixin.py:95}} INFO - [2019-10-04 09:33:36,295] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:28:36.295067+00:00
[2019-10-04 09:33:36,304] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.951 seconds
[2019-10-04 09:33:46,833] {{logging_mixin.py:95}} INFO - [2019-10-04 09:33:46,832] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:33:46,840] {{jobs.py:386}} INFO - Started process (PID=1750) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:33:46,846] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:33:46,846] {{logging_mixin.py:95}} INFO - [2019-10-04 09:33:46,846] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:33:46,969] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:33:47,580] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:33:47,630] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:33:47,638] {{logging_mixin.py:95}} INFO - [2019-10-04 09:33:47,638] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:33:47,638] {{logging_mixin.py:95}} INFO - [2019-10-04 09:33:47,638] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:28:47.638352+00:00
[2019-10-04 09:33:47,689] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.849 seconds
[2019-10-04 09:33:58,345] {{logging_mixin.py:95}} INFO - [2019-10-04 09:33:58,345] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:33:58,399] {{jobs.py:386}} INFO - Started process (PID=1754) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:33:58,409] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:33:58,413] {{logging_mixin.py:95}} INFO - [2019-10-04 09:33:58,413] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:33:58,458] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:33:58,712] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:33:58,881] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:33:58,891] {{logging_mixin.py:95}} INFO - [2019-10-04 09:33:58,891] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:33:58,892] {{logging_mixin.py:95}} INFO - [2019-10-04 09:33:58,892] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:28:58.892309+00:00
[2019-10-04 09:33:58,899] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.500 seconds
[2019-10-04 09:34:09,815] {{logging_mixin.py:95}} INFO - [2019-10-04 09:34:09,815] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:34:10,051] {{jobs.py:386}} INFO - Started process (PID=1758) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:34:10,218] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:34:10,219] {{logging_mixin.py:95}} INFO - [2019-10-04 09:34:10,219] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:34:10,489] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:34:13,662] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:34:13,669] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:34:13,967] {{logging_mixin.py:95}} INFO - [2019-10-04 09:34:13,676] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:34:13,968] {{logging_mixin.py:95}} INFO - [2019-10-04 09:34:13,968] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:29:13.968299+00:00
[2019-10-04 09:34:13,975] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.924 seconds
[2019-10-04 09:34:24,775] {{logging_mixin.py:95}} INFO - [2019-10-04 09:34:24,775] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:34:24,779] {{jobs.py:386}} INFO - Started process (PID=1767) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:34:24,823] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:34:24,824] {{logging_mixin.py:95}} INFO - [2019-10-04 09:34:24,824] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:34:24,870] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:34:26,245] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:34:26,696] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:34:26,704] {{logging_mixin.py:95}} INFO - [2019-10-04 09:34:26,704] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:34:26,705] {{logging_mixin.py:95}} INFO - [2019-10-04 09:34:26,704] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:29:26.704760+00:00
[2019-10-04 09:34:26,712] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.933 seconds
[2019-10-04 09:34:38,174] {{logging_mixin.py:95}} INFO - [2019-10-04 09:34:38,174] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:34:38,435] {{jobs.py:386}} INFO - Started process (PID=1771) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:34:38,565] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:34:38,566] {{logging_mixin.py:95}} INFO - [2019-10-04 09:34:38,566] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:34:38,603] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:34:38,935] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:34:38,941] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:34:38,952] {{logging_mixin.py:95}} INFO - [2019-10-04 09:34:38,952] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:34:38,955] {{logging_mixin.py:95}} INFO - [2019-10-04 09:34:38,954] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:29:38.954686+00:00
[2019-10-04 09:34:38,969] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.534 seconds
[2019-10-04 09:34:50,014] {{logging_mixin.py:95}} INFO - [2019-10-04 09:34:50,014] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:34:50,038] {{jobs.py:386}} INFO - Started process (PID=1780) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:34:50,220] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:34:50,221] {{logging_mixin.py:95}} INFO - [2019-10-04 09:34:50,221] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:34:50,385] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:34:52,287] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:34:52,295] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:34:52,304] {{logging_mixin.py:95}} INFO - [2019-10-04 09:34:52,304] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:34:52,306] {{logging_mixin.py:95}} INFO - [2019-10-04 09:34:52,305] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:29:52.305669+00:00
[2019-10-04 09:34:52,312] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.273 seconds
[2019-10-04 09:35:03,756] {{logging_mixin.py:95}} INFO - [2019-10-04 09:35:03,756] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:35:03,759] {{jobs.py:386}} INFO - Started process (PID=1786) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:35:03,762] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:35:03,762] {{logging_mixin.py:95}} INFO - [2019-10-04 09:35:03,762] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:35:03,779] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:35:03,996] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:35:04,045] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:35:04,052] {{logging_mixin.py:95}} INFO - [2019-10-04 09:35:04,052] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:35:04,053] {{logging_mixin.py:95}} INFO - [2019-10-04 09:35:04,052] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:30:04.052551+00:00
[2019-10-04 09:35:04,060] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.301 seconds
[2019-10-04 09:35:16,205] {{logging_mixin.py:95}} INFO - [2019-10-04 09:35:16,205] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:35:16,599] {{jobs.py:386}} INFO - Started process (PID=1789) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:35:16,603] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:35:16,604] {{logging_mixin.py:95}} INFO - [2019-10-04 09:35:16,604] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:35:16,626] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:35:17,031] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:35:17,056] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:35:17,064] {{logging_mixin.py:95}} INFO - [2019-10-04 09:35:17,064] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:35:17,065] {{logging_mixin.py:95}} INFO - [2019-10-04 09:35:17,065] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:30:17.065124+00:00
[2019-10-04 09:35:17,071] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.472 seconds
[2019-10-04 09:35:28,626] {{logging_mixin.py:95}} INFO - [2019-10-04 09:35:28,626] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:35:28,629] {{jobs.py:386}} INFO - Started process (PID=1797) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:35:28,638] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:35:28,640] {{logging_mixin.py:95}} INFO - [2019-10-04 09:35:28,640] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:35:28,737] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:35:29,353] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:35:29,358] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:35:29,371] {{logging_mixin.py:95}} INFO - [2019-10-04 09:35:29,371] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:35:29,373] {{logging_mixin.py:95}} INFO - [2019-10-04 09:35:29,372] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:30:29.372533+00:00
[2019-10-04 09:35:29,581] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.952 seconds
[2019-10-04 09:35:41,138] {{logging_mixin.py:95}} INFO - [2019-10-04 09:35:41,138] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:35:41,142] {{jobs.py:386}} INFO - Started process (PID=1801) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:35:41,282] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:35:41,283] {{logging_mixin.py:95}} INFO - [2019-10-04 09:35:41,282] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:35:41,440] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:35:42,273] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:35:42,279] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:35:42,288] {{logging_mixin.py:95}} INFO - [2019-10-04 09:35:42,288] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:35:42,290] {{logging_mixin.py:95}} INFO - [2019-10-04 09:35:42,289] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:30:42.289582+00:00
[2019-10-04 09:35:42,440] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.298 seconds
[2019-10-04 09:35:53,680] {{logging_mixin.py:95}} INFO - [2019-10-04 09:35:53,680] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:35:53,723] {{jobs.py:386}} INFO - Started process (PID=1805) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:35:54,036] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:35:54,037] {{logging_mixin.py:95}} INFO - [2019-10-04 09:35:54,037] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:35:54,306] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:35:54,866] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:35:54,871] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:35:54,879] {{logging_mixin.py:95}} INFO - [2019-10-04 09:35:54,879] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:35:54,880] {{logging_mixin.py:95}} INFO - [2019-10-04 09:35:54,880] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:30:54.880101+00:00
[2019-10-04 09:35:55,348] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.625 seconds
[2019-10-04 09:36:06,271] {{logging_mixin.py:95}} INFO - [2019-10-04 09:36:06,271] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:36:06,453] {{jobs.py:386}} INFO - Started process (PID=1814) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:36:06,615] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:36:06,616] {{logging_mixin.py:95}} INFO - [2019-10-04 09:36:06,616] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:36:06,954] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:36:09,830] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:36:10,004] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:36:10,014] {{logging_mixin.py:95}} INFO - [2019-10-04 09:36:10,014] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:36:10,016] {{logging_mixin.py:95}} INFO - [2019-10-04 09:36:10,015] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:31:10.015420+00:00
[2019-10-04 09:36:10,022] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.570 seconds
[2019-10-04 09:36:21,457] {{logging_mixin.py:95}} INFO - [2019-10-04 09:36:21,440] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:36:21,577] {{jobs.py:386}} INFO - Started process (PID=1818) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:36:21,880] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:36:21,881] {{logging_mixin.py:95}} INFO - [2019-10-04 09:36:21,881] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:36:21,945] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:36:29,529] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:36:29,826] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:36:29,844] {{logging_mixin.py:95}} INFO - [2019-10-04 09:36:29,844] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:36:29,846] {{logging_mixin.py:95}} INFO - [2019-10-04 09:36:29,845] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:31:29.845345+00:00
[2019-10-04 09:36:30,937] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 9.360 seconds
[2019-10-04 09:36:44,163] {{logging_mixin.py:95}} INFO - [2019-10-04 09:36:44,163] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:36:44,199] {{jobs.py:386}} INFO - Started process (PID=1822) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:36:44,744] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:36:44,746] {{logging_mixin.py:95}} INFO - [2019-10-04 09:36:44,746] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:36:46,804] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:37:04,102] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:37:04,711] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:37:04,720] {{logging_mixin.py:95}} INFO - [2019-10-04 09:37:04,720] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:37:04,722] {{logging_mixin.py:95}} INFO - [2019-10-04 09:37:04,721] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:32:04.721706+00:00
[2019-10-04 09:37:07,437] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 23.238 seconds
[2019-10-04 09:37:21,290] {{logging_mixin.py:95}} INFO - [2019-10-04 09:37:21,257] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:37:21,373] {{jobs.py:386}} INFO - Started process (PID=1832) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:37:22,396] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:37:22,397] {{logging_mixin.py:95}} INFO - [2019-10-04 09:37:22,397] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:37:23,443] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:37:29,952] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:37:29,982] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:37:30,236] {{logging_mixin.py:95}} INFO - [2019-10-04 09:37:29,990] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:37:30,237] {{logging_mixin.py:95}} INFO - [2019-10-04 09:37:30,237] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:32:30.237184+00:00
[2019-10-04 09:37:30,244] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 8.871 seconds
[2019-10-04 09:37:41,671] {{logging_mixin.py:95}} INFO - [2019-10-04 09:37:41,671] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:37:41,676] {{jobs.py:386}} INFO - Started process (PID=1836) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:37:41,703] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:37:41,705] {{logging_mixin.py:95}} INFO - [2019-10-04 09:37:41,705] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:37:41,738] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:37:41,843] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:37:41,852] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:37:42,093] {{logging_mixin.py:95}} INFO - [2019-10-04 09:37:42,093] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:37:42,115] {{logging_mixin.py:95}} INFO - [2019-10-04 09:37:42,115] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:32:42.115101+00:00
[2019-10-04 09:37:42,181] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.506 seconds
[2019-10-04 09:37:52,994] {{logging_mixin.py:95}} INFO - [2019-10-04 09:37:52,994] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:37:53,018] {{jobs.py:386}} INFO - Started process (PID=1846) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:37:53,023] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:37:53,025] {{logging_mixin.py:95}} INFO - [2019-10-04 09:37:53,025] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:37:53,054] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:37:53,434] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:37:53,439] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:37:53,448] {{logging_mixin.py:95}} INFO - [2019-10-04 09:37:53,448] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:37:53,449] {{logging_mixin.py:95}} INFO - [2019-10-04 09:37:53,449] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:32:53.448994+00:00
[2019-10-04 09:37:53,618] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.599 seconds
[2019-10-04 09:38:04,465] {{logging_mixin.py:95}} INFO - [2019-10-04 09:38:04,465] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:38:04,469] {{jobs.py:386}} INFO - Started process (PID=1850) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:38:04,473] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:38:04,506] {{logging_mixin.py:95}} INFO - [2019-10-04 09:38:04,506] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:38:04,536] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:38:06,335] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:38:06,341] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:38:06,416] {{logging_mixin.py:95}} INFO - [2019-10-04 09:38:06,416] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:38:06,417] {{logging_mixin.py:95}} INFO - [2019-10-04 09:38:06,416] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:33:06.416661+00:00
[2019-10-04 09:38:06,424] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.955 seconds
[2019-10-04 09:38:20,129] {{logging_mixin.py:95}} INFO - [2019-10-04 09:38:19,859] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:38:21,239] {{jobs.py:386}} INFO - Started process (PID=1854) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:38:22,116] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:38:22,118] {{logging_mixin.py:95}} INFO - [2019-10-04 09:38:22,118] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:38:25,108] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:38:31,702] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:38:31,741] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:38:31,895] {{logging_mixin.py:95}} INFO - [2019-10-04 09:38:31,895] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:38:31,897] {{logging_mixin.py:95}} INFO - [2019-10-04 09:38:31,896] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:33:31.896637+00:00
[2019-10-04 09:38:32,060] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 10.821 seconds
[2019-10-04 09:38:44,609] {{logging_mixin.py:95}} INFO - [2019-10-04 09:38:44,608] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:38:44,612] {{jobs.py:386}} INFO - Started process (PID=1868) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:38:44,623] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:38:44,630] {{logging_mixin.py:95}} INFO - [2019-10-04 09:38:44,630] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:38:44,680] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:38:44,950] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:38:45,039] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:38:45,046] {{logging_mixin.py:95}} INFO - [2019-10-04 09:38:45,046] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:38:45,047] {{logging_mixin.py:95}} INFO - [2019-10-04 09:38:45,047] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:33:45.047238+00:00
[2019-10-04 09:38:45,105] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.493 seconds
[2019-10-04 09:38:58,836] {{logging_mixin.py:95}} INFO - [2019-10-04 09:38:58,734] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:38:58,920] {{jobs.py:386}} INFO - Started process (PID=1872) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:38:59,560] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:38:59,561] {{logging_mixin.py:95}} INFO - [2019-10-04 09:38:59,561] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:39:01,700] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:39:07,391] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:39:07,553] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:39:07,737] {{logging_mixin.py:95}} INFO - [2019-10-04 09:39:07,737] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:39:07,738] {{logging_mixin.py:95}} INFO - [2019-10-04 09:39:07,737] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:34:07.737703+00:00
[2019-10-04 09:39:07,792] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 8.871 seconds
[2019-10-04 09:39:26,435] {{logging_mixin.py:95}} INFO - [2019-10-04 09:39:25,411] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:39:27,136] {{jobs.py:386}} INFO - Started process (PID=1884) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:39:29,459] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:39:29,460] {{logging_mixin.py:95}} INFO - [2019-10-04 09:39:29,460] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:39:32,752] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:39:39,975] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:39:40,238] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:39:40,251] {{logging_mixin.py:95}} INFO - [2019-10-04 09:39:40,251] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:39:40,252] {{logging_mixin.py:95}} INFO - [2019-10-04 09:39:40,252] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:34:40.252132+00:00
[2019-10-04 09:39:41,249] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 14.113 seconds
[2019-10-04 09:39:57,927] {{logging_mixin.py:95}} INFO - [2019-10-04 09:39:57,828] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:39:58,085] {{jobs.py:386}} INFO - Started process (PID=1888) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:40:01,050] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:40:01,052] {{logging_mixin.py:95}} INFO - [2019-10-04 09:40:01,052] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:40:04,496] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:40:16,880] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:40:17,037] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:40:17,043] {{logging_mixin.py:95}} INFO - [2019-10-04 09:40:17,043] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:40:17,045] {{logging_mixin.py:95}} INFO - [2019-10-04 09:40:17,044] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:35:17.044749+00:00
[2019-10-04 09:40:17,277] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 19.191 seconds
[2019-10-04 09:40:29,182] {{logging_mixin.py:95}} INFO - [2019-10-04 09:40:29,181] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:40:29,185] {{jobs.py:386}} INFO - Started process (PID=1898) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:40:29,194] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:40:29,221] {{logging_mixin.py:95}} INFO - [2019-10-04 09:40:29,221] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:40:29,262] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:40:30,147] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:40:30,171] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:40:30,178] {{logging_mixin.py:95}} INFO - [2019-10-04 09:40:30,178] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:40:30,179] {{logging_mixin.py:95}} INFO - [2019-10-04 09:40:30,178] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:35:30.178952+00:00
[2019-10-04 09:40:30,192] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.007 seconds
[2019-10-04 09:40:41,679] {{logging_mixin.py:95}} INFO - [2019-10-04 09:40:41,679] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:40:41,682] {{jobs.py:386}} INFO - Started process (PID=1904) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:40:41,692] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:40:41,694] {{logging_mixin.py:95}} INFO - [2019-10-04 09:40:41,694] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:40:41,723] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:40:42,189] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:40:42,195] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:40:42,203] {{logging_mixin.py:95}} INFO - [2019-10-04 09:40:42,203] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:40:42,205] {{logging_mixin.py:95}} INFO - [2019-10-04 09:40:42,204] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:35:42.204632+00:00
[2019-10-04 09:40:42,211] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.529 seconds
[2019-10-04 09:40:53,066] {{logging_mixin.py:95}} INFO - [2019-10-04 09:40:53,066] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:40:53,069] {{jobs.py:386}} INFO - Started process (PID=1907) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:40:53,072] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:40:53,073] {{logging_mixin.py:95}} INFO - [2019-10-04 09:40:53,073] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:40:53,092] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:40:53,472] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:40:53,479] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:40:53,487] {{logging_mixin.py:95}} INFO - [2019-10-04 09:40:53,487] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:40:53,489] {{logging_mixin.py:95}} INFO - [2019-10-04 09:40:53,489] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:35:53.489459+00:00
[2019-10-04 09:40:53,498] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.428 seconds
[2019-10-04 09:41:04,654] {{logging_mixin.py:95}} INFO - [2019-10-04 09:41:04,653] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:41:04,659] {{jobs.py:386}} INFO - Started process (PID=1918) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:41:04,666] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:41:04,667] {{logging_mixin.py:95}} INFO - [2019-10-04 09:41:04,667] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:41:04,693] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:41:05,245] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:41:05,250] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:41:05,256] {{logging_mixin.py:95}} INFO - [2019-10-04 09:41:05,256] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:41:05,257] {{logging_mixin.py:95}} INFO - [2019-10-04 09:41:05,257] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:36:05.257070+00:00
[2019-10-04 09:41:05,266] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.608 seconds
[2019-10-04 09:41:16,646] {{logging_mixin.py:95}} INFO - [2019-10-04 09:41:16,646] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:41:16,800] {{jobs.py:386}} INFO - Started process (PID=1922) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:41:17,097] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:41:17,098] {{logging_mixin.py:95}} INFO - [2019-10-04 09:41:17,098] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:41:17,838] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:41:18,629] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:41:18,668] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:41:18,676] {{logging_mixin.py:95}} INFO - [2019-10-04 09:41:18,676] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:41:18,678] {{logging_mixin.py:95}} INFO - [2019-10-04 09:41:18,677] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:36:18.677678+00:00
[2019-10-04 09:41:18,744] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.944 seconds
[2019-10-04 09:41:29,783] {{logging_mixin.py:95}} INFO - [2019-10-04 09:41:29,783] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:41:29,787] {{jobs.py:386}} INFO - Started process (PID=1931) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:41:30,047] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:41:30,048] {{logging_mixin.py:95}} INFO - [2019-10-04 09:41:30,048] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:41:30,083] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:41:34,038] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:41:34,252] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:41:34,260] {{logging_mixin.py:95}} INFO - [2019-10-04 09:41:34,259] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:41:34,261] {{logging_mixin.py:95}} INFO - [2019-10-04 09:41:34,260] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:36:34.260679+00:00
[2019-10-04 09:41:34,775] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.988 seconds
[2019-10-04 09:41:45,552] {{logging_mixin.py:95}} INFO - [2019-10-04 09:41:45,552] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:41:45,555] {{jobs.py:386}} INFO - Started process (PID=1935) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:41:45,795] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:41:45,796] {{logging_mixin.py:95}} INFO - [2019-10-04 09:41:45,796] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:41:45,883] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:41:48,026] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:41:48,051] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:41:48,059] {{logging_mixin.py:95}} INFO - [2019-10-04 09:41:48,059] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:41:48,060] {{logging_mixin.py:95}} INFO - [2019-10-04 09:41:48,059] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:36:48.059926+00:00
[2019-10-04 09:41:48,068] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.513 seconds
[2019-10-04 09:42:03,948] {{logging_mixin.py:95}} INFO - [2019-10-04 09:42:03,407] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:42:04,167] {{jobs.py:386}} INFO - Started process (PID=1939) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:42:04,797] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:42:04,799] {{logging_mixin.py:95}} INFO - [2019-10-04 09:42:04,799] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:42:07,960] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:42:22,729] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:42:23,251] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:42:23,261] {{logging_mixin.py:95}} INFO - [2019-10-04 09:42:23,260] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:42:23,262] {{logging_mixin.py:95}} INFO - [2019-10-04 09:42:23,261] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:37:23.261883+00:00
[2019-10-04 09:42:25,353] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 21.185 seconds
[2019-10-04 09:42:39,312] {{logging_mixin.py:95}} INFO - [2019-10-04 09:42:39,142] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:42:39,438] {{jobs.py:386}} INFO - Started process (PID=1948) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:42:40,101] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:42:40,102] {{logging_mixin.py:95}} INFO - [2019-10-04 09:42:40,102] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:42:43,315] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:43:15,125] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 09:43:42,453] {{logging_mixin.py:95}} INFO - [2019-10-04 09:43:42,452] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:43:42,511] {{jobs.py:386}} INFO - Started process (PID=1950) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:43:43,530] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:43:43,532] {{logging_mixin.py:95}} INFO - [2019-10-04 09:43:43,531] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:43:45,568] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:44:01,001] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 09:44:29,834] {{logging_mixin.py:95}} INFO - [2019-10-04 09:44:29,834] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:44:29,877] {{jobs.py:386}} INFO - Started process (PID=1952) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:44:29,967] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:44:29,968] {{logging_mixin.py:95}} INFO - [2019-10-04 09:44:29,968] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:44:32,604] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:44:40,032] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:44:40,210] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:44:40,220] {{logging_mixin.py:95}} INFO - [2019-10-04 09:44:40,220] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:44:40,221] {{logging_mixin.py:95}} INFO - [2019-10-04 09:44:40,220] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:39:40.220949+00:00
[2019-10-04 09:44:40,228] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 10.352 seconds
[2019-10-04 09:44:51,184] {{logging_mixin.py:95}} INFO - [2019-10-04 09:44:51,184] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:44:51,188] {{jobs.py:386}} INFO - Started process (PID=1963) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:44:51,191] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:44:51,192] {{logging_mixin.py:95}} INFO - [2019-10-04 09:44:51,192] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:44:51,218] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:44:51,502] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:44:51,506] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:44:51,514] {{logging_mixin.py:95}} INFO - [2019-10-04 09:44:51,514] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:44:51,515] {{logging_mixin.py:95}} INFO - [2019-10-04 09:44:51,514] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:39:51.514937+00:00
[2019-10-04 09:44:51,521] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.333 seconds
[2019-10-04 09:45:02,612] {{logging_mixin.py:95}} INFO - [2019-10-04 09:45:02,612] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:45:02,615] {{jobs.py:386}} INFO - Started process (PID=1967) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:45:02,619] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:45:02,620] {{logging_mixin.py:95}} INFO - [2019-10-04 09:45:02,620] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:45:02,651] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:45:02,849] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:45:02,856] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:45:02,864] {{logging_mixin.py:95}} INFO - [2019-10-04 09:45:02,864] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:45:02,865] {{logging_mixin.py:95}} INFO - [2019-10-04 09:45:02,864] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:40:02.864933+00:00
[2019-10-04 09:45:02,875] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.259 seconds
[2019-10-04 09:45:14,781] {{logging_mixin.py:95}} INFO - [2019-10-04 09:45:14,781] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:45:14,785] {{jobs.py:386}} INFO - Started process (PID=1977) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:45:15,430] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:45:15,432] {{logging_mixin.py:95}} INFO - [2019-10-04 09:45:15,432] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:45:16,262] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:45:19,064] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:45:19,165] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:45:19,175] {{logging_mixin.py:95}} INFO - [2019-10-04 09:45:19,175] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:45:19,177] {{logging_mixin.py:95}} INFO - [2019-10-04 09:45:19,176] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:40:19.176801+00:00
[2019-10-04 09:45:19,209] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.424 seconds
[2019-10-04 09:45:33,348] {{logging_mixin.py:95}} INFO - [2019-10-04 09:45:32,958] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:45:33,433] {{jobs.py:386}} INFO - Started process (PID=1981) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:45:34,280] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:45:34,281] {{logging_mixin.py:95}} INFO - [2019-10-04 09:45:34,280] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:45:35,586] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:45:44,924] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:45:44,928] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:45:44,935] {{logging_mixin.py:95}} INFO - [2019-10-04 09:45:44,935] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:45:44,935] {{logging_mixin.py:95}} INFO - [2019-10-04 09:45:44,935] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:40:44.935364+00:00
[2019-10-04 09:45:45,173] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 11.740 seconds
[2019-10-04 09:45:57,043] {{logging_mixin.py:95}} INFO - [2019-10-04 09:45:57,043] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:45:57,048] {{jobs.py:386}} INFO - Started process (PID=1990) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:45:57,060] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:45:57,062] {{logging_mixin.py:95}} INFO - [2019-10-04 09:45:57,062] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:45:57,194] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:45:57,327] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:45:57,489] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:45:57,518] {{logging_mixin.py:95}} INFO - [2019-10-04 09:45:57,518] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:45:57,520] {{logging_mixin.py:95}} INFO - [2019-10-04 09:45:57,520] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:40:57.520187+00:00
[2019-10-04 09:45:57,529] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.481 seconds
[2019-10-04 09:46:09,140] {{logging_mixin.py:95}} INFO - [2019-10-04 09:46:09,140] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:46:09,555] {{jobs.py:386}} INFO - Started process (PID=1994) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:46:09,761] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:46:09,763] {{logging_mixin.py:95}} INFO - [2019-10-04 09:46:09,763] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:46:10,396] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:46:16,039] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:46:16,128] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:46:16,210] {{logging_mixin.py:95}} INFO - [2019-10-04 09:46:16,210] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:46:16,211] {{logging_mixin.py:95}} INFO - [2019-10-04 09:46:16,211] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:41:16.211315+00:00
[2019-10-04 09:46:16,219] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 6.664 seconds
[2019-10-04 09:46:29,087] {{logging_mixin.py:95}} INFO - [2019-10-04 09:46:28,947] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:46:29,362] {{jobs.py:386}} INFO - Started process (PID=2003) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:46:29,974] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:46:29,975] {{logging_mixin.py:95}} INFO - [2019-10-04 09:46:29,975] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:46:33,933] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:46:48,798] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:46:48,921] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:46:48,930] {{logging_mixin.py:95}} INFO - [2019-10-04 09:46:48,929] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:46:48,931] {{logging_mixin.py:95}} INFO - [2019-10-04 09:46:48,931] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:41:48.931180+00:00
[2019-10-04 09:46:49,775] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 20.412 seconds
[2019-10-04 09:47:02,144] {{logging_mixin.py:95}} INFO - [2019-10-04 09:47:01,935] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:47:02,171] {{jobs.py:386}} INFO - Started process (PID=2007) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:47:02,500] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:47:02,501] {{logging_mixin.py:95}} INFO - [2019-10-04 09:47:02,501] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:47:03,320] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:47:28,283] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 09:47:59,722] {{logging_mixin.py:95}} INFO - [2019-10-04 09:47:59,722] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:47:59,817] {{jobs.py:386}} INFO - Started process (PID=2014) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:48:00,150] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:48:00,151] {{logging_mixin.py:95}} INFO - [2019-10-04 09:48:00,151] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:48:01,164] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:48:02,540] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:48:02,628] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:48:02,637] {{logging_mixin.py:95}} INFO - [2019-10-04 09:48:02,637] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:48:02,639] {{logging_mixin.py:95}} INFO - [2019-10-04 09:48:02,638] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:43:02.638683+00:00
[2019-10-04 09:48:02,645] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.829 seconds
[2019-10-04 09:48:14,044] {{logging_mixin.py:95}} INFO - [2019-10-04 09:48:14,043] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:48:14,047] {{jobs.py:386}} INFO - Started process (PID=2018) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:48:14,050] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:48:14,054] {{logging_mixin.py:95}} INFO - [2019-10-04 09:48:14,054] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:48:14,094] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:48:14,290] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:48:14,410] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:48:14,418] {{logging_mixin.py:95}} INFO - [2019-10-04 09:48:14,418] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:48:14,419] {{logging_mixin.py:95}} INFO - [2019-10-04 09:48:14,419] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:43:14.419304+00:00
[2019-10-04 09:48:14,427] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.380 seconds
[2019-10-04 09:48:25,480] {{logging_mixin.py:95}} INFO - [2019-10-04 09:48:25,479] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:48:25,483] {{jobs.py:386}} INFO - Started process (PID=2029) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:48:25,486] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:48:25,493] {{logging_mixin.py:95}} INFO - [2019-10-04 09:48:25,492] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:48:25,519] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:48:26,142] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:48:26,146] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:48:26,154] {{logging_mixin.py:95}} INFO - [2019-10-04 09:48:26,153] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:48:26,155] {{logging_mixin.py:95}} INFO - [2019-10-04 09:48:26,154] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:43:26.154232+00:00
[2019-10-04 09:48:26,163] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.680 seconds
[2019-10-04 09:48:36,828] {{logging_mixin.py:95}} INFO - [2019-10-04 09:48:36,828] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:48:36,933] {{jobs.py:386}} INFO - Started process (PID=2033) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:48:37,616] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:48:37,617] {{logging_mixin.py:95}} INFO - [2019-10-04 09:48:37,617] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:48:38,261] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:48:41,445] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:48:41,601] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:48:41,610] {{logging_mixin.py:95}} INFO - [2019-10-04 09:48:41,610] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:48:41,613] {{logging_mixin.py:95}} INFO - [2019-10-04 09:48:41,611] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:43:41.611473+00:00
[2019-10-04 09:48:41,620] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.687 seconds
[2019-10-04 09:48:52,360] {{logging_mixin.py:95}} INFO - [2019-10-04 09:48:52,360] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:48:52,415] {{jobs.py:386}} INFO - Started process (PID=2037) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:48:53,147] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:48:53,149] {{logging_mixin.py:95}} INFO - [2019-10-04 09:48:53,148] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:48:53,847] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:48:55,011] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:48:55,159] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:48:55,168] {{logging_mixin.py:95}} INFO - [2019-10-04 09:48:55,168] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:48:55,170] {{logging_mixin.py:95}} INFO - [2019-10-04 09:48:55,169] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:43:55.169780+00:00
[2019-10-04 09:48:55,177] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.762 seconds
[2019-10-04 09:49:05,806] {{logging_mixin.py:95}} INFO - [2019-10-04 09:49:05,806] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:49:05,848] {{jobs.py:386}} INFO - Started process (PID=2046) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:49:05,851] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:49:05,852] {{logging_mixin.py:95}} INFO - [2019-10-04 09:49:05,852] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:49:05,874] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:49:06,241] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:49:06,247] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:49:06,256] {{logging_mixin.py:95}} INFO - [2019-10-04 09:49:06,256] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:49:06,256] {{logging_mixin.py:95}} INFO - [2019-10-04 09:49:06,256] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:44:06.256291+00:00
[2019-10-04 09:49:06,264] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.416 seconds
[2019-10-04 09:49:17,574] {{logging_mixin.py:95}} INFO - [2019-10-04 09:49:17,573] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:49:17,607] {{jobs.py:386}} INFO - Started process (PID=2050) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:49:17,812] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:49:17,813] {{logging_mixin.py:95}} INFO - [2019-10-04 09:49:17,813] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:49:19,247] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:49:28,163] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:49:28,325] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:49:28,333] {{logging_mixin.py:95}} INFO - [2019-10-04 09:49:28,333] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:49:28,334] {{logging_mixin.py:95}} INFO - [2019-10-04 09:49:28,333] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:44:28.333941+00:00
[2019-10-04 09:49:28,567] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 10.960 seconds
[2019-10-04 09:49:40,488] {{logging_mixin.py:95}} INFO - [2019-10-04 09:49:40,421] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:49:40,537] {{jobs.py:386}} INFO - Started process (PID=2059) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:49:40,966] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:49:40,968] {{logging_mixin.py:95}} INFO - [2019-10-04 09:49:40,967] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:49:42,197] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:49:54,128] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:49:55,376] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:49:55,501] {{logging_mixin.py:95}} INFO - [2019-10-04 09:49:55,500] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:49:55,630] {{logging_mixin.py:95}} INFO - [2019-10-04 09:49:55,502] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:44:55.502019+00:00
[2019-10-04 09:49:56,902] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 16.365 seconds
[2019-10-04 09:50:09,892] {{logging_mixin.py:95}} INFO - [2019-10-04 09:50:09,892] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:50:09,947] {{jobs.py:386}} INFO - Started process (PID=2063) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:50:11,095] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:50:11,098] {{logging_mixin.py:95}} INFO - [2019-10-04 09:50:11,097] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:50:14,918] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:50:29,557] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 09:50:46,280] {{logging_mixin.py:95}} INFO - [2019-10-04 09:50:45,989] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:50:46,653] {{jobs.py:386}} INFO - Started process (PID=2065) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:50:47,751] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:50:47,753] {{logging_mixin.py:95}} INFO - [2019-10-04 09:50:47,753] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:50:50,850] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:51:12,813] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 09:51:32,735] {{logging_mixin.py:95}} INFO - [2019-10-04 09:51:32,735] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:51:33,077] {{jobs.py:386}} INFO - Started process (PID=2067) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:51:33,779] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:51:33,780] {{logging_mixin.py:95}} INFO - [2019-10-04 09:51:33,780] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:51:35,538] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:51:59,695] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 09:52:25,391] {{logging_mixin.py:95}} INFO - [2019-10-04 09:52:25,297] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:52:25,625] {{jobs.py:386}} INFO - Started process (PID=2069) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:52:26,711] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:52:26,712] {{logging_mixin.py:95}} INFO - [2019-10-04 09:52:26,712] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:52:29,316] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:52:45,438] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 09:53:12,795] {{logging_mixin.py:95}} INFO - [2019-10-04 09:53:12,795] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:53:12,857] {{jobs.py:386}} INFO - Started process (PID=2071) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:53:15,065] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:53:15,066] {{logging_mixin.py:95}} INFO - [2019-10-04 09:53:15,066] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:53:21,429] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:53:29,014] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:53:29,225] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:53:29,233] {{logging_mixin.py:95}} INFO - [2019-10-04 09:53:29,233] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:53:29,235] {{logging_mixin.py:95}} INFO - [2019-10-04 09:53:29,234] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:48:29.234656+00:00
[2019-10-04 09:53:29,243] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 16.387 seconds
[2019-10-04 09:53:40,707] {{logging_mixin.py:95}} INFO - [2019-10-04 09:53:40,706] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:53:40,723] {{jobs.py:386}} INFO - Started process (PID=2080) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:53:40,731] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:53:40,758] {{logging_mixin.py:95}} INFO - [2019-10-04 09:53:40,758] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:53:41,090] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:53:41,431] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:53:41,759] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:53:41,794] {{logging_mixin.py:95}} INFO - [2019-10-04 09:53:41,793] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:53:41,795] {{logging_mixin.py:95}} INFO - [2019-10-04 09:53:41,795] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:48:41.795125+00:00
[2019-10-04 09:53:41,803] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.080 seconds
[2019-10-04 09:53:52,587] {{logging_mixin.py:95}} INFO - [2019-10-04 09:53:52,587] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:53:52,614] {{jobs.py:386}} INFO - Started process (PID=2084) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:53:52,658] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:53:52,659] {{logging_mixin.py:95}} INFO - [2019-10-04 09:53:52,659] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:53:52,703] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:53:53,502] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:53:53,508] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:53:53,516] {{logging_mixin.py:95}} INFO - [2019-10-04 09:53:53,516] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:53:53,518] {{logging_mixin.py:95}} INFO - [2019-10-04 09:53:53,517] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:48:53.517796+00:00
[2019-10-04 09:53:53,525] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.911 seconds
[2019-10-04 09:54:03,592] {{logging_mixin.py:95}} INFO - [2019-10-04 09:54:03,592] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:54:03,597] {{jobs.py:386}} INFO - Started process (PID=2093) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:54:03,601] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:54:03,603] {{logging_mixin.py:95}} INFO - [2019-10-04 09:54:03,603] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:54:03,632] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:54:04,123] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:54:04,131] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:54:04,143] {{logging_mixin.py:95}} INFO - [2019-10-04 09:54:04,143] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:54:04,145] {{logging_mixin.py:95}} INFO - [2019-10-04 09:54:04,144] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:49:04.144693+00:00
[2019-10-04 09:54:04,155] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.559 seconds
[2019-10-04 09:54:15,235] {{logging_mixin.py:95}} INFO - [2019-10-04 09:54:15,235] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:54:15,238] {{jobs.py:386}} INFO - Started process (PID=2097) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:54:15,242] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:54:15,243] {{logging_mixin.py:95}} INFO - [2019-10-04 09:54:15,243] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:54:15,561] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:54:16,445] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:54:16,458] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:54:16,470] {{logging_mixin.py:95}} INFO - [2019-10-04 09:54:16,470] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:54:16,472] {{logging_mixin.py:95}} INFO - [2019-10-04 09:54:16,471] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:49:16.471695+00:00
[2019-10-04 09:54:16,491] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.253 seconds
[2019-10-04 09:54:28,728] {{logging_mixin.py:95}} INFO - [2019-10-04 09:54:28,727] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:54:28,912] {{jobs.py:386}} INFO - Started process (PID=2101) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:54:30,055] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:54:30,056] {{logging_mixin.py:95}} INFO - [2019-10-04 09:54:30,056] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:54:31,067] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:54:35,467] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:54:35,548] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:54:35,569] {{logging_mixin.py:95}} INFO - [2019-10-04 09:54:35,568] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:54:35,570] {{logging_mixin.py:95}} INFO - [2019-10-04 09:54:35,570] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:49:35.570196+00:00
[2019-10-04 09:54:35,648] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 6.736 seconds
[2019-10-04 09:54:47,089] {{logging_mixin.py:95}} INFO - [2019-10-04 09:54:47,089] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:54:47,094] {{jobs.py:386}} INFO - Started process (PID=2111) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:54:47,103] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:54:47,105] {{logging_mixin.py:95}} INFO - [2019-10-04 09:54:47,105] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:54:47,155] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:54:48,363] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:54:48,370] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:54:48,382] {{logging_mixin.py:95}} INFO - [2019-10-04 09:54:48,382] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:54:48,383] {{logging_mixin.py:95}} INFO - [2019-10-04 09:54:48,383] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:49:48.383191+00:00
[2019-10-04 09:54:48,390] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.296 seconds
[2019-10-04 09:54:59,979] {{logging_mixin.py:95}} INFO - [2019-10-04 09:54:59,978] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:54:59,982] {{jobs.py:386}} INFO - Started process (PID=2115) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:55:00,701] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:55:00,706] {{logging_mixin.py:95}} INFO - [2019-10-04 09:55:00,706] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:55:00,914] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:55:02,835] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:55:02,840] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:55:02,852] {{logging_mixin.py:95}} INFO - [2019-10-04 09:55:02,852] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:55:02,855] {{logging_mixin.py:95}} INFO - [2019-10-04 09:55:02,854] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:50:02.854880+00:00
[2019-10-04 09:55:02,862] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.880 seconds
[2019-10-04 09:55:13,922] {{logging_mixin.py:95}} INFO - [2019-10-04 09:55:13,921] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:55:14,035] {{jobs.py:386}} INFO - Started process (PID=2119) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:55:14,234] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:55:14,236] {{logging_mixin.py:95}} INFO - [2019-10-04 09:55:14,236] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:55:14,788] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:55:16,734] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:55:16,830] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:55:16,840] {{logging_mixin.py:95}} INFO - [2019-10-04 09:55:16,840] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:55:16,842] {{logging_mixin.py:95}} INFO - [2019-10-04 09:55:16,841] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:50:16.841455+00:00
[2019-10-04 09:55:16,896] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.860 seconds
[2019-10-04 09:55:28,397] {{logging_mixin.py:95}} INFO - [2019-10-04 09:55:28,396] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:55:28,459] {{jobs.py:386}} INFO - Started process (PID=2128) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:55:28,724] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:55:28,726] {{logging_mixin.py:95}} INFO - [2019-10-04 09:55:28,726] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:55:30,508] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:55:36,840] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:55:36,845] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:55:36,856] {{logging_mixin.py:95}} INFO - [2019-10-04 09:55:36,856] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:55:36,858] {{logging_mixin.py:95}} INFO - [2019-10-04 09:55:36,857] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:50:36.857619+00:00
[2019-10-04 09:55:37,132] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 8.672 seconds
[2019-10-04 09:55:47,910] {{logging_mixin.py:95}} INFO - [2019-10-04 09:55:47,908] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:55:47,914] {{jobs.py:386}} INFO - Started process (PID=2132) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:55:47,919] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:55:47,921] {{logging_mixin.py:95}} INFO - [2019-10-04 09:55:47,920] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:55:47,956] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:55:48,382] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:55:48,388] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:55:48,396] {{logging_mixin.py:95}} INFO - [2019-10-04 09:55:48,396] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:55:48,398] {{logging_mixin.py:95}} INFO - [2019-10-04 09:55:48,397] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:50:48.397948+00:00
[2019-10-04 09:55:48,406] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.491 seconds
[2019-10-04 09:55:59,775] {{logging_mixin.py:95}} INFO - [2019-10-04 09:55:59,775] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:55:59,779] {{jobs.py:386}} INFO - Started process (PID=2136) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:55:59,794] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:55:59,802] {{logging_mixin.py:95}} INFO - [2019-10-04 09:55:59,802] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:56:00,394] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:56:01,699] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:56:01,708] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:56:01,715] {{logging_mixin.py:95}} INFO - [2019-10-04 09:56:01,715] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:56:01,723] {{logging_mixin.py:95}} INFO - [2019-10-04 09:56:01,722] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:51:01.722226+00:00
[2019-10-04 09:56:01,730] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.951 seconds
[2019-10-04 09:56:12,642] {{logging_mixin.py:95}} INFO - [2019-10-04 09:56:12,585] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:56:12,645] {{jobs.py:386}} INFO - Started process (PID=2145) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:56:12,724] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:56:12,725] {{logging_mixin.py:95}} INFO - [2019-10-04 09:56:12,725] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:56:12,756] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:56:14,466] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:56:14,472] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:56:14,481] {{logging_mixin.py:95}} INFO - [2019-10-04 09:56:14,481] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:56:14,481] {{logging_mixin.py:95}} INFO - [2019-10-04 09:56:14,481] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:51:14.481293+00:00
[2019-10-04 09:56:14,494] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.849 seconds
[2019-10-04 09:56:26,430] {{logging_mixin.py:95}} INFO - [2019-10-04 09:56:26,429] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:56:26,433] {{jobs.py:386}} INFO - Started process (PID=2150) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:56:26,435] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:56:26,436] {{logging_mixin.py:95}} INFO - [2019-10-04 09:56:26,436] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:56:26,457] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:56:29,870] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:56:29,980] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:56:30,039] {{logging_mixin.py:95}} INFO - [2019-10-04 09:56:30,038] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:56:30,040] {{logging_mixin.py:95}} INFO - [2019-10-04 09:56:30,040] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:51:30.040223+00:00
[2019-10-04 09:56:30,137] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.705 seconds
[2019-10-04 09:56:41,044] {{logging_mixin.py:95}} INFO - [2019-10-04 09:56:41,043] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:56:41,048] {{jobs.py:386}} INFO - Started process (PID=2153) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:56:41,142] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:56:41,143] {{logging_mixin.py:95}} INFO - [2019-10-04 09:56:41,143] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:56:41,178] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:56:41,479] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:56:41,485] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:56:41,507] {{logging_mixin.py:95}} INFO - [2019-10-04 09:56:41,507] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:56:41,509] {{logging_mixin.py:95}} INFO - [2019-10-04 09:56:41,508] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:51:41.508603+00:00
[2019-10-04 09:56:41,515] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.467 seconds
[2019-10-04 09:56:52,645] {{logging_mixin.py:95}} INFO - [2019-10-04 09:56:52,645] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:56:52,649] {{jobs.py:386}} INFO - Started process (PID=2162) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:56:52,660] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:56:52,661] {{logging_mixin.py:95}} INFO - [2019-10-04 09:56:52,661] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:56:52,746] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:56:55,437] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:56:55,443] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:56:55,453] {{logging_mixin.py:95}} INFO - [2019-10-04 09:56:55,453] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:56:55,454] {{logging_mixin.py:95}} INFO - [2019-10-04 09:56:55,453] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:51:55.453402+00:00
[2019-10-04 09:56:55,460] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.810 seconds
[2019-10-04 09:57:06,405] {{logging_mixin.py:95}} INFO - [2019-10-04 09:57:06,405] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:57:06,409] {{jobs.py:386}} INFO - Started process (PID=2166) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:57:06,998] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:57:07,010] {{logging_mixin.py:95}} INFO - [2019-10-04 09:57:07,010] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:57:08,943] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:57:15,736] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:57:15,907] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:57:15,917] {{logging_mixin.py:95}} INFO - [2019-10-04 09:57:15,916] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:57:15,919] {{logging_mixin.py:95}} INFO - [2019-10-04 09:57:15,918] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:52:15.918034+00:00
[2019-10-04 09:57:16,130] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 9.721 seconds
[2019-10-04 09:57:28,527] {{logging_mixin.py:95}} INFO - [2019-10-04 09:57:28,526] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:57:28,657] {{jobs.py:386}} INFO - Started process (PID=2175) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:57:29,110] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:57:29,112] {{logging_mixin.py:95}} INFO - [2019-10-04 09:57:29,112] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:57:30,025] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:57:34,026] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:57:34,140] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:57:34,151] {{logging_mixin.py:95}} INFO - [2019-10-04 09:57:34,151] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:57:34,153] {{logging_mixin.py:95}} INFO - [2019-10-04 09:57:34,153] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:52:34.152996+00:00
[2019-10-04 09:57:34,232] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.575 seconds
[2019-10-04 09:57:46,222] {{logging_mixin.py:95}} INFO - [2019-10-04 09:57:46,222] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:57:46,287] {{jobs.py:386}} INFO - Started process (PID=2179) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:57:47,189] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:57:47,190] {{logging_mixin.py:95}} INFO - [2019-10-04 09:57:47,190] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:57:50,550] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:58:05,713] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:58:06,290] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:58:06,301] {{logging_mixin.py:95}} INFO - [2019-10-04 09:58:06,301] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:58:06,303] {{logging_mixin.py:95}} INFO - [2019-10-04 09:58:06,302] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:53:06.302701+00:00
[2019-10-04 09:58:07,399] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 21.113 seconds
[2019-10-04 09:58:18,971] {{logging_mixin.py:95}} INFO - [2019-10-04 09:58:18,970] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:58:19,036] {{jobs.py:386}} INFO - Started process (PID=2190) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:58:19,984] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:58:19,985] {{logging_mixin.py:95}} INFO - [2019-10-04 09:58:19,985] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:58:22,532] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:58:39,612] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 09:58:58,191] {{logging_mixin.py:95}} INFO - [2019-10-04 09:58:58,190] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:58:58,342] {{jobs.py:386}} INFO - Started process (PID=2192) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:58:59,073] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:58:59,074] {{logging_mixin.py:95}} INFO - [2019-10-04 09:58:59,074] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:59:00,298] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:59:03,499] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:59:03,505] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:59:03,518] {{logging_mixin.py:95}} INFO - [2019-10-04 09:59:03,518] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:59:03,519] {{logging_mixin.py:95}} INFO - [2019-10-04 09:59:03,519] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:54:03.519200+00:00
[2019-10-04 09:59:03,534] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.192 seconds
[2019-10-04 09:59:15,767] {{logging_mixin.py:95}} INFO - [2019-10-04 09:59:15,767] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:59:15,779] {{jobs.py:386}} INFO - Started process (PID=2201) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:59:15,783] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:59:15,784] {{logging_mixin.py:95}} INFO - [2019-10-04 09:59:15,784] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:59:16,149] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:59:17,663] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:59:17,758] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:59:17,769] {{logging_mixin.py:95}} INFO - [2019-10-04 09:59:17,769] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:59:17,771] {{logging_mixin.py:95}} INFO - [2019-10-04 09:59:17,770] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:54:17.770631+00:00
[2019-10-04 09:59:17,779] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.000 seconds
[2019-10-04 09:59:29,250] {{logging_mixin.py:95}} INFO - [2019-10-04 09:59:29,250] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:59:29,267] {{jobs.py:386}} INFO - Started process (PID=2205) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:59:29,389] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:59:29,390] {{logging_mixin.py:95}} INFO - [2019-10-04 09:59:29,390] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:59:29,436] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:59:30,577] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:59:30,651] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:59:30,658] {{logging_mixin.py:95}} INFO - [2019-10-04 09:59:30,658] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:59:30,659] {{logging_mixin.py:95}} INFO - [2019-10-04 09:59:30,659] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:54:30.659041+00:00
[2019-10-04 09:59:30,674] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.407 seconds
[2019-10-04 09:59:42,607] {{logging_mixin.py:95}} INFO - [2019-10-04 09:59:42,556] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:59:42,749] {{jobs.py:386}} INFO - Started process (PID=2209) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:59:43,173] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:59:43,174] {{logging_mixin.py:95}} INFO - [2019-10-04 09:59:43,174] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:59:43,571] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:59:46,332] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 09:59:46,456] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 09:59:46,484] {{logging_mixin.py:95}} INFO - [2019-10-04 09:59:46,484] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 09:59:46,486] {{logging_mixin.py:95}} INFO - [2019-10-04 09:59:46,485] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:54:46.485432+00:00
[2019-10-04 09:59:46,609] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.860 seconds
[2019-10-04 09:59:58,591] {{logging_mixin.py:95}} INFO - [2019-10-04 09:59:58,591] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 09:59:58,639] {{jobs.py:386}} INFO - Started process (PID=2221) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 09:59:58,771] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 09:59:58,772] {{logging_mixin.py:95}} INFO - [2019-10-04 09:59:58,772] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:00:00,319] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:00:01,131] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:00:01,142] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:00:01,155] {{logging_mixin.py:95}} INFO - [2019-10-04 10:00:01,155] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:00:01,157] {{logging_mixin.py:95}} INFO - [2019-10-04 10:00:01,156] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:55:01.156722+00:00
[2019-10-04 10:00:01,282] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.642 seconds
[2019-10-04 10:00:14,661] {{logging_mixin.py:95}} INFO - [2019-10-04 10:00:14,661] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:00:14,827] {{jobs.py:386}} INFO - Started process (PID=2225) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:00:15,462] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:00:15,465] {{logging_mixin.py:95}} INFO - [2019-10-04 10:00:15,465] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:00:15,618] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:00:17,915] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:00:17,921] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:00:17,929] {{logging_mixin.py:95}} INFO - [2019-10-04 10:00:17,929] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:00:17,930] {{logging_mixin.py:95}} INFO - [2019-10-04 10:00:17,929] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:55:17.929850+00:00
[2019-10-04 10:00:17,938] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.111 seconds
[2019-10-04 10:00:28,651] {{logging_mixin.py:95}} INFO - [2019-10-04 10:00:28,651] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:00:28,660] {{jobs.py:386}} INFO - Started process (PID=2229) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:00:28,731] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:00:28,738] {{logging_mixin.py:95}} INFO - [2019-10-04 10:00:28,737] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:00:28,772] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:00:33,585] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:00:33,640] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:00:33,649] {{logging_mixin.py:95}} INFO - [2019-10-04 10:00:33,649] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:00:33,650] {{logging_mixin.py:95}} INFO - [2019-10-04 10:00:33,650] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:55:33.650077+00:00
[2019-10-04 10:00:34,424] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.764 seconds
[2019-10-04 10:00:46,656] {{logging_mixin.py:95}} INFO - [2019-10-04 10:00:46,656] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:00:47,004] {{jobs.py:386}} INFO - Started process (PID=2233) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:00:47,898] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:00:47,900] {{logging_mixin.py:95}} INFO - [2019-10-04 10:00:47,900] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:00:50,183] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:01:06,590] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:01:07,747] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:01:07,830] {{logging_mixin.py:95}} INFO - [2019-10-04 10:01:07,830] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:01:07,832] {{logging_mixin.py:95}} INFO - [2019-10-04 10:01:07,831] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:56:07.831689+00:00
[2019-10-04 10:01:08,600] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 21.596 seconds
[2019-10-04 10:01:21,034] {{logging_mixin.py:95}} INFO - [2019-10-04 10:01:21,034] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:01:21,086] {{jobs.py:386}} INFO - Started process (PID=2242) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:01:21,742] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:01:21,743] {{logging_mixin.py:95}} INFO - [2019-10-04 10:01:21,743] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:01:25,627] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:01:38,789] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:01:39,179] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:01:39,189] {{logging_mixin.py:95}} INFO - [2019-10-04 10:01:39,189] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:01:39,192] {{logging_mixin.py:95}} INFO - [2019-10-04 10:01:39,190] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:56:39.190493+00:00
[2019-10-04 10:01:40,604] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 19.518 seconds
[2019-10-04 10:01:53,087] {{logging_mixin.py:95}} INFO - [2019-10-04 10:01:53,086] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:01:53,309] {{jobs.py:386}} INFO - Started process (PID=2246) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:01:54,358] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:01:54,359] {{logging_mixin.py:95}} INFO - [2019-10-04 10:01:54,359] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:02:02,989] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:02:14,030] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:02:14,361] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:02:14,636] {{logging_mixin.py:95}} INFO - [2019-10-04 10:02:14,636] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:02:14,637] {{logging_mixin.py:95}} INFO - [2019-10-04 10:02:14,637] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:57:14.637263+00:00
[2019-10-04 10:02:15,706] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 22.397 seconds
[2019-10-04 10:02:27,696] {{logging_mixin.py:95}} INFO - [2019-10-04 10:02:27,695] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:02:27,725] {{jobs.py:386}} INFO - Started process (PID=2255) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:02:27,857] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:02:27,859] {{logging_mixin.py:95}} INFO - [2019-10-04 10:02:27,859] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:02:28,743] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:02:30,109] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:02:30,115] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:02:30,126] {{logging_mixin.py:95}} INFO - [2019-10-04 10:02:30,126] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:02:30,127] {{logging_mixin.py:95}} INFO - [2019-10-04 10:02:30,127] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:57:30.127413+00:00
[2019-10-04 10:02:30,134] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.409 seconds
[2019-10-04 10:02:40,977] {{logging_mixin.py:95}} INFO - [2019-10-04 10:02:40,977] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:02:40,981] {{jobs.py:386}} INFO - Started process (PID=2259) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:02:40,985] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:02:40,985] {{logging_mixin.py:95}} INFO - [2019-10-04 10:02:40,985] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:02:41,016] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:02:41,288] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:02:41,295] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:02:41,303] {{logging_mixin.py:95}} INFO - [2019-10-04 10:02:41,303] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:02:41,304] {{logging_mixin.py:95}} INFO - [2019-10-04 10:02:41,303] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:57:41.303611+00:00
[2019-10-04 10:02:41,311] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.330 seconds
[2019-10-04 10:02:52,677] {{logging_mixin.py:95}} INFO - [2019-10-04 10:02:52,677] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:02:52,681] {{jobs.py:386}} INFO - Started process (PID=2263) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:02:52,699] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:02:52,700] {{logging_mixin.py:95}} INFO - [2019-10-04 10:02:52,700] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:02:52,740] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:02:55,640] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:02:55,645] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:02:55,700] {{logging_mixin.py:95}} INFO - [2019-10-04 10:02:55,700] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:02:55,701] {{logging_mixin.py:95}} INFO - [2019-10-04 10:02:55,701] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:57:55.701145+00:00
[2019-10-04 10:02:55,708] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.027 seconds
[2019-10-04 10:03:10,930] {{logging_mixin.py:95}} INFO - [2019-10-04 10:03:10,709] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:03:11,012] {{jobs.py:386}} INFO - Started process (PID=2272) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:03:11,524] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:03:11,539] {{logging_mixin.py:95}} INFO - [2019-10-04 10:03:11,538] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:03:12,488] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:03:15,870] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:03:15,874] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:03:15,881] {{logging_mixin.py:95}} INFO - [2019-10-04 10:03:15,881] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:03:15,883] {{logging_mixin.py:95}} INFO - [2019-10-04 10:03:15,882] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:58:15.882687+00:00
[2019-10-04 10:03:15,889] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.877 seconds
[2019-10-04 10:03:26,877] {{logging_mixin.py:95}} INFO - [2019-10-04 10:03:26,877] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:03:26,881] {{jobs.py:386}} INFO - Started process (PID=2276) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:03:26,941] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:03:26,941] {{logging_mixin.py:95}} INFO - [2019-10-04 10:03:26,941] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:03:26,971] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:03:27,105] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:03:27,110] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:03:27,117] {{logging_mixin.py:95}} INFO - [2019-10-04 10:03:27,117] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:03:27,118] {{logging_mixin.py:95}} INFO - [2019-10-04 10:03:27,118] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:58:27.118044+00:00
[2019-10-04 10:03:27,125] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.244 seconds
[2019-10-04 10:03:39,112] {{logging_mixin.py:95}} INFO - [2019-10-04 10:03:39,112] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:03:39,154] {{jobs.py:386}} INFO - Started process (PID=2280) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:03:39,354] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:03:39,356] {{logging_mixin.py:95}} INFO - [2019-10-04 10:03:39,356] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:03:39,818] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:03:43,477] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:03:43,517] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:03:43,531] {{logging_mixin.py:95}} INFO - [2019-10-04 10:03:43,531] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:03:43,538] {{logging_mixin.py:95}} INFO - [2019-10-04 10:03:43,537] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:58:43.537497+00:00
[2019-10-04 10:03:43,545] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.391 seconds
[2019-10-04 10:03:54,876] {{logging_mixin.py:95}} INFO - [2019-10-04 10:03:54,875] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:03:54,899] {{jobs.py:386}} INFO - Started process (PID=2289) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:03:54,905] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:03:54,912] {{logging_mixin.py:95}} INFO - [2019-10-04 10:03:54,911] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:03:54,964] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:03:57,363] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:03:57,407] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:03:57,421] {{logging_mixin.py:95}} INFO - [2019-10-04 10:03:57,421] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:03:57,422] {{logging_mixin.py:95}} INFO - [2019-10-04 10:03:57,422] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:58:57.422274+00:00
[2019-10-04 10:03:57,430] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.531 seconds
[2019-10-04 10:04:10,427] {{logging_mixin.py:95}} INFO - [2019-10-04 10:04:10,427] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:04:10,569] {{jobs.py:386}} INFO - Started process (PID=2293) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:04:11,336] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:04:11,337] {{logging_mixin.py:95}} INFO - [2019-10-04 10:04:11,337] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:04:13,074] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:04:19,831] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:04:20,246] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:04:20,255] {{logging_mixin.py:95}} INFO - [2019-10-04 10:04:20,255] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:04:20,256] {{logging_mixin.py:95}} INFO - [2019-10-04 10:04:20,256] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:59:20.256017+00:00
[2019-10-04 10:04:20,291] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 9.722 seconds
[2019-10-04 10:04:32,258] {{logging_mixin.py:95}} INFO - [2019-10-04 10:04:32,258] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:04:32,294] {{jobs.py:386}} INFO - Started process (PID=2297) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:04:32,691] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:04:32,693] {{logging_mixin.py:95}} INFO - [2019-10-04 10:04:32,693] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:04:33,682] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:04:49,679] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:04:50,305] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:04:50,314] {{logging_mixin.py:95}} INFO - [2019-10-04 10:04:50,314] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:04:50,315] {{logging_mixin.py:95}} INFO - [2019-10-04 10:04:50,315] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 09:59:50.315197+00:00
[2019-10-04 10:04:50,787] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 18.493 seconds
[2019-10-04 10:05:06,266] {{logging_mixin.py:95}} INFO - [2019-10-04 10:05:06,224] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:05:06,350] {{jobs.py:386}} INFO - Started process (PID=2301) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:05:06,698] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:05:06,699] {{logging_mixin.py:95}} INFO - [2019-10-04 10:05:06,699] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:05:09,180] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:05:30,972] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 10:05:44,353] {{logging_mixin.py:95}} INFO - [2019-10-04 10:05:44,353] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:05:44,623] {{jobs.py:386}} INFO - Started process (PID=2303) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:05:45,248] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:05:45,249] {{logging_mixin.py:95}} INFO - [2019-10-04 10:05:45,249] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:05:46,197] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:05:52,308] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:05:52,482] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:05:52,499] {{logging_mixin.py:95}} INFO - [2019-10-04 10:05:52,499] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:05:52,501] {{logging_mixin.py:95}} INFO - [2019-10-04 10:05:52,500] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:00:52.500678+00:00
[2019-10-04 10:05:52,508] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 7.885 seconds
[2019-10-04 10:06:03,941] {{logging_mixin.py:95}} INFO - [2019-10-04 10:06:03,941] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:06:03,946] {{jobs.py:386}} INFO - Started process (PID=2307) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:06:03,952] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:06:03,958] {{logging_mixin.py:95}} INFO - [2019-10-04 10:06:03,957] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:06:04,047] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:06:04,342] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:06:04,375] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:06:04,382] {{logging_mixin.py:95}} INFO - [2019-10-04 10:06:04,382] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:06:04,382] {{logging_mixin.py:95}} INFO - [2019-10-04 10:06:04,382] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:01:04.382341+00:00
[2019-10-04 10:06:04,395] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.449 seconds
[2019-10-04 10:06:15,627] {{logging_mixin.py:95}} INFO - [2019-10-04 10:06:15,627] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:06:15,630] {{jobs.py:386}} INFO - Started process (PID=2316) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:06:15,633] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:06:15,640] {{logging_mixin.py:95}} INFO - [2019-10-04 10:06:15,639] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:06:15,681] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:06:16,104] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:06:16,110] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:06:16,119] {{logging_mixin.py:95}} INFO - [2019-10-04 10:06:16,119] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:06:16,122] {{logging_mixin.py:95}} INFO - [2019-10-04 10:06:16,121] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:01:16.121083+00:00
[2019-10-04 10:06:16,129] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.499 seconds
[2019-10-04 10:06:27,429] {{logging_mixin.py:95}} INFO - [2019-10-04 10:06:27,429] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:06:27,432] {{jobs.py:386}} INFO - Started process (PID=2320) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:06:27,804] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:06:27,806] {{logging_mixin.py:95}} INFO - [2019-10-04 10:06:27,806] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:06:28,486] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:06:33,315] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:06:33,372] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:06:33,378] {{logging_mixin.py:95}} INFO - [2019-10-04 10:06:33,378] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:06:33,381] {{logging_mixin.py:95}} INFO - [2019-10-04 10:06:33,381] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:01:33.381033+00:00
[2019-10-04 10:06:33,389] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.957 seconds
[2019-10-04 10:06:44,092] {{logging_mixin.py:95}} INFO - [2019-10-04 10:06:44,092] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:06:44,098] {{jobs.py:386}} INFO - Started process (PID=2331) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:06:44,101] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:06:44,101] {{logging_mixin.py:95}} INFO - [2019-10-04 10:06:44,101] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:06:44,121] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:06:44,391] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:06:44,396] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:06:44,403] {{logging_mixin.py:95}} INFO - [2019-10-04 10:06:44,403] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:06:44,404] {{logging_mixin.py:95}} INFO - [2019-10-04 10:06:44,404] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:01:44.404050+00:00
[2019-10-04 10:06:44,415] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.317 seconds
[2019-10-04 10:06:55,768] {{logging_mixin.py:95}} INFO - [2019-10-04 10:06:55,768] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:06:55,772] {{jobs.py:386}} INFO - Started process (PID=2335) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:06:55,774] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:06:55,775] {{logging_mixin.py:95}} INFO - [2019-10-04 10:06:55,775] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:06:55,808] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:06:56,281] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:06:56,288] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:06:56,298] {{logging_mixin.py:95}} INFO - [2019-10-04 10:06:56,298] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:06:56,300] {{logging_mixin.py:95}} INFO - [2019-10-04 10:06:56,299] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:01:56.299923+00:00
[2019-10-04 10:06:56,406] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.634 seconds
[2019-10-04 10:07:07,197] {{logging_mixin.py:95}} INFO - [2019-10-04 10:07:07,197] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:07:07,201] {{jobs.py:386}} INFO - Started process (PID=2339) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:07:07,204] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:07:07,205] {{logging_mixin.py:95}} INFO - [2019-10-04 10:07:07,205] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:07:07,228] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:07:07,390] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:07:07,438] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:07:07,448] {{logging_mixin.py:95}} INFO - [2019-10-04 10:07:07,448] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:07:07,450] {{logging_mixin.py:95}} INFO - [2019-10-04 10:07:07,449] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:02:07.449606+00:00
[2019-10-04 10:07:07,456] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.255 seconds
[2019-10-04 10:07:20,793] {{logging_mixin.py:95}} INFO - [2019-10-04 10:07:20,642] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:07:20,936] {{jobs.py:386}} INFO - Started process (PID=2342) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:07:21,494] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:07:21,495] {{logging_mixin.py:95}} INFO - [2019-10-04 10:07:21,495] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:07:24,073] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:07:36,350] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:07:36,355] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:07:36,364] {{logging_mixin.py:95}} INFO - [2019-10-04 10:07:36,364] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:07:36,365] {{logging_mixin.py:95}} INFO - [2019-10-04 10:07:36,365] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:02:36.365152+00:00
[2019-10-04 10:07:36,924] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 15.988 seconds
[2019-10-04 10:07:48,571] {{logging_mixin.py:95}} INFO - [2019-10-04 10:07:48,571] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:07:48,576] {{jobs.py:386}} INFO - Started process (PID=2354) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:07:48,589] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:07:48,594] {{logging_mixin.py:95}} INFO - [2019-10-04 10:07:48,594] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:07:48,642] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:07:49,042] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:07:49,048] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:07:49,057] {{logging_mixin.py:95}} INFO - [2019-10-04 10:07:49,057] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:07:49,059] {{logging_mixin.py:95}} INFO - [2019-10-04 10:07:49,058] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:02:49.058473+00:00
[2019-10-04 10:07:49,067] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.491 seconds
[2019-10-04 10:08:00,161] {{logging_mixin.py:95}} INFO - [2019-10-04 10:08:00,160] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:08:00,168] {{jobs.py:386}} INFO - Started process (PID=2358) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:08:00,172] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:08:00,173] {{logging_mixin.py:95}} INFO - [2019-10-04 10:08:00,172] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:08:00,214] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:08:00,700] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:08:00,711] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:08:00,731] {{logging_mixin.py:95}} INFO - [2019-10-04 10:08:00,731] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:08:00,732] {{logging_mixin.py:95}} INFO - [2019-10-04 10:08:00,732] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:03:00.732078+00:00
[2019-10-04 10:08:00,740] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.572 seconds
[2019-10-04 10:08:11,916] {{logging_mixin.py:95}} INFO - [2019-10-04 10:08:11,916] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:08:11,924] {{jobs.py:386}} INFO - Started process (PID=2368) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:08:11,928] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:08:11,929] {{logging_mixin.py:95}} INFO - [2019-10-04 10:08:11,929] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:08:11,961] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:08:12,509] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:08:12,513] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:08:12,521] {{logging_mixin.py:95}} INFO - [2019-10-04 10:08:12,521] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:08:12,522] {{logging_mixin.py:95}} INFO - [2019-10-04 10:08:12,522] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:03:12.522106+00:00
[2019-10-04 10:08:12,531] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.607 seconds
[2019-10-04 10:08:23,514] {{logging_mixin.py:95}} INFO - [2019-10-04 10:08:23,514] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:08:23,520] {{jobs.py:386}} INFO - Started process (PID=2372) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:08:23,525] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:08:23,528] {{logging_mixin.py:95}} INFO - [2019-10-04 10:08:23,528] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:08:23,584] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:08:23,785] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:08:23,801] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:08:23,871] {{logging_mixin.py:95}} INFO - [2019-10-04 10:08:23,871] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:08:23,957] {{logging_mixin.py:95}} INFO - [2019-10-04 10:08:23,956] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:03:23.956745+00:00
[2019-10-04 10:08:23,969] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.449 seconds
[2019-10-04 10:08:36,507] {{logging_mixin.py:95}} INFO - [2019-10-04 10:08:36,507] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:08:36,632] {{jobs.py:386}} INFO - Started process (PID=2376) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:08:36,958] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:08:36,959] {{logging_mixin.py:95}} INFO - [2019-10-04 10:08:36,959] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:08:37,091] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:08:37,341] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:08:37,349] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:08:37,359] {{logging_mixin.py:95}} INFO - [2019-10-04 10:08:37,359] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:08:37,360] {{logging_mixin.py:95}} INFO - [2019-10-04 10:08:37,359] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:03:37.359871+00:00
[2019-10-04 10:08:37,370] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.737 seconds
[2019-10-04 10:08:49,262] {{logging_mixin.py:95}} INFO - [2019-10-04 10:08:49,261] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:08:49,266] {{jobs.py:386}} INFO - Started process (PID=2385) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:08:49,275] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:08:49,276] {{logging_mixin.py:95}} INFO - [2019-10-04 10:08:49,276] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:08:49,311] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:08:49,620] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:08:49,625] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:08:49,632] {{logging_mixin.py:95}} INFO - [2019-10-04 10:08:49,632] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:08:49,634] {{logging_mixin.py:95}} INFO - [2019-10-04 10:08:49,633] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:03:49.633531+00:00
[2019-10-04 10:08:49,641] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.375 seconds
[2019-10-04 10:09:00,620] {{logging_mixin.py:95}} INFO - [2019-10-04 10:09:00,620] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:09:00,629] {{jobs.py:386}} INFO - Started process (PID=2389) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:09:00,632] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:09:00,635] {{logging_mixin.py:95}} INFO - [2019-10-04 10:09:00,634] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:09:00,672] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:09:01,190] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:09:01,198] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:09:01,210] {{logging_mixin.py:95}} INFO - [2019-10-04 10:09:01,210] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:09:01,212] {{logging_mixin.py:95}} INFO - [2019-10-04 10:09:01,211] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:04:01.211308+00:00
[2019-10-04 10:09:01,220] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.592 seconds
[2019-10-04 10:09:13,126] {{logging_mixin.py:95}} INFO - [2019-10-04 10:09:13,125] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:09:13,181] {{jobs.py:386}} INFO - Started process (PID=2393) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:09:13,511] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:09:13,513] {{logging_mixin.py:95}} INFO - [2019-10-04 10:09:13,513] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:09:14,358] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:09:22,179] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:09:22,465] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:09:22,474] {{logging_mixin.py:95}} INFO - [2019-10-04 10:09:22,474] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:09:22,474] {{logging_mixin.py:95}} INFO - [2019-10-04 10:09:22,474] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:04:22.474308+00:00
[2019-10-04 10:09:22,964] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 9.783 seconds
[2019-10-04 10:09:33,975] {{logging_mixin.py:95}} INFO - [2019-10-04 10:09:33,974] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:09:33,978] {{jobs.py:386}} INFO - Started process (PID=2405) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:09:33,981] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:09:33,982] {{logging_mixin.py:95}} INFO - [2019-10-04 10:09:33,982] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:09:34,617] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:09:38,389] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:09:38,400] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:09:38,410] {{logging_mixin.py:95}} INFO - [2019-10-04 10:09:38,410] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:09:38,412] {{logging_mixin.py:95}} INFO - [2019-10-04 10:09:38,411] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:04:38.411745+00:00
[2019-10-04 10:09:38,668] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.690 seconds
[2019-10-04 10:09:50,475] {{logging_mixin.py:95}} INFO - [2019-10-04 10:09:50,475] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:09:50,480] {{jobs.py:386}} INFO - Started process (PID=2408) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:09:50,561] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:09:50,562] {{logging_mixin.py:95}} INFO - [2019-10-04 10:09:50,562] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:09:50,598] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:09:51,209] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:09:51,214] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:09:51,223] {{logging_mixin.py:95}} INFO - [2019-10-04 10:09:51,223] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:09:51,225] {{logging_mixin.py:95}} INFO - [2019-10-04 10:09:51,224] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:04:51.224554+00:00
[2019-10-04 10:09:51,233] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.753 seconds
[2019-10-04 10:10:02,203] {{logging_mixin.py:95}} INFO - [2019-10-04 10:10:02,203] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:10:02,236] {{jobs.py:386}} INFO - Started process (PID=2417) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:10:02,884] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:10:02,885] {{logging_mixin.py:95}} INFO - [2019-10-04 10:10:02,885] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:10:05,836] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:10:08,668] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:10:08,765] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:10:08,824] {{logging_mixin.py:95}} INFO - [2019-10-04 10:10:08,824] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:10:08,825] {{logging_mixin.py:95}} INFO - [2019-10-04 10:10:08,824] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:05:08.824764+00:00
[2019-10-04 10:10:08,838] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 6.602 seconds
[2019-10-04 10:10:20,375] {{logging_mixin.py:95}} INFO - [2019-10-04 10:10:20,374] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:10:20,384] {{jobs.py:386}} INFO - Started process (PID=2421) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:10:20,397] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:10:20,399] {{logging_mixin.py:95}} INFO - [2019-10-04 10:10:20,399] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:10:20,467] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:10:20,648] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:10:20,657] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:10:20,669] {{logging_mixin.py:95}} INFO - [2019-10-04 10:10:20,669] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:10:20,671] {{logging_mixin.py:95}} INFO - [2019-10-04 10:10:20,670] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:05:20.670240+00:00
[2019-10-04 10:10:20,681] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.297 seconds
[2019-10-04 10:10:31,941] {{logging_mixin.py:95}} INFO - [2019-10-04 10:10:31,941] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:10:31,945] {{jobs.py:386}} INFO - Started process (PID=2425) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:10:32,611] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:10:32,637] {{logging_mixin.py:95}} INFO - [2019-10-04 10:10:32,637] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:10:33,612] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:10:37,813] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:10:37,954] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:10:37,966] {{logging_mixin.py:95}} INFO - [2019-10-04 10:10:37,966] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:10:37,968] {{logging_mixin.py:95}} INFO - [2019-10-04 10:10:37,967] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:05:37.967631+00:00
[2019-10-04 10:10:38,496] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 6.551 seconds
[2019-10-04 10:10:50,047] {{logging_mixin.py:95}} INFO - [2019-10-04 10:10:50,046] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:10:50,056] {{jobs.py:386}} INFO - Started process (PID=2435) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:10:50,063] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:10:50,069] {{logging_mixin.py:95}} INFO - [2019-10-04 10:10:50,068] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:10:50,108] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:10:50,469] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:10:50,474] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:10:50,482] {{logging_mixin.py:95}} INFO - [2019-10-04 10:10:50,482] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:10:50,483] {{logging_mixin.py:95}} INFO - [2019-10-04 10:10:50,482] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:05:50.482684+00:00
[2019-10-04 10:10:50,489] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.433 seconds
[2019-10-04 10:11:01,497] {{logging_mixin.py:95}} INFO - [2019-10-04 10:11:01,496] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:11:01,503] {{jobs.py:386}} INFO - Started process (PID=2439) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:11:01,512] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:11:01,520] {{logging_mixin.py:95}} INFO - [2019-10-04 10:11:01,520] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:11:01,547] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:11:01,745] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:11:01,754] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:11:01,769] {{logging_mixin.py:95}} INFO - [2019-10-04 10:11:01,769] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:11:01,771] {{logging_mixin.py:95}} INFO - [2019-10-04 10:11:01,770] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:06:01.770899+00:00
[2019-10-04 10:11:01,784] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.280 seconds
[2019-10-04 10:11:14,034] {{logging_mixin.py:95}} INFO - [2019-10-04 10:11:13,986] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:11:14,299] {{jobs.py:386}} INFO - Started process (PID=2443) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:11:15,175] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:11:15,177] {{logging_mixin.py:95}} INFO - [2019-10-04 10:11:15,177] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:11:18,883] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:11:22,613] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:11:22,751] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:11:22,759] {{logging_mixin.py:95}} INFO - [2019-10-04 10:11:22,759] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:11:22,761] {{logging_mixin.py:95}} INFO - [2019-10-04 10:11:22,760] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:06:22.760579+00:00
[2019-10-04 10:11:22,922] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 8.622 seconds
[2019-10-04 10:11:33,791] {{logging_mixin.py:95}} INFO - [2019-10-04 10:11:33,791] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:11:33,804] {{jobs.py:386}} INFO - Started process (PID=2453) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:11:33,806] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:11:33,808] {{logging_mixin.py:95}} INFO - [2019-10-04 10:11:33,808] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:11:33,842] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:11:34,088] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:11:34,152] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:11:34,167] {{logging_mixin.py:95}} INFO - [2019-10-04 10:11:34,167] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:11:34,168] {{logging_mixin.py:95}} INFO - [2019-10-04 10:11:34,167] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:06:34.167765+00:00
[2019-10-04 10:11:34,175] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.372 seconds
[2019-10-04 10:11:45,415] {{logging_mixin.py:95}} INFO - [2019-10-04 10:11:45,415] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:11:45,450] {{jobs.py:386}} INFO - Started process (PID=2457) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:11:46,038] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:11:46,039] {{logging_mixin.py:95}} INFO - [2019-10-04 10:11:46,039] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:11:46,771] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:11:53,023] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:11:53,226] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:11:53,236] {{logging_mixin.py:95}} INFO - [2019-10-04 10:11:53,236] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:11:53,238] {{logging_mixin.py:95}} INFO - [2019-10-04 10:11:53,237] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:06:53.237362+00:00
[2019-10-04 10:11:54,121] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 8.671 seconds
[2019-10-04 10:12:05,102] {{logging_mixin.py:95}} INFO - [2019-10-04 10:12:05,102] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:12:05,106] {{jobs.py:386}} INFO - Started process (PID=2461) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:12:05,270] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:12:05,272] {{logging_mixin.py:95}} INFO - [2019-10-04 10:12:05,271] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:12:05,608] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:12:10,147] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:12:10,250] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:12:10,265] {{logging_mixin.py:95}} INFO - [2019-10-04 10:12:10,265] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:12:10,267] {{logging_mixin.py:95}} INFO - [2019-10-04 10:12:10,266] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:07:10.266675+00:00
[2019-10-04 10:12:10,279] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.173 seconds
[2019-10-04 10:12:22,279] {{logging_mixin.py:95}} INFO - [2019-10-04 10:12:22,044] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:12:22,355] {{jobs.py:386}} INFO - Started process (PID=2470) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:12:23,411] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:12:23,412] {{logging_mixin.py:95}} INFO - [2019-10-04 10:12:23,412] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:12:24,993] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:12:31,007] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:12:31,040] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:12:31,047] {{logging_mixin.py:95}} INFO - [2019-10-04 10:12:31,046] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:12:31,047] {{logging_mixin.py:95}} INFO - [2019-10-04 10:12:31,047] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:07:31.047249+00:00
[2019-10-04 10:12:31,407] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 9.052 seconds
[2019-10-04 10:12:43,472] {{logging_mixin.py:95}} INFO - [2019-10-04 10:12:43,472] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:12:43,476] {{jobs.py:386}} INFO - Started process (PID=2474) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:12:43,482] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:12:43,484] {{logging_mixin.py:95}} INFO - [2019-10-04 10:12:43,484] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:12:43,552] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:12:43,828] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:12:43,833] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:12:43,839] {{logging_mixin.py:95}} INFO - [2019-10-04 10:12:43,839] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:12:43,841] {{logging_mixin.py:95}} INFO - [2019-10-04 10:12:43,840] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:07:43.840659+00:00
[2019-10-04 10:12:43,847] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.371 seconds
[2019-10-04 10:12:55,254] {{logging_mixin.py:95}} INFO - [2019-10-04 10:12:55,253] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:12:55,258] {{jobs.py:386}} INFO - Started process (PID=2483) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:12:55,277] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:12:55,279] {{logging_mixin.py:95}} INFO - [2019-10-04 10:12:55,278] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:12:55,324] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:12:55,641] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:12:55,645] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:12:55,654] {{logging_mixin.py:95}} INFO - [2019-10-04 10:12:55,654] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:12:55,656] {{logging_mixin.py:95}} INFO - [2019-10-04 10:12:55,655] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:07:55.655744+00:00
[2019-10-04 10:12:55,671] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.413 seconds
[2019-10-04 10:13:06,535] {{logging_mixin.py:95}} INFO - [2019-10-04 10:13:06,534] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:13:06,541] {{jobs.py:386}} INFO - Started process (PID=2487) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:13:06,607] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:13:06,608] {{logging_mixin.py:95}} INFO - [2019-10-04 10:13:06,608] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:13:06,666] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:13:11,647] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:13:11,932] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:13:11,944] {{logging_mixin.py:95}} INFO - [2019-10-04 10:13:11,944] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:13:11,945] {{logging_mixin.py:95}} INFO - [2019-10-04 10:13:11,945] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:08:11.945388+00:00
[2019-10-04 10:13:11,972] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.430 seconds
[2019-10-04 10:13:23,141] {{logging_mixin.py:95}} INFO - [2019-10-04 10:13:23,141] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:13:23,204] {{jobs.py:386}} INFO - Started process (PID=2491) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:13:23,358] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:13:23,361] {{logging_mixin.py:95}} INFO - [2019-10-04 10:13:23,361] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:13:23,391] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:13:23,604] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:13:23,611] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:13:23,621] {{logging_mixin.py:95}} INFO - [2019-10-04 10:13:23,621] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:13:23,623] {{logging_mixin.py:95}} INFO - [2019-10-04 10:13:23,622] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:08:23.622480+00:00
[2019-10-04 10:13:23,631] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.427 seconds
[2019-10-04 10:13:34,837] {{logging_mixin.py:95}} INFO - [2019-10-04 10:13:34,837] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:13:34,843] {{jobs.py:386}} INFO - Started process (PID=2500) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:13:34,847] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:13:34,850] {{logging_mixin.py:95}} INFO - [2019-10-04 10:13:34,850] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:13:34,880] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:13:35,027] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:13:35,062] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:13:35,074] {{logging_mixin.py:95}} INFO - [2019-10-04 10:13:35,074] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:13:35,076] {{logging_mixin.py:95}} INFO - [2019-10-04 10:13:35,075] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:08:35.075457+00:00
[2019-10-04 10:13:35,085] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.242 seconds
[2019-10-04 10:13:46,138] {{logging_mixin.py:95}} INFO - [2019-10-04 10:13:46,137] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:13:46,149] {{jobs.py:386}} INFO - Started process (PID=2504) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:13:46,160] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:13:46,160] {{logging_mixin.py:95}} INFO - [2019-10-04 10:13:46,160] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:13:46,219] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:13:46,426] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:13:46,432] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:13:46,442] {{logging_mixin.py:95}} INFO - [2019-10-04 10:13:46,442] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:13:46,443] {{logging_mixin.py:95}} INFO - [2019-10-04 10:13:46,443] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:08:46.443018+00:00
[2019-10-04 10:13:46,452] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.303 seconds
[2019-10-04 10:13:58,243] {{logging_mixin.py:95}} INFO - [2019-10-04 10:13:58,243] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:13:58,476] {{jobs.py:386}} INFO - Started process (PID=2508) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:13:58,953] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:13:58,955] {{logging_mixin.py:95}} INFO - [2019-10-04 10:13:58,955] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:13:59,445] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:14:01,496] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:14:01,521] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:14:01,535] {{logging_mixin.py:95}} INFO - [2019-10-04 10:14:01,535] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:14:01,536] {{logging_mixin.py:95}} INFO - [2019-10-04 10:14:01,536] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:09:01.536459+00:00
[2019-10-04 10:14:01,545] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.069 seconds
[2019-10-04 10:14:13,059] {{logging_mixin.py:95}} INFO - [2019-10-04 10:14:13,059] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:14:13,063] {{jobs.py:386}} INFO - Started process (PID=2517) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:14:13,066] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:14:13,067] {{logging_mixin.py:95}} INFO - [2019-10-04 10:14:13,067] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:14:13,092] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:14:13,871] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:14:13,879] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:14:13,887] {{logging_mixin.py:95}} INFO - [2019-10-04 10:14:13,887] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:14:13,892] {{logging_mixin.py:95}} INFO - [2019-10-04 10:14:13,892] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:09:13.892002+00:00
[2019-10-04 10:14:13,900] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.837 seconds
[2019-10-04 10:14:24,809] {{logging_mixin.py:95}} INFO - [2019-10-04 10:14:24,808] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:14:24,813] {{jobs.py:386}} INFO - Started process (PID=2521) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:14:24,849] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:14:24,850] {{logging_mixin.py:95}} INFO - [2019-10-04 10:14:24,850] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:14:25,287] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:14:25,729] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:14:25,751] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:14:25,772] {{logging_mixin.py:95}} INFO - [2019-10-04 10:14:25,772] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:14:25,773] {{logging_mixin.py:95}} INFO - [2019-10-04 10:14:25,773] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:09:25.773063+00:00
[2019-10-04 10:14:25,787] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.974 seconds
[2019-10-04 10:14:37,465] {{logging_mixin.py:95}} INFO - [2019-10-04 10:14:37,465] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:14:37,468] {{jobs.py:386}} INFO - Started process (PID=2525) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:14:37,711] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:14:37,712] {{logging_mixin.py:95}} INFO - [2019-10-04 10:14:37,712] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:14:41,097] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:14:52,719] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:14:52,758] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:14:52,768] {{logging_mixin.py:95}} INFO - [2019-10-04 10:14:52,768] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:14:52,770] {{logging_mixin.py:95}} INFO - [2019-10-04 10:14:52,769] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:09:52.769654+00:00
[2019-10-04 10:14:52,778] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 15.310 seconds
[2019-10-04 10:15:05,767] {{logging_mixin.py:95}} INFO - [2019-10-04 10:15:05,766] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:15:06,063] {{jobs.py:386}} INFO - Started process (PID=2535) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:15:06,445] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:15:06,446] {{logging_mixin.py:95}} INFO - [2019-10-04 10:15:06,446] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:15:08,626] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:15:09,890] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:15:09,932] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:15:09,943] {{logging_mixin.py:95}} INFO - [2019-10-04 10:15:09,943] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:15:09,945] {{logging_mixin.py:95}} INFO - [2019-10-04 10:15:09,944] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:10:09.944412+00:00
[2019-10-04 10:15:09,953] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.890 seconds
[2019-10-04 10:15:22,440] {{logging_mixin.py:95}} INFO - [2019-10-04 10:15:22,419] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:15:22,629] {{jobs.py:386}} INFO - Started process (PID=2539) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:15:23,169] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:15:23,171] {{logging_mixin.py:95}} INFO - [2019-10-04 10:15:23,171] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:15:24,602] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:15:37,899] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:15:38,099] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:15:38,114] {{logging_mixin.py:95}} INFO - [2019-10-04 10:15:38,113] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:15:38,116] {{logging_mixin.py:95}} INFO - [2019-10-04 10:15:38,115] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:10:38.115337+00:00
[2019-10-04 10:15:38,542] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 15.913 seconds
[2019-10-04 10:15:50,857] {{logging_mixin.py:95}} INFO - [2019-10-04 10:15:50,857] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:15:50,939] {{jobs.py:386}} INFO - Started process (PID=2548) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:15:50,944] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:15:50,946] {{logging_mixin.py:95}} INFO - [2019-10-04 10:15:50,946] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:15:51,176] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:15:51,801] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:15:51,807] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:15:51,817] {{logging_mixin.py:95}} INFO - [2019-10-04 10:15:51,817] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:15:51,819] {{logging_mixin.py:95}} INFO - [2019-10-04 10:15:51,818] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:10:51.818738+00:00
[2019-10-04 10:15:51,826] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.887 seconds
[2019-10-04 10:16:02,918] {{logging_mixin.py:95}} INFO - [2019-10-04 10:16:02,918] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:16:02,922] {{jobs.py:386}} INFO - Started process (PID=2552) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:16:02,925] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:16:02,926] {{logging_mixin.py:95}} INFO - [2019-10-04 10:16:02,926] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:16:02,959] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:16:03,266] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:16:03,277] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:16:03,284] {{logging_mixin.py:95}} INFO - [2019-10-04 10:16:03,283] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:16:03,285] {{logging_mixin.py:95}} INFO - [2019-10-04 10:16:03,284] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:11:03.284732+00:00
[2019-10-04 10:16:03,291] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.369 seconds
[2019-10-04 10:16:14,419] {{logging_mixin.py:95}} INFO - [2019-10-04 10:16:14,418] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:16:14,422] {{jobs.py:386}} INFO - Started process (PID=2556) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:16:14,427] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:16:14,428] {{logging_mixin.py:95}} INFO - [2019-10-04 10:16:14,428] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:16:14,455] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:16:15,263] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:16:15,268] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:16:15,276] {{logging_mixin.py:95}} INFO - [2019-10-04 10:16:15,276] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:16:15,277] {{logging_mixin.py:95}} INFO - [2019-10-04 10:16:15,277] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:11:15.277035+00:00
[2019-10-04 10:16:15,284] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.862 seconds
[2019-10-04 10:16:25,982] {{logging_mixin.py:95}} INFO - [2019-10-04 10:16:25,981] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:16:25,989] {{jobs.py:386}} INFO - Started process (PID=2565) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:16:25,993] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:16:25,995] {{logging_mixin.py:95}} INFO - [2019-10-04 10:16:25,994] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:16:26,106] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:16:26,266] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:16:26,281] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:16:26,300] {{logging_mixin.py:95}} INFO - [2019-10-04 10:16:26,300] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:16:26,302] {{logging_mixin.py:95}} INFO - [2019-10-04 10:16:26,301] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:11:26.301557+00:00
[2019-10-04 10:16:26,314] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.325 seconds
[2019-10-04 10:16:37,609] {{logging_mixin.py:95}} INFO - [2019-10-04 10:16:37,608] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:16:37,612] {{jobs.py:386}} INFO - Started process (PID=2569) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:16:37,615] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:16:37,616] {{logging_mixin.py:95}} INFO - [2019-10-04 10:16:37,616] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:16:37,636] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:16:38,365] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:16:38,378] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:16:38,393] {{logging_mixin.py:95}} INFO - [2019-10-04 10:16:38,393] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:16:38,396] {{logging_mixin.py:95}} INFO - [2019-10-04 10:16:38,394] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:11:38.394596+00:00
[2019-10-04 10:16:38,407] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.795 seconds
[2019-10-04 10:16:49,103] {{logging_mixin.py:95}} INFO - [2019-10-04 10:16:49,103] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:16:49,107] {{jobs.py:386}} INFO - Started process (PID=2573) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:16:49,113] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:16:49,115] {{logging_mixin.py:95}} INFO - [2019-10-04 10:16:49,114] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:16:49,141] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:16:49,253] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:16:49,260] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:16:49,270] {{logging_mixin.py:95}} INFO - [2019-10-04 10:16:49,270] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:16:49,272] {{logging_mixin.py:95}} INFO - [2019-10-04 10:16:49,271] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:11:49.271623+00:00
[2019-10-04 10:16:49,280] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.173 seconds
[2019-10-04 10:17:00,950] {{logging_mixin.py:95}} INFO - [2019-10-04 10:17:00,950] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:17:01,242] {{jobs.py:386}} INFO - Started process (PID=2583) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:17:01,727] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:17:01,728] {{logging_mixin.py:95}} INFO - [2019-10-04 10:17:01,728] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:17:02,396] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:17:06,309] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:17:06,995] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:17:07,008] {{logging_mixin.py:95}} INFO - [2019-10-04 10:17:07,008] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:17:07,021] {{logging_mixin.py:95}} INFO - [2019-10-04 10:17:07,020] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:12:07.020526+00:00
[2019-10-04 10:17:07,034] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.792 seconds
[2019-10-04 10:17:19,065] {{logging_mixin.py:95}} INFO - [2019-10-04 10:17:19,065] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:17:19,109] {{jobs.py:386}} INFO - Started process (PID=2587) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:17:19,531] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:17:19,535] {{logging_mixin.py:95}} INFO - [2019-10-04 10:17:19,535] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:17:19,803] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:17:22,002] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:17:22,144] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:17:22,204] {{logging_mixin.py:95}} INFO - [2019-10-04 10:17:22,204] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:17:22,205] {{logging_mixin.py:95}} INFO - [2019-10-04 10:17:22,204] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:12:22.204875+00:00
[2019-10-04 10:17:22,221] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.111 seconds
[2019-10-04 10:17:34,185] {{logging_mixin.py:95}} INFO - [2019-10-04 10:17:34,185] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:17:34,441] {{jobs.py:386}} INFO - Started process (PID=2599) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:17:35,267] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:17:35,270] {{logging_mixin.py:95}} INFO - [2019-10-04 10:17:35,270] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:17:39,003] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:17:53,125] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:17:53,426] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:17:53,437] {{logging_mixin.py:95}} INFO - [2019-10-04 10:17:53,437] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:17:53,438] {{logging_mixin.py:95}} INFO - [2019-10-04 10:17:53,438] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:12:53.438276+00:00
[2019-10-04 10:17:54,606] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 20.165 seconds
[2019-10-04 10:18:07,094] {{logging_mixin.py:95}} INFO - [2019-10-04 10:18:07,093] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:18:07,147] {{jobs.py:386}} INFO - Started process (PID=2603) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:18:07,764] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:18:07,766] {{logging_mixin.py:95}} INFO - [2019-10-04 10:18:07,766] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:18:10,410] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:18:11,142] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:18:11,150] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:18:11,162] {{logging_mixin.py:95}} INFO - [2019-10-04 10:18:11,162] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:18:11,164] {{logging_mixin.py:95}} INFO - [2019-10-04 10:18:11,163] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:13:11.163436+00:00
[2019-10-04 10:18:11,174] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.027 seconds
[2019-10-04 10:18:21,989] {{logging_mixin.py:95}} INFO - [2019-10-04 10:18:21,989] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:18:21,994] {{jobs.py:386}} INFO - Started process (PID=2612) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:18:22,009] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:18:22,009] {{logging_mixin.py:95}} INFO - [2019-10-04 10:18:22,009] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:18:22,037] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:18:22,251] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:18:22,256] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:18:22,263] {{logging_mixin.py:95}} INFO - [2019-10-04 10:18:22,263] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:18:22,264] {{logging_mixin.py:95}} INFO - [2019-10-04 10:18:22,263] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:13:22.263751+00:00
[2019-10-04 10:18:22,269] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.275 seconds
[2019-10-04 10:18:33,431] {{logging_mixin.py:95}} INFO - [2019-10-04 10:18:33,430] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:18:33,447] {{jobs.py:386}} INFO - Started process (PID=2616) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:18:33,535] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:18:33,537] {{logging_mixin.py:95}} INFO - [2019-10-04 10:18:33,537] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:18:33,581] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:18:34,316] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:18:34,332] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:18:34,346] {{logging_mixin.py:95}} INFO - [2019-10-04 10:18:34,346] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:18:34,350] {{logging_mixin.py:95}} INFO - [2019-10-04 10:18:34,349] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:13:34.349500+00:00
[2019-10-04 10:18:34,361] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.914 seconds
[2019-10-04 10:18:45,237] {{logging_mixin.py:95}} INFO - [2019-10-04 10:18:45,236] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:18:45,262] {{jobs.py:386}} INFO - Started process (PID=2620) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:18:45,290] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:18:45,298] {{logging_mixin.py:95}} INFO - [2019-10-04 10:18:45,297] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:18:45,379] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:18:50,081] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:18:50,088] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:18:50,096] {{logging_mixin.py:95}} INFO - [2019-10-04 10:18:50,096] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:18:50,098] {{logging_mixin.py:95}} INFO - [2019-10-04 10:18:50,097] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:13:50.097481+00:00
[2019-10-04 10:18:50,105] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.842 seconds
[2019-10-04 10:19:00,887] {{logging_mixin.py:95}} INFO - [2019-10-04 10:19:00,886] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:19:00,891] {{jobs.py:386}} INFO - Started process (PID=2629) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:19:00,903] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:19:00,904] {{logging_mixin.py:95}} INFO - [2019-10-04 10:19:00,904] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:19:00,956] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:19:01,401] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:19:01,405] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:19:01,412] {{logging_mixin.py:95}} INFO - [2019-10-04 10:19:01,412] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:19:01,414] {{logging_mixin.py:95}} INFO - [2019-10-04 10:19:01,413] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:14:01.413257+00:00
[2019-10-04 10:19:01,421] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.530 seconds
[2019-10-04 10:19:12,740] {{logging_mixin.py:95}} INFO - [2019-10-04 10:19:12,740] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:19:12,744] {{jobs.py:386}} INFO - Started process (PID=2633) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:19:12,752] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:19:12,757] {{logging_mixin.py:95}} INFO - [2019-10-04 10:19:12,757] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:19:13,102] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:19:15,643] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:19:15,754] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:19:15,770] {{logging_mixin.py:95}} INFO - [2019-10-04 10:19:15,769] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:19:15,771] {{logging_mixin.py:95}} INFO - [2019-10-04 10:19:15,771] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:14:15.771024+00:00
[2019-10-04 10:19:15,780] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.036 seconds
[2019-10-04 10:19:26,510] {{logging_mixin.py:95}} INFO - [2019-10-04 10:19:26,509] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:19:26,516] {{jobs.py:386}} INFO - Started process (PID=2642) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:19:26,523] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:19:26,525] {{logging_mixin.py:95}} INFO - [2019-10-04 10:19:26,525] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:19:26,563] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:19:26,697] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:19:26,704] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:19:26,714] {{logging_mixin.py:95}} INFO - [2019-10-04 10:19:26,714] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:19:26,717] {{logging_mixin.py:95}} INFO - [2019-10-04 10:19:26,716] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:14:26.716086+00:00
[2019-10-04 10:19:26,724] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.209 seconds
[2019-10-04 10:19:38,923] {{logging_mixin.py:95}} INFO - [2019-10-04 10:19:38,923] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:19:38,943] {{jobs.py:386}} INFO - Started process (PID=2646) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:19:39,207] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:19:39,211] {{logging_mixin.py:95}} INFO - [2019-10-04 10:19:39,211] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:19:40,448] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:19:44,280] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:19:44,387] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:19:44,397] {{logging_mixin.py:95}} INFO - [2019-10-04 10:19:44,397] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:19:44,398] {{logging_mixin.py:95}} INFO - [2019-10-04 10:19:44,397] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:14:44.397820+00:00
[2019-10-04 10:19:44,406] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.463 seconds
[2019-10-04 10:19:57,268] {{logging_mixin.py:95}} INFO - [2019-10-04 10:19:57,156] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:19:57,475] {{jobs.py:386}} INFO - Started process (PID=2650) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:19:58,315] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:19:58,320] {{logging_mixin.py:95}} INFO - [2019-10-04 10:19:58,320] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:20:00,480] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:20:03,330] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:20:03,338] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:20:03,373] {{logging_mixin.py:95}} INFO - [2019-10-04 10:20:03,373] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:20:03,382] {{logging_mixin.py:95}} INFO - [2019-10-04 10:20:03,382] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:15:03.382267+00:00
[2019-10-04 10:20:03,403] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.929 seconds
[2019-10-04 10:20:15,901] {{logging_mixin.py:95}} INFO - [2019-10-04 10:20:15,900] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:20:16,089] {{jobs.py:386}} INFO - Started process (PID=2659) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:20:16,605] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:20:16,606] {{logging_mixin.py:95}} INFO - [2019-10-04 10:20:16,606] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:20:17,303] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:20:31,470] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:20:31,876] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:20:31,898] {{logging_mixin.py:95}} INFO - [2019-10-04 10:20:31,898] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:20:31,903] {{logging_mixin.py:95}} INFO - [2019-10-04 10:20:31,902] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:15:31.902894+00:00
[2019-10-04 10:20:32,043] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 15.953 seconds
[2019-10-04 10:20:43,282] {{logging_mixin.py:95}} INFO - [2019-10-04 10:20:43,214] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:20:43,358] {{jobs.py:386}} INFO - Started process (PID=2668) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:20:43,914] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:20:43,920] {{logging_mixin.py:95}} INFO - [2019-10-04 10:20:43,920] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:20:47,217] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:21:01,484] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:21:01,826] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:21:01,835] {{logging_mixin.py:95}} INFO - [2019-10-04 10:21:01,835] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:21:01,837] {{logging_mixin.py:95}} INFO - [2019-10-04 10:21:01,836] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:16:01.836674+00:00
[2019-10-04 10:21:02,311] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 18.953 seconds
[2019-10-04 10:21:14,577] {{logging_mixin.py:95}} INFO - [2019-10-04 10:21:14,576] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:21:14,656] {{jobs.py:386}} INFO - Started process (PID=2672) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:21:15,220] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:21:15,221] {{logging_mixin.py:95}} INFO - [2019-10-04 10:21:15,221] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:21:16,059] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:21:16,426] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:21:16,431] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:21:16,441] {{logging_mixin.py:95}} INFO - [2019-10-04 10:21:16,441] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:21:16,443] {{logging_mixin.py:95}} INFO - [2019-10-04 10:21:16,442] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:16:16.442692+00:00
[2019-10-04 10:21:16,451] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.795 seconds
[2019-10-04 10:21:27,704] {{logging_mixin.py:95}} INFO - [2019-10-04 10:21:27,704] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:21:27,710] {{jobs.py:386}} INFO - Started process (PID=2678) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:21:27,715] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:21:27,716] {{logging_mixin.py:95}} INFO - [2019-10-04 10:21:27,716] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:21:27,756] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:21:28,035] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:21:28,041] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:21:28,051] {{logging_mixin.py:95}} INFO - [2019-10-04 10:21:28,051] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:21:28,053] {{logging_mixin.py:95}} INFO - [2019-10-04 10:21:28,052] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:16:28.052749+00:00
[2019-10-04 10:21:28,061] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.352 seconds
[2019-10-04 10:21:39,479] {{logging_mixin.py:95}} INFO - [2019-10-04 10:21:39,479] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:21:39,483] {{jobs.py:386}} INFO - Started process (PID=2681) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:21:39,854] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:21:39,856] {{logging_mixin.py:95}} INFO - [2019-10-04 10:21:39,855] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:21:39,988] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:21:41,106] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:21:41,113] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:21:41,121] {{logging_mixin.py:95}} INFO - [2019-10-04 10:21:41,121] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:21:41,122] {{logging_mixin.py:95}} INFO - [2019-10-04 10:21:41,122] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:16:41.122278+00:00
[2019-10-04 10:21:41,350] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.867 seconds
[2019-10-04 10:21:52,795] {{logging_mixin.py:95}} INFO - [2019-10-04 10:21:52,795] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:21:52,853] {{jobs.py:386}} INFO - Started process (PID=2689) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:21:53,260] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:21:53,261] {{logging_mixin.py:95}} INFO - [2019-10-04 10:21:53,261] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:21:53,568] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:21:55,755] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:21:55,764] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:21:55,774] {{logging_mixin.py:95}} INFO - [2019-10-04 10:21:55,774] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:21:55,776] {{logging_mixin.py:95}} INFO - [2019-10-04 10:21:55,776] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:16:55.775990+00:00
[2019-10-04 10:21:55,870] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.017 seconds
[2019-10-04 10:22:07,263] {{logging_mixin.py:95}} INFO - [2019-10-04 10:22:07,263] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:22:07,282] {{jobs.py:386}} INFO - Started process (PID=2693) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:22:07,310] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:22:07,319] {{logging_mixin.py:95}} INFO - [2019-10-04 10:22:07,319] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:22:07,468] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:22:07,712] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:22:07,721] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:22:07,731] {{logging_mixin.py:95}} INFO - [2019-10-04 10:22:07,731] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:22:07,732] {{logging_mixin.py:95}} INFO - [2019-10-04 10:22:07,732] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:17:07.732001+00:00
[2019-10-04 10:22:07,749] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.467 seconds
[2019-10-04 10:22:19,157] {{logging_mixin.py:95}} INFO - [2019-10-04 10:22:19,156] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:22:19,165] {{jobs.py:386}} INFO - Started process (PID=2706) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:22:19,546] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:22:19,547] {{logging_mixin.py:95}} INFO - [2019-10-04 10:22:19,547] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:22:19,733] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:22:22,153] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:22:22,229] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:22:22,238] {{logging_mixin.py:95}} INFO - [2019-10-04 10:22:22,238] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:22:22,239] {{logging_mixin.py:95}} INFO - [2019-10-04 10:22:22,239] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:17:22.239082+00:00
[2019-10-04 10:22:22,469] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.304 seconds
[2019-10-04 10:22:35,084] {{logging_mixin.py:95}} INFO - [2019-10-04 10:22:35,083] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:22:35,127] {{jobs.py:386}} INFO - Started process (PID=2710) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:22:35,369] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:22:35,370] {{logging_mixin.py:95}} INFO - [2019-10-04 10:22:35,370] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:22:36,319] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:22:48,987] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:22:49,121] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:22:49,132] {{logging_mixin.py:95}} INFO - [2019-10-04 10:22:49,131] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:22:49,133] {{logging_mixin.py:95}} INFO - [2019-10-04 10:22:49,132] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:17:49.132840+00:00
[2019-10-04 10:22:50,466] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 15.339 seconds
[2019-10-04 10:23:05,301] {{logging_mixin.py:95}} INFO - [2019-10-04 10:23:05,151] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:23:05,477] {{jobs.py:386}} INFO - Started process (PID=2721) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:23:05,783] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:23:05,784] {{logging_mixin.py:95}} INFO - [2019-10-04 10:23:05,784] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:23:08,108] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:23:25,139] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:23:25,739] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:23:25,972] {{logging_mixin.py:95}} INFO - [2019-10-04 10:23:25,972] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:23:25,973] {{logging_mixin.py:95}} INFO - [2019-10-04 10:23:25,973] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:18:25.973278+00:00
[2019-10-04 10:23:28,182] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 22.705 seconds
[2019-10-04 10:23:44,444] {{logging_mixin.py:95}} INFO - [2019-10-04 10:23:44,419] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:23:44,609] {{jobs.py:386}} INFO - Started process (PID=2725) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:23:45,912] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:23:45,915] {{logging_mixin.py:95}} INFO - [2019-10-04 10:23:45,915] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:23:50,344] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:23:57,266] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:23:57,272] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:23:57,281] {{logging_mixin.py:95}} INFO - [2019-10-04 10:23:57,281] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:23:57,283] {{logging_mixin.py:95}} INFO - [2019-10-04 10:23:57,282] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:18:57.282701+00:00
[2019-10-04 10:23:57,487] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 12.878 seconds
[2019-10-04 10:24:08,420] {{logging_mixin.py:95}} INFO - [2019-10-04 10:24:08,419] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:24:08,423] {{jobs.py:386}} INFO - Started process (PID=2734) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:24:08,425] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:24:08,427] {{logging_mixin.py:95}} INFO - [2019-10-04 10:24:08,427] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:24:08,448] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:24:08,634] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:24:08,640] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:24:08,653] {{logging_mixin.py:95}} INFO - [2019-10-04 10:24:08,653] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:24:08,655] {{logging_mixin.py:95}} INFO - [2019-10-04 10:24:08,654] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:19:08.654515+00:00
[2019-10-04 10:24:08,711] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.288 seconds
[2019-10-04 10:24:19,770] {{logging_mixin.py:95}} INFO - [2019-10-04 10:24:19,770] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:24:19,774] {{jobs.py:386}} INFO - Started process (PID=2738) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:24:19,778] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:24:19,780] {{logging_mixin.py:95}} INFO - [2019-10-04 10:24:19,779] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:24:19,830] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:24:20,034] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:24:20,040] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:24:20,052] {{logging_mixin.py:95}} INFO - [2019-10-04 10:24:20,052] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:24:20,053] {{logging_mixin.py:95}} INFO - [2019-10-04 10:24:20,053] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:19:20.053280+00:00
[2019-10-04 10:24:20,064] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.290 seconds
[2019-10-04 10:24:31,194] {{logging_mixin.py:95}} INFO - [2019-10-04 10:24:31,194] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:24:31,199] {{jobs.py:386}} INFO - Started process (PID=2742) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:24:31,292] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:24:31,303] {{logging_mixin.py:95}} INFO - [2019-10-04 10:24:31,303] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:24:31,345] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:24:32,585] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:24:32,592] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:24:32,654] {{logging_mixin.py:95}} INFO - [2019-10-04 10:24:32,654] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:24:32,655] {{logging_mixin.py:95}} INFO - [2019-10-04 10:24:32,655] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:19:32.655237+00:00
[2019-10-04 10:24:32,663] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.464 seconds
[2019-10-04 10:24:44,450] {{logging_mixin.py:95}} INFO - [2019-10-04 10:24:44,450] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:24:44,484] {{jobs.py:386}} INFO - Started process (PID=2752) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:24:44,647] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:24:44,648] {{logging_mixin.py:95}} INFO - [2019-10-04 10:24:44,648] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:24:45,656] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:24:47,162] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:24:47,194] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:24:47,203] {{logging_mixin.py:95}} INFO - [2019-10-04 10:24:47,203] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:24:47,207] {{logging_mixin.py:95}} INFO - [2019-10-04 10:24:47,204] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:19:47.204395+00:00
[2019-10-04 10:24:47,217] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.733 seconds
[2019-10-04 10:24:58,713] {{logging_mixin.py:95}} INFO - [2019-10-04 10:24:58,713] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:24:58,717] {{jobs.py:386}} INFO - Started process (PID=2756) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:24:58,726] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:24:58,727] {{logging_mixin.py:95}} INFO - [2019-10-04 10:24:58,727] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:24:58,767] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:24:58,963] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:24:58,970] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:24:58,980] {{logging_mixin.py:95}} INFO - [2019-10-04 10:24:58,980] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:24:58,982] {{logging_mixin.py:95}} INFO - [2019-10-04 10:24:58,981] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:19:58.981839+00:00
[2019-10-04 10:24:58,989] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.272 seconds
[2019-10-04 10:25:10,041] {{logging_mixin.py:95}} INFO - [2019-10-04 10:25:10,041] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:25:10,045] {{jobs.py:386}} INFO - Started process (PID=2760) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:25:10,056] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:25:10,060] {{logging_mixin.py:95}} INFO - [2019-10-04 10:25:10,060] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:25:10,095] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:25:10,502] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:25:10,509] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:25:10,520] {{logging_mixin.py:95}} INFO - [2019-10-04 10:25:10,520] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:25:10,522] {{logging_mixin.py:95}} INFO - [2019-10-04 10:25:10,521] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:20:10.521460+00:00
[2019-10-04 10:25:10,531] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.486 seconds
[2019-10-04 10:25:21,912] {{logging_mixin.py:95}} INFO - [2019-10-04 10:25:21,911] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:25:21,976] {{jobs.py:386}} INFO - Started process (PID=2774) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:25:22,347] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:25:22,350] {{logging_mixin.py:95}} INFO - [2019-10-04 10:25:22,349] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:25:22,588] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:25:26,179] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:25:26,369] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:25:26,380] {{logging_mixin.py:95}} INFO - [2019-10-04 10:25:26,380] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:25:26,382] {{logging_mixin.py:95}} INFO - [2019-10-04 10:25:26,381] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:20:26.381745+00:00
[2019-10-04 10:25:26,668] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.692 seconds
[2019-10-04 10:25:40,702] {{logging_mixin.py:95}} INFO - [2019-10-04 10:25:40,701] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:25:41,024] {{jobs.py:386}} INFO - Started process (PID=2778) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:25:42,189] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:25:42,191] {{logging_mixin.py:95}} INFO - [2019-10-04 10:25:42,191] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:25:49,788] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:26:00,696] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:26:00,853] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:26:00,871] {{logging_mixin.py:95}} INFO - [2019-10-04 10:26:00,870] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:26:00,876] {{logging_mixin.py:95}} INFO - [2019-10-04 10:26:00,874] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:21:00.874850+00:00
[2019-10-04 10:26:01,217] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 20.193 seconds
[2019-10-04 10:26:14,389] {{logging_mixin.py:95}} INFO - [2019-10-04 10:26:14,248] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:26:14,548] {{jobs.py:386}} INFO - Started process (PID=2787) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:26:15,696] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:26:15,698] {{logging_mixin.py:95}} INFO - [2019-10-04 10:26:15,698] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:26:18,608] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:26:34,542] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:26:34,667] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:26:34,676] {{logging_mixin.py:95}} INFO - [2019-10-04 10:26:34,676] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:26:34,678] {{logging_mixin.py:95}} INFO - [2019-10-04 10:26:34,677] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:21:34.677774+00:00
[2019-10-04 10:26:34,969] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 20.420 seconds
[2019-10-04 10:26:46,515] {{logging_mixin.py:95}} INFO - [2019-10-04 10:26:46,514] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:26:46,520] {{jobs.py:386}} INFO - Started process (PID=2791) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:26:47,096] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:26:47,097] {{logging_mixin.py:95}} INFO - [2019-10-04 10:26:47,097] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:26:47,133] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:26:47,358] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:26:47,464] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:26:47,481] {{logging_mixin.py:95}} INFO - [2019-10-04 10:26:47,481] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:26:47,483] {{logging_mixin.py:95}} INFO - [2019-10-04 10:26:47,482] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:21:47.482536+00:00
[2019-10-04 10:26:47,493] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.972 seconds
[2019-10-04 10:26:57,798] {{logging_mixin.py:95}} INFO - [2019-10-04 10:26:57,798] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:26:57,813] {{jobs.py:386}} INFO - Started process (PID=2795) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:26:57,817] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:26:57,819] {{logging_mixin.py:95}} INFO - [2019-10-04 10:26:57,819] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:26:57,852] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:26:58,113] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:26:58,121] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:26:58,130] {{logging_mixin.py:95}} INFO - [2019-10-04 10:26:58,130] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:26:58,131] {{logging_mixin.py:95}} INFO - [2019-10-04 10:26:58,131] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:21:58.130987+00:00
[2019-10-04 10:26:58,140] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.327 seconds
[2019-10-04 10:27:09,701] {{logging_mixin.py:95}} INFO - [2019-10-04 10:27:09,701] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:27:09,705] {{jobs.py:386}} INFO - Started process (PID=2808) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:27:09,709] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:27:09,711] {{logging_mixin.py:95}} INFO - [2019-10-04 10:27:09,711] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:27:09,757] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:27:09,957] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:27:09,964] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:27:09,974] {{logging_mixin.py:95}} INFO - [2019-10-04 10:27:09,974] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:27:09,976] {{logging_mixin.py:95}} INFO - [2019-10-04 10:27:09,975] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:22:09.975638+00:00
[2019-10-04 10:27:09,990] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.285 seconds
[2019-10-04 10:27:22,714] {{logging_mixin.py:95}} INFO - [2019-10-04 10:27:22,613] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:27:23,013] {{jobs.py:386}} INFO - Started process (PID=2812) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:27:23,537] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:27:23,552] {{logging_mixin.py:95}} INFO - [2019-10-04 10:27:23,551] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:27:25,002] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:27:28,738] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:27:28,887] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:27:28,895] {{logging_mixin.py:95}} INFO - [2019-10-04 10:27:28,895] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:27:28,896] {{logging_mixin.py:95}} INFO - [2019-10-04 10:27:28,896] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:22:28.896180+00:00
[2019-10-04 10:27:28,924] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.911 seconds
[2019-10-04 10:27:40,613] {{logging_mixin.py:95}} INFO - [2019-10-04 10:27:40,613] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:27:40,617] {{jobs.py:386}} INFO - Started process (PID=2827) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:27:40,620] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:27:40,621] {{logging_mixin.py:95}} INFO - [2019-10-04 10:27:40,620] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:27:40,641] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:27:40,815] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:27:40,821] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:27:40,829] {{logging_mixin.py:95}} INFO - [2019-10-04 10:27:40,829] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:27:40,830] {{logging_mixin.py:95}} INFO - [2019-10-04 10:27:40,830] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:22:40.830078+00:00
[2019-10-04 10:27:40,836] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.219 seconds
[2019-10-04 10:27:51,856] {{logging_mixin.py:95}} INFO - [2019-10-04 10:27:51,856] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:27:51,860] {{jobs.py:386}} INFO - Started process (PID=2830) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:27:51,863] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:27:51,865] {{logging_mixin.py:95}} INFO - [2019-10-04 10:27:51,865] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:27:51,887] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:27:52,457] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:27:52,464] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:27:52,474] {{logging_mixin.py:95}} INFO - [2019-10-04 10:27:52,474] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:27:52,476] {{logging_mixin.py:95}} INFO - [2019-10-04 10:27:52,475] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:22:52.475700+00:00
[2019-10-04 10:27:52,484] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.624 seconds
[2019-10-04 10:28:04,355] {{logging_mixin.py:95}} INFO - [2019-10-04 10:28:04,355] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:28:04,422] {{jobs.py:386}} INFO - Started process (PID=2833) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:28:05,302] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:28:05,306] {{logging_mixin.py:95}} INFO - [2019-10-04 10:28:05,305] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:28:06,192] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:28:10,072] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:28:10,152] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:28:10,167] {{logging_mixin.py:95}} INFO - [2019-10-04 10:28:10,167] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:28:10,170] {{logging_mixin.py:95}} INFO - [2019-10-04 10:28:10,168] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:23:10.168539+00:00
[2019-10-04 10:28:10,183] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.761 seconds
[2019-10-04 10:28:23,369] {{logging_mixin.py:95}} INFO - [2019-10-04 10:28:23,294] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:28:23,455] {{jobs.py:386}} INFO - Started process (PID=2842) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:28:25,172] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:28:25,173] {{logging_mixin.py:95}} INFO - [2019-10-04 10:28:25,173] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:28:27,177] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:28:42,831] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:28:43,003] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:28:43,021] {{logging_mixin.py:95}} INFO - [2019-10-04 10:28:43,020] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:28:43,023] {{logging_mixin.py:95}} INFO - [2019-10-04 10:28:43,022] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:23:43.022488+00:00
[2019-10-04 10:28:43,608] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 20.153 seconds
[2019-10-04 10:29:00,926] {{logging_mixin.py:95}} INFO - [2019-10-04 10:29:00,535] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:29:01,510] {{jobs.py:386}} INFO - Started process (PID=2846) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:29:02,800] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:29:02,802] {{logging_mixin.py:95}} INFO - [2019-10-04 10:29:02,802] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:29:07,985] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:29:22,812] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:29:23,080] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:29:23,101] {{logging_mixin.py:95}} INFO - [2019-10-04 10:29:23,101] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:29:23,104] {{logging_mixin.py:95}} INFO - [2019-10-04 10:29:23,103] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:24:23.102992+00:00
[2019-10-04 10:29:24,598] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 23.087 seconds
[2019-10-04 10:29:37,043] {{logging_mixin.py:95}} INFO - [2019-10-04 10:29:37,042] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:29:37,110] {{jobs.py:386}} INFO - Started process (PID=2850) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:29:37,465] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:29:37,466] {{logging_mixin.py:95}} INFO - [2019-10-04 10:29:37,466] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:29:38,098] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:29:38,922] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:29:38,930] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:29:38,949] {{logging_mixin.py:95}} INFO - [2019-10-04 10:29:38,949] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:29:38,952] {{logging_mixin.py:95}} INFO - [2019-10-04 10:29:38,951] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:24:38.951399+00:00
[2019-10-04 10:29:38,973] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.863 seconds
[2019-10-04 10:29:50,374] {{logging_mixin.py:95}} INFO - [2019-10-04 10:29:50,374] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:29:50,387] {{jobs.py:386}} INFO - Started process (PID=2854) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:29:50,395] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:29:50,396] {{logging_mixin.py:95}} INFO - [2019-10-04 10:29:50,396] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:29:50,435] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:29:50,966] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:29:50,972] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:29:50,982] {{logging_mixin.py:95}} INFO - [2019-10-04 10:29:50,982] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:29:50,984] {{logging_mixin.py:95}} INFO - [2019-10-04 10:29:50,983] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:24:50.983665+00:00
[2019-10-04 10:29:50,992] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.605 seconds
[2019-10-04 10:30:01,765] {{logging_mixin.py:95}} INFO - [2019-10-04 10:30:01,765] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:30:01,769] {{jobs.py:386}} INFO - Started process (PID=2858) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:30:01,829] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:30:01,830] {{logging_mixin.py:95}} INFO - [2019-10-04 10:30:01,829] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:30:01,995] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:30:02,920] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:30:02,927] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:30:02,936] {{logging_mixin.py:95}} INFO - [2019-10-04 10:30:02,936] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:30:02,938] {{logging_mixin.py:95}} INFO - [2019-10-04 10:30:02,937] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:25:02.937689+00:00
[2019-10-04 10:30:02,946] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.177 seconds
[2019-10-04 10:30:14,484] {{logging_mixin.py:95}} INFO - [2019-10-04 10:30:14,484] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:30:14,487] {{jobs.py:386}} INFO - Started process (PID=2871) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:30:14,655] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:30:14,657] {{logging_mixin.py:95}} INFO - [2019-10-04 10:30:14,657] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:30:15,629] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:30:20,302] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:30:20,361] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:30:20,370] {{logging_mixin.py:95}} INFO - [2019-10-04 10:30:20,370] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:30:20,372] {{logging_mixin.py:95}} INFO - [2019-10-04 10:30:20,371] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:25:20.371771+00:00
[2019-10-04 10:30:20,610] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 6.123 seconds
[2019-10-04 10:30:31,656] {{logging_mixin.py:95}} INFO - [2019-10-04 10:30:31,656] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:30:31,660] {{jobs.py:386}} INFO - Started process (PID=2874) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:30:31,672] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:30:31,672] {{logging_mixin.py:95}} INFO - [2019-10-04 10:30:31,672] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:30:31,708] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:30:31,818] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:30:31,824] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:30:31,832] {{logging_mixin.py:95}} INFO - [2019-10-04 10:30:31,832] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:30:31,833] {{logging_mixin.py:95}} INFO - [2019-10-04 10:30:31,833] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:25:31.833182+00:00
[2019-10-04 10:30:31,841] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.181 seconds
[2019-10-04 10:30:44,474] {{logging_mixin.py:95}} INFO - [2019-10-04 10:30:44,459] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:30:44,740] {{jobs.py:386}} INFO - Started process (PID=2883) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:30:45,065] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:30:45,066] {{logging_mixin.py:95}} INFO - [2019-10-04 10:30:45,066] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:30:46,190] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:30:48,412] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:30:48,418] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:30:48,429] {{logging_mixin.py:95}} INFO - [2019-10-04 10:30:48,429] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:30:48,430] {{logging_mixin.py:95}} INFO - [2019-10-04 10:30:48,429] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:25:48.429927+00:00
[2019-10-04 10:30:48,439] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.699 seconds
[2019-10-04 10:30:59,941] {{logging_mixin.py:95}} INFO - [2019-10-04 10:30:59,902] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:31:00,031] {{jobs.py:386}} INFO - Started process (PID=2887) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:31:00,346] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:31:00,347] {{logging_mixin.py:95}} INFO - [2019-10-04 10:31:00,347] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:31:01,385] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:31:17,942] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:31:18,543] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:31:18,552] {{logging_mixin.py:95}} INFO - [2019-10-04 10:31:18,552] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:31:18,554] {{logging_mixin.py:95}} INFO - [2019-10-04 10:31:18,553] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:26:18.553321+00:00
[2019-10-04 10:31:21,094] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 21.064 seconds
[2019-10-04 10:31:36,566] {{logging_mixin.py:95}} INFO - [2019-10-04 10:31:36,566] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:31:36,846] {{jobs.py:386}} INFO - Started process (PID=2896) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:31:39,253] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:31:39,253] {{logging_mixin.py:95}} INFO - [2019-10-04 10:31:39,253] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:31:47,279] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:31:57,396] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:31:57,482] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:31:57,498] {{logging_mixin.py:95}} INFO - [2019-10-04 10:31:57,498] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:31:57,499] {{logging_mixin.py:95}} INFO - [2019-10-04 10:31:57,498] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:26:57.498800+00:00
[2019-10-04 10:31:57,684] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 20.838 seconds
[2019-10-04 10:32:09,179] {{logging_mixin.py:95}} INFO - [2019-10-04 10:32:09,179] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:32:09,183] {{jobs.py:386}} INFO - Started process (PID=2900) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:32:09,188] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:32:09,190] {{logging_mixin.py:95}} INFO - [2019-10-04 10:32:09,190] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:32:09,211] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:32:09,446] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:32:09,452] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:32:09,460] {{logging_mixin.py:95}} INFO - [2019-10-04 10:32:09,460] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:32:09,461] {{logging_mixin.py:95}} INFO - [2019-10-04 10:32:09,461] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:27:09.461289+00:00
[2019-10-04 10:32:09,468] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.285 seconds
[2019-10-04 10:32:20,859] {{logging_mixin.py:95}} INFO - [2019-10-04 10:32:20,859] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:32:20,863] {{jobs.py:386}} INFO - Started process (PID=2915) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:32:20,867] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:32:20,871] {{logging_mixin.py:95}} INFO - [2019-10-04 10:32:20,871] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:32:20,914] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:32:21,447] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:32:21,466] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:32:21,478] {{logging_mixin.py:95}} INFO - [2019-10-04 10:32:21,478] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:32:21,480] {{logging_mixin.py:95}} INFO - [2019-10-04 10:32:21,479] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:27:21.479586+00:00
[2019-10-04 10:32:21,488] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.625 seconds
[2019-10-04 10:32:32,289] {{logging_mixin.py:95}} INFO - [2019-10-04 10:32:32,289] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:32:32,295] {{jobs.py:386}} INFO - Started process (PID=2919) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:32:32,509] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:32:32,509] {{logging_mixin.py:95}} INFO - [2019-10-04 10:32:32,509] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:32:33,170] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:32:35,262] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:32:35,267] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:32:35,276] {{logging_mixin.py:95}} INFO - [2019-10-04 10:32:35,276] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:32:35,277] {{logging_mixin.py:95}} INFO - [2019-10-04 10:32:35,276] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:27:35.276737+00:00
[2019-10-04 10:32:35,347] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.051 seconds
[2019-10-04 10:32:47,475] {{logging_mixin.py:95}} INFO - [2019-10-04 10:32:47,475] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:32:47,479] {{jobs.py:386}} INFO - Started process (PID=2923) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:32:47,699] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:32:47,703] {{logging_mixin.py:95}} INFO - [2019-10-04 10:32:47,703] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:32:47,754] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:32:48,781] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:32:48,787] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:32:48,797] {{logging_mixin.py:95}} INFO - [2019-10-04 10:32:48,797] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:32:48,798] {{logging_mixin.py:95}} INFO - [2019-10-04 10:32:48,798] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:27:48.798386+00:00
[2019-10-04 10:32:48,832] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.352 seconds
[2019-10-04 10:33:05,969] {{logging_mixin.py:95}} INFO - [2019-10-04 10:33:05,721] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:33:06,226] {{jobs.py:386}} INFO - Started process (PID=2934) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:33:07,267] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:33:07,268] {{logging_mixin.py:95}} INFO - [2019-10-04 10:33:07,268] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:33:07,888] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:33:09,120] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:33:09,328] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:33:09,338] {{logging_mixin.py:95}} INFO - [2019-10-04 10:33:09,338] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:33:09,340] {{logging_mixin.py:95}} INFO - [2019-10-04 10:33:09,339] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:28:09.339483+00:00
[2019-10-04 10:33:09,347] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.120 seconds
[2019-10-04 10:33:20,720] {{logging_mixin.py:95}} INFO - [2019-10-04 10:33:20,720] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:33:20,723] {{jobs.py:386}} INFO - Started process (PID=2938) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:33:20,729] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:33:20,731] {{logging_mixin.py:95}} INFO - [2019-10-04 10:33:20,731] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:33:20,761] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:33:20,966] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:33:20,972] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:33:20,982] {{logging_mixin.py:95}} INFO - [2019-10-04 10:33:20,982] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:33:20,984] {{logging_mixin.py:95}} INFO - [2019-10-04 10:33:20,983] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:28:20.983967+00:00
[2019-10-04 10:33:20,992] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.269 seconds
[2019-10-04 10:33:34,059] {{logging_mixin.py:95}} INFO - [2019-10-04 10:33:34,016] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:33:34,158] {{jobs.py:386}} INFO - Started process (PID=2942) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:33:34,898] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:33:34,899] {{logging_mixin.py:95}} INFO - [2019-10-04 10:33:34,899] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:33:36,299] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:33:41,234] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:33:41,251] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:33:41,268] {{logging_mixin.py:95}} INFO - [2019-10-04 10:33:41,268] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:33:41,270] {{logging_mixin.py:95}} INFO - [2019-10-04 10:33:41,269] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:28:41.269621+00:00
[2019-10-04 10:33:41,279] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 7.121 seconds
[2019-10-04 10:33:58,542] {{logging_mixin.py:95}} INFO - [2019-10-04 10:33:58,449] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:33:58,624] {{jobs.py:386}} INFO - Started process (PID=2951) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:33:58,843] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:33:58,849] {{logging_mixin.py:95}} INFO - [2019-10-04 10:33:58,849] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:34:00,770] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:34:08,788] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:34:08,793] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:34:08,808] {{logging_mixin.py:95}} INFO - [2019-10-04 10:34:08,808] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:34:08,809] {{logging_mixin.py:95}} INFO - [2019-10-04 10:34:08,809] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:29:08.809197+00:00
[2019-10-04 10:34:09,134] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 10.511 seconds
[2019-10-04 10:34:22,465] {{logging_mixin.py:95}} INFO - [2019-10-04 10:34:22,429] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:34:22,498] {{jobs.py:386}} INFO - Started process (PID=2955) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:34:22,916] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:34:22,918] {{logging_mixin.py:95}} INFO - [2019-10-04 10:34:22,918] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:34:25,135] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:34:40,969] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:34:41,283] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:34:41,291] {{logging_mixin.py:95}} INFO - [2019-10-04 10:34:41,291] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:34:41,293] {{logging_mixin.py:95}} INFO - [2019-10-04 10:34:41,292] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:29:41.292726+00:00
[2019-10-04 10:34:42,143] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 19.645 seconds
[2019-10-04 10:34:55,940] {{logging_mixin.py:95}} INFO - [2019-10-04 10:34:55,940] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:34:56,069] {{jobs.py:386}} INFO - Started process (PID=2964) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:34:57,645] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:34:57,647] {{logging_mixin.py:95}} INFO - [2019-10-04 10:34:57,646] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:34:59,793] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:35:03,109] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:35:03,116] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:35:03,127] {{logging_mixin.py:95}} INFO - [2019-10-04 10:35:03,127] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:35:03,129] {{logging_mixin.py:95}} INFO - [2019-10-04 10:35:03,128] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:30:03.128424+00:00
[2019-10-04 10:35:03,138] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 7.069 seconds
[2019-10-04 10:35:14,396] {{logging_mixin.py:95}} INFO - [2019-10-04 10:35:14,396] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:35:14,400] {{jobs.py:386}} INFO - Started process (PID=2968) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:35:14,406] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:35:14,407] {{logging_mixin.py:95}} INFO - [2019-10-04 10:35:14,407] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:35:14,428] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:35:14,746] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:35:14,753] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:35:14,760] {{logging_mixin.py:95}} INFO - [2019-10-04 10:35:14,760] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:35:14,768] {{logging_mixin.py:95}} INFO - [2019-10-04 10:35:14,767] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:30:14.767914+00:00
[2019-10-04 10:35:14,776] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.376 seconds
[2019-10-04 10:35:25,985] {{logging_mixin.py:95}} INFO - [2019-10-04 10:35:25,985] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:35:25,989] {{jobs.py:386}} INFO - Started process (PID=2972) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:35:25,994] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:35:25,995] {{logging_mixin.py:95}} INFO - [2019-10-04 10:35:25,995] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:35:26,029] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:35:26,305] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:35:26,440] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:35:26,454] {{logging_mixin.py:95}} INFO - [2019-10-04 10:35:26,454] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:35:26,456] {{logging_mixin.py:95}} INFO - [2019-10-04 10:35:26,455] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:30:26.455630+00:00
[2019-10-04 10:35:26,523] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.534 seconds
[2019-10-04 10:35:37,836] {{logging_mixin.py:95}} INFO - [2019-10-04 10:35:37,835] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:35:37,843] {{jobs.py:386}} INFO - Started process (PID=2982) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:35:37,846] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:35:37,851] {{logging_mixin.py:95}} INFO - [2019-10-04 10:35:37,851] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:35:37,903] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:35:38,829] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:35:38,882] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:35:38,909] {{logging_mixin.py:95}} INFO - [2019-10-04 10:35:38,909] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:35:38,910] {{logging_mixin.py:95}} INFO - [2019-10-04 10:35:38,910] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:30:38.910047+00:00
[2019-10-04 10:35:38,921] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.078 seconds
[2019-10-04 10:35:50,391] {{logging_mixin.py:95}} INFO - [2019-10-04 10:35:50,391] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:35:50,405] {{jobs.py:386}} INFO - Started process (PID=2986) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:35:50,410] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:35:50,411] {{logging_mixin.py:95}} INFO - [2019-10-04 10:35:50,411] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:35:50,439] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:35:50,731] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:35:50,736] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:35:50,743] {{logging_mixin.py:95}} INFO - [2019-10-04 10:35:50,743] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:35:50,743] {{logging_mixin.py:95}} INFO - [2019-10-04 10:35:50,743] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:30:50.743380+00:00
[2019-10-04 10:35:50,748] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.344 seconds
[2019-10-04 10:36:02,167] {{logging_mixin.py:95}} INFO - [2019-10-04 10:36:02,167] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:36:02,285] {{jobs.py:386}} INFO - Started process (PID=2990) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:36:02,396] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:36:02,399] {{logging_mixin.py:95}} INFO - [2019-10-04 10:36:02,399] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:36:02,716] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:36:06,751] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:36:06,771] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:36:06,782] {{logging_mixin.py:95}} INFO - [2019-10-04 10:36:06,782] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:36:06,784] {{logging_mixin.py:95}} INFO - [2019-10-04 10:36:06,783] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:31:06.783356+00:00
[2019-10-04 10:36:06,805] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.520 seconds
[2019-10-04 10:36:20,174] {{logging_mixin.py:95}} INFO - [2019-10-04 10:36:20,173] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:36:20,710] {{jobs.py:386}} INFO - Started process (PID=2999) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:36:21,553] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:36:21,556] {{logging_mixin.py:95}} INFO - [2019-10-04 10:36:21,556] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:36:23,908] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:36:27,877] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:36:27,969] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:36:27,979] {{logging_mixin.py:95}} INFO - [2019-10-04 10:36:27,979] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:36:27,980] {{logging_mixin.py:95}} INFO - [2019-10-04 10:36:27,980] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:31:27.980126+00:00
[2019-10-04 10:36:27,988] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 7.279 seconds
[2019-10-04 10:36:39,626] {{logging_mixin.py:95}} INFO - [2019-10-04 10:36:39,575] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:36:39,638] {{jobs.py:386}} INFO - Started process (PID=3003) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:36:40,373] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:36:40,376] {{logging_mixin.py:95}} INFO - [2019-10-04 10:36:40,375] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:36:43,147] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:36:56,201] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:36:56,327] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:36:56,337] {{logging_mixin.py:95}} INFO - [2019-10-04 10:36:56,337] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:36:56,338] {{logging_mixin.py:95}} INFO - [2019-10-04 10:36:56,337] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:31:56.337883+00:00
[2019-10-04 10:36:57,355] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 17.717 seconds
[2019-10-04 10:37:09,384] {{logging_mixin.py:95}} INFO - [2019-10-04 10:37:09,384] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:37:09,499] {{jobs.py:386}} INFO - Started process (PID=3012) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:37:09,635] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:37:09,636] {{logging_mixin.py:95}} INFO - [2019-10-04 10:37:09,636] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:37:10,185] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:37:11,418] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:37:11,425] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:37:11,437] {{logging_mixin.py:95}} INFO - [2019-10-04 10:37:11,437] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:37:11,440] {{logging_mixin.py:95}} INFO - [2019-10-04 10:37:11,439] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:32:11.439463+00:00
[2019-10-04 10:37:11,452] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.952 seconds
[2019-10-04 10:37:22,646] {{logging_mixin.py:95}} INFO - [2019-10-04 10:37:22,646] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:37:22,650] {{jobs.py:386}} INFO - Started process (PID=3018) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:37:22,655] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:37:22,656] {{logging_mixin.py:95}} INFO - [2019-10-04 10:37:22,656] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:37:22,672] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:37:23,196] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:37:23,205] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:37:23,220] {{logging_mixin.py:95}} INFO - [2019-10-04 10:37:23,220] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:37:23,223] {{logging_mixin.py:95}} INFO - [2019-10-04 10:37:23,222] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:32:23.222120+00:00
[2019-10-04 10:37:23,235] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.584 seconds
[2019-10-04 10:37:33,971] {{logging_mixin.py:95}} INFO - [2019-10-04 10:37:33,970] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:37:33,978] {{jobs.py:386}} INFO - Started process (PID=3021) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:37:33,984] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:37:33,986] {{logging_mixin.py:95}} INFO - [2019-10-04 10:37:33,986] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:37:34,026] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:37:35,868] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:37:36,017] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:37:36,026] {{logging_mixin.py:95}} INFO - [2019-10-04 10:37:36,026] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:37:36,027] {{logging_mixin.py:95}} INFO - [2019-10-04 10:37:36,027] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:32:36.027079+00:00
[2019-10-04 10:37:36,035] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.057 seconds
[2019-10-04 10:37:47,005] {{logging_mixin.py:95}} INFO - [2019-10-04 10:37:47,005] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:37:47,017] {{jobs.py:386}} INFO - Started process (PID=3029) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:37:47,029] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:37:47,033] {{logging_mixin.py:95}} INFO - [2019-10-04 10:37:47,033] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:37:47,534] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:37:53,020] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:37:53,302] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:37:53,313] {{logging_mixin.py:95}} INFO - [2019-10-04 10:37:53,313] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:37:53,314] {{logging_mixin.py:95}} INFO - [2019-10-04 10:37:53,314] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:32:53.314373+00:00
[2019-10-04 10:37:53,323] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 6.306 seconds
[2019-10-04 10:38:04,772] {{logging_mixin.py:95}} INFO - [2019-10-04 10:38:04,772] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:38:04,814] {{jobs.py:386}} INFO - Started process (PID=3033) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:38:04,834] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:38:04,836] {{logging_mixin.py:95}} INFO - [2019-10-04 10:38:04,836] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:38:04,911] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:38:05,141] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:38:05,147] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:38:05,155] {{logging_mixin.py:95}} INFO - [2019-10-04 10:38:05,155] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:38:05,157] {{logging_mixin.py:95}} INFO - [2019-10-04 10:38:05,156] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:33:05.156720+00:00
[2019-10-04 10:38:05,164] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.350 seconds
[2019-10-04 10:38:17,038] {{logging_mixin.py:95}} INFO - [2019-10-04 10:38:17,038] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:38:17,081] {{jobs.py:386}} INFO - Started process (PID=3037) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:38:17,436] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:38:17,437] {{logging_mixin.py:95}} INFO - [2019-10-04 10:38:17,437] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:38:19,135] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:38:32,463] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:38:32,614] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:38:32,623] {{logging_mixin.py:95}} INFO - [2019-10-04 10:38:32,623] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:38:32,624] {{logging_mixin.py:95}} INFO - [2019-10-04 10:38:32,624] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:33:32.624100+00:00
[2019-10-04 10:38:33,717] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 16.636 seconds
[2019-10-04 10:38:47,932] {{logging_mixin.py:95}} INFO - [2019-10-04 10:38:47,932] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:38:48,145] {{jobs.py:386}} INFO - Started process (PID=3046) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:38:49,352] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:38:49,353] {{logging_mixin.py:95}} INFO - [2019-10-04 10:38:49,353] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:38:52,276] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:39:01,226] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:39:01,237] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:39:01,247] {{logging_mixin.py:95}} INFO - [2019-10-04 10:39:01,247] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:39:01,248] {{logging_mixin.py:95}} INFO - [2019-10-04 10:39:01,248] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:34:01.248419+00:00
[2019-10-04 10:39:02,266] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 14.121 seconds
[2019-10-04 10:39:16,401] {{logging_mixin.py:95}} INFO - [2019-10-04 10:39:16,372] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:39:16,827] {{jobs.py:386}} INFO - Started process (PID=3050) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:39:17,394] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:39:17,396] {{logging_mixin.py:95}} INFO - [2019-10-04 10:39:17,395] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:39:21,368] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:39:35,390] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:39:36,889] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:39:36,898] {{logging_mixin.py:95}} INFO - [2019-10-04 10:39:36,898] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:39:36,900] {{logging_mixin.py:95}} INFO - [2019-10-04 10:39:36,899] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:34:36.899818+00:00
[2019-10-04 10:39:38,215] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 21.389 seconds
[2019-10-04 10:39:50,698] {{logging_mixin.py:95}} INFO - [2019-10-04 10:39:50,698] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:39:50,734] {{jobs.py:386}} INFO - Started process (PID=3060) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:39:51,233] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:39:51,235] {{logging_mixin.py:95}} INFO - [2019-10-04 10:39:51,235] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:39:52,081] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:39:55,188] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:39:55,193] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:39:55,204] {{logging_mixin.py:95}} INFO - [2019-10-04 10:39:55,204] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:39:55,205] {{logging_mixin.py:95}} INFO - [2019-10-04 10:39:55,204] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:34:55.204765+00:00
[2019-10-04 10:39:55,215] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.481 seconds
[2019-10-04 10:40:06,066] {{logging_mixin.py:95}} INFO - [2019-10-04 10:40:06,065] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:40:06,069] {{jobs.py:386}} INFO - Started process (PID=3064) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:40:06,072] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:40:06,074] {{logging_mixin.py:95}} INFO - [2019-10-04 10:40:06,074] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:40:06,106] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:40:06,366] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:40:06,378] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:40:06,387] {{logging_mixin.py:95}} INFO - [2019-10-04 10:40:06,387] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:40:06,388] {{logging_mixin.py:95}} INFO - [2019-10-04 10:40:06,387] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:35:06.387796+00:00
[2019-10-04 10:40:06,395] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.325 seconds
[2019-10-04 10:40:17,230] {{logging_mixin.py:95}} INFO - [2019-10-04 10:40:17,230] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:40:17,243] {{jobs.py:386}} INFO - Started process (PID=3068) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:40:17,255] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:40:17,258] {{logging_mixin.py:95}} INFO - [2019-10-04 10:40:17,258] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:40:17,331] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:40:17,582] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:40:17,592] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:40:17,607] {{logging_mixin.py:95}} INFO - [2019-10-04 10:40:17,607] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:40:17,609] {{logging_mixin.py:95}} INFO - [2019-10-04 10:40:17,608] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:35:17.608696+00:00
[2019-10-04 10:40:17,622] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.382 seconds
[2019-10-04 10:40:29,074] {{logging_mixin.py:95}} INFO - [2019-10-04 10:40:29,073] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:40:29,100] {{jobs.py:386}} INFO - Started process (PID=3078) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:40:29,849] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:40:29,850] {{logging_mixin.py:95}} INFO - [2019-10-04 10:40:29,850] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:40:30,378] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:40:32,958] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:40:33,068] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:40:33,077] {{logging_mixin.py:95}} INFO - [2019-10-04 10:40:33,077] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:40:33,078] {{logging_mixin.py:95}} INFO - [2019-10-04 10:40:33,077] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:35:33.077921+00:00
[2019-10-04 10:40:33,085] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.985 seconds
[2019-10-04 10:40:44,225] {{logging_mixin.py:95}} INFO - [2019-10-04 10:40:44,224] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:40:44,230] {{jobs.py:386}} INFO - Started process (PID=3082) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:40:44,236] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:40:44,238] {{logging_mixin.py:95}} INFO - [2019-10-04 10:40:44,237] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:40:44,274] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:40:44,380] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:40:44,394] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:40:44,406] {{logging_mixin.py:95}} INFO - [2019-10-04 10:40:44,406] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:40:44,407] {{logging_mixin.py:95}} INFO - [2019-10-04 10:40:44,407] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:35:44.407354+00:00
[2019-10-04 10:40:44,414] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.184 seconds
[2019-10-04 10:40:56,106] {{logging_mixin.py:95}} INFO - [2019-10-04 10:40:56,106] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:40:56,113] {{jobs.py:386}} INFO - Started process (PID=3086) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:40:56,122] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:40:56,123] {{logging_mixin.py:95}} INFO - [2019-10-04 10:40:56,123] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:40:56,187] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:40:56,641] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:40:56,768] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:40:56,783] {{logging_mixin.py:95}} INFO - [2019-10-04 10:40:56,782] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:40:56,785] {{logging_mixin.py:95}} INFO - [2019-10-04 10:40:56,784] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:35:56.784232+00:00
[2019-10-04 10:40:56,799] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.686 seconds
[2019-10-04 10:41:08,347] {{logging_mixin.py:95}} INFO - [2019-10-04 10:41:08,315] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:41:08,367] {{jobs.py:386}} INFO - Started process (PID=3090) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:41:08,921] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:41:08,922] {{logging_mixin.py:95}} INFO - [2019-10-04 10:41:08,922] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:41:10,010] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:41:21,440] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:41:21,684] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:41:21,722] {{logging_mixin.py:95}} INFO - [2019-10-04 10:41:21,722] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:41:21,723] {{logging_mixin.py:95}} INFO - [2019-10-04 10:41:21,723] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:36:21.722980+00:00
[2019-10-04 10:41:21,842] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 13.475 seconds
[2019-10-04 10:41:34,684] {{logging_mixin.py:95}} INFO - [2019-10-04 10:41:34,683] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:41:34,830] {{jobs.py:386}} INFO - Started process (PID=3099) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:41:35,032] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:41:35,033] {{logging_mixin.py:95}} INFO - [2019-10-04 10:41:35,033] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:41:36,321] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:41:57,205] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 10:42:15,017] {{logging_mixin.py:95}} INFO - [2019-10-04 10:42:15,017] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:42:15,186] {{jobs.py:386}} INFO - Started process (PID=3101) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:42:17,451] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:42:17,452] {{logging_mixin.py:95}} INFO - [2019-10-04 10:42:17,452] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:42:20,733] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:42:37,030] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:42:38,032] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:42:38,050] {{logging_mixin.py:95}} INFO - [2019-10-04 10:42:38,050] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:42:38,052] {{logging_mixin.py:95}} INFO - [2019-10-04 10:42:38,051] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:37:38.051869+00:00
[2019-10-04 10:42:38,605] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 23.419 seconds
[2019-10-04 10:42:52,744] {{logging_mixin.py:95}} INFO - [2019-10-04 10:42:52,358] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:42:53,452] {{jobs.py:386}} INFO - Started process (PID=3105) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:42:54,286] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:42:54,289] {{logging_mixin.py:95}} INFO - [2019-10-04 10:42:54,289] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:42:57,997] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:43:07,809] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:43:09,205] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:43:09,216] {{logging_mixin.py:95}} INFO - [2019-10-04 10:43:09,216] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:43:09,217] {{logging_mixin.py:95}} INFO - [2019-10-04 10:43:09,217] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:38:09.217095+00:00
[2019-10-04 10:43:11,087] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 17.635 seconds
[2019-10-04 10:43:27,451] {{logging_mixin.py:95}} INFO - [2019-10-04 10:43:27,451] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:43:27,734] {{jobs.py:386}} INFO - Started process (PID=3114) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:43:28,065] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:43:28,065] {{logging_mixin.py:95}} INFO - [2019-10-04 10:43:28,065] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:43:30,200] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:43:35,543] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:43:35,553] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:43:35,573] {{logging_mixin.py:95}} INFO - [2019-10-04 10:43:35,573] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:43:35,574] {{logging_mixin.py:95}} INFO - [2019-10-04 10:43:35,573] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:38:35.573943+00:00
[2019-10-04 10:43:35,669] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 7.936 seconds
[2019-10-04 10:43:46,437] {{logging_mixin.py:95}} INFO - [2019-10-04 10:43:46,436] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:43:46,442] {{jobs.py:386}} INFO - Started process (PID=3118) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:43:46,446] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:43:46,454] {{logging_mixin.py:95}} INFO - [2019-10-04 10:43:46,454] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:43:46,496] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:43:46,613] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:43:46,618] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:43:46,626] {{logging_mixin.py:95}} INFO - [2019-10-04 10:43:46,626] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:43:46,628] {{logging_mixin.py:95}} INFO - [2019-10-04 10:43:46,627] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:38:46.627766+00:00
[2019-10-04 10:43:46,637] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.195 seconds
[2019-10-04 10:43:58,213] {{logging_mixin.py:95}} INFO - [2019-10-04 10:43:58,212] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:43:58,332] {{jobs.py:386}} INFO - Started process (PID=3131) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:43:58,417] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:43:58,418] {{logging_mixin.py:95}} INFO - [2019-10-04 10:43:58,418] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:43:58,603] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:43:59,739] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:43:59,749] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:43:59,764] {{logging_mixin.py:95}} INFO - [2019-10-04 10:43:59,764] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:43:59,766] {{logging_mixin.py:95}} INFO - [2019-10-04 10:43:59,765] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:38:59.765847+00:00
[2019-10-04 10:43:59,779] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.446 seconds
[2019-10-04 10:44:11,608] {{logging_mixin.py:95}} INFO - [2019-10-04 10:44:11,607] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:44:11,734] {{jobs.py:386}} INFO - Started process (PID=3135) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:44:11,997] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:44:11,998] {{logging_mixin.py:95}} INFO - [2019-10-04 10:44:11,998] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:44:12,220] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:44:14,982] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:44:15,119] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:44:15,134] {{logging_mixin.py:95}} INFO - [2019-10-04 10:44:15,134] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:44:15,135] {{logging_mixin.py:95}} INFO - [2019-10-04 10:44:15,134] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:39:15.134669+00:00
[2019-10-04 10:44:15,147] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.413 seconds
[2019-10-04 10:44:25,936] {{logging_mixin.py:95}} INFO - [2019-10-04 10:44:25,936] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:44:25,968] {{jobs.py:386}} INFO - Started process (PID=3139) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:44:26,080] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:44:26,081] {{logging_mixin.py:95}} INFO - [2019-10-04 10:44:26,081] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:44:26,358] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:44:30,160] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:44:30,175] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:44:30,205] {{logging_mixin.py:95}} INFO - [2019-10-04 10:44:30,205] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:44:30,207] {{logging_mixin.py:95}} INFO - [2019-10-04 10:44:30,206] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:39:30.206781+00:00
[2019-10-04 10:44:30,222] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.254 seconds
[2019-10-04 10:44:41,485] {{logging_mixin.py:95}} INFO - [2019-10-04 10:44:41,484] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:44:41,489] {{jobs.py:386}} INFO - Started process (PID=3148) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:44:41,493] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:44:41,493] {{logging_mixin.py:95}} INFO - [2019-10-04 10:44:41,493] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:44:41,522] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:44:41,751] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:44:41,758] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:44:41,770] {{logging_mixin.py:95}} INFO - [2019-10-04 10:44:41,770] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:44:41,772] {{logging_mixin.py:95}} INFO - [2019-10-04 10:44:41,771] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:39:41.771793+00:00
[2019-10-04 10:44:41,781] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.293 seconds
[2019-10-04 10:44:53,044] {{logging_mixin.py:95}} INFO - [2019-10-04 10:44:53,044] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:44:53,113] {{jobs.py:386}} INFO - Started process (PID=3152) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:44:53,355] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:44:53,355] {{logging_mixin.py:95}} INFO - [2019-10-04 10:44:53,355] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:44:55,048] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:44:57,799] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:44:57,941] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:44:57,957] {{logging_mixin.py:95}} INFO - [2019-10-04 10:44:57,956] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:44:57,958] {{logging_mixin.py:95}} INFO - [2019-10-04 10:44:57,957] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:39:57.957837+00:00
[2019-10-04 10:44:57,968] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.855 seconds
[2019-10-04 10:45:08,507] {{logging_mixin.py:95}} INFO - [2019-10-04 10:45:08,506] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:45:08,511] {{jobs.py:386}} INFO - Started process (PID=3163) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:45:08,514] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:45:08,515] {{logging_mixin.py:95}} INFO - [2019-10-04 10:45:08,515] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:45:08,565] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:45:13,469] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:45:14,325] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:45:14,342] {{logging_mixin.py:95}} INFO - [2019-10-04 10:45:14,342] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:45:14,345] {{logging_mixin.py:95}} INFO - [2019-10-04 10:45:14,344] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:40:14.344018+00:00
[2019-10-04 10:45:14,399] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.887 seconds
[2019-10-04 10:45:28,580] {{logging_mixin.py:95}} INFO - [2019-10-04 10:45:28,433] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:45:28,729] {{jobs.py:386}} INFO - Started process (PID=3167) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:45:30,335] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:45:30,336] {{logging_mixin.py:95}} INFO - [2019-10-04 10:45:30,336] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:45:35,307] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:45:43,561] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:45:43,723] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:45:43,738] {{logging_mixin.py:95}} INFO - [2019-10-04 10:45:43,738] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:45:43,746] {{logging_mixin.py:95}} INFO - [2019-10-04 10:45:43,745] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:40:43.745825+00:00
[2019-10-04 10:45:44,275] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 15.546 seconds
[2019-10-04 10:45:56,418] {{logging_mixin.py:95}} INFO - [2019-10-04 10:45:56,372] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:45:56,589] {{jobs.py:386}} INFO - Started process (PID=3171) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:45:57,414] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:45:57,415] {{logging_mixin.py:95}} INFO - [2019-10-04 10:45:57,415] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:46:00,332] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:46:17,306] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:46:17,341] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:46:17,360] {{logging_mixin.py:95}} INFO - [2019-10-04 10:46:17,360] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:46:17,362] {{logging_mixin.py:95}} INFO - [2019-10-04 10:46:17,361] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:41:17.361908+00:00
[2019-10-04 10:46:18,419] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 21.830 seconds
[2019-10-04 10:46:30,744] {{logging_mixin.py:95}} INFO - [2019-10-04 10:46:30,743] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:46:30,940] {{jobs.py:386}} INFO - Started process (PID=3184) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:46:31,870] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:46:31,872] {{logging_mixin.py:95}} INFO - [2019-10-04 10:46:31,872] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:46:34,131] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:46:38,978] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:46:38,985] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:46:38,996] {{logging_mixin.py:95}} INFO - [2019-10-04 10:46:38,996] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:46:38,998] {{logging_mixin.py:95}} INFO - [2019-10-04 10:46:38,997] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:41:38.997295+00:00
[2019-10-04 10:46:39,007] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 8.067 seconds
[2019-10-04 10:46:50,872] {{logging_mixin.py:95}} INFO - [2019-10-04 10:46:50,872] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:46:50,877] {{jobs.py:386}} INFO - Started process (PID=3188) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:46:51,007] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:46:51,021] {{logging_mixin.py:95}} INFO - [2019-10-04 10:46:51,021] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:46:51,158] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:46:51,944] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:46:52,182] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:46:52,191] {{logging_mixin.py:95}} INFO - [2019-10-04 10:46:52,190] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:46:52,192] {{logging_mixin.py:95}} INFO - [2019-10-04 10:46:52,191] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:41:52.191854+00:00
[2019-10-04 10:46:52,199] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.322 seconds
[2019-10-04 10:47:03,164] {{logging_mixin.py:95}} INFO - [2019-10-04 10:47:03,163] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:47:03,195] {{jobs.py:386}} INFO - Started process (PID=3198) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:47:03,198] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:47:03,201] {{logging_mixin.py:95}} INFO - [2019-10-04 10:47:03,201] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:47:03,595] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:47:07,121] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:47:07,142] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:47:07,152] {{logging_mixin.py:95}} INFO - [2019-10-04 10:47:07,152] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:47:07,154] {{logging_mixin.py:95}} INFO - [2019-10-04 10:47:07,153] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:42:07.153705+00:00
[2019-10-04 10:47:07,162] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.967 seconds
[2019-10-04 10:47:17,956] {{logging_mixin.py:95}} INFO - [2019-10-04 10:47:17,956] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:47:18,015] {{jobs.py:386}} INFO - Started process (PID=3202) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:47:18,385] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:47:18,387] {{logging_mixin.py:95}} INFO - [2019-10-04 10:47:18,387] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:47:18,785] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:47:19,643] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:47:19,648] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:47:19,657] {{logging_mixin.py:95}} INFO - [2019-10-04 10:47:19,656] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:47:19,658] {{logging_mixin.py:95}} INFO - [2019-10-04 10:47:19,657] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:42:19.657865+00:00
[2019-10-04 10:47:19,666] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.651 seconds
[2019-10-04 10:47:31,458] {{logging_mixin.py:95}} INFO - [2019-10-04 10:47:31,458] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:47:31,462] {{jobs.py:386}} INFO - Started process (PID=3208) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:47:31,465] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:47:31,466] {{logging_mixin.py:95}} INFO - [2019-10-04 10:47:31,465] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:47:31,482] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:47:31,619] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:47:31,653] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:47:31,661] {{logging_mixin.py:95}} INFO - [2019-10-04 10:47:31,660] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:47:31,662] {{logging_mixin.py:95}} INFO - [2019-10-04 10:47:31,661] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:42:31.661798+00:00
[2019-10-04 10:47:31,669] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.207 seconds
[2019-10-04 10:47:42,943] {{logging_mixin.py:95}} INFO - [2019-10-04 10:47:42,942] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:47:42,947] {{jobs.py:386}} INFO - Started process (PID=3211) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:47:42,950] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:47:42,951] {{logging_mixin.py:95}} INFO - [2019-10-04 10:47:42,951] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:47:44,489] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:47:48,442] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:47:48,583] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:47:48,592] {{logging_mixin.py:95}} INFO - [2019-10-04 10:47:48,592] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:47:48,594] {{logging_mixin.py:95}} INFO - [2019-10-04 10:47:48,593] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:42:48.593545+00:00
[2019-10-04 10:47:48,717] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.770 seconds
[2019-10-04 10:47:59,621] {{logging_mixin.py:95}} INFO - [2019-10-04 10:47:59,621] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:47:59,625] {{jobs.py:386}} INFO - Started process (PID=3219) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:47:59,629] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:47:59,631] {{logging_mixin.py:95}} INFO - [2019-10-04 10:47:59,631] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:47:59,662] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:48:00,002] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:48:00,016] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:48:00,033] {{logging_mixin.py:95}} INFO - [2019-10-04 10:48:00,033] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:48:00,035] {{logging_mixin.py:95}} INFO - [2019-10-04 10:48:00,034] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:43:00.034809+00:00
[2019-10-04 10:48:00,047] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.422 seconds
[2019-10-04 10:48:11,407] {{logging_mixin.py:95}} INFO - [2019-10-04 10:48:11,407] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:48:11,505] {{jobs.py:386}} INFO - Started process (PID=3223) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:48:12,020] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:48:12,023] {{logging_mixin.py:95}} INFO - [2019-10-04 10:48:12,023] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:48:12,869] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:48:16,576] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:48:16,582] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:48:16,596] {{logging_mixin.py:95}} INFO - [2019-10-04 10:48:16,596] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:48:16,597] {{logging_mixin.py:95}} INFO - [2019-10-04 10:48:16,597] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:43:16.597001+00:00
[2019-10-04 10:48:16,682] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.178 seconds
[2019-10-04 10:48:28,345] {{logging_mixin.py:95}} INFO - [2019-10-04 10:48:28,288] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:48:28,440] {{jobs.py:386}} INFO - Started process (PID=3227) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:48:28,605] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:48:28,606] {{logging_mixin.py:95}} INFO - [2019-10-04 10:48:28,606] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:48:30,075] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:48:58,272] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:48:58,590] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:48:58,605] {{logging_mixin.py:95}} INFO - [2019-10-04 10:48:58,605] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:48:58,607] {{logging_mixin.py:95}} INFO - [2019-10-04 10:48:58,606] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:43:58.606569+00:00
[2019-10-04 10:48:59,155] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 30.715 seconds
[2019-10-04 10:49:11,057] {{logging_mixin.py:95}} INFO - [2019-10-04 10:49:11,057] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:49:11,137] {{jobs.py:386}} INFO - Started process (PID=3236) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:49:12,101] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:49:12,115] {{logging_mixin.py:95}} INFO - [2019-10-04 10:49:12,114] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:49:13,206] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:49:31,149] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:49:32,672] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:49:32,690] {{logging_mixin.py:95}} INFO - [2019-10-04 10:49:32,690] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:49:32,693] {{logging_mixin.py:95}} INFO - [2019-10-04 10:49:32,692] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:44:32.692164+00:00
[2019-10-04 10:49:34,048] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 22.910 seconds
[2019-10-04 10:49:50,568] {{logging_mixin.py:95}} INFO - [2019-10-04 10:49:50,533] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:49:50,909] {{jobs.py:386}} INFO - Started process (PID=3240) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:49:52,020] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:49:52,021] {{logging_mixin.py:95}} INFO - [2019-10-04 10:49:52,021] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:49:55,396] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:50:06,312] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:50:06,318] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:50:06,327] {{logging_mixin.py:95}} INFO - [2019-10-04 10:50:06,327] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:50:06,329] {{logging_mixin.py:95}} INFO - [2019-10-04 10:50:06,328] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:45:06.328782+00:00
[2019-10-04 10:50:07,296] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 16.387 seconds
[2019-10-04 10:50:19,413] {{logging_mixin.py:95}} INFO - [2019-10-04 10:50:19,413] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:50:19,478] {{jobs.py:386}} INFO - Started process (PID=3250) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:50:19,638] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:50:19,639] {{logging_mixin.py:95}} INFO - [2019-10-04 10:50:19,639] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:50:20,313] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:50:21,162] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:50:21,175] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:50:21,191] {{logging_mixin.py:95}} INFO - [2019-10-04 10:50:21,191] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:50:21,193] {{logging_mixin.py:95}} INFO - [2019-10-04 10:50:21,192] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:45:21.192587+00:00
[2019-10-04 10:50:21,207] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.729 seconds
[2019-10-04 10:50:33,086] {{logging_mixin.py:95}} INFO - [2019-10-04 10:50:33,086] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:50:33,096] {{jobs.py:386}} INFO - Started process (PID=3254) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:50:33,134] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:50:33,138] {{logging_mixin.py:95}} INFO - [2019-10-04 10:50:33,137] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:50:33,155] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:50:33,518] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:50:33,525] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:50:33,551] {{logging_mixin.py:95}} INFO - [2019-10-04 10:50:33,551] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:50:33,552] {{logging_mixin.py:95}} INFO - [2019-10-04 10:50:33,551] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:45:33.551846+00:00
[2019-10-04 10:50:33,559] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.463 seconds
[2019-10-04 10:50:44,477] {{logging_mixin.py:95}} INFO - [2019-10-04 10:50:44,477] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:50:44,487] {{jobs.py:386}} INFO - Started process (PID=3258) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:50:44,528] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:50:44,532] {{logging_mixin.py:95}} INFO - [2019-10-04 10:50:44,532] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:50:44,560] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:50:44,850] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:50:44,865] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:50:44,877] {{logging_mixin.py:95}} INFO - [2019-10-04 10:50:44,877] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:50:44,880] {{logging_mixin.py:95}} INFO - [2019-10-04 10:50:44,877] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:45:44.877935+00:00
[2019-10-04 10:50:44,906] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.418 seconds
[2019-10-04 10:50:56,923] {{logging_mixin.py:95}} INFO - [2019-10-04 10:50:56,639] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:50:57,139] {{jobs.py:386}} INFO - Started process (PID=3270) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:50:57,529] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:50:57,532] {{logging_mixin.py:95}} INFO - [2019-10-04 10:50:57,531] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:50:58,510] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:51:01,471] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:51:01,591] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:51:01,601] {{logging_mixin.py:95}} INFO - [2019-10-04 10:51:01,601] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:51:01,603] {{logging_mixin.py:95}} INFO - [2019-10-04 10:51:01,602] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:46:01.602593+00:00
[2019-10-04 10:51:01,612] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.473 seconds
[2019-10-04 10:51:12,872] {{logging_mixin.py:95}} INFO - [2019-10-04 10:51:12,872] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:51:12,876] {{jobs.py:386}} INFO - Started process (PID=3274) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:51:12,881] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:51:12,883] {{logging_mixin.py:95}} INFO - [2019-10-04 10:51:12,882] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:51:12,925] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:51:13,140] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:51:13,147] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:51:13,157] {{logging_mixin.py:95}} INFO - [2019-10-04 10:51:13,157] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:51:13,159] {{logging_mixin.py:95}} INFO - [2019-10-04 10:51:13,158] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:46:13.158806+00:00
[2019-10-04 10:51:13,171] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.295 seconds
[2019-10-04 10:51:24,210] {{logging_mixin.py:95}} INFO - [2019-10-04 10:51:24,209] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:51:24,214] {{jobs.py:386}} INFO - Started process (PID=3278) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:51:24,217] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:51:24,218] {{logging_mixin.py:95}} INFO - [2019-10-04 10:51:24,218] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:51:24,250] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:51:24,566] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:51:24,571] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:51:24,582] {{logging_mixin.py:95}} INFO - [2019-10-04 10:51:24,582] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:51:24,583] {{logging_mixin.py:95}} INFO - [2019-10-04 10:51:24,583] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:46:24.582980+00:00
[2019-10-04 10:51:24,590] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.376 seconds
[2019-10-04 10:51:35,778] {{logging_mixin.py:95}} INFO - [2019-10-04 10:51:35,777] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:51:35,847] {{jobs.py:386}} INFO - Started process (PID=3282) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:51:36,037] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:51:36,038] {{logging_mixin.py:95}} INFO - [2019-10-04 10:51:36,038] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:51:36,217] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:51:37,314] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:51:37,360] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:51:37,372] {{logging_mixin.py:95}} INFO - [2019-10-04 10:51:37,372] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:51:37,374] {{logging_mixin.py:95}} INFO - [2019-10-04 10:51:37,373] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:46:37.373116+00:00
[2019-10-04 10:51:37,384] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.537 seconds
[2019-10-04 10:51:49,678] {{logging_mixin.py:95}} INFO - [2019-10-04 10:51:49,678] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:51:49,717] {{jobs.py:386}} INFO - Started process (PID=3291) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:51:50,117] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:51:50,118] {{logging_mixin.py:95}} INFO - [2019-10-04 10:51:50,118] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:51:52,049] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:51:57,652] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:51:57,717] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:51:57,888] {{logging_mixin.py:95}} INFO - [2019-10-04 10:51:57,888] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:51:57,890] {{logging_mixin.py:95}} INFO - [2019-10-04 10:51:57,889] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:46:57.889270+00:00
[2019-10-04 10:51:57,900] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 8.183 seconds
[2019-10-04 10:52:09,386] {{logging_mixin.py:95}} INFO - [2019-10-04 10:52:09,385] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:52:09,463] {{jobs.py:386}} INFO - Started process (PID=3295) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:52:10,275] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:52:10,276] {{logging_mixin.py:95}} INFO - [2019-10-04 10:52:10,276] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:52:11,324] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:52:17,001] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:52:17,212] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:52:17,220] {{logging_mixin.py:95}} INFO - [2019-10-04 10:52:17,220] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:52:17,221] {{logging_mixin.py:95}} INFO - [2019-10-04 10:52:17,221] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:47:17.221154+00:00
[2019-10-04 10:52:17,380] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 7.917 seconds
[2019-10-04 10:52:28,684] {{logging_mixin.py:95}} INFO - [2019-10-04 10:52:28,668] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:52:28,825] {{jobs.py:386}} INFO - Started process (PID=3304) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:52:29,176] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:52:29,177] {{logging_mixin.py:95}} INFO - [2019-10-04 10:52:29,177] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:52:30,149] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:52:45,581] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 10:53:05,986] {{logging_mixin.py:95}} INFO - [2019-10-04 10:53:05,986] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:53:06,566] {{jobs.py:386}} INFO - Started process (PID=3311) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:53:07,535] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:53:07,567] {{logging_mixin.py:95}} INFO - [2019-10-04 10:53:07,566] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:53:10,412] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:53:32,042] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 10:53:56,356] {{logging_mixin.py:95}} INFO - [2019-10-04 10:53:56,356] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:53:56,907] {{jobs.py:386}} INFO - Started process (PID=3313) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:53:57,928] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:53:57,930] {{logging_mixin.py:95}} INFO - [2019-10-04 10:53:57,930] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:54:00,398] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:54:16,467] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:54:16,615] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:54:16,638] {{logging_mixin.py:95}} INFO - [2019-10-04 10:54:16,638] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:54:16,639] {{logging_mixin.py:95}} INFO - [2019-10-04 10:54:16,639] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:49:16.639004+00:00
[2019-10-04 10:54:19,635] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 22.729 seconds
[2019-10-04 10:54:34,041] {{logging_mixin.py:95}} INFO - [2019-10-04 10:54:34,040] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:54:34,447] {{jobs.py:386}} INFO - Started process (PID=3322) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:54:35,023] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:54:35,028] {{logging_mixin.py:95}} INFO - [2019-10-04 10:54:35,028] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:54:37,067] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:54:40,688] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:54:40,693] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:54:40,704] {{logging_mixin.py:95}} INFO - [2019-10-04 10:54:40,703] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:54:40,705] {{logging_mixin.py:95}} INFO - [2019-10-04 10:54:40,704] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:49:40.704809+00:00
[2019-10-04 10:54:40,711] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 6.265 seconds
[2019-10-04 10:54:52,235] {{logging_mixin.py:95}} INFO - [2019-10-04 10:54:52,235] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:54:52,239] {{jobs.py:386}} INFO - Started process (PID=3328) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:54:52,243] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:54:52,244] {{logging_mixin.py:95}} INFO - [2019-10-04 10:54:52,243] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:54:52,275] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:54:52,555] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:54:52,562] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:54:52,572] {{logging_mixin.py:95}} INFO - [2019-10-04 10:54:52,571] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:54:52,573] {{logging_mixin.py:95}} INFO - [2019-10-04 10:54:52,572] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:49:52.572291+00:00
[2019-10-04 10:54:52,581] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.341 seconds
[2019-10-04 10:55:03,755] {{logging_mixin.py:95}} INFO - [2019-10-04 10:55:03,755] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:55:03,781] {{jobs.py:386}} INFO - Started process (PID=3331) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:55:03,783] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:55:03,784] {{logging_mixin.py:95}} INFO - [2019-10-04 10:55:03,784] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:55:03,853] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:55:06,158] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:55:06,240] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:55:06,257] {{logging_mixin.py:95}} INFO - [2019-10-04 10:55:06,257] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:55:06,259] {{logging_mixin.py:95}} INFO - [2019-10-04 10:55:06,258] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:50:06.258189+00:00
[2019-10-04 10:55:06,343] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.563 seconds
[2019-10-04 10:55:17,593] {{logging_mixin.py:95}} INFO - [2019-10-04 10:55:17,593] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:55:17,599] {{jobs.py:386}} INFO - Started process (PID=3339) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:55:17,613] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:55:17,615] {{logging_mixin.py:95}} INFO - [2019-10-04 10:55:17,615] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:55:17,843] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:55:19,931] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:55:19,996] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:55:20,004] {{logging_mixin.py:95}} INFO - [2019-10-04 10:55:20,004] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:55:20,005] {{logging_mixin.py:95}} INFO - [2019-10-04 10:55:20,004] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:50:20.004879+00:00
[2019-10-04 10:55:20,012] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.413 seconds
[2019-10-04 10:55:32,051] {{logging_mixin.py:95}} INFO - [2019-10-04 10:55:31,949] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:55:32,252] {{jobs.py:386}} INFO - Started process (PID=3343) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:55:32,945] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:55:32,947] {{logging_mixin.py:95}} INFO - [2019-10-04 10:55:32,947] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:55:33,964] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:55:35,449] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:55:35,463] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:55:35,570] {{logging_mixin.py:95}} INFO - [2019-10-04 10:55:35,570] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:55:35,571] {{logging_mixin.py:95}} INFO - [2019-10-04 10:55:35,570] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:50:35.570518+00:00
[2019-10-04 10:55:35,579] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.327 seconds
[2019-10-04 10:55:46,957] {{logging_mixin.py:95}} INFO - [2019-10-04 10:55:46,956] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:55:46,968] {{jobs.py:386}} INFO - Started process (PID=3352) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:55:46,985] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:55:46,986] {{logging_mixin.py:95}} INFO - [2019-10-04 10:55:46,986] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:55:47,139] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:55:47,873] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:55:47,882] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:55:47,893] {{logging_mixin.py:95}} INFO - [2019-10-04 10:55:47,893] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:55:47,895] {{logging_mixin.py:95}} INFO - [2019-10-04 10:55:47,894] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:50:47.894495+00:00
[2019-10-04 10:55:47,902] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.935 seconds
[2019-10-04 10:56:04,624] {{logging_mixin.py:95}} INFO - [2019-10-04 10:56:04,624] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 10:56:04,643] {{jobs.py:386}} INFO - Started process (PID=3356) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:56:04,656] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 10:56:04,657] {{logging_mixin.py:95}} INFO - [2019-10-04 10:56:04,657] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:56:04,695] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 10:56:07,558] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 10:56:07,636] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 10:56:07,843] {{logging_mixin.py:95}} INFO - [2019-10-04 10:56:07,843] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 10:56:08,504] {{logging_mixin.py:95}} INFO - [2019-10-04 10:56:08,503] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 10:51:08.503867+00:00
[2019-10-04 10:56:08,627] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.984 seconds
[2019-10-04 16:41:35,281] {{logging_mixin.py:95}} INFO - [2019-10-04 16:41:35,281] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:41:35,285] {{jobs.py:386}} INFO - Started process (PID=3368) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:41:35,289] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:41:35,290] {{logging_mixin.py:95}} INFO - [2019-10-04 16:41:35,290] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:41:35,328] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:41:38,138] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:41:38,152] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:41:38,180] {{logging_mixin.py:95}} INFO - [2019-10-04 16:41:38,180] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:41:38,181] {{logging_mixin.py:95}} INFO - [2019-10-04 16:41:38,180] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:36:38.180546+00:00
[2019-10-04 16:41:38,199] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.914 seconds
[2019-10-04 16:41:48,329] {{logging_mixin.py:95}} INFO - [2019-10-04 16:41:48,329] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:41:48,332] {{jobs.py:386}} INFO - Started process (PID=3372) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:41:48,334] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:41:48,335] {{logging_mixin.py:95}} INFO - [2019-10-04 16:41:48,335] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:41:48,359] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:41:48,697] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:41:48,702] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:41:48,711] {{logging_mixin.py:95}} INFO - [2019-10-04 16:41:48,711] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:41:48,712] {{logging_mixin.py:95}} INFO - [2019-10-04 16:41:48,711] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:36:48.711924+00:00
[2019-10-04 16:41:48,719] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.387 seconds
[2019-10-04 16:42:01,435] {{logging_mixin.py:95}} INFO - [2019-10-04 16:42:01,435] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:42:01,438] {{jobs.py:386}} INFO - Started process (PID=3376) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:42:02,432] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:42:02,433] {{logging_mixin.py:95}} INFO - [2019-10-04 16:42:02,433] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:42:03,088] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:42:06,631] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:42:06,752] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:42:06,919] {{logging_mixin.py:95}} INFO - [2019-10-04 16:42:06,919] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:42:06,920] {{logging_mixin.py:95}} INFO - [2019-10-04 16:42:06,920] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:37:06.920238+00:00
[2019-10-04 16:42:07,119] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.681 seconds
[2019-10-04 16:42:20,248] {{logging_mixin.py:95}} INFO - [2019-10-04 16:42:20,247] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:42:21,167] {{jobs.py:386}} INFO - Started process (PID=3380) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:42:21,369] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:42:21,370] {{logging_mixin.py:95}} INFO - [2019-10-04 16:42:21,370] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:42:22,065] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:42:24,879] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:42:24,884] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:42:24,893] {{logging_mixin.py:95}} INFO - [2019-10-04 16:42:24,893] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:42:24,894] {{logging_mixin.py:95}} INFO - [2019-10-04 16:42:24,893] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:37:24.893560+00:00
[2019-10-04 16:42:24,901] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.734 seconds
[2019-10-04 16:42:35,973] {{logging_mixin.py:95}} INFO - [2019-10-04 16:42:35,972] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:42:35,978] {{jobs.py:386}} INFO - Started process (PID=3389) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:42:35,986] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:42:35,987] {{logging_mixin.py:95}} INFO - [2019-10-04 16:42:35,987] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:42:36,011] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:42:36,204] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:42:36,209] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:42:36,216] {{logging_mixin.py:95}} INFO - [2019-10-04 16:42:36,216] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:42:36,217] {{logging_mixin.py:95}} INFO - [2019-10-04 16:42:36,217] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:37:36.217061+00:00
[2019-10-04 16:42:36,225] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.247 seconds
[2019-10-04 16:42:47,393] {{logging_mixin.py:95}} INFO - [2019-10-04 16:42:47,393] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:42:47,397] {{jobs.py:386}} INFO - Started process (PID=3393) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:42:47,400] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:42:47,402] {{logging_mixin.py:95}} INFO - [2019-10-04 16:42:47,401] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:42:47,433] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:42:48,487] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:42:48,492] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:42:48,503] {{logging_mixin.py:95}} INFO - [2019-10-04 16:42:48,503] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:42:48,505] {{logging_mixin.py:95}} INFO - [2019-10-04 16:42:48,504] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:37:48.504176+00:00
[2019-10-04 16:42:48,512] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.115 seconds
[2019-10-04 16:42:59,253] {{logging_mixin.py:95}} INFO - [2019-10-04 16:42:59,253] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:42:59,259] {{jobs.py:386}} INFO - Started process (PID=3403) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:42:59,272] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:42:59,272] {{logging_mixin.py:95}} INFO - [2019-10-04 16:42:59,272] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:42:59,398] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:42:59,732] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:42:59,738] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:42:59,748] {{logging_mixin.py:95}} INFO - [2019-10-04 16:42:59,748] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:42:59,749] {{logging_mixin.py:95}} INFO - [2019-10-04 16:42:59,748] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:37:59.748735+00:00
[2019-10-04 16:42:59,758] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.500 seconds
[2019-10-04 16:43:10,824] {{logging_mixin.py:95}} INFO - [2019-10-04 16:43:10,824] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:43:10,861] {{jobs.py:386}} INFO - Started process (PID=3407) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:43:10,926] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:43:10,928] {{logging_mixin.py:95}} INFO - [2019-10-04 16:43:10,928] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:43:11,708] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:43:12,231] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:43:12,243] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:43:12,258] {{logging_mixin.py:95}} INFO - [2019-10-04 16:43:12,258] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:43:12,261] {{logging_mixin.py:95}} INFO - [2019-10-04 16:43:12,260] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:38:12.260289+00:00
[2019-10-04 16:43:12,342] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.481 seconds
[2019-10-04 16:43:23,248] {{logging_mixin.py:95}} INFO - [2019-10-04 16:43:23,248] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:43:23,251] {{jobs.py:386}} INFO - Started process (PID=3411) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:43:23,255] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:43:23,256] {{logging_mixin.py:95}} INFO - [2019-10-04 16:43:23,256] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:43:23,270] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:43:23,512] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:43:23,519] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:43:23,530] {{logging_mixin.py:95}} INFO - [2019-10-04 16:43:23,530] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:43:23,533] {{logging_mixin.py:95}} INFO - [2019-10-04 16:43:23,532] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:38:23.532165+00:00
[2019-10-04 16:43:23,546] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.295 seconds
[2019-10-04 16:43:34,680] {{logging_mixin.py:95}} INFO - [2019-10-04 16:43:34,676] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:43:34,693] {{jobs.py:386}} INFO - Started process (PID=3420) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:43:34,701] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:43:34,705] {{logging_mixin.py:95}} INFO - [2019-10-04 16:43:34,705] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:43:34,889] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:43:35,444] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:43:35,453] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:43:35,465] {{logging_mixin.py:95}} INFO - [2019-10-04 16:43:35,465] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:43:35,467] {{logging_mixin.py:95}} INFO - [2019-10-04 16:43:35,466] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:38:35.466143+00:00
[2019-10-04 16:43:35,478] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.785 seconds
[2019-10-04 16:43:46,185] {{logging_mixin.py:95}} INFO - [2019-10-04 16:43:46,185] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:43:46,189] {{jobs.py:386}} INFO - Started process (PID=3424) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:43:46,195] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:43:46,204] {{logging_mixin.py:95}} INFO - [2019-10-04 16:43:46,204] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:43:46,235] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:43:48,033] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:43:48,045] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:43:48,057] {{logging_mixin.py:95}} INFO - [2019-10-04 16:43:48,057] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:43:48,059] {{logging_mixin.py:95}} INFO - [2019-10-04 16:43:48,058] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:38:48.058621+00:00
[2019-10-04 16:43:48,069] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.880 seconds
[2019-10-04 16:44:00,021] {{logging_mixin.py:95}} INFO - [2019-10-04 16:44:00,021] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:44:00,121] {{jobs.py:386}} INFO - Started process (PID=3428) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:44:00,360] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:44:00,362] {{logging_mixin.py:95}} INFO - [2019-10-04 16:44:00,362] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:44:02,552] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:44:10,558] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:44:10,730] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:44:10,876] {{logging_mixin.py:95}} INFO - [2019-10-04 16:44:10,876] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:44:10,878] {{logging_mixin.py:95}} INFO - [2019-10-04 16:44:10,877] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:39:10.877308+00:00
[2019-10-04 16:44:10,893] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 10.772 seconds
[2019-10-04 16:44:22,606] {{logging_mixin.py:95}} INFO - [2019-10-04 16:44:22,606] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:44:22,631] {{jobs.py:386}} INFO - Started process (PID=3438) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:44:22,643] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:44:22,644] {{logging_mixin.py:95}} INFO - [2019-10-04 16:44:22,644] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:44:22,682] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:44:23,439] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:44:23,647] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:44:23,733] {{logging_mixin.py:95}} INFO - [2019-10-04 16:44:23,733] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:44:23,737] {{logging_mixin.py:95}} INFO - [2019-10-04 16:44:23,735] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:39:23.735426+00:00
[2019-10-04 16:44:23,763] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.132 seconds
[2019-10-04 16:44:35,303] {{logging_mixin.py:95}} INFO - [2019-10-04 16:44:35,302] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:44:35,581] {{jobs.py:386}} INFO - Started process (PID=3443) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:44:35,659] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:44:35,660] {{logging_mixin.py:95}} INFO - [2019-10-04 16:44:35,660] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:44:36,386] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:44:38,466] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:44:38,480] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:44:38,491] {{logging_mixin.py:95}} INFO - [2019-10-04 16:44:38,491] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:44:38,493] {{logging_mixin.py:95}} INFO - [2019-10-04 16:44:38,492] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:39:38.492751+00:00
[2019-10-04 16:44:38,503] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.922 seconds
[2019-10-04 16:44:50,173] {{logging_mixin.py:95}} INFO - [2019-10-04 16:44:50,172] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:44:50,183] {{jobs.py:386}} INFO - Started process (PID=3452) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:44:50,188] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:44:50,189] {{logging_mixin.py:95}} INFO - [2019-10-04 16:44:50,189] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:44:50,233] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:44:50,711] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:44:50,725] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:44:50,742] {{logging_mixin.py:95}} INFO - [2019-10-04 16:44:50,742] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:44:50,743] {{logging_mixin.py:95}} INFO - [2019-10-04 16:44:50,743] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:39:50.743110+00:00
[2019-10-04 16:44:50,753] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.570 seconds
[2019-10-04 16:45:01,512] {{logging_mixin.py:95}} INFO - [2019-10-04 16:45:01,511] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:45:01,523] {{jobs.py:386}} INFO - Started process (PID=3456) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:45:01,535] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:45:01,538] {{logging_mixin.py:95}} INFO - [2019-10-04 16:45:01,538] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:45:01,727] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:45:02,170] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:45:02,176] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:45:02,264] {{logging_mixin.py:95}} INFO - [2019-10-04 16:45:02,263] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:45:02,266] {{logging_mixin.py:95}} INFO - [2019-10-04 16:45:02,265] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:40:02.265400+00:00
[2019-10-04 16:45:02,281] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.758 seconds
[2019-10-04 16:45:12,915] {{logging_mixin.py:95}} INFO - [2019-10-04 16:45:12,914] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:45:12,919] {{jobs.py:386}} INFO - Started process (PID=3460) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:45:12,937] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:45:12,938] {{logging_mixin.py:95}} INFO - [2019-10-04 16:45:12,938] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:45:12,991] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:45:13,944] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:45:13,955] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:45:13,974] {{logging_mixin.py:95}} INFO - [2019-10-04 16:45:13,974] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:45:13,977] {{logging_mixin.py:95}} INFO - [2019-10-04 16:45:13,976] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:40:13.976403+00:00
[2019-10-04 16:45:13,991] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.071 seconds
[2019-10-04 16:45:26,577] {{logging_mixin.py:95}} INFO - [2019-10-04 16:45:26,576] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:45:26,635] {{jobs.py:386}} INFO - Started process (PID=3469) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:45:27,108] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:45:27,111] {{logging_mixin.py:95}} INFO - [2019-10-04 16:45:27,111] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:45:27,433] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:45:32,887] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:45:33,054] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:45:33,073] {{logging_mixin.py:95}} INFO - [2019-10-04 16:45:33,072] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:45:33,075] {{logging_mixin.py:95}} INFO - [2019-10-04 16:45:33,074] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:40:33.074750+00:00
[2019-10-04 16:45:33,090] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 6.454 seconds
[2019-10-04 16:45:44,883] {{logging_mixin.py:95}} INFO - [2019-10-04 16:45:44,883] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:45:45,052] {{jobs.py:386}} INFO - Started process (PID=3473) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:45:45,152] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:45:45,167] {{logging_mixin.py:95}} INFO - [2019-10-04 16:45:45,166] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:45:45,196] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:45:46,053] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:45:46,063] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:45:46,078] {{logging_mixin.py:95}} INFO - [2019-10-04 16:45:46,078] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:45:46,081] {{logging_mixin.py:95}} INFO - [2019-10-04 16:45:46,080] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:40:46.080162+00:00
[2019-10-04 16:45:46,099] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.047 seconds
[2019-10-04 16:45:57,512] {{logging_mixin.py:95}} INFO - [2019-10-04 16:45:57,511] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:45:57,515] {{jobs.py:386}} INFO - Started process (PID=3477) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:45:57,519] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:45:57,519] {{logging_mixin.py:95}} INFO - [2019-10-04 16:45:57,519] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:45:57,566] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:45:57,720] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:45:57,725] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:45:57,868] {{logging_mixin.py:95}} INFO - [2019-10-04 16:45:57,737] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:45:57,870] {{logging_mixin.py:95}} INFO - [2019-10-04 16:45:57,869] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:40:57.869810+00:00
[2019-10-04 16:45:57,879] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.363 seconds
[2019-10-04 16:46:09,678] {{logging_mixin.py:95}} INFO - [2019-10-04 16:46:09,678] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:46:09,682] {{jobs.py:386}} INFO - Started process (PID=3489) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:46:09,753] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:46:09,785] {{logging_mixin.py:95}} INFO - [2019-10-04 16:46:09,785] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:46:09,821] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:46:10,598] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:46:10,755] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:46:10,763] {{logging_mixin.py:95}} INFO - [2019-10-04 16:46:10,763] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:46:10,765] {{logging_mixin.py:95}} INFO - [2019-10-04 16:46:10,764] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:41:10.764808+00:00
[2019-10-04 16:46:10,772] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.090 seconds
[2019-10-04 16:46:22,372] {{logging_mixin.py:95}} INFO - [2019-10-04 16:46:22,371] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:46:22,376] {{jobs.py:386}} INFO - Started process (PID=3493) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:46:22,490] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:46:22,555] {{logging_mixin.py:95}} INFO - [2019-10-04 16:46:22,555] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:46:23,426] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:46:25,057] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:46:25,553] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:46:25,563] {{logging_mixin.py:95}} INFO - [2019-10-04 16:46:25,562] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:46:25,564] {{logging_mixin.py:95}} INFO - [2019-10-04 16:46:25,564] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:41:25.563957+00:00
[2019-10-04 16:46:25,574] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.198 seconds
[2019-10-04 16:46:36,401] {{logging_mixin.py:95}} INFO - [2019-10-04 16:46:36,401] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:46:36,405] {{jobs.py:386}} INFO - Started process (PID=3498) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:46:36,410] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:46:36,412] {{logging_mixin.py:95}} INFO - [2019-10-04 16:46:36,412] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:46:36,443] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:46:38,840] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:46:38,973] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:46:38,980] {{logging_mixin.py:95}} INFO - [2019-10-04 16:46:38,980] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:46:38,981] {{logging_mixin.py:95}} INFO - [2019-10-04 16:46:38,981] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:41:38.981116+00:00
[2019-10-04 16:46:38,999] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.594 seconds
[2019-10-04 16:46:49,776] {{logging_mixin.py:95}} INFO - [2019-10-04 16:46:49,776] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:46:49,780] {{jobs.py:386}} INFO - Started process (PID=3507) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:46:49,784] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:46:49,788] {{logging_mixin.py:95}} INFO - [2019-10-04 16:46:49,788] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:46:49,829] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:46:50,187] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:46:50,193] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:46:50,205] {{logging_mixin.py:95}} INFO - [2019-10-04 16:46:50,204] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:46:50,205] {{logging_mixin.py:95}} INFO - [2019-10-04 16:46:50,205] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:41:50.205185+00:00
[2019-10-04 16:46:50,212] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.432 seconds
[2019-10-04 16:47:01,162] {{logging_mixin.py:95}} INFO - [2019-10-04 16:47:01,161] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:47:01,165] {{jobs.py:386}} INFO - Started process (PID=3511) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:47:01,310] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:47:01,311] {{logging_mixin.py:95}} INFO - [2019-10-04 16:47:01,311] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:47:01,340] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:47:02,205] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:47:02,212] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:47:02,287] {{logging_mixin.py:95}} INFO - [2019-10-04 16:47:02,287] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:47:02,289] {{logging_mixin.py:95}} INFO - [2019-10-04 16:47:02,288] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:42:02.288758+00:00
[2019-10-04 16:47:02,323] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.159 seconds
[2019-10-04 16:47:12,727] {{logging_mixin.py:95}} INFO - [2019-10-04 16:47:12,726] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:47:12,730] {{jobs.py:386}} INFO - Started process (PID=3515) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:47:12,734] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:47:12,737] {{logging_mixin.py:95}} INFO - [2019-10-04 16:47:12,737] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:47:12,768] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:47:14,188] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:47:14,194] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:47:14,209] {{logging_mixin.py:95}} INFO - [2019-10-04 16:47:14,209] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:47:14,210] {{logging_mixin.py:95}} INFO - [2019-10-04 16:47:14,210] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:42:14.210242+00:00
[2019-10-04 16:47:14,219] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.489 seconds
[2019-10-04 16:47:25,162] {{logging_mixin.py:95}} INFO - [2019-10-04 16:47:25,161] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:47:25,171] {{jobs.py:386}} INFO - Started process (PID=3524) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:47:25,182] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:47:25,184] {{logging_mixin.py:95}} INFO - [2019-10-04 16:47:25,183] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:47:25,266] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:47:28,209] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:47:28,412] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:47:28,419] {{logging_mixin.py:95}} INFO - [2019-10-04 16:47:28,419] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:47:28,420] {{logging_mixin.py:95}} INFO - [2019-10-04 16:47:28,419] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:42:28.419598+00:00
[2019-10-04 16:47:28,427] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.256 seconds
[2019-10-04 16:47:40,695] {{logging_mixin.py:95}} INFO - [2019-10-04 16:47:40,695] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:47:40,985] {{jobs.py:386}} INFO - Started process (PID=3528) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:47:42,941] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:47:42,943] {{logging_mixin.py:95}} INFO - [2019-10-04 16:47:42,943] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:47:46,847] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:47:55,791] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:47:55,904] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:47:55,919] {{logging_mixin.py:95}} INFO - [2019-10-04 16:47:55,919] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:47:55,921] {{logging_mixin.py:95}} INFO - [2019-10-04 16:47:55,921] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:42:55.921151+00:00
[2019-10-04 16:47:55,930] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 14.945 seconds
[2019-10-04 16:48:07,552] {{logging_mixin.py:95}} INFO - [2019-10-04 16:48:07,552] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:48:07,562] {{jobs.py:386}} INFO - Started process (PID=3537) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:48:07,570] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:48:07,571] {{logging_mixin.py:95}} INFO - [2019-10-04 16:48:07,571] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:48:07,613] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:48:08,076] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:48:08,081] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:48:08,088] {{logging_mixin.py:95}} INFO - [2019-10-04 16:48:08,088] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:48:08,089] {{logging_mixin.py:95}} INFO - [2019-10-04 16:48:08,089] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:43:08.089384+00:00
[2019-10-04 16:48:08,097] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.535 seconds
[2019-10-04 16:48:19,023] {{logging_mixin.py:95}} INFO - [2019-10-04 16:48:19,022] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:48:19,027] {{jobs.py:386}} INFO - Started process (PID=3541) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:48:19,030] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:48:19,038] {{logging_mixin.py:95}} INFO - [2019-10-04 16:48:19,038] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:48:19,070] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:48:19,374] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:48:19,387] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:48:19,406] {{logging_mixin.py:95}} INFO - [2019-10-04 16:48:19,405] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:48:19,406] {{logging_mixin.py:95}} INFO - [2019-10-04 16:48:19,406] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:43:19.406182+00:00
[2019-10-04 16:48:19,420] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.393 seconds
[2019-10-04 16:48:30,758] {{logging_mixin.py:95}} INFO - [2019-10-04 16:48:30,758] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:48:30,767] {{jobs.py:386}} INFO - Started process (PID=3551) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:48:30,771] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:48:30,773] {{logging_mixin.py:95}} INFO - [2019-10-04 16:48:30,772] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:48:30,803] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:48:31,118] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:48:31,126] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:48:31,134] {{logging_mixin.py:95}} INFO - [2019-10-04 16:48:31,134] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:48:31,136] {{logging_mixin.py:95}} INFO - [2019-10-04 16:48:31,135] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:43:31.135451+00:00
[2019-10-04 16:48:31,150] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.383 seconds
[2019-10-04 16:48:42,635] {{logging_mixin.py:95}} INFO - [2019-10-04 16:48:42,635] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:48:42,692] {{jobs.py:386}} INFO - Started process (PID=3555) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:48:43,897] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:48:43,898] {{logging_mixin.py:95}} INFO - [2019-10-04 16:48:43,898] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:48:44,316] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:48:55,146] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:48:55,584] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:48:55,594] {{logging_mixin.py:95}} INFO - [2019-10-04 16:48:55,594] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:48:55,596] {{logging_mixin.py:95}} INFO - [2019-10-04 16:48:55,595] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:43:55.595474+00:00
[2019-10-04 16:53:05,108] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 262.417 seconds
[2019-10-04 16:53:15,807] {{logging_mixin.py:95}} INFO - [2019-10-04 16:53:15,806] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:53:15,846] {{jobs.py:386}} INFO - Started process (PID=3620) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:53:16,046] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:53:16,047] {{logging_mixin.py:95}} INFO - [2019-10-04 16:53:16,047] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:53:16,104] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:53:16,713] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:53:16,897] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:53:17,268] {{logging_mixin.py:95}} INFO - [2019-10-04 16:53:17,268] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:53:17,268] {{logging_mixin.py:95}} INFO - [2019-10-04 16:53:17,268] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:48:17.268442+00:00
[2019-10-04 16:53:17,276] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.430 seconds
[2019-10-04 16:53:29,577] {{logging_mixin.py:95}} INFO - [2019-10-04 16:53:29,546] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:53:29,595] {{jobs.py:386}} INFO - Started process (PID=3624) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:53:30,126] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:53:30,127] {{logging_mixin.py:95}} INFO - [2019-10-04 16:53:30,127] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:53:31,848] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:53:45,374] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:53:45,387] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:53:45,404] {{logging_mixin.py:95}} INFO - [2019-10-04 16:53:45,404] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:53:45,407] {{logging_mixin.py:95}} INFO - [2019-10-04 16:53:45,406] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:48:45.406743+00:00
[2019-10-04 16:53:46,608] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 17.012 seconds
[2019-10-04 16:54:03,576] {{logging_mixin.py:95}} INFO - [2019-10-04 16:54:02,285] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:54:04,086] {{jobs.py:386}} INFO - Started process (PID=3633) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:54:05,213] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:54:05,214] {{logging_mixin.py:95}} INFO - [2019-10-04 16:54:05,214] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:54:10,473] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:54:24,134] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:54:25,505] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:54:25,514] {{logging_mixin.py:95}} INFO - [2019-10-04 16:54:25,514] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:54:25,516] {{logging_mixin.py:95}} INFO - [2019-10-04 16:54:25,515] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:49:25.515820+00:00
[2019-10-04 16:54:27,889] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 23.803 seconds
[2019-10-04 16:54:40,621] {{logging_mixin.py:95}} INFO - [2019-10-04 16:54:40,620] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:54:40,709] {{jobs.py:386}} INFO - Started process (PID=3637) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:54:41,848] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:54:41,848] {{logging_mixin.py:95}} INFO - [2019-10-04 16:54:41,848] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:54:43,787] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:54:47,610] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:54:47,614] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:54:47,622] {{logging_mixin.py:95}} INFO - [2019-10-04 16:54:47,622] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:54:47,623] {{logging_mixin.py:95}} INFO - [2019-10-04 16:54:47,622] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:49:47.622859+00:00
[2019-10-04 16:54:47,628] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 6.919 seconds
[2019-10-04 16:54:59,333] {{logging_mixin.py:95}} INFO - [2019-10-04 16:54:59,333] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:54:59,344] {{jobs.py:386}} INFO - Started process (PID=3641) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:54:59,369] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:54:59,370] {{logging_mixin.py:95}} INFO - [2019-10-04 16:54:59,370] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:54:59,541] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:54:59,851] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:54:59,856] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:54:59,867] {{logging_mixin.py:95}} INFO - [2019-10-04 16:54:59,867] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:54:59,869] {{logging_mixin.py:95}} INFO - [2019-10-04 16:54:59,869] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:49:59.869054+00:00
[2019-10-04 16:54:59,967] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.623 seconds
[2019-10-04 16:55:10,674] {{logging_mixin.py:95}} INFO - [2019-10-04 16:55:10,674] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:55:10,725] {{jobs.py:386}} INFO - Started process (PID=3655) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:55:10,980] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:55:10,981] {{logging_mixin.py:95}} INFO - [2019-10-04 16:55:10,981] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:55:11,523] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:55:13,652] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:55:13,835] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:55:13,848] {{logging_mixin.py:95}} INFO - [2019-10-04 16:55:13,848] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:55:13,851] {{logging_mixin.py:95}} INFO - [2019-10-04 16:55:13,850] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:50:13.850139+00:00
[2019-10-04 16:55:13,934] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.209 seconds
[2019-10-04 16:55:25,502] {{logging_mixin.py:95}} INFO - [2019-10-04 16:55:25,502] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:55:25,506] {{jobs.py:386}} INFO - Started process (PID=3659) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:55:25,566] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:55:25,567] {{logging_mixin.py:95}} INFO - [2019-10-04 16:55:25,567] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:55:25,593] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:55:26,190] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:55:26,197] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:55:26,207] {{logging_mixin.py:95}} INFO - [2019-10-04 16:55:26,207] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:55:26,207] {{logging_mixin.py:95}} INFO - [2019-10-04 16:55:26,207] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:50:26.207285+00:00
[2019-10-04 16:55:26,213] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.707 seconds
[2019-10-04 16:55:37,338] {{logging_mixin.py:95}} INFO - [2019-10-04 16:55:37,338] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:55:37,342] {{jobs.py:386}} INFO - Started process (PID=3663) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:55:37,354] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:55:37,357] {{logging_mixin.py:95}} INFO - [2019-10-04 16:55:37,355] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:55:37,397] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:55:38,529] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:55:38,636] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:55:38,648] {{logging_mixin.py:95}} INFO - [2019-10-04 16:55:38,647] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:55:38,651] {{logging_mixin.py:95}} INFO - [2019-10-04 16:55:38,650] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:50:38.650870+00:00
[2019-10-04 16:55:38,665] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.323 seconds
[2019-10-04 16:55:50,003] {{logging_mixin.py:95}} INFO - [2019-10-04 16:55:50,003] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:55:50,047] {{jobs.py:386}} INFO - Started process (PID=3673) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:55:50,169] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:55:50,170] {{logging_mixin.py:95}} INFO - [2019-10-04 16:55:50,170] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:55:51,152] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:56:03,260] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:56:03,524] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:56:03,634] {{logging_mixin.py:95}} INFO - [2019-10-04 16:56:03,633] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:56:03,635] {{logging_mixin.py:95}} INFO - [2019-10-04 16:56:03,635] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:51:03.635197+00:00
[2019-10-04 16:56:04,886] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 14.839 seconds
[2019-10-04 16:56:16,938] {{logging_mixin.py:95}} INFO - [2019-10-04 16:56:16,937] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:56:17,191] {{jobs.py:386}} INFO - Started process (PID=3677) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:56:17,560] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:56:17,561] {{logging_mixin.py:95}} INFO - [2019-10-04 16:56:17,560] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:56:18,959] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:56:20,749] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:56:20,839] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:56:20,847] {{logging_mixin.py:95}} INFO - [2019-10-04 16:56:20,847] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:56:20,848] {{logging_mixin.py:95}} INFO - [2019-10-04 16:56:20,847] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:51:20.847400+00:00
[2019-10-04 16:56:20,855] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.664 seconds
[2019-10-04 16:56:32,694] {{logging_mixin.py:95}} INFO - [2019-10-04 16:56:32,640] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:56:32,953] {{jobs.py:386}} INFO - Started process (PID=3681) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:56:33,516] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:56:33,518] {{logging_mixin.py:95}} INFO - [2019-10-04 16:56:33,518] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:56:34,676] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:56:38,785] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:56:38,805] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:56:38,814] {{logging_mixin.py:95}} INFO - [2019-10-04 16:56:38,814] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:56:38,816] {{logging_mixin.py:95}} INFO - [2019-10-04 16:56:38,815] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:51:38.815861+00:00
[2019-10-04 16:56:38,824] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.871 seconds
[2019-10-04 16:56:53,962] {{logging_mixin.py:95}} INFO - [2019-10-04 16:56:53,927] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:56:54,061] {{jobs.py:386}} INFO - Started process (PID=3690) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:56:54,850] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:56:54,852] {{logging_mixin.py:95}} INFO - [2019-10-04 16:56:54,852] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:56:57,333] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:57:09,017] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 16:57:32,083] {{logging_mixin.py:95}} INFO - [2019-10-04 16:57:31,917] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:57:32,167] {{jobs.py:386}} INFO - Started process (PID=3692) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:57:33,038] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:57:33,040] {{logging_mixin.py:95}} INFO - [2019-10-04 16:57:33,040] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:57:36,381] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:58:05,148] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 16:58:27,145] {{logging_mixin.py:95}} INFO - [2019-10-04 16:58:27,145] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:58:27,257] {{jobs.py:386}} INFO - Started process (PID=3694) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:58:27,523] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:58:27,524] {{logging_mixin.py:95}} INFO - [2019-10-04 16:58:27,524] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:58:30,502] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:58:39,601] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:58:39,658] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:58:39,669] {{logging_mixin.py:95}} INFO - [2019-10-04 16:58:39,669] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:58:39,672] {{logging_mixin.py:95}} INFO - [2019-10-04 16:58:39,671] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:53:39.671726+00:00
[2019-10-04 16:58:41,934] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 14.677 seconds
[2019-10-04 16:58:53,104] {{logging_mixin.py:95}} INFO - [2019-10-04 16:58:53,104] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:58:53,164] {{jobs.py:386}} INFO - Started process (PID=3703) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:58:53,233] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:58:53,235] {{logging_mixin.py:95}} INFO - [2019-10-04 16:58:53,235] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:58:53,393] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:58:53,604] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:58:53,608] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:58:53,617] {{logging_mixin.py:95}} INFO - [2019-10-04 16:58:53,616] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:58:53,617] {{logging_mixin.py:95}} INFO - [2019-10-04 16:58:53,617] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:53:53.617227+00:00
[2019-10-04 16:58:53,623] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.460 seconds
[2019-10-04 16:59:04,541] {{logging_mixin.py:95}} INFO - [2019-10-04 16:59:04,541] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:59:04,545] {{jobs.py:386}} INFO - Started process (PID=3707) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:59:04,715] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:59:04,716] {{logging_mixin.py:95}} INFO - [2019-10-04 16:59:04,716] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:59:05,164] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:59:07,175] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:59:07,180] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:59:07,187] {{logging_mixin.py:95}} INFO - [2019-10-04 16:59:07,187] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:59:07,189] {{logging_mixin.py:95}} INFO - [2019-10-04 16:59:07,188] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:54:07.188744+00:00
[2019-10-04 16:59:07,197] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.653 seconds
[2019-10-04 16:59:18,037] {{logging_mixin.py:95}} INFO - [2019-10-04 16:59:18,036] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:59:18,073] {{jobs.py:386}} INFO - Started process (PID=3711) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:59:18,402] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:59:18,403] {{logging_mixin.py:95}} INFO - [2019-10-04 16:59:18,403] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:59:18,751] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:59:19,219] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:59:19,224] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:59:19,233] {{logging_mixin.py:95}} INFO - [2019-10-04 16:59:19,233] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:59:19,234] {{logging_mixin.py:95}} INFO - [2019-10-04 16:59:19,233] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:54:19.233787+00:00
[2019-10-04 16:59:19,242] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.169 seconds
[2019-10-04 16:59:30,372] {{logging_mixin.py:95}} INFO - [2019-10-04 16:59:30,371] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:59:30,375] {{jobs.py:386}} INFO - Started process (PID=3720) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:59:30,378] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:59:30,378] {{logging_mixin.py:95}} INFO - [2019-10-04 16:59:30,378] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:59:30,418] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:59:32,900] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:59:32,905] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:59:32,913] {{logging_mixin.py:95}} INFO - [2019-10-04 16:59:32,913] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:59:32,914] {{logging_mixin.py:95}} INFO - [2019-10-04 16:59:32,913] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:54:32.913438+00:00
[2019-10-04 16:59:33,039] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.665 seconds
[2019-10-04 16:59:44,496] {{logging_mixin.py:95}} INFO - [2019-10-04 16:59:44,395] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 16:59:44,570] {{jobs.py:386}} INFO - Started process (PID=3724) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:59:44,976] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 16:59:44,978] {{logging_mixin.py:95}} INFO - [2019-10-04 16:59:44,978] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:59:46,910] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 16:59:53,131] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 16:59:53,347] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 16:59:53,354] {{logging_mixin.py:95}} INFO - [2019-10-04 16:59:53,354] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 16:59:53,356] {{logging_mixin.py:95}} INFO - [2019-10-04 16:59:53,355] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:54:53.355556+00:00
[2019-10-04 16:59:53,564] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 8.994 seconds
[2019-10-04 17:00:04,102] {{logging_mixin.py:95}} INFO - [2019-10-04 17:00:04,102] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:00:04,106] {{jobs.py:386}} INFO - Started process (PID=3733) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:00:04,110] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:00:04,112] {{logging_mixin.py:95}} INFO - [2019-10-04 17:00:04,111] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:00:04,165] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:00:04,476] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:00:04,606] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:00:04,618] {{logging_mixin.py:95}} INFO - [2019-10-04 17:00:04,618] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:00:04,621] {{logging_mixin.py:95}} INFO - [2019-10-04 17:00:04,620] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:55:04.620278+00:00
[2019-10-04 17:00:04,639] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.533 seconds
[2019-10-04 17:00:17,309] {{logging_mixin.py:95}} INFO - [2019-10-04 17:00:17,113] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:00:17,618] {{jobs.py:386}} INFO - Started process (PID=3737) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:00:19,208] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:00:19,208] {{logging_mixin.py:95}} INFO - [2019-10-04 17:00:19,208] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:00:22,514] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:00:29,958] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:00:30,395] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:00:30,401] {{logging_mixin.py:95}} INFO - [2019-10-04 17:00:30,401] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:00:30,404] {{logging_mixin.py:95}} INFO - [2019-10-04 17:00:30,401] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:55:30.401859+00:00
[2019-10-04 17:00:30,604] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 12.986 seconds
[2019-10-04 17:00:43,304] {{logging_mixin.py:95}} INFO - [2019-10-04 17:00:43,304] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:00:43,751] {{jobs.py:386}} INFO - Started process (PID=3752) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:00:44,565] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:00:44,567] {{logging_mixin.py:95}} INFO - [2019-10-04 17:00:44,567] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:00:46,966] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:00:59,906] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:01:00,218] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:01:00,235] {{logging_mixin.py:95}} INFO - [2019-10-04 17:01:00,235] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:01:00,237] {{logging_mixin.py:95}} INFO - [2019-10-04 17:01:00,237] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:56:00.237097+00:00
[2019-10-04 17:01:01,605] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 17.854 seconds
[2019-10-04 17:01:16,290] {{logging_mixin.py:95}} INFO - [2019-10-04 17:01:16,140] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:01:16,741] {{jobs.py:386}} INFO - Started process (PID=3756) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:01:17,311] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:01:17,312] {{logging_mixin.py:95}} INFO - [2019-10-04 17:01:17,312] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:01:20,077] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:01:39,208] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 17:01:53,563] {{logging_mixin.py:95}} INFO - [2019-10-04 17:01:53,563] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:01:53,805] {{jobs.py:386}} INFO - Started process (PID=3763) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:01:54,140] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:01:54,141] {{logging_mixin.py:95}} INFO - [2019-10-04 17:01:54,140] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:01:54,593] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:01:58,717] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:01:58,857] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:01:58,865] {{logging_mixin.py:95}} INFO - [2019-10-04 17:01:58,864] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:01:58,867] {{logging_mixin.py:95}} INFO - [2019-10-04 17:01:58,866] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:56:58.866830+00:00
[2019-10-04 17:01:58,876] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.071 seconds
[2019-10-04 17:02:10,172] {{logging_mixin.py:95}} INFO - [2019-10-04 17:02:10,172] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:02:10,176] {{jobs.py:386}} INFO - Started process (PID=3767) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:02:10,182] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:02:10,182] {{logging_mixin.py:95}} INFO - [2019-10-04 17:02:10,182] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:02:10,220] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:02:10,490] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:02:10,549] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:02:10,562] {{logging_mixin.py:95}} INFO - [2019-10-04 17:02:10,562] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:02:10,564] {{logging_mixin.py:95}} INFO - [2019-10-04 17:02:10,563] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:57:10.563414+00:00
[2019-10-04 17:02:10,574] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.398 seconds
[2019-10-04 17:02:21,424] {{logging_mixin.py:95}} INFO - [2019-10-04 17:02:21,424] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:02:21,428] {{jobs.py:386}} INFO - Started process (PID=3771) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:02:21,464] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:02:21,465] {{logging_mixin.py:95}} INFO - [2019-10-04 17:02:21,464] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:02:22,244] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:02:23,818] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:02:23,823] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:02:23,832] {{logging_mixin.py:95}} INFO - [2019-10-04 17:02:23,832] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:02:23,834] {{logging_mixin.py:95}} INFO - [2019-10-04 17:02:23,833] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:57:23.833348+00:00
[2019-10-04 17:02:23,842] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.413 seconds
[2019-10-04 17:02:34,943] {{logging_mixin.py:95}} INFO - [2019-10-04 17:02:34,942] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:02:34,958] {{jobs.py:386}} INFO - Started process (PID=3781) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:02:35,043] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:02:35,047] {{logging_mixin.py:95}} INFO - [2019-10-04 17:02:35,047] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:02:35,143] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:02:35,468] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:02:35,480] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:02:35,496] {{logging_mixin.py:95}} INFO - [2019-10-04 17:02:35,496] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:02:35,499] {{logging_mixin.py:95}} INFO - [2019-10-04 17:02:35,499] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:57:35.499454+00:00
[2019-10-04 17:02:35,508] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.550 seconds
[2019-10-04 17:02:46,337] {{logging_mixin.py:95}} INFO - [2019-10-04 17:02:46,337] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:02:46,340] {{jobs.py:386}} INFO - Started process (PID=3785) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:02:46,343] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:02:46,343] {{logging_mixin.py:95}} INFO - [2019-10-04 17:02:46,343] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:02:46,380] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:02:46,607] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:02:46,611] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:02:46,619] {{logging_mixin.py:95}} INFO - [2019-10-04 17:02:46,619] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:02:46,620] {{logging_mixin.py:95}} INFO - [2019-10-04 17:02:46,620] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:57:46.620112+00:00
[2019-10-04 17:02:46,630] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.290 seconds
[2019-10-04 17:02:58,248] {{logging_mixin.py:95}} INFO - [2019-10-04 17:02:58,247] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:02:58,304] {{jobs.py:386}} INFO - Started process (PID=3789) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:02:58,689] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:02:58,714] {{logging_mixin.py:95}} INFO - [2019-10-04 17:02:58,714] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:02:59,651] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:03:03,658] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:03:03,746] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:03:03,754] {{logging_mixin.py:95}} INFO - [2019-10-04 17:03:03,754] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:03:03,756] {{logging_mixin.py:95}} INFO - [2019-10-04 17:03:03,755] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:58:03.755688+00:00
[2019-10-04 17:03:03,922] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.617 seconds
[2019-10-04 17:03:15,730] {{logging_mixin.py:95}} INFO - [2019-10-04 17:03:15,730] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:03:15,779] {{jobs.py:386}} INFO - Started process (PID=3798) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:03:15,968] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:03:15,970] {{logging_mixin.py:95}} INFO - [2019-10-04 17:03:15,970] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:03:16,949] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:03:20,291] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:03:20,345] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:03:20,354] {{logging_mixin.py:95}} INFO - [2019-10-04 17:03:20,354] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:03:20,355] {{logging_mixin.py:95}} INFO - [2019-10-04 17:03:20,355] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:58:20.355087+00:00
[2019-10-04 17:03:20,378] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.599 seconds
[2019-10-04 17:03:32,586] {{logging_mixin.py:95}} INFO - [2019-10-04 17:03:32,586] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:03:32,751] {{jobs.py:386}} INFO - Started process (PID=3802) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:03:33,503] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:03:33,504] {{logging_mixin.py:95}} INFO - [2019-10-04 17:03:33,504] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:03:34,360] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:03:41,353] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:03:41,411] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:03:41,429] {{logging_mixin.py:95}} INFO - [2019-10-04 17:03:41,429] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:03:41,430] {{logging_mixin.py:95}} INFO - [2019-10-04 17:03:41,429] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:58:41.429805+00:00
[2019-10-04 17:03:41,437] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 8.686 seconds
[2019-10-04 17:03:53,511] {{logging_mixin.py:95}} INFO - [2019-10-04 17:03:53,511] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:03:53,551] {{jobs.py:386}} INFO - Started process (PID=3806) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:03:53,890] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:03:53,891] {{logging_mixin.py:95}} INFO - [2019-10-04 17:03:53,891] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:03:54,331] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:04:15,426] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 17:04:31,336] {{logging_mixin.py:95}} INFO - [2019-10-04 17:04:31,336] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:04:31,515] {{jobs.py:386}} INFO - Started process (PID=3813) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:04:32,514] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:04:32,515] {{logging_mixin.py:95}} INFO - [2019-10-04 17:04:32,515] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:04:34,487] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:04:47,798] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:04:47,968] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:04:47,976] {{logging_mixin.py:95}} INFO - [2019-10-04 17:04:47,976] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:04:47,978] {{logging_mixin.py:95}} INFO - [2019-10-04 17:04:47,977] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 16:59:47.977778+00:00
[2019-10-04 17:04:48,344] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 16.829 seconds
[2019-10-04 17:05:02,215] {{logging_mixin.py:95}} INFO - [2019-10-04 17:05:02,155] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:05:02,464] {{jobs.py:386}} INFO - Started process (PID=3817) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:05:03,587] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:05:03,588] {{logging_mixin.py:95}} INFO - [2019-10-04 17:05:03,587] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:05:06,246] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:05:21,277] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 17:05:38,670] {{logging_mixin.py:95}} INFO - [2019-10-04 17:05:38,670] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:05:38,754] {{jobs.py:386}} INFO - Started process (PID=3819) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:05:40,644] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:05:40,647] {{logging_mixin.py:95}} INFO - [2019-10-04 17:05:40,647] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:05:42,337] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:05:45,638] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:05:45,789] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:05:45,801] {{logging_mixin.py:95}} INFO - [2019-10-04 17:05:45,801] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:05:45,803] {{logging_mixin.py:95}} INFO - [2019-10-04 17:05:45,802] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:00:45.802895+00:00
[2019-10-04 17:05:45,831] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 7.078 seconds
[2019-10-04 17:05:57,391] {{logging_mixin.py:95}} INFO - [2019-10-04 17:05:57,390] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:05:57,399] {{jobs.py:386}} INFO - Started process (PID=3823) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:05:57,404] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:05:57,415] {{logging_mixin.py:95}} INFO - [2019-10-04 17:05:57,415] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:05:57,454] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:05:57,838] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:05:57,842] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:05:57,851] {{logging_mixin.py:95}} INFO - [2019-10-04 17:05:57,851] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:05:57,851] {{logging_mixin.py:95}} INFO - [2019-10-04 17:05:57,851] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:00:57.851394+00:00
[2019-10-04 17:05:57,859] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.460 seconds
[2019-10-04 17:06:09,179] {{logging_mixin.py:95}} INFO - [2019-10-04 17:06:09,178] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:06:09,183] {{jobs.py:386}} INFO - Started process (PID=3827) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:06:09,468] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:06:09,470] {{logging_mixin.py:95}} INFO - [2019-10-04 17:06:09,470] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:06:09,782] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:06:13,187] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:06:13,251] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:06:13,259] {{logging_mixin.py:95}} INFO - [2019-10-04 17:06:13,258] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:06:13,260] {{logging_mixin.py:95}} INFO - [2019-10-04 17:06:13,260] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:01:13.260037+00:00
[2019-10-04 17:06:13,267] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.084 seconds
[2019-10-04 17:06:24,936] {{logging_mixin.py:95}} INFO - [2019-10-04 17:06:24,936] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:06:24,939] {{jobs.py:386}} INFO - Started process (PID=3839) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:06:24,943] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:06:24,945] {{logging_mixin.py:95}} INFO - [2019-10-04 17:06:24,944] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:06:24,961] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:06:25,147] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:06:25,153] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:06:25,162] {{logging_mixin.py:95}} INFO - [2019-10-04 17:06:25,162] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:06:25,166] {{logging_mixin.py:95}} INFO - [2019-10-04 17:06:25,163] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:01:25.163127+00:00
[2019-10-04 17:06:25,177] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.238 seconds
[2019-10-04 17:06:36,183] {{logging_mixin.py:95}} INFO - [2019-10-04 17:06:36,182] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:06:36,186] {{jobs.py:386}} INFO - Started process (PID=3843) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:06:36,188] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:06:36,189] {{logging_mixin.py:95}} INFO - [2019-10-04 17:06:36,189] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:06:36,214] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:06:36,537] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:06:36,543] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:06:36,551] {{logging_mixin.py:95}} INFO - [2019-10-04 17:06:36,551] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:06:36,552] {{logging_mixin.py:95}} INFO - [2019-10-04 17:06:36,551] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:01:36.551703+00:00
[2019-10-04 17:06:36,562] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.376 seconds
[2019-10-04 17:06:47,764] {{logging_mixin.py:95}} INFO - [2019-10-04 17:06:47,764] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:06:47,768] {{jobs.py:386}} INFO - Started process (PID=3846) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:06:47,772] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:06:47,774] {{logging_mixin.py:95}} INFO - [2019-10-04 17:06:47,773] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:06:49,532] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:06:55,597] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:06:55,653] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:06:55,663] {{logging_mixin.py:95}} INFO - [2019-10-04 17:06:55,663] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:06:55,665] {{logging_mixin.py:95}} INFO - [2019-10-04 17:06:55,664] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:01:55.664749+00:00
[2019-10-04 17:06:55,673] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 7.905 seconds
[2019-10-04 17:07:07,360] {{logging_mixin.py:95}} INFO - [2019-10-04 17:07:07,360] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:07:07,366] {{jobs.py:386}} INFO - Started process (PID=3854) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:07:07,368] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:07:07,370] {{logging_mixin.py:95}} INFO - [2019-10-04 17:07:07,370] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:07:07,454] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:07:07,816] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:07:07,823] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:07:07,831] {{logging_mixin.py:95}} INFO - [2019-10-04 17:07:07,830] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:07:07,832] {{logging_mixin.py:95}} INFO - [2019-10-04 17:07:07,832] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:02:07.832059+00:00
[2019-10-04 17:07:07,843] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.477 seconds
[2019-10-04 17:07:19,759] {{logging_mixin.py:95}} INFO - [2019-10-04 17:07:19,675] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:07:19,863] {{jobs.py:386}} INFO - Started process (PID=3858) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:07:20,614] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:07:20,614] {{logging_mixin.py:95}} INFO - [2019-10-04 17:07:20,614] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:07:22,879] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:07:24,545] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:07:24,549] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:07:24,567] {{logging_mixin.py:95}} INFO - [2019-10-04 17:07:24,567] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:07:24,568] {{logging_mixin.py:95}} INFO - [2019-10-04 17:07:24,568] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:02:24.568118+00:00
[2019-10-04 17:07:24,578] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.715 seconds
[2019-10-04 17:07:37,249] {{logging_mixin.py:95}} INFO - [2019-10-04 17:07:37,083] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:07:37,374] {{jobs.py:386}} INFO - Started process (PID=3862) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:07:38,155] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:07:38,157] {{logging_mixin.py:95}} INFO - [2019-10-04 17:07:38,157] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:07:39,487] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:07:48,329] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:07:48,458] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:07:48,468] {{logging_mixin.py:95}} INFO - [2019-10-04 17:07:48,468] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:07:48,470] {{logging_mixin.py:95}} INFO - [2019-10-04 17:07:48,470] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:02:48.470281+00:00
[2019-10-04 17:07:49,195] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 11.821 seconds
[2019-10-04 17:08:05,229] {{logging_mixin.py:95}} INFO - [2019-10-04 17:08:05,228] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:08:05,606] {{jobs.py:386}} INFO - Started process (PID=3871) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:08:06,670] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:08:06,671] {{logging_mixin.py:95}} INFO - [2019-10-04 17:08:06,671] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:08:09,779] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:08:17,357] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:08:17,417] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:08:17,435] {{logging_mixin.py:95}} INFO - [2019-10-04 17:08:17,434] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:08:17,441] {{logging_mixin.py:95}} INFO - [2019-10-04 17:08:17,440] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:03:17.440951+00:00
[2019-10-04 17:08:17,447] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 11.841 seconds
[2019-10-04 17:08:29,588] {{logging_mixin.py:95}} INFO - [2019-10-04 17:08:29,552] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:08:29,622] {{jobs.py:386}} INFO - Started process (PID=3875) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:08:29,787] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:08:29,788] {{logging_mixin.py:95}} INFO - [2019-10-04 17:08:29,788] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:08:32,351] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:08:43,084] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:08:43,149] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:08:43,162] {{logging_mixin.py:95}} INFO - [2019-10-04 17:08:43,162] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:08:43,164] {{logging_mixin.py:95}} INFO - [2019-10-04 17:08:43,163] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:03:43.163272+00:00
[2019-10-04 17:08:44,043] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 14.421 seconds
[2019-10-04 17:08:59,154] {{logging_mixin.py:95}} INFO - [2019-10-04 17:08:59,141] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:08:59,604] {{jobs.py:386}} INFO - Started process (PID=3884) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:09:00,164] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:09:00,167] {{logging_mixin.py:95}} INFO - [2019-10-04 17:09:00,166] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:09:02,350] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:09:10,626] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:09:10,705] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:09:10,722] {{logging_mixin.py:95}} INFO - [2019-10-04 17:09:10,721] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:09:10,723] {{logging_mixin.py:95}} INFO - [2019-10-04 17:09:10,722] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:04:10.722725+00:00
[2019-10-04 17:09:10,731] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 11.127 seconds
[2019-10-04 17:09:21,680] {{logging_mixin.py:95}} INFO - [2019-10-04 17:09:21,636] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:09:21,763] {{jobs.py:386}} INFO - Started process (PID=3888) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:09:21,807] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:09:21,810] {{logging_mixin.py:95}} INFO - [2019-10-04 17:09:21,809] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:09:21,891] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:09:22,946] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:09:22,951] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:09:22,960] {{logging_mixin.py:95}} INFO - [2019-10-04 17:09:22,960] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:09:22,962] {{logging_mixin.py:95}} INFO - [2019-10-04 17:09:22,961] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:04:22.961815+00:00
[2019-10-04 17:09:23,174] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.411 seconds
[2019-10-04 17:09:34,647] {{logging_mixin.py:95}} INFO - [2019-10-04 17:09:34,647] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:09:34,650] {{jobs.py:386}} INFO - Started process (PID=3892) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:09:35,400] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:09:35,401] {{logging_mixin.py:95}} INFO - [2019-10-04 17:09:35,401] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:09:35,673] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:09:37,665] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:09:37,679] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:09:37,686] {{logging_mixin.py:95}} INFO - [2019-10-04 17:09:37,686] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:09:37,687] {{logging_mixin.py:95}} INFO - [2019-10-04 17:09:37,687] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:04:37.687294+00:00
[2019-10-04 17:09:37,694] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.044 seconds
[2019-10-04 17:09:49,023] {{logging_mixin.py:95}} INFO - [2019-10-04 17:09:49,022] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:09:49,027] {{jobs.py:386}} INFO - Started process (PID=3904) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:09:49,029] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:09:49,033] {{logging_mixin.py:95}} INFO - [2019-10-04 17:09:49,030] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:09:49,078] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:09:49,591] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:09:49,617] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:09:49,632] {{logging_mixin.py:95}} INFO - [2019-10-04 17:09:49,632] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:09:49,633] {{logging_mixin.py:95}} INFO - [2019-10-04 17:09:49,633] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:04:49.633041+00:00
[2019-10-04 17:09:49,643] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.617 seconds
[2019-10-04 17:10:01,402] {{logging_mixin.py:95}} INFO - [2019-10-04 17:10:01,380] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:10:01,465] {{jobs.py:386}} INFO - Started process (PID=3908) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:10:01,724] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:10:01,727] {{logging_mixin.py:95}} INFO - [2019-10-04 17:10:01,726] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:10:02,722] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:10:08,682] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:10:09,613] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:10:09,620] {{logging_mixin.py:95}} INFO - [2019-10-04 17:10:09,620] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:10:09,621] {{logging_mixin.py:95}} INFO - [2019-10-04 17:10:09,621] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:05:09.621093+00:00
[2019-10-04 17:10:11,122] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 9.657 seconds
[2019-10-04 17:10:23,276] {{logging_mixin.py:95}} INFO - [2019-10-04 17:10:23,276] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:10:23,358] {{jobs.py:386}} INFO - Started process (PID=3918) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:10:23,601] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:10:23,603] {{logging_mixin.py:95}} INFO - [2019-10-04 17:10:23,603] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:10:25,824] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:10:27,598] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:10:27,604] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:10:27,613] {{logging_mixin.py:95}} INFO - [2019-10-04 17:10:27,613] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:10:27,614] {{logging_mixin.py:95}} INFO - [2019-10-04 17:10:27,614] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:05:27.614445+00:00
[2019-10-04 17:10:27,626] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.267 seconds
[2019-10-04 17:10:38,950] {{logging_mixin.py:95}} INFO - [2019-10-04 17:10:38,950] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:10:38,996] {{jobs.py:386}} INFO - Started process (PID=3922) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:10:39,201] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:10:39,202] {{logging_mixin.py:95}} INFO - [2019-10-04 17:10:39,201] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:10:39,466] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:10:40,558] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:10:40,564] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:10:40,572] {{logging_mixin.py:95}} INFO - [2019-10-04 17:10:40,572] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:10:40,573] {{logging_mixin.py:95}} INFO - [2019-10-04 17:10:40,573] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:05:40.573254+00:00
[2019-10-04 17:10:40,651] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.655 seconds
[2019-10-04 17:10:51,950] {{logging_mixin.py:95}} INFO - [2019-10-04 17:10:51,950] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:10:52,024] {{jobs.py:386}} INFO - Started process (PID=3926) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:10:52,905] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:10:52,905] {{logging_mixin.py:95}} INFO - [2019-10-04 17:10:52,905] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:10:53,265] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:11:00,715] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:11:00,852] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:11:00,887] {{logging_mixin.py:95}} INFO - [2019-10-04 17:11:00,887] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:11:00,889] {{logging_mixin.py:95}} INFO - [2019-10-04 17:11:00,888] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:06:00.888663+00:00
[2019-10-04 17:11:01,601] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 9.577 seconds
[2019-10-04 17:11:14,607] {{logging_mixin.py:95}} INFO - [2019-10-04 17:11:14,341] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:11:14,898] {{jobs.py:386}} INFO - Started process (PID=3930) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:11:16,846] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:11:16,847] {{logging_mixin.py:95}} INFO - [2019-10-04 17:11:16,847] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:11:18,843] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:11:30,662] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:11:32,090] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:11:32,174] {{logging_mixin.py:95}} INFO - [2019-10-04 17:11:32,174] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:11:32,176] {{logging_mixin.py:95}} INFO - [2019-10-04 17:11:32,175] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:06:32.175898+00:00
[2019-10-04 17:11:33,799] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 18.902 seconds
[2019-10-04 17:11:46,630] {{logging_mixin.py:95}} INFO - [2019-10-04 17:11:46,575] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:11:46,755] {{jobs.py:386}} INFO - Started process (PID=3944) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:11:47,135] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:11:47,137] {{logging_mixin.py:95}} INFO - [2019-10-04 17:11:47,136] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:11:52,791] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:12:01,206] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:12:01,422] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:12:01,431] {{logging_mixin.py:95}} INFO - [2019-10-04 17:12:01,431] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:12:01,434] {{logging_mixin.py:95}} INFO - [2019-10-04 17:12:01,433] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:07:01.433483+00:00
[2019-10-04 17:12:03,169] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 16.415 seconds
[2019-10-04 17:12:15,101] {{logging_mixin.py:95}} INFO - [2019-10-04 17:12:15,101] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:12:15,153] {{jobs.py:386}} INFO - Started process (PID=3948) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:12:15,471] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:12:15,473] {{logging_mixin.py:95}} INFO - [2019-10-04 17:12:15,472] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:12:17,050] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:12:20,133] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:12:20,138] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:12:20,145] {{logging_mixin.py:95}} INFO - [2019-10-04 17:12:20,144] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:12:20,146] {{logging_mixin.py:95}} INFO - [2019-10-04 17:12:20,145] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:07:20.145257+00:00
[2019-10-04 17:12:20,155] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.002 seconds
[2019-10-04 17:12:31,116] {{logging_mixin.py:95}} INFO - [2019-10-04 17:12:31,116] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:12:31,120] {{jobs.py:386}} INFO - Started process (PID=3957) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:12:31,124] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:12:31,125] {{logging_mixin.py:95}} INFO - [2019-10-04 17:12:31,125] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:12:31,167] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:12:32,108] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:12:32,163] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:12:32,171] {{logging_mixin.py:95}} INFO - [2019-10-04 17:12:32,171] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:12:32,172] {{logging_mixin.py:95}} INFO - [2019-10-04 17:12:32,172] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:07:32.172083+00:00
[2019-10-04 17:12:32,185] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.064 seconds
[2019-10-04 17:12:43,544] {{logging_mixin.py:95}} INFO - [2019-10-04 17:12:43,544] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:12:43,547] {{jobs.py:386}} INFO - Started process (PID=3962) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:12:43,550] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:12:43,551] {{logging_mixin.py:95}} INFO - [2019-10-04 17:12:43,551] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:12:43,574] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:12:45,077] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:12:45,134] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:12:45,304] {{logging_mixin.py:95}} INFO - [2019-10-04 17:12:45,304] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:12:45,305] {{logging_mixin.py:95}} INFO - [2019-10-04 17:12:45,305] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:07:45.305250+00:00
[2019-10-04 17:12:45,314] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.767 seconds
[2019-10-04 17:12:56,225] {{logging_mixin.py:95}} INFO - [2019-10-04 17:12:56,224] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:12:56,230] {{jobs.py:386}} INFO - Started process (PID=3965) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:12:56,383] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:12:56,384] {{logging_mixin.py:95}} INFO - [2019-10-04 17:12:56,384] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:12:56,660] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:12:57,242] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:12:57,252] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:12:57,263] {{logging_mixin.py:95}} INFO - [2019-10-04 17:12:57,263] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:12:57,263] {{logging_mixin.py:95}} INFO - [2019-10-04 17:12:57,263] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:07:57.263368+00:00
[2019-10-04 17:12:57,374] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.144 seconds
[2019-10-04 17:13:08,504] {{logging_mixin.py:95}} INFO - [2019-10-04 17:13:08,504] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:13:08,508] {{jobs.py:386}} INFO - Started process (PID=3974) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:13:08,512] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:13:08,512] {{logging_mixin.py:95}} INFO - [2019-10-04 17:13:08,512] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:13:08,550] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:13:08,681] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:13:08,786] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:13:08,795] {{logging_mixin.py:95}} INFO - [2019-10-04 17:13:08,795] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:13:08,796] {{logging_mixin.py:95}} INFO - [2019-10-04 17:13:08,796] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:08:08.796192+00:00
[2019-10-04 17:13:08,803] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.295 seconds
[2019-10-04 17:13:19,951] {{logging_mixin.py:95}} INFO - [2019-10-04 17:13:19,951] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:13:19,954] {{jobs.py:386}} INFO - Started process (PID=3978) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:13:20,223] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:13:20,224] {{logging_mixin.py:95}} INFO - [2019-10-04 17:13:20,224] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:13:20,741] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:13:28,444] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:13:28,769] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:13:28,778] {{logging_mixin.py:95}} INFO - [2019-10-04 17:13:28,778] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:13:28,779] {{logging_mixin.py:95}} INFO - [2019-10-04 17:13:28,779] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:08:28.779233+00:00
[2019-10-04 17:13:28,861] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 8.906 seconds
[2019-10-04 17:13:41,672] {{logging_mixin.py:95}} INFO - [2019-10-04 17:13:41,672] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:13:41,749] {{jobs.py:386}} INFO - Started process (PID=3987) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:13:41,932] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:13:41,934] {{logging_mixin.py:95}} INFO - [2019-10-04 17:13:41,934] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:13:43,344] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:13:44,884] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:13:45,050] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:13:45,058] {{logging_mixin.py:95}} INFO - [2019-10-04 17:13:45,058] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:13:45,059] {{logging_mixin.py:95}} INFO - [2019-10-04 17:13:45,058] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:08:45.058574+00:00
[2019-10-04 17:13:45,064] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.315 seconds
[2019-10-04 17:13:57,081] {{logging_mixin.py:95}} INFO - [2019-10-04 17:13:57,080] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:13:57,165] {{jobs.py:386}} INFO - Started process (PID=3991) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:13:57,930] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:13:57,931] {{logging_mixin.py:95}} INFO - [2019-10-04 17:13:57,931] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:13:59,342] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:14:13,748] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:14:14,119] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:14:14,127] {{logging_mixin.py:95}} INFO - [2019-10-04 17:14:14,127] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:14:14,128] {{logging_mixin.py:95}} INFO - [2019-10-04 17:14:14,128] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:09:14.128128+00:00
[2019-10-04 17:14:14,687] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 17.521 seconds
[2019-10-04 17:14:27,763] {{logging_mixin.py:95}} INFO - [2019-10-04 17:14:27,464] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:14:28,105] {{jobs.py:386}} INFO - Started process (PID=4000) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:14:28,785] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:14:28,786] {{logging_mixin.py:95}} INFO - [2019-10-04 17:14:28,786] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:14:31,973] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:14:47,975] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:14:48,039] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:14:48,052] {{logging_mixin.py:95}} INFO - [2019-10-04 17:14:48,052] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:14:48,054] {{logging_mixin.py:95}} INFO - [2019-10-04 17:14:48,053] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:09:48.053591+00:00
[2019-10-04 17:14:48,501] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 20.395 seconds
[2019-10-04 17:15:00,085] {{logging_mixin.py:95}} INFO - [2019-10-04 17:15:00,084] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:15:00,257] {{jobs.py:386}} INFO - Started process (PID=4004) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:15:00,720] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:15:00,720] {{logging_mixin.py:95}} INFO - [2019-10-04 17:15:00,720] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:15:01,277] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:15:03,338] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:15:03,433] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:15:03,444] {{logging_mixin.py:95}} INFO - [2019-10-04 17:15:03,444] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:15:03,445] {{logging_mixin.py:95}} INFO - [2019-10-04 17:15:03,444] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:10:03.444834+00:00
[2019-10-04 17:15:03,451] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.193 seconds
[2019-10-04 17:15:14,328] {{logging_mixin.py:95}} INFO - [2019-10-04 17:15:14,328] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:15:14,343] {{jobs.py:386}} INFO - Started process (PID=4008) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:15:14,368] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:15:14,371] {{logging_mixin.py:95}} INFO - [2019-10-04 17:15:14,370] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:15:14,669] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:15:15,051] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:15:15,057] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:15:15,066] {{logging_mixin.py:95}} INFO - [2019-10-04 17:15:15,066] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:15:15,067] {{logging_mixin.py:95}} INFO - [2019-10-04 17:15:15,067] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:10:15.067393+00:00
[2019-10-04 17:15:15,098] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.756 seconds
[2019-10-04 17:15:25,912] {{logging_mixin.py:95}} INFO - [2019-10-04 17:15:25,911] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:15:26,017] {{jobs.py:386}} INFO - Started process (PID=4017) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:15:26,104] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:15:26,105] {{logging_mixin.py:95}} INFO - [2019-10-04 17:15:26,105] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:15:26,150] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:15:27,285] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:15:27,358] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:15:27,367] {{logging_mixin.py:95}} INFO - [2019-10-04 17:15:27,367] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:15:27,368] {{logging_mixin.py:95}} INFO - [2019-10-04 17:15:27,368] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:10:27.368049+00:00
[2019-10-04 17:15:27,376] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.358 seconds
[2019-10-04 17:15:38,652] {{logging_mixin.py:95}} INFO - [2019-10-04 17:15:38,510] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:15:38,761] {{jobs.py:386}} INFO - Started process (PID=4021) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:15:39,358] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:15:39,359] {{logging_mixin.py:95}} INFO - [2019-10-04 17:15:39,359] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:15:39,627] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:15:42,946] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:15:43,046] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:15:43,063] {{logging_mixin.py:95}} INFO - [2019-10-04 17:15:43,063] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:15:43,064] {{logging_mixin.py:95}} INFO - [2019-10-04 17:15:43,063] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:10:43.063515+00:00
[2019-10-04 17:15:43,071] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.309 seconds
[2019-10-04 17:15:54,025] {{logging_mixin.py:95}} INFO - [2019-10-04 17:15:54,025] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:15:54,033] {{jobs.py:386}} INFO - Started process (PID=4025) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:15:54,039] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:15:54,042] {{logging_mixin.py:95}} INFO - [2019-10-04 17:15:54,042] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:15:54,088] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:15:54,644] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:15:54,650] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:15:54,664] {{logging_mixin.py:95}} INFO - [2019-10-04 17:15:54,664] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:15:54,666] {{logging_mixin.py:95}} INFO - [2019-10-04 17:15:54,666] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:10:54.665986+00:00
[2019-10-04 17:15:54,675] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.642 seconds
[2019-10-04 17:16:05,285] {{logging_mixin.py:95}} INFO - [2019-10-04 17:16:05,284] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:16:05,328] {{jobs.py:386}} INFO - Started process (PID=4029) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:16:05,388] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:16:05,389] {{logging_mixin.py:95}} INFO - [2019-10-04 17:16:05,389] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:16:05,497] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:16:06,410] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:16:06,416] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:16:06,425] {{logging_mixin.py:95}} INFO - [2019-10-04 17:16:06,425] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:16:06,427] {{logging_mixin.py:95}} INFO - [2019-10-04 17:16:06,426] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:11:06.426570+00:00
[2019-10-04 17:16:06,436] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.108 seconds
[2019-10-04 17:16:18,157] {{logging_mixin.py:95}} INFO - [2019-10-04 17:16:18,156] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:16:18,164] {{jobs.py:386}} INFO - Started process (PID=4044) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:16:18,781] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:16:18,782] {{logging_mixin.py:95}} INFO - [2019-10-04 17:16:18,782] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:16:21,734] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:16:25,088] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:16:25,093] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:16:25,101] {{logging_mixin.py:95}} INFO - [2019-10-04 17:16:25,101] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:16:25,102] {{logging_mixin.py:95}} INFO - [2019-10-04 17:16:25,101] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:11:25.101583+00:00
[2019-10-04 17:16:25,251] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 7.087 seconds
[2019-10-04 17:16:35,781] {{logging_mixin.py:95}} INFO - [2019-10-04 17:16:35,781] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:16:35,785] {{jobs.py:386}} INFO - Started process (PID=4047) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:16:35,788] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:16:35,790] {{logging_mixin.py:95}} INFO - [2019-10-04 17:16:35,790] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:16:35,835] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:16:36,357] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:16:36,475] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:16:36,497] {{logging_mixin.py:95}} INFO - [2019-10-04 17:16:36,496] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:16:36,498] {{logging_mixin.py:95}} INFO - [2019-10-04 17:16:36,498] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:11:36.498138+00:00
[2019-10-04 17:16:36,506] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.721 seconds
[2019-10-04 17:16:48,457] {{logging_mixin.py:95}} INFO - [2019-10-04 17:16:48,387] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:16:48,460] {{jobs.py:386}} INFO - Started process (PID=4056) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:16:48,566] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:16:48,567] {{logging_mixin.py:95}} INFO - [2019-10-04 17:16:48,567] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:16:50,112] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:16:59,412] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:16:59,601] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:16:59,608] {{logging_mixin.py:95}} INFO - [2019-10-04 17:16:59,608] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:16:59,609] {{logging_mixin.py:95}} INFO - [2019-10-04 17:16:59,609] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:11:59.609123+00:00
[2019-10-04 17:16:59,625] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 11.165 seconds
[2019-10-04 17:17:11,224] {{logging_mixin.py:95}} INFO - [2019-10-04 17:17:11,224] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:17:11,382] {{jobs.py:386}} INFO - Started process (PID=4060) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:17:11,823] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:17:11,823] {{logging_mixin.py:95}} INFO - [2019-10-04 17:17:11,823] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:17:14,369] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:17:28,287] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:17:28,593] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:17:28,602] {{logging_mixin.py:95}} INFO - [2019-10-04 17:17:28,602] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:17:28,603] {{logging_mixin.py:95}} INFO - [2019-10-04 17:17:28,603] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:12:28.603114+00:00
[2019-10-04 17:17:29,776] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 18.394 seconds
[2019-10-04 17:17:44,413] {{logging_mixin.py:95}} INFO - [2019-10-04 17:17:44,136] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:17:44,513] {{jobs.py:386}} INFO - Started process (PID=4064) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:17:45,037] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:17:45,038] {{logging_mixin.py:95}} INFO - [2019-10-04 17:17:45,038] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:17:46,739] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:18:04,815] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 17:18:29,892] {{logging_mixin.py:95}} INFO - [2019-10-04 17:18:29,891] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:18:30,095] {{jobs.py:386}} INFO - Started process (PID=4072) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:18:31,805] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:18:31,807] {{logging_mixin.py:95}} INFO - [2019-10-04 17:18:31,807] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:18:35,033] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:18:56,473] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 17:19:11,170] {{logging_mixin.py:95}} INFO - [2019-10-04 17:19:11,170] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:19:11,343] {{jobs.py:386}} INFO - Started process (PID=4074) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:19:11,991] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:19:11,997] {{logging_mixin.py:95}} INFO - [2019-10-04 17:19:11,997] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:19:13,175] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:19:18,087] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:19:18,287] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:19:18,296] {{logging_mixin.py:95}} INFO - [2019-10-04 17:19:18,296] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:19:18,297] {{logging_mixin.py:95}} INFO - [2019-10-04 17:19:18,297] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:14:18.297086+00:00
[2019-10-04 17:19:18,304] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 6.961 seconds
[2019-10-04 17:19:30,317] {{logging_mixin.py:95}} INFO - [2019-10-04 17:19:30,317] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:19:30,321] {{jobs.py:386}} INFO - Started process (PID=4078) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:19:30,523] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:19:30,525] {{logging_mixin.py:95}} INFO - [2019-10-04 17:19:30,525] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:19:30,565] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:19:32,770] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:19:33,045] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:19:33,053] {{logging_mixin.py:95}} INFO - [2019-10-04 17:19:33,053] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:19:33,055] {{logging_mixin.py:95}} INFO - [2019-10-04 17:19:33,054] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:14:33.054710+00:00
[2019-10-04 17:19:33,061] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.741 seconds
[2019-10-04 17:19:43,887] {{logging_mixin.py:95}} INFO - [2019-10-04 17:19:43,886] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:19:43,895] {{jobs.py:386}} INFO - Started process (PID=4087) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:19:43,942] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:19:43,945] {{logging_mixin.py:95}} INFO - [2019-10-04 17:19:43,945] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:19:44,082] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:19:44,283] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:19:44,288] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:19:44,297] {{logging_mixin.py:95}} INFO - [2019-10-04 17:19:44,297] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:19:44,298] {{logging_mixin.py:95}} INFO - [2019-10-04 17:19:44,297] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:14:44.297564+00:00
[2019-10-04 17:19:44,305] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.410 seconds
[2019-10-04 17:19:55,255] {{logging_mixin.py:95}} INFO - [2019-10-04 17:19:55,250] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:19:55,259] {{jobs.py:386}} INFO - Started process (PID=4091) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:19:55,261] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:19:55,262] {{logging_mixin.py:95}} INFO - [2019-10-04 17:19:55,262] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:19:55,287] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:19:55,563] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:19:55,571] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:19:55,582] {{logging_mixin.py:95}} INFO - [2019-10-04 17:19:55,582] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:19:55,583] {{logging_mixin.py:95}} INFO - [2019-10-04 17:19:55,583] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:14:55.583374+00:00
[2019-10-04 17:19:55,599] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.341 seconds
[2019-10-04 17:20:08,179] {{logging_mixin.py:95}} INFO - [2019-10-04 17:20:08,179] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:20:08,582] {{jobs.py:386}} INFO - Started process (PID=4095) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:20:10,047] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:20:10,049] {{logging_mixin.py:95}} INFO - [2019-10-04 17:20:10,049] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:20:11,586] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:20:19,448] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:20:19,559] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:20:19,568] {{logging_mixin.py:95}} INFO - [2019-10-04 17:20:19,567] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:20:19,570] {{logging_mixin.py:95}} INFO - [2019-10-04 17:20:19,569] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:15:19.569513+00:00
[2019-10-04 17:20:19,577] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 10.995 seconds
[2019-10-04 17:20:30,915] {{logging_mixin.py:95}} INFO - [2019-10-04 17:20:30,811] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:20:31,181] {{jobs.py:386}} INFO - Started process (PID=4104) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:20:32,529] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:20:32,530] {{logging_mixin.py:95}} INFO - [2019-10-04 17:20:32,530] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:20:33,452] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:20:42,129] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:20:42,525] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:20:42,533] {{logging_mixin.py:95}} INFO - [2019-10-04 17:20:42,533] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:20:42,534] {{logging_mixin.py:95}} INFO - [2019-10-04 17:20:42,534] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:15:42.534178+00:00
[2019-10-04 17:20:43,594] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 12.413 seconds
[2019-10-04 17:20:56,439] {{logging_mixin.py:95}} INFO - [2019-10-04 17:20:56,439] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:20:56,581] {{jobs.py:386}} INFO - Started process (PID=4108) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:20:57,412] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:20:57,413] {{logging_mixin.py:95}} INFO - [2019-10-04 17:20:57,413] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:20:59,261] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:21:11,032] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:21:11,532] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:21:11,540] {{logging_mixin.py:95}} INFO - [2019-10-04 17:21:11,540] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:21:11,542] {{logging_mixin.py:95}} INFO - [2019-10-04 17:21:11,541] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:16:11.541555+00:00
[2019-10-04 17:21:12,517] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 15.936 seconds
[2019-10-04 17:21:28,636] {{logging_mixin.py:95}} INFO - [2019-10-04 17:21:28,459] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:21:28,837] {{jobs.py:386}} INFO - Started process (PID=4120) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:21:29,686] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:21:29,688] {{logging_mixin.py:95}} INFO - [2019-10-04 17:21:29,687] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:21:33,050] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:21:48,230] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 17:22:05,530] {{logging_mixin.py:95}} INFO - [2019-10-04 17:22:05,530] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:22:05,635] {{jobs.py:386}} INFO - Started process (PID=4122) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:22:06,513] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:22:06,517] {{logging_mixin.py:95}} INFO - [2019-10-04 17:22:06,517] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:22:08,851] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:22:23,901] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:22:24,970] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:22:24,978] {{logging_mixin.py:95}} INFO - [2019-10-04 17:22:24,978] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:22:24,979] {{logging_mixin.py:95}} INFO - [2019-10-04 17:22:24,978] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:17:24.978885+00:00
[2019-10-04 17:22:26,254] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 20.619 seconds
[2019-10-04 17:22:44,826] {{logging_mixin.py:95}} INFO - [2019-10-04 17:22:44,786] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:22:45,225] {{jobs.py:386}} INFO - Started process (PID=4126) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:22:45,501] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:22:45,502] {{logging_mixin.py:95}} INFO - [2019-10-04 17:22:45,502] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:22:47,212] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:22:53,753] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:22:54,027] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:22:54,045] {{logging_mixin.py:95}} INFO - [2019-10-04 17:22:54,045] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:22:54,045] {{logging_mixin.py:95}} INFO - [2019-10-04 17:22:54,045] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:17:54.045470+00:00
[2019-10-04 17:22:54,051] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 8.826 seconds
[2019-10-04 17:23:04,860] {{logging_mixin.py:95}} INFO - [2019-10-04 17:23:04,859] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:23:04,863] {{jobs.py:386}} INFO - Started process (PID=4130) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:23:04,877] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:23:04,879] {{logging_mixin.py:95}} INFO - [2019-10-04 17:23:04,879] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:23:05,063] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:23:06,466] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:23:06,514] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:23:06,523] {{logging_mixin.py:95}} INFO - [2019-10-04 17:23:06,523] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:23:06,525] {{logging_mixin.py:95}} INFO - [2019-10-04 17:23:06,524] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:18:06.524857+00:00
[2019-10-04 17:23:06,531] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.668 seconds
[2019-10-04 17:23:17,237] {{logging_mixin.py:95}} INFO - [2019-10-04 17:23:17,236] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:23:17,275] {{jobs.py:386}} INFO - Started process (PID=4134) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:23:17,341] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:23:17,343] {{logging_mixin.py:95}} INFO - [2019-10-04 17:23:17,343] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:23:17,663] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:23:18,546] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:23:18,625] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:23:18,633] {{logging_mixin.py:95}} INFO - [2019-10-04 17:23:18,633] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:23:18,634] {{logging_mixin.py:95}} INFO - [2019-10-04 17:23:18,634] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:18:18.634460+00:00
[2019-10-04 17:23:18,685] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.410 seconds
[2019-10-04 17:23:30,090] {{logging_mixin.py:95}} INFO - [2019-10-04 17:23:30,090] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:23:30,094] {{jobs.py:386}} INFO - Started process (PID=4143) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:23:30,100] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:23:30,104] {{logging_mixin.py:95}} INFO - [2019-10-04 17:23:30,104] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:23:30,138] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:23:30,546] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:23:30,552] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:23:30,562] {{logging_mixin.py:95}} INFO - [2019-10-04 17:23:30,562] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:23:30,562] {{logging_mixin.py:95}} INFO - [2019-10-04 17:23:30,562] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:18:30.562365+00:00
[2019-10-04 17:23:30,570] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.477 seconds
[2019-10-04 17:23:41,601] {{logging_mixin.py:95}} INFO - [2019-10-04 17:23:41,601] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:23:41,604] {{jobs.py:386}} INFO - Started process (PID=4147) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:23:41,610] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:23:41,613] {{logging_mixin.py:95}} INFO - [2019-10-04 17:23:41,613] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:23:41,743] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:23:42,282] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:23:42,292] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:23:42,301] {{logging_mixin.py:95}} INFO - [2019-10-04 17:23:42,301] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:23:42,302] {{logging_mixin.py:95}} INFO - [2019-10-04 17:23:42,302] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:18:42.302237+00:00
[2019-10-04 17:23:42,309] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.705 seconds
[2019-10-04 17:23:56,239] {{logging_mixin.py:95}} INFO - [2019-10-04 17:23:56,238] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:23:56,572] {{jobs.py:386}} INFO - Started process (PID=4151) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:23:57,404] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:23:57,405] {{logging_mixin.py:95}} INFO - [2019-10-04 17:23:57,405] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:24:00,035] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:24:07,967] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:24:07,999] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:24:08,008] {{logging_mixin.py:95}} INFO - [2019-10-04 17:24:08,008] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:24:08,010] {{logging_mixin.py:95}} INFO - [2019-10-04 17:24:08,009] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:19:08.009845+00:00
[2019-10-04 17:24:08,018] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 11.446 seconds
[2019-10-04 17:24:20,409] {{logging_mixin.py:95}} INFO - [2019-10-04 17:24:20,408] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:24:20,446] {{jobs.py:386}} INFO - Started process (PID=4160) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:24:20,844] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:24:20,844] {{logging_mixin.py:95}} INFO - [2019-10-04 17:24:20,844] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:24:21,898] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:24:29,725] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:24:30,200] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:24:30,208] {{logging_mixin.py:95}} INFO - [2019-10-04 17:24:30,208] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:24:30,210] {{logging_mixin.py:95}} INFO - [2019-10-04 17:24:30,209] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:19:30.209509+00:00
[2019-10-04 17:24:31,098] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 10.652 seconds
[2019-10-04 17:24:49,019] {{logging_mixin.py:95}} INFO - [2019-10-04 17:24:48,811] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:24:49,662] {{jobs.py:386}} INFO - Started process (PID=4164) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:24:51,314] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:24:51,315] {{logging_mixin.py:95}} INFO - [2019-10-04 17:24:51,315] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:24:53,599] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:25:04,591] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:25:05,182] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:25:05,325] {{logging_mixin.py:95}} INFO - [2019-10-04 17:25:05,325] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:25:05,327] {{logging_mixin.py:95}} INFO - [2019-10-04 17:25:05,326] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:20:05.326585+00:00
[2019-10-04 17:25:05,831] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 16.169 seconds
[2019-10-04 17:25:18,500] {{logging_mixin.py:95}} INFO - [2019-10-04 17:25:18,500] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:25:18,711] {{jobs.py:386}} INFO - Started process (PID=4173) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:25:19,774] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:25:19,776] {{logging_mixin.py:95}} INFO - [2019-10-04 17:25:19,776] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:25:22,242] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:25:27,482] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:25:27,488] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:25:27,496] {{logging_mixin.py:95}} INFO - [2019-10-04 17:25:27,496] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:25:27,498] {{logging_mixin.py:95}} INFO - [2019-10-04 17:25:27,497] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:20:27.497672+00:00
[2019-10-04 17:25:27,632] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 8.920 seconds
[2019-10-04 17:25:38,175] {{logging_mixin.py:95}} INFO - [2019-10-04 17:25:38,175] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:25:38,179] {{jobs.py:386}} INFO - Started process (PID=4177) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:25:38,181] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:25:38,181] {{logging_mixin.py:95}} INFO - [2019-10-04 17:25:38,181] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:25:38,221] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:25:38,751] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:25:38,757] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:25:38,764] {{logging_mixin.py:95}} INFO - [2019-10-04 17:25:38,764] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:25:38,765] {{logging_mixin.py:95}} INFO - [2019-10-04 17:25:38,764] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:20:38.764566+00:00
[2019-10-04 17:25:38,770] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.591 seconds
[2019-10-04 17:25:49,600] {{logging_mixin.py:95}} INFO - [2019-10-04 17:25:49,600] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:25:49,603] {{jobs.py:386}} INFO - Started process (PID=4181) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:25:49,773] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:25:49,775] {{logging_mixin.py:95}} INFO - [2019-10-04 17:25:49,775] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:25:50,210] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:25:51,656] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:25:51,662] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:25:51,671] {{logging_mixin.py:95}} INFO - [2019-10-04 17:25:51,671] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:25:51,672] {{logging_mixin.py:95}} INFO - [2019-10-04 17:25:51,672] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:20:51.672034+00:00
[2019-10-04 17:25:51,679] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.076 seconds
[2019-10-04 17:26:03,606] {{logging_mixin.py:95}} INFO - [2019-10-04 17:26:03,605] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:26:03,613] {{jobs.py:386}} INFO - Started process (PID=4192) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:26:03,741] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:26:03,742] {{logging_mixin.py:95}} INFO - [2019-10-04 17:26:03,742] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:26:04,487] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:26:07,391] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:26:07,576] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:26:07,585] {{logging_mixin.py:95}} INFO - [2019-10-04 17:26:07,585] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:26:07,586] {{logging_mixin.py:95}} INFO - [2019-10-04 17:26:07,586] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:21:07.586039+00:00
[2019-10-04 17:26:07,593] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.980 seconds
[2019-10-04 17:26:18,280] {{logging_mixin.py:95}} INFO - [2019-10-04 17:26:18,279] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:26:18,284] {{jobs.py:386}} INFO - Started process (PID=4196) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:26:18,605] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:26:18,607] {{logging_mixin.py:95}} INFO - [2019-10-04 17:26:18,607] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:26:18,637] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:26:18,899] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:26:18,904] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:26:18,913] {{logging_mixin.py:95}} INFO - [2019-10-04 17:26:18,913] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:26:18,914] {{logging_mixin.py:95}} INFO - [2019-10-04 17:26:18,913] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:21:18.913958+00:00
[2019-10-04 17:26:18,921] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.637 seconds
[2019-10-04 17:26:29,909] {{logging_mixin.py:95}} INFO - [2019-10-04 17:26:29,909] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:26:29,915] {{jobs.py:386}} INFO - Started process (PID=4200) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:26:29,918] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:26:29,920] {{logging_mixin.py:95}} INFO - [2019-10-04 17:26:29,920] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:26:29,951] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:26:30,197] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:26:30,203] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:26:30,211] {{logging_mixin.py:95}} INFO - [2019-10-04 17:26:30,211] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:26:30,286] {{logging_mixin.py:95}} INFO - [2019-10-04 17:26:30,285] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:21:30.285092+00:00
[2019-10-04 17:26:30,323] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.408 seconds
[2019-10-04 17:26:41,654] {{logging_mixin.py:95}} INFO - [2019-10-04 17:26:41,654] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:26:41,658] {{jobs.py:386}} INFO - Started process (PID=4213) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:26:42,079] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:26:42,080] {{logging_mixin.py:95}} INFO - [2019-10-04 17:26:42,080] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:26:43,561] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:26:45,275] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:26:45,372] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:26:45,386] {{logging_mixin.py:95}} INFO - [2019-10-04 17:26:45,386] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:26:45,388] {{logging_mixin.py:95}} INFO - [2019-10-04 17:26:45,387] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:21:45.387173+00:00
[2019-10-04 17:26:45,394] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.737 seconds
[2019-10-04 17:26:55,965] {{logging_mixin.py:95}} INFO - [2019-10-04 17:26:55,964] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:26:55,969] {{jobs.py:386}} INFO - Started process (PID=4217) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:26:55,972] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:26:55,973] {{logging_mixin.py:95}} INFO - [2019-10-04 17:26:55,973] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:26:55,997] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:26:56,958] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:26:57,101] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:26:57,109] {{logging_mixin.py:95}} INFO - [2019-10-04 17:26:57,109] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:26:57,110] {{logging_mixin.py:95}} INFO - [2019-10-04 17:26:57,110] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:21:57.110135+00:00
[2019-10-04 17:26:57,117] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.149 seconds
[2019-10-04 17:27:08,177] {{logging_mixin.py:95}} INFO - [2019-10-04 17:27:08,176] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:27:08,180] {{jobs.py:386}} INFO - Started process (PID=4222) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:27:08,182] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:27:08,183] {{logging_mixin.py:95}} INFO - [2019-10-04 17:27:08,183] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:27:08,211] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:27:20,329] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:27:20,917] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:27:20,927] {{logging_mixin.py:95}} INFO - [2019-10-04 17:27:20,927] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:27:20,928] {{logging_mixin.py:95}} INFO - [2019-10-04 17:27:20,927] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:22:20.927948+00:00
[2019-10-04 17:27:21,724] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 13.544 seconds
[2019-10-04 17:27:33,210] {{logging_mixin.py:95}} INFO - [2019-10-04 17:27:33,210] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:27:33,346] {{jobs.py:386}} INFO - Started process (PID=4230) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:27:33,703] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:27:33,704] {{logging_mixin.py:95}} INFO - [2019-10-04 17:27:33,704] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:27:34,987] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:27:55,909] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:27:57,732] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:27:57,740] {{logging_mixin.py:95}} INFO - [2019-10-04 17:27:57,740] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:27:57,744] {{logging_mixin.py:95}} INFO - [2019-10-04 17:27:57,743] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:22:57.743527+00:00
[2019-10-04 17:27:58,500] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 25.154 seconds
[2019-10-04 17:28:11,908] {{logging_mixin.py:95}} INFO - [2019-10-04 17:28:11,907] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:28:12,761] {{jobs.py:386}} INFO - Started process (PID=4234) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:28:13,293] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:28:13,294] {{logging_mixin.py:95}} INFO - [2019-10-04 17:28:13,294] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:28:16,390] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:28:28,800] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:28:29,322] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:28:29,373] {{logging_mixin.py:95}} INFO - [2019-10-04 17:28:29,373] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:28:29,374] {{logging_mixin.py:95}} INFO - [2019-10-04 17:28:29,374] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:23:29.374357+00:00
[2019-10-04 17:28:29,544] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 16.784 seconds
[2019-10-04 17:28:54,877] {{logging_mixin.py:95}} INFO - [2019-10-04 17:28:54,877] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:28:55,034] {{jobs.py:386}} INFO - Started process (PID=4247) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:28:57,315] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:28:57,316] {{logging_mixin.py:95}} INFO - [2019-10-04 17:28:57,316] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:29:04,276] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:29:14,962] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:29:15,387] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:29:15,395] {{logging_mixin.py:95}} INFO - [2019-10-04 17:29:15,395] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:29:15,397] {{logging_mixin.py:95}} INFO - [2019-10-04 17:29:15,396] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:24:15.396499+00:00
[2019-10-04 17:29:15,980] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 20.946 seconds
[2019-10-04 17:29:29,192] {{logging_mixin.py:95}} INFO - [2019-10-04 17:29:29,192] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:29:29,532] {{jobs.py:386}} INFO - Started process (PID=4251) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:29:30,773] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:29:30,775] {{logging_mixin.py:95}} INFO - [2019-10-04 17:29:30,775] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:29:33,755] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:29:43,789] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:29:43,812] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:29:43,820] {{logging_mixin.py:95}} INFO - [2019-10-04 17:29:43,820] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:29:43,821] {{logging_mixin.py:95}} INFO - [2019-10-04 17:29:43,820] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:24:43.820744+00:00
[2019-10-04 17:29:44,829] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 15.296 seconds
[2019-10-04 17:29:58,020] {{logging_mixin.py:95}} INFO - [2019-10-04 17:29:58,019] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:29:58,075] {{jobs.py:386}} INFO - Started process (PID=4255) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:29:59,626] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:29:59,627] {{logging_mixin.py:95}} INFO - [2019-10-04 17:29:59,626] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:30:01,352] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:30:17,364] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 17:30:33,856] {{logging_mixin.py:95}} INFO - [2019-10-04 17:30:33,856] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:30:34,429] {{jobs.py:386}} INFO - Started process (PID=4264) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:30:36,219] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:30:36,220] {{logging_mixin.py:95}} INFO - [2019-10-04 17:30:36,220] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:30:42,428] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:30:56,279] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:30:56,306] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:30:56,443] {{logging_mixin.py:95}} INFO - [2019-10-04 17:30:56,443] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:30:56,599] {{logging_mixin.py:95}} INFO - [2019-10-04 17:30:56,599] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:25:56.599126+00:00
[2019-10-04 17:30:58,173] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 23.743 seconds
[2019-10-04 17:31:11,712] {{logging_mixin.py:95}} INFO - [2019-10-04 17:31:11,656] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:31:12,169] {{jobs.py:386}} INFO - Started process (PID=4268) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:31:14,180] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:31:14,181] {{logging_mixin.py:95}} INFO - [2019-10-04 17:31:14,181] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:31:16,182] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:31:28,044] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:31:28,412] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:31:28,421] {{logging_mixin.py:95}} INFO - [2019-10-04 17:31:28,421] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:31:28,422] {{logging_mixin.py:95}} INFO - [2019-10-04 17:31:28,422] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:26:28.422484+00:00
[2019-10-04 17:31:29,413] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 17.244 seconds
[2019-10-04 17:31:45,209] {{logging_mixin.py:95}} INFO - [2019-10-04 17:31:45,010] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:31:45,401] {{jobs.py:386}} INFO - Started process (PID=4281) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:31:47,455] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:31:47,456] {{logging_mixin.py:95}} INFO - [2019-10-04 17:31:47,456] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:31:54,563] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:32:12,224] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:32:13,685] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:32:13,695] {{logging_mixin.py:95}} INFO - [2019-10-04 17:32:13,695] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:32:13,696] {{logging_mixin.py:95}} INFO - [2019-10-04 17:32:13,696] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:27:13.696168+00:00
[2019-10-04 17:32:17,011] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 31.610 seconds
[2019-10-04 17:32:31,117] {{logging_mixin.py:95}} INFO - [2019-10-04 17:32:31,117] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:32:31,191] {{jobs.py:386}} INFO - Started process (PID=4285) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:32:31,956] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:32:31,958] {{logging_mixin.py:95}} INFO - [2019-10-04 17:32:31,957] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:32:33,904] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:32:59,706] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 17:33:23,863] {{logging_mixin.py:95}} INFO - [2019-10-04 17:33:23,757] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:33:24,339] {{jobs.py:386}} INFO - Started process (PID=4287) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:33:25,478] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:33:25,479] {{logging_mixin.py:95}} INFO - [2019-10-04 17:33:25,479] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:33:27,601] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:33:49,406] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 17:34:28,627] {{logging_mixin.py:95}} INFO - [2019-10-04 17:34:28,277] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:34:28,711] {{jobs.py:386}} INFO - Started process (PID=4289) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:34:30,096] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:34:30,097] {{logging_mixin.py:95}} INFO - [2019-10-04 17:34:30,097] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:34:32,407] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:34:53,678] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 17:35:32,557] {{logging_mixin.py:95}} INFO - [2019-10-04 17:35:32,432] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:35:32,817] {{jobs.py:386}} INFO - Started process (PID=4291) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:35:34,394] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:35:34,395] {{logging_mixin.py:95}} INFO - [2019-10-04 17:35:34,395] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:35:43,537] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:36:12,014] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 17:36:44,199] {{logging_mixin.py:95}} INFO - [2019-10-04 17:36:43,985] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:36:44,430] {{jobs.py:386}} INFO - Started process (PID=4293) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:36:44,719] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:36:44,721] {{logging_mixin.py:95}} INFO - [2019-10-04 17:36:44,721] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:36:46,787] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:37:08,248] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 17:37:30,060] {{logging_mixin.py:95}} INFO - [2019-10-04 17:37:30,025] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:37:30,078] {{jobs.py:386}} INFO - Started process (PID=4295) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:37:30,450] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:37:30,452] {{logging_mixin.py:95}} INFO - [2019-10-04 17:37:30,452] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:37:31,366] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:37:52,970] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 17:38:12,652] {{logging_mixin.py:95}} INFO - [2019-10-04 17:38:12,652] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:38:12,717] {{jobs.py:386}} INFO - Started process (PID=4297) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:38:13,101] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:38:13,102] {{logging_mixin.py:95}} INFO - [2019-10-04 17:38:13,102] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:38:15,479] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:38:26,002] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:38:26,354] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:38:26,363] {{logging_mixin.py:95}} INFO - [2019-10-04 17:38:26,363] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:38:26,364] {{logging_mixin.py:95}} INFO - [2019-10-04 17:38:26,364] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:33:26.364130+00:00
[2019-10-04 17:38:27,414] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 14.697 seconds
[2019-10-04 17:38:41,334] {{logging_mixin.py:95}} INFO - [2019-10-04 17:38:41,205] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:38:41,623] {{jobs.py:386}} INFO - Started process (PID=4301) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:38:43,427] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:38:43,428] {{logging_mixin.py:95}} INFO - [2019-10-04 17:38:43,428] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:38:44,326] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:38:55,848] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 17:39:08,357] {{logging_mixin.py:95}} INFO - [2019-10-04 17:39:08,357] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:39:08,361] {{jobs.py:386}} INFO - Started process (PID=4308) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:39:08,440] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:39:08,440] {{logging_mixin.py:95}} INFO - [2019-10-04 17:39:08,440] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:39:08,705] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:39:12,020] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:39:12,208] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:39:12,214] {{logging_mixin.py:95}} INFO - [2019-10-04 17:39:12,214] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:39:12,214] {{logging_mixin.py:95}} INFO - [2019-10-04 17:39:12,214] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:34:12.214326+00:00
[2019-10-04 17:39:12,220] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.859 seconds
[2019-10-04 17:39:23,007] {{logging_mixin.py:95}} INFO - [2019-10-04 17:39:23,007] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:39:23,010] {{jobs.py:386}} INFO - Started process (PID=4312) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:39:23,013] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:39:23,014] {{logging_mixin.py:95}} INFO - [2019-10-04 17:39:23,014] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:39:23,030] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:39:23,491] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:39:23,508] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:39:23,516] {{logging_mixin.py:95}} INFO - [2019-10-04 17:39:23,516] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:39:23,518] {{logging_mixin.py:95}} INFO - [2019-10-04 17:39:23,517] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:34:23.517914+00:00
[2019-10-04 17:39:23,526] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.516 seconds
[2019-10-04 17:39:34,970] {{logging_mixin.py:95}} INFO - [2019-10-04 17:39:34,970] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:39:34,974] {{jobs.py:386}} INFO - Started process (PID=4316) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:39:34,976] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:39:34,977] {{logging_mixin.py:95}} INFO - [2019-10-04 17:39:34,977] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:39:34,999] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:39:35,203] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:39:35,211] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:39:35,220] {{logging_mixin.py:95}} INFO - [2019-10-04 17:39:35,220] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:39:35,222] {{logging_mixin.py:95}} INFO - [2019-10-04 17:39:35,221] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:34:35.221272+00:00
[2019-10-04 17:39:35,229] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.256 seconds
[2019-10-04 17:39:46,465] {{logging_mixin.py:95}} INFO - [2019-10-04 17:39:46,465] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:39:46,468] {{jobs.py:386}} INFO - Started process (PID=4325) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:39:46,471] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:39:46,476] {{logging_mixin.py:95}} INFO - [2019-10-04 17:39:46,476] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:39:46,494] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:39:46,747] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:39:46,751] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:39:46,761] {{logging_mixin.py:95}} INFO - [2019-10-04 17:39:46,761] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:39:46,763] {{logging_mixin.py:95}} INFO - [2019-10-04 17:39:46,763] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:34:46.763185+00:00
[2019-10-04 17:39:46,771] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.303 seconds
[2019-10-04 17:39:58,589] {{logging_mixin.py:95}} INFO - [2019-10-04 17:39:58,485] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:39:58,694] {{jobs.py:386}} INFO - Started process (PID=4329) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:39:58,779] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:39:58,780] {{logging_mixin.py:95}} INFO - [2019-10-04 17:39:58,780] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:40:00,345] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:40:04,018] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:40:04,023] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:40:04,031] {{logging_mixin.py:95}} INFO - [2019-10-04 17:40:04,031] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:40:04,032] {{logging_mixin.py:95}} INFO - [2019-10-04 17:40:04,032] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:35:04.032000+00:00
[2019-10-04 17:40:04,038] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.345 seconds
[2019-10-04 17:40:15,211] {{logging_mixin.py:95}} INFO - [2019-10-04 17:40:15,211] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:40:15,215] {{jobs.py:386}} INFO - Started process (PID=4338) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:40:15,225] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:40:15,227] {{logging_mixin.py:95}} INFO - [2019-10-04 17:40:15,227] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:40:15,257] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:40:15,416] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:40:15,422] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:40:15,432] {{logging_mixin.py:95}} INFO - [2019-10-04 17:40:15,432] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:40:15,433] {{logging_mixin.py:95}} INFO - [2019-10-04 17:40:15,433] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:35:15.433347+00:00
[2019-10-04 17:40:15,441] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.226 seconds
[2019-10-04 17:40:26,535] {{logging_mixin.py:95}} INFO - [2019-10-04 17:40:26,535] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:40:26,540] {{jobs.py:386}} INFO - Started process (PID=4342) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:40:26,553] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:40:26,556] {{logging_mixin.py:95}} INFO - [2019-10-04 17:40:26,556] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:40:26,591] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:40:26,728] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:40:26,734] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:40:26,744] {{logging_mixin.py:95}} INFO - [2019-10-04 17:40:26,744] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:40:26,746] {{logging_mixin.py:95}} INFO - [2019-10-04 17:40:26,745] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:35:26.745760+00:00
[2019-10-04 17:40:26,755] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.215 seconds
[2019-10-04 17:40:39,007] {{logging_mixin.py:95}} INFO - [2019-10-04 17:40:39,007] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:40:39,112] {{jobs.py:386}} INFO - Started process (PID=4346) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:40:39,747] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:40:39,748] {{logging_mixin.py:95}} INFO - [2019-10-04 17:40:39,748] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:40:40,757] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:40:43,814] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:40:43,894] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:40:43,904] {{logging_mixin.py:95}} INFO - [2019-10-04 17:40:43,904] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:40:43,905] {{logging_mixin.py:95}} INFO - [2019-10-04 17:40:43,905] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:35:43.905357+00:00
[2019-10-04 17:40:44,095] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.983 seconds
[2019-10-04 17:40:54,634] {{logging_mixin.py:95}} INFO - [2019-10-04 17:40:54,634] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:40:54,638] {{jobs.py:386}} INFO - Started process (PID=4355) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:40:54,641] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:40:54,642] {{logging_mixin.py:95}} INFO - [2019-10-04 17:40:54,641] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:40:54,682] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:40:54,791] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:40:54,797] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:40:54,807] {{logging_mixin.py:95}} INFO - [2019-10-04 17:40:54,807] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:40:54,809] {{logging_mixin.py:95}} INFO - [2019-10-04 17:40:54,808] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:35:54.808628+00:00
[2019-10-04 17:40:54,823] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.185 seconds
[2019-10-04 17:41:05,988] {{logging_mixin.py:95}} INFO - [2019-10-04 17:41:05,988] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:41:05,991] {{jobs.py:386}} INFO - Started process (PID=4359) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:41:05,995] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:41:06,000] {{logging_mixin.py:95}} INFO - [2019-10-04 17:41:06,000] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:41:06,042] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:41:06,545] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:41:06,557] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:41:06,567] {{logging_mixin.py:95}} INFO - [2019-10-04 17:41:06,567] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:41:06,569] {{logging_mixin.py:95}} INFO - [2019-10-04 17:41:06,568] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:36:06.568384+00:00
[2019-10-04 17:41:06,576] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.585 seconds
[2019-10-04 17:41:17,309] {{logging_mixin.py:95}} INFO - [2019-10-04 17:41:17,309] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:41:17,313] {{jobs.py:386}} INFO - Started process (PID=4363) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:41:17,319] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:41:17,320] {{logging_mixin.py:95}} INFO - [2019-10-04 17:41:17,320] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:41:17,352] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:41:17,524] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:41:17,536] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:41:17,571] {{logging_mixin.py:95}} INFO - [2019-10-04 17:41:17,570] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:41:17,572] {{logging_mixin.py:95}} INFO - [2019-10-04 17:41:17,572] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:36:17.571994+00:00
[2019-10-04 17:41:17,578] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.265 seconds
[2019-10-04 17:41:29,693] {{logging_mixin.py:95}} INFO - [2019-10-04 17:41:29,669] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:41:29,817] {{jobs.py:386}} INFO - Started process (PID=4372) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:41:30,203] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:41:30,204] {{logging_mixin.py:95}} INFO - [2019-10-04 17:41:30,204] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:41:31,121] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:41:31,651] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:41:31,675] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:41:31,685] {{logging_mixin.py:95}} INFO - [2019-10-04 17:41:31,685] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:41:31,686] {{logging_mixin.py:95}} INFO - [2019-10-04 17:41:31,686] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:36:31.686044+00:00
[2019-10-04 17:41:31,700] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.883 seconds
[2019-10-04 17:41:43,540] {{logging_mixin.py:95}} INFO - [2019-10-04 17:41:43,539] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:41:43,616] {{jobs.py:386}} INFO - Started process (PID=4376) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:41:44,664] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:41:44,666] {{logging_mixin.py:95}} INFO - [2019-10-04 17:41:44,666] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:41:46,339] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:41:51,475] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:41:51,481] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:41:51,491] {{logging_mixin.py:95}} INFO - [2019-10-04 17:41:51,491] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:41:51,493] {{logging_mixin.py:95}} INFO - [2019-10-04 17:41:51,493] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:36:51.492981+00:00
[2019-10-04 17:41:51,503] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 7.886 seconds
[2019-10-04 17:42:03,133] {{logging_mixin.py:95}} INFO - [2019-10-04 17:42:03,132] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:42:03,136] {{jobs.py:386}} INFO - Started process (PID=4385) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:42:03,139] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:42:03,142] {{logging_mixin.py:95}} INFO - [2019-10-04 17:42:03,142] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:42:03,190] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:42:03,521] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:42:03,528] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:42:03,541] {{logging_mixin.py:95}} INFO - [2019-10-04 17:42:03,540] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:42:03,543] {{logging_mixin.py:95}} INFO - [2019-10-04 17:42:03,542] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:37:03.542550+00:00
[2019-10-04 17:42:03,550] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.413 seconds
[2019-10-04 17:42:16,208] {{logging_mixin.py:95}} INFO - [2019-10-04 17:42:16,153] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:42:16,212] {{jobs.py:386}} INFO - Started process (PID=4389) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:42:17,723] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:42:17,725] {{logging_mixin.py:95}} INFO - [2019-10-04 17:42:17,725] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:42:19,853] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:42:26,505] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:42:26,544] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:42:26,553] {{logging_mixin.py:95}} INFO - [2019-10-04 17:42:26,552] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:42:26,554] {{logging_mixin.py:95}} INFO - [2019-10-04 17:42:26,553] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:37:26.553187+00:00
[2019-10-04 17:42:26,564] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 10.352 seconds
[2019-10-04 17:42:37,553] {{logging_mixin.py:95}} INFO - [2019-10-04 17:42:37,552] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:42:37,569] {{jobs.py:386}} INFO - Started process (PID=4399) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:42:37,606] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:42:37,609] {{logging_mixin.py:95}} INFO - [2019-10-04 17:42:37,609] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:42:37,689] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:42:38,293] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:42:38,425] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:42:38,434] {{logging_mixin.py:95}} INFO - [2019-10-04 17:42:38,434] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:42:38,435] {{logging_mixin.py:95}} INFO - [2019-10-04 17:42:38,435] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:37:38.435262+00:00
[2019-10-04 17:42:38,442] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.873 seconds
[2019-10-04 17:42:48,824] {{logging_mixin.py:95}} INFO - [2019-10-04 17:42:48,824] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:42:48,827] {{jobs.py:386}} INFO - Started process (PID=4403) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:42:48,830] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:42:48,831] {{logging_mixin.py:95}} INFO - [2019-10-04 17:42:48,831] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:42:48,854] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:42:48,960] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:42:48,966] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:42:48,977] {{logging_mixin.py:95}} INFO - [2019-10-04 17:42:48,977] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:42:48,979] {{logging_mixin.py:95}} INFO - [2019-10-04 17:42:48,978] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:37:48.978769+00:00
[2019-10-04 17:42:48,988] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.161 seconds
[2019-10-04 17:43:00,053] {{logging_mixin.py:95}} INFO - [2019-10-04 17:43:00,053] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:43:00,057] {{jobs.py:386}} INFO - Started process (PID=4407) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:43:00,059] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:43:00,060] {{logging_mixin.py:95}} INFO - [2019-10-04 17:43:00,060] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:43:01,088] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:43:01,815] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:43:01,820] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:43:01,829] {{logging_mixin.py:95}} INFO - [2019-10-04 17:43:01,829] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:43:01,839] {{logging_mixin.py:95}} INFO - [2019-10-04 17:43:01,833] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:38:01.833914+00:00
[2019-10-04 17:43:01,999] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.942 seconds
[2019-10-04 17:43:13,190] {{logging_mixin.py:95}} INFO - [2019-10-04 17:43:13,190] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:43:13,227] {{jobs.py:386}} INFO - Started process (PID=4418) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:43:13,230] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:43:13,231] {{logging_mixin.py:95}} INFO - [2019-10-04 17:43:13,231] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:43:13,543] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:43:13,938] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:43:13,943] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:43:13,954] {{logging_mixin.py:95}} INFO - [2019-10-04 17:43:13,954] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:43:13,956] {{logging_mixin.py:95}} INFO - [2019-10-04 17:43:13,955] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:38:13.955249+00:00
[2019-10-04 17:43:13,964] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.737 seconds
[2019-10-04 17:43:25,480] {{logging_mixin.py:95}} INFO - [2019-10-04 17:43:25,479] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:43:25,484] {{jobs.py:386}} INFO - Started process (PID=4422) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:43:25,768] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:43:25,772] {{logging_mixin.py:95}} INFO - [2019-10-04 17:43:25,771] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:43:25,984] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:43:26,298] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:43:26,529] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:43:26,606] {{logging_mixin.py:95}} INFO - [2019-10-04 17:43:26,606] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:43:26,609] {{logging_mixin.py:95}} INFO - [2019-10-04 17:43:26,608] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:38:26.608878+00:00
[2019-10-04 17:43:26,617] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.133 seconds
[2019-10-04 17:43:38,469] {{logging_mixin.py:95}} INFO - [2019-10-04 17:43:38,469] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:43:38,505] {{jobs.py:386}} INFO - Started process (PID=4426) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:43:38,585] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:43:38,586] {{logging_mixin.py:95}} INFO - [2019-10-04 17:43:38,586] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:43:38,701] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:43:40,064] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:43:40,072] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:43:40,081] {{logging_mixin.py:95}} INFO - [2019-10-04 17:43:40,081] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:43:40,082] {{logging_mixin.py:95}} INFO - [2019-10-04 17:43:40,081] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:38:40.081544+00:00
[2019-10-04 17:43:40,090] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.585 seconds
[2019-10-04 17:43:52,065] {{logging_mixin.py:95}} INFO - [2019-10-04 17:43:52,064] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:43:52,350] {{jobs.py:386}} INFO - Started process (PID=4430) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:43:53,472] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:43:53,473] {{logging_mixin.py:95}} INFO - [2019-10-04 17:43:53,473] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:43:55,637] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:44:01,747] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:44:01,971] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:44:01,979] {{logging_mixin.py:95}} INFO - [2019-10-04 17:44:01,979] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:44:01,985] {{logging_mixin.py:95}} INFO - [2019-10-04 17:44:01,983] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:39:01.983764+00:00
[2019-10-04 17:44:02,294] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 9.944 seconds
[2019-10-04 17:44:17,342] {{logging_mixin.py:95}} INFO - [2019-10-04 17:44:16,375] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:44:18,286] {{jobs.py:386}} INFO - Started process (PID=4443) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:44:19,707] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:44:19,708] {{logging_mixin.py:95}} INFO - [2019-10-04 17:44:19,708] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:44:21,156] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:44:29,037] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:44:29,187] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:44:29,194] {{logging_mixin.py:95}} INFO - [2019-10-04 17:44:29,194] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:44:29,196] {{logging_mixin.py:95}} INFO - [2019-10-04 17:44:29,195] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:39:29.195616+00:00
[2019-10-04 17:44:29,237] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 10.951 seconds
[2019-10-04 17:44:42,314] {{logging_mixin.py:95}} INFO - [2019-10-04 17:44:42,314] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:44:42,359] {{jobs.py:386}} INFO - Started process (PID=4447) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:44:42,915] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:44:42,916] {{logging_mixin.py:95}} INFO - [2019-10-04 17:44:42,916] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:44:43,656] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:44:48,684] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:44:48,753] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:44:48,760] {{logging_mixin.py:95}} INFO - [2019-10-04 17:44:48,760] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:44:48,763] {{logging_mixin.py:95}} INFO - [2019-10-04 17:44:48,761] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:39:48.761694+00:00
[2019-10-04 17:44:48,770] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 6.411 seconds
[2019-10-04 17:44:59,735] {{logging_mixin.py:95}} INFO - [2019-10-04 17:44:59,735] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:44:59,745] {{jobs.py:386}} INFO - Started process (PID=4456) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:44:59,754] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:44:59,755] {{logging_mixin.py:95}} INFO - [2019-10-04 17:44:59,755] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:44:59,796] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:45:00,364] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:45:00,374] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:45:00,381] {{logging_mixin.py:95}} INFO - [2019-10-04 17:45:00,381] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:45:00,383] {{logging_mixin.py:95}} INFO - [2019-10-04 17:45:00,382] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:40:00.382655+00:00
[2019-10-04 17:45:00,391] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.647 seconds
[2019-10-04 17:45:11,206] {{logging_mixin.py:95}} INFO - [2019-10-04 17:45:11,206] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:45:11,211] {{jobs.py:386}} INFO - Started process (PID=4460) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:45:11,220] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:45:11,223] {{logging_mixin.py:95}} INFO - [2019-10-04 17:45:11,222] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:45:11,259] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:45:11,573] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:45:11,581] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:45:11,592] {{logging_mixin.py:95}} INFO - [2019-10-04 17:45:11,592] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:45:11,598] {{logging_mixin.py:95}} INFO - [2019-10-04 17:45:11,598] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:40:11.598262+00:00
[2019-10-04 17:45:11,606] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.395 seconds
[2019-10-04 17:45:22,586] {{logging_mixin.py:95}} INFO - [2019-10-04 17:45:22,585] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:45:22,589] {{jobs.py:386}} INFO - Started process (PID=4464) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:45:22,593] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:45:22,600] {{logging_mixin.py:95}} INFO - [2019-10-04 17:45:22,599] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:45:22,633] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:45:23,072] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:45:23,157] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:45:23,218] {{logging_mixin.py:95}} INFO - [2019-10-04 17:45:23,218] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:45:23,219] {{logging_mixin.py:95}} INFO - [2019-10-04 17:45:23,218] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:40:23.218568+00:00
[2019-10-04 17:45:23,231] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.642 seconds
[2019-10-04 17:45:34,167] {{logging_mixin.py:95}} INFO - [2019-10-04 17:45:34,167] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:45:34,226] {{jobs.py:386}} INFO - Started process (PID=4477) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:45:34,302] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:45:34,303] {{logging_mixin.py:95}} INFO - [2019-10-04 17:45:34,303] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:45:34,332] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:45:34,591] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:45:34,597] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:45:34,606] {{logging_mixin.py:95}} INFO - [2019-10-04 17:45:34,606] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:45:34,608] {{logging_mixin.py:95}} INFO - [2019-10-04 17:45:34,607] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:40:34.607484+00:00
[2019-10-04 17:45:34,616] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.390 seconds
[2019-10-04 17:45:45,048] {{logging_mixin.py:95}} INFO - [2019-10-04 17:45:45,047] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:45:45,051] {{jobs.py:386}} INFO - Started process (PID=4481) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:45:45,055] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:45:45,061] {{logging_mixin.py:95}} INFO - [2019-10-04 17:45:45,061] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:45:45,125] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:45:45,603] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:45:45,608] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:45:45,621] {{logging_mixin.py:95}} INFO - [2019-10-04 17:45:45,620] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:45:45,622] {{logging_mixin.py:95}} INFO - [2019-10-04 17:45:45,621] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:40:45.621902+00:00
[2019-10-04 17:45:45,630] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.579 seconds
[2019-10-04 17:45:56,145] {{logging_mixin.py:95}} INFO - [2019-10-04 17:45:56,144] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:45:56,148] {{jobs.py:386}} INFO - Started process (PID=4485) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:45:56,150] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:45:56,150] {{logging_mixin.py:95}} INFO - [2019-10-04 17:45:56,150] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:45:56,178] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:45:56,352] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:45:56,358] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:45:56,369] {{logging_mixin.py:95}} INFO - [2019-10-04 17:45:56,369] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:45:56,369] {{logging_mixin.py:95}} INFO - [2019-10-04 17:45:56,369] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:40:56.369345+00:00
[2019-10-04 17:45:56,377] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.229 seconds
[2019-10-04 17:46:07,789] {{logging_mixin.py:95}} INFO - [2019-10-04 17:46:07,789] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:46:07,798] {{jobs.py:386}} INFO - Started process (PID=4494) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:46:08,011] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:46:08,013] {{logging_mixin.py:95}} INFO - [2019-10-04 17:46:08,013] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:46:08,500] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:46:09,126] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:46:09,131] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:46:09,143] {{logging_mixin.py:95}} INFO - [2019-10-04 17:46:09,143] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:46:09,145] {{logging_mixin.py:95}} INFO - [2019-10-04 17:46:09,144] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:41:09.144713+00:00
[2019-10-04 17:46:09,159] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.361 seconds
[2019-10-04 17:46:22,068] {{logging_mixin.py:95}} INFO - [2019-10-04 17:46:22,024] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:46:22,322] {{jobs.py:386}} INFO - Started process (PID=4498) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:46:23,460] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:46:23,462] {{logging_mixin.py:95}} INFO - [2019-10-04 17:46:23,461] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:46:25,578] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:46:38,847] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:46:39,625] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:46:39,637] {{logging_mixin.py:95}} INFO - [2019-10-04 17:46:39,637] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:46:39,638] {{logging_mixin.py:95}} INFO - [2019-10-04 17:46:39,638] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:41:39.638207+00:00
[2019-10-04 17:46:40,125] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 17.803 seconds
[2019-10-04 17:46:51,796] {{logging_mixin.py:95}} INFO - [2019-10-04 17:46:51,796] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:46:51,945] {{jobs.py:386}} INFO - Started process (PID=4507) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:46:52,891] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:46:52,892] {{logging_mixin.py:95}} INFO - [2019-10-04 17:46:52,891] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:46:53,996] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:46:55,715] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:46:55,721] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:46:55,729] {{logging_mixin.py:95}} INFO - [2019-10-04 17:46:55,729] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:46:55,731] {{logging_mixin.py:95}} INFO - [2019-10-04 17:46:55,730] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:41:55.730486+00:00
[2019-10-04 17:46:55,741] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.796 seconds
[2019-10-04 17:47:06,245] {{logging_mixin.py:95}} INFO - [2019-10-04 17:47:06,245] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:47:06,248] {{jobs.py:386}} INFO - Started process (PID=4511) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:47:06,252] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:47:06,253] {{logging_mixin.py:95}} INFO - [2019-10-04 17:47:06,253] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:47:06,274] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:47:06,587] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:47:06,593] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:47:06,602] {{logging_mixin.py:95}} INFO - [2019-10-04 17:47:06,602] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:47:06,604] {{logging_mixin.py:95}} INFO - [2019-10-04 17:47:06,603] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:42:06.603560+00:00
[2019-10-04 17:47:06,611] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.363 seconds
[2019-10-04 17:47:17,592] {{logging_mixin.py:95}} INFO - [2019-10-04 17:47:17,591] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:47:17,594] {{jobs.py:386}} INFO - Started process (PID=4515) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:47:17,597] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:47:17,599] {{logging_mixin.py:95}} INFO - [2019-10-04 17:47:17,599] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:47:17,621] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:47:17,772] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:47:17,778] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:47:17,787] {{logging_mixin.py:95}} INFO - [2019-10-04 17:47:17,787] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:47:17,788] {{logging_mixin.py:95}} INFO - [2019-10-04 17:47:17,788] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:42:17.788250+00:00
[2019-10-04 17:47:17,796] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.202 seconds
[2019-10-04 17:47:29,114] {{logging_mixin.py:95}} INFO - [2019-10-04 17:47:29,114] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:47:29,210] {{jobs.py:386}} INFO - Started process (PID=4524) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:47:29,550] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:47:29,566] {{logging_mixin.py:95}} INFO - [2019-10-04 17:47:29,566] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:47:30,808] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:47:32,618] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:47:32,690] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:47:32,762] {{logging_mixin.py:95}} INFO - [2019-10-04 17:47:32,762] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:47:32,764] {{logging_mixin.py:95}} INFO - [2019-10-04 17:47:32,763] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:42:32.763747+00:00
[2019-10-04 17:47:32,779] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.570 seconds
[2019-10-04 17:47:43,640] {{logging_mixin.py:95}} INFO - [2019-10-04 17:47:43,640] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:47:43,643] {{jobs.py:386}} INFO - Started process (PID=4528) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:47:43,924] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:47:43,925] {{logging_mixin.py:95}} INFO - [2019-10-04 17:47:43,925] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:47:44,128] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:47:44,704] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:47:44,713] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:47:44,723] {{logging_mixin.py:95}} INFO - [2019-10-04 17:47:44,723] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:47:44,725] {{logging_mixin.py:95}} INFO - [2019-10-04 17:47:44,724] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:42:44.724417+00:00
[2019-10-04 17:47:44,736] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.093 seconds
[2019-10-04 17:47:56,102] {{logging_mixin.py:95}} INFO - [2019-10-04 17:47:56,101] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:47:56,105] {{jobs.py:386}} INFO - Started process (PID=4537) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:47:56,109] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:47:56,110] {{logging_mixin.py:95}} INFO - [2019-10-04 17:47:56,110] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:47:56,143] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:47:56,346] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:47:56,380] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:47:56,389] {{logging_mixin.py:95}} INFO - [2019-10-04 17:47:56,389] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:47:56,390] {{logging_mixin.py:95}} INFO - [2019-10-04 17:47:56,390] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:42:56.390104+00:00
[2019-10-04 17:47:56,399] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.294 seconds
[2019-10-04 17:48:08,859] {{logging_mixin.py:95}} INFO - [2019-10-04 17:48:08,752] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:48:08,966] {{jobs.py:386}} INFO - Started process (PID=4541) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:48:09,315] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:48:09,317] {{logging_mixin.py:95}} INFO - [2019-10-04 17:48:09,317] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:48:11,046] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:48:14,371] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:48:14,422] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:48:14,439] {{logging_mixin.py:95}} INFO - [2019-10-04 17:48:14,439] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:48:14,441] {{logging_mixin.py:95}} INFO - [2019-10-04 17:48:14,441] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:43:14.441097+00:00
[2019-10-04 17:48:14,471] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.505 seconds
[2019-10-04 17:48:25,809] {{logging_mixin.py:95}} INFO - [2019-10-04 17:48:25,809] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:48:25,959] {{jobs.py:386}} INFO - Started process (PID=4550) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:48:26,556] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:48:26,558] {{logging_mixin.py:95}} INFO - [2019-10-04 17:48:26,557] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:48:27,579] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:48:42,046] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 17:48:58,152] {{logging_mixin.py:95}} INFO - [2019-10-04 17:48:58,151] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:48:58,314] {{jobs.py:386}} INFO - Started process (PID=4552) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:48:59,446] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:48:59,447] {{logging_mixin.py:95}} INFO - [2019-10-04 17:48:59,447] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:49:00,819] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:49:08,758] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:49:08,849] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:49:08,863] {{logging_mixin.py:95}} INFO - [2019-10-04 17:49:08,863] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:49:08,876] {{logging_mixin.py:95}} INFO - [2019-10-04 17:49:08,875] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:44:08.875558+00:00
[2019-10-04 17:49:09,752] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 11.438 seconds
[2019-10-04 17:49:22,097] {{logging_mixin.py:95}} INFO - [2019-10-04 17:49:22,096] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:49:22,305] {{jobs.py:386}} INFO - Started process (PID=4556) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:49:23,377] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:49:23,379] {{logging_mixin.py:95}} INFO - [2019-10-04 17:49:23,378] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:49:24,941] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:49:38,890] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 17:49:58,063] {{logging_mixin.py:95}} INFO - [2019-10-04 17:49:58,063] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:49:58,786] {{jobs.py:386}} INFO - Started process (PID=4558) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:50:01,067] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:50:01,070] {{logging_mixin.py:95}} INFO - [2019-10-04 17:50:01,070] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:50:03,846] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:50:10,703] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:50:10,876] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:50:10,883] {{logging_mixin.py:95}} INFO - [2019-10-04 17:50:10,883] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:50:10,885] {{logging_mixin.py:95}} INFO - [2019-10-04 17:50:10,884] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:45:10.884860+00:00
[2019-10-04 17:50:10,890] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 12.104 seconds
[2019-10-04 17:50:22,010] {{logging_mixin.py:95}} INFO - [2019-10-04 17:50:22,010] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:50:22,017] {{jobs.py:386}} INFO - Started process (PID=4567) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:50:22,021] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:50:22,021] {{logging_mixin.py:95}} INFO - [2019-10-04 17:50:22,021] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:50:22,066] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:50:22,251] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:50:22,257] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:50:22,265] {{logging_mixin.py:95}} INFO - [2019-10-04 17:50:22,265] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:50:22,266] {{logging_mixin.py:95}} INFO - [2019-10-04 17:50:22,266] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:45:22.266078+00:00
[2019-10-04 17:50:22,274] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.257 seconds
[2019-10-04 17:50:33,316] {{logging_mixin.py:95}} INFO - [2019-10-04 17:50:33,316] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:50:33,320] {{jobs.py:386}} INFO - Started process (PID=4571) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:50:33,325] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:50:33,327] {{logging_mixin.py:95}} INFO - [2019-10-04 17:50:33,327] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:50:33,368] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:50:33,563] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:50:33,569] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:50:33,578] {{logging_mixin.py:95}} INFO - [2019-10-04 17:50:33,578] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:50:33,580] {{logging_mixin.py:95}} INFO - [2019-10-04 17:50:33,579] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:45:33.579789+00:00
[2019-10-04 17:50:33,589] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.269 seconds
[2019-10-04 17:50:44,811] {{logging_mixin.py:95}} INFO - [2019-10-04 17:50:44,811] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:50:44,815] {{jobs.py:386}} INFO - Started process (PID=4580) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:50:44,822] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:50:44,823] {{logging_mixin.py:95}} INFO - [2019-10-04 17:50:44,823] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:50:44,854] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:50:45,657] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:50:45,668] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:50:45,680] {{logging_mixin.py:95}} INFO - [2019-10-04 17:50:45,679] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:50:45,681] {{logging_mixin.py:95}} INFO - [2019-10-04 17:50:45,680] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:45:45.680823+00:00
[2019-10-04 17:50:45,689] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.875 seconds
[2019-10-04 17:50:56,562] {{logging_mixin.py:95}} INFO - [2019-10-04 17:50:56,562] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:50:56,625] {{jobs.py:386}} INFO - Started process (PID=4584) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:50:57,240] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:50:57,241] {{logging_mixin.py:95}} INFO - [2019-10-04 17:50:57,241] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:50:57,758] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:50:59,571] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:50:59,671] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:50:59,682] {{logging_mixin.py:95}} INFO - [2019-10-04 17:50:59,682] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:50:59,683] {{logging_mixin.py:95}} INFO - [2019-10-04 17:50:59,683] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:45:59.683320+00:00
[2019-10-04 17:50:59,801] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.175 seconds
[2019-10-04 17:51:10,716] {{logging_mixin.py:95}} INFO - [2019-10-04 17:51:10,715] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:51:10,719] {{jobs.py:386}} INFO - Started process (PID=4588) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:51:10,935] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:51:10,936] {{logging_mixin.py:95}} INFO - [2019-10-04 17:51:10,936] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:51:10,977] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:51:11,520] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:51:11,527] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:51:11,535] {{logging_mixin.py:95}} INFO - [2019-10-04 17:51:11,535] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:51:11,537] {{logging_mixin.py:95}} INFO - [2019-10-04 17:51:11,536] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:46:11.536650+00:00
[2019-10-04 17:51:11,548] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.829 seconds
[2019-10-04 17:51:22,725] {{logging_mixin.py:95}} INFO - [2019-10-04 17:51:22,697] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:51:22,757] {{jobs.py:386}} INFO - Started process (PID=4597) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:51:22,850] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:51:22,851] {{logging_mixin.py:95}} INFO - [2019-10-04 17:51:22,851] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:51:23,271] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:51:27,999] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:51:28,005] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:51:28,019] {{logging_mixin.py:95}} INFO - [2019-10-04 17:51:28,019] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:51:28,020] {{logging_mixin.py:95}} INFO - [2019-10-04 17:51:28,020] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:46:28.020409+00:00
[2019-10-04 17:51:28,028] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.270 seconds
[2019-10-04 17:51:38,781] {{logging_mixin.py:95}} INFO - [2019-10-04 17:51:38,781] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:51:38,785] {{jobs.py:386}} INFO - Started process (PID=4601) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:51:38,791] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:51:38,797] {{logging_mixin.py:95}} INFO - [2019-10-04 17:51:38,797] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:51:39,011] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:51:39,499] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:51:39,673] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:51:39,683] {{logging_mixin.py:95}} INFO - [2019-10-04 17:51:39,683] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:51:39,685] {{logging_mixin.py:95}} INFO - [2019-10-04 17:51:39,684] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:46:39.684592+00:00
[2019-10-04 17:51:39,692] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.906 seconds
[2019-10-04 17:51:51,166] {{logging_mixin.py:95}} INFO - [2019-10-04 17:51:51,166] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:51:51,227] {{jobs.py:386}} INFO - Started process (PID=4610) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:51:51,765] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:51:51,766] {{logging_mixin.py:95}} INFO - [2019-10-04 17:51:51,766] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:51:53,170] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:52:04,390] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:52:04,550] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:52:04,560] {{logging_mixin.py:95}} INFO - [2019-10-04 17:52:04,559] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:52:04,561] {{logging_mixin.py:95}} INFO - [2019-10-04 17:52:04,561] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:47:04.561133+00:00
[2019-10-04 17:52:05,111] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 13.884 seconds
[2019-10-04 17:52:17,129] {{logging_mixin.py:95}} INFO - [2019-10-04 17:52:17,129] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:52:17,199] {{jobs.py:386}} INFO - Started process (PID=4614) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:52:17,871] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:52:17,872] {{logging_mixin.py:95}} INFO - [2019-10-04 17:52:17,872] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:52:18,977] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:52:19,803] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:52:19,808] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:52:19,816] {{logging_mixin.py:95}} INFO - [2019-10-04 17:52:19,816] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:52:19,818] {{logging_mixin.py:95}} INFO - [2019-10-04 17:52:19,817] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:47:19.817766+00:00
[2019-10-04 17:52:19,825] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.627 seconds
[2019-10-04 17:52:30,467] {{logging_mixin.py:95}} INFO - [2019-10-04 17:52:30,467] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:52:30,474] {{jobs.py:386}} INFO - Started process (PID=4618) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:52:30,476] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:52:30,478] {{logging_mixin.py:95}} INFO - [2019-10-04 17:52:30,478] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:52:30,511] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:52:30,667] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:52:30,673] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:52:30,683] {{logging_mixin.py:95}} INFO - [2019-10-04 17:52:30,683] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:52:30,685] {{logging_mixin.py:95}} INFO - [2019-10-04 17:52:30,684] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:47:30.683967+00:00
[2019-10-04 17:52:30,692] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.219 seconds
[2019-10-04 17:52:42,397] {{logging_mixin.py:95}} INFO - [2019-10-04 17:52:42,370] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:52:42,462] {{jobs.py:386}} INFO - Started process (PID=4627) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:52:42,538] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:52:42,539] {{logging_mixin.py:95}} INFO - [2019-10-04 17:52:42,539] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:52:43,016] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:52:44,602] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:52:44,609] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:52:44,677] {{logging_mixin.py:95}} INFO - [2019-10-04 17:52:44,676] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:52:44,679] {{logging_mixin.py:95}} INFO - [2019-10-04 17:52:44,678] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:47:44.678478+00:00
[2019-10-04 17:52:44,710] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.248 seconds
[2019-10-04 17:52:56,129] {{logging_mixin.py:95}} INFO - [2019-10-04 17:52:56,128] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:52:56,136] {{jobs.py:386}} INFO - Started process (PID=4631) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:52:56,146] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:52:56,148] {{logging_mixin.py:95}} INFO - [2019-10-04 17:52:56,148] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:52:56,183] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:52:56,490] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:52:56,495] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:52:57,080] {{logging_mixin.py:95}} INFO - [2019-10-04 17:52:57,080] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:52:57,081] {{logging_mixin.py:95}} INFO - [2019-10-04 17:52:57,081] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:47:57.081269+00:00
[2019-10-04 17:52:57,090] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.954 seconds
[2019-10-04 17:53:08,523] {{logging_mixin.py:95}} INFO - [2019-10-04 17:53:08,523] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:53:08,527] {{jobs.py:386}} INFO - Started process (PID=4640) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:53:08,529] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:53:08,530] {{logging_mixin.py:95}} INFO - [2019-10-04 17:53:08,530] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:53:08,625] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:53:08,827] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:53:08,834] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:53:08,844] {{logging_mixin.py:95}} INFO - [2019-10-04 17:53:08,844] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:53:08,846] {{logging_mixin.py:95}} INFO - [2019-10-04 17:53:08,845] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:48:08.845561+00:00
[2019-10-04 17:53:08,855] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.328 seconds
[2019-10-04 17:53:20,395] {{logging_mixin.py:95}} INFO - [2019-10-04 17:53:20,395] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:53:20,487] {{jobs.py:386}} INFO - Started process (PID=4644) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:53:20,826] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:53:20,827] {{logging_mixin.py:95}} INFO - [2019-10-04 17:53:20,827] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:53:21,094] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:53:24,894] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:53:24,901] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:53:24,911] {{logging_mixin.py:95}} INFO - [2019-10-04 17:53:24,911] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:53:24,912] {{logging_mixin.py:95}} INFO - [2019-10-04 17:53:24,912] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:48:24.912033+00:00
[2019-10-04 17:53:24,940] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.454 seconds
[2019-10-04 17:53:36,441] {{logging_mixin.py:95}} INFO - [2019-10-04 17:53:36,440] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:53:36,539] {{jobs.py:386}} INFO - Started process (PID=4648) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:53:37,046] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:53:37,047] {{logging_mixin.py:95}} INFO - [2019-10-04 17:53:37,047] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:53:42,183] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:53:53,168] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:53:53,178] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:53:53,187] {{logging_mixin.py:95}} INFO - [2019-10-04 17:53:53,187] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:53:53,187] {{logging_mixin.py:95}} INFO - [2019-10-04 17:53:53,187] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:48:53.187409+00:00
[2019-10-04 17:53:53,390] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 16.854 seconds
[2019-10-04 17:54:07,444] {{logging_mixin.py:95}} INFO - [2019-10-04 17:54:07,444] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:54:07,535] {{jobs.py:386}} INFO - Started process (PID=4661) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:54:08,881] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:54:08,882] {{logging_mixin.py:95}} INFO - [2019-10-04 17:54:08,882] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:54:11,354] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:54:18,868] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:54:18,894] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:54:18,975] {{logging_mixin.py:95}} INFO - [2019-10-04 17:54:18,975] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:54:18,987] {{logging_mixin.py:95}} INFO - [2019-10-04 17:54:18,986] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:49:18.986327+00:00
[2019-10-04 17:54:19,422] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 11.886 seconds
[2019-10-04 17:54:32,165] {{logging_mixin.py:95}} INFO - [2019-10-04 17:54:32,132] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:54:32,474] {{jobs.py:386}} INFO - Started process (PID=4665) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:54:33,510] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:54:33,511] {{logging_mixin.py:95}} INFO - [2019-10-04 17:54:33,511] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:54:34,991] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:54:45,098] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:54:45,428] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:54:45,436] {{logging_mixin.py:95}} INFO - [2019-10-04 17:54:45,436] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:54:45,438] {{logging_mixin.py:95}} INFO - [2019-10-04 17:54:45,437] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:49:45.437474+00:00
[2019-10-04 17:54:46,918] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 14.444 seconds
[2019-10-04 17:54:58,447] {{logging_mixin.py:95}} INFO - [2019-10-04 17:54:58,446] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:54:58,665] {{jobs.py:386}} INFO - Started process (PID=4674) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:54:59,423] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:54:59,425] {{logging_mixin.py:95}} INFO - [2019-10-04 17:54:59,424] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:55:02,759] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:55:04,156] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:55:04,161] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:55:04,169] {{logging_mixin.py:95}} INFO - [2019-10-04 17:55:04,169] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:55:04,170] {{logging_mixin.py:95}} INFO - [2019-10-04 17:55:04,169] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:50:04.169590+00:00
[2019-10-04 17:55:04,180] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.515 seconds
[2019-10-04 17:55:15,649] {{logging_mixin.py:95}} INFO - [2019-10-04 17:55:15,649] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:55:15,652] {{jobs.py:386}} INFO - Started process (PID=4680) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:55:15,656] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:55:15,656] {{logging_mixin.py:95}} INFO - [2019-10-04 17:55:15,656] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:55:15,687] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:55:15,783] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:55:15,791] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:55:15,800] {{logging_mixin.py:95}} INFO - [2019-10-04 17:55:15,800] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:55:15,802] {{logging_mixin.py:95}} INFO - [2019-10-04 17:55:15,802] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:50:15.802101+00:00
[2019-10-04 17:55:15,812] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.159 seconds
[2019-10-04 17:55:27,071] {{logging_mixin.py:95}} INFO - [2019-10-04 17:55:27,070] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:55:27,075] {{jobs.py:386}} INFO - Started process (PID=4684) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:55:27,079] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:55:27,080] {{logging_mixin.py:95}} INFO - [2019-10-04 17:55:27,080] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:55:27,142] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:55:27,578] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:55:27,584] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:55:27,599] {{logging_mixin.py:95}} INFO - [2019-10-04 17:55:27,599] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:55:27,601] {{logging_mixin.py:95}} INFO - [2019-10-04 17:55:27,600] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:50:27.600667+00:00
[2019-10-04 17:55:27,610] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.535 seconds
[2019-10-04 17:55:38,765] {{logging_mixin.py:95}} INFO - [2019-10-04 17:55:38,765] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:55:38,770] {{jobs.py:386}} INFO - Started process (PID=4692) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:55:38,773] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:55:38,774] {{logging_mixin.py:95}} INFO - [2019-10-04 17:55:38,774] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:55:38,798] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:55:39,110] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:55:39,197] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:55:39,206] {{logging_mixin.py:95}} INFO - [2019-10-04 17:55:39,205] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:55:39,207] {{logging_mixin.py:95}} INFO - [2019-10-04 17:55:39,206] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:50:39.206250+00:00
[2019-10-04 17:55:39,216] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.446 seconds
[2019-10-04 17:55:50,467] {{logging_mixin.py:95}} INFO - [2019-10-04 17:55:50,467] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:55:50,546] {{jobs.py:386}} INFO - Started process (PID=4695) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:55:51,002] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:55:51,003] {{logging_mixin.py:95}} INFO - [2019-10-04 17:55:51,003] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:55:51,860] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:55:54,367] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:55:54,415] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:55:54,424] {{logging_mixin.py:95}} INFO - [2019-10-04 17:55:54,424] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:55:54,425] {{logging_mixin.py:95}} INFO - [2019-10-04 17:55:54,425] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:50:54.425249+00:00
[2019-10-04 17:55:54,438] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.892 seconds
[2019-10-04 17:56:04,747] {{logging_mixin.py:95}} INFO - [2019-10-04 17:56:04,747] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:56:04,751] {{jobs.py:386}} INFO - Started process (PID=4699) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:56:04,755] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:56:04,767] {{logging_mixin.py:95}} INFO - [2019-10-04 17:56:04,767] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:56:04,801] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:56:05,177] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:56:05,182] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:56:05,192] {{logging_mixin.py:95}} INFO - [2019-10-04 17:56:05,192] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:56:05,195] {{logging_mixin.py:95}} INFO - [2019-10-04 17:56:05,193] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:51:05.193515+00:00
[2019-10-04 17:56:05,203] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.452 seconds
[2019-10-04 17:56:16,879] {{logging_mixin.py:95}} INFO - [2019-10-04 17:56:16,866] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:56:16,907] {{jobs.py:386}} INFO - Started process (PID=4708) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:56:17,092] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:56:17,094] {{logging_mixin.py:95}} INFO - [2019-10-04 17:56:17,093] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:56:17,559] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:56:21,661] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:56:21,846] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:56:21,856] {{logging_mixin.py:95}} INFO - [2019-10-04 17:56:21,856] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:56:21,860] {{logging_mixin.py:95}} INFO - [2019-10-04 17:56:21,859] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:51:21.859593+00:00
[2019-10-04 17:56:22,145] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.237 seconds
[2019-10-04 17:56:33,629] {{logging_mixin.py:95}} INFO - [2019-10-04 17:56:33,629] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:56:33,635] {{jobs.py:386}} INFO - Started process (PID=4712) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:56:34,016] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:56:34,019] {{logging_mixin.py:95}} INFO - [2019-10-04 17:56:34,018] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:56:35,354] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:56:42,227] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:56:42,462] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:56:42,472] {{logging_mixin.py:95}} INFO - [2019-10-04 17:56:42,472] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:56:42,474] {{logging_mixin.py:95}} INFO - [2019-10-04 17:56:42,473] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:51:42.473889+00:00
[2019-10-04 17:56:43,299] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 9.664 seconds
[2019-10-04 17:56:55,418] {{logging_mixin.py:95}} INFO - [2019-10-04 17:56:55,418] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:56:55,610] {{jobs.py:386}} INFO - Started process (PID=4716) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:56:56,466] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:56:56,467] {{logging_mixin.py:95}} INFO - [2019-10-04 17:56:56,467] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:56:58,192] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:57:00,197] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:57:00,202] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:57:00,208] {{logging_mixin.py:95}} INFO - [2019-10-04 17:57:00,208] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:57:00,209] {{logging_mixin.py:95}} INFO - [2019-10-04 17:57:00,209] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:52:00.209106+00:00
[2019-10-04 17:57:00,216] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.606 seconds
[2019-10-04 17:57:10,705] {{logging_mixin.py:95}} INFO - [2019-10-04 17:57:10,705] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:57:10,709] {{jobs.py:386}} INFO - Started process (PID=4725) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:57:10,711] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:57:10,712] {{logging_mixin.py:95}} INFO - [2019-10-04 17:57:10,712] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:57:10,733] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:57:10,886] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:57:10,894] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:57:10,904] {{logging_mixin.py:95}} INFO - [2019-10-04 17:57:10,904] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:57:10,904] {{logging_mixin.py:95}} INFO - [2019-10-04 17:57:10,904] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:52:10.904375+00:00
[2019-10-04 17:57:10,910] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.202 seconds
[2019-10-04 17:57:22,079] {{logging_mixin.py:95}} INFO - [2019-10-04 17:57:22,079] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:57:22,084] {{jobs.py:386}} INFO - Started process (PID=4729) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:57:22,086] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:57:22,087] {{logging_mixin.py:95}} INFO - [2019-10-04 17:57:22,087] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:57:22,109] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:57:22,344] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:57:22,350] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:57:22,359] {{logging_mixin.py:95}} INFO - [2019-10-04 17:57:22,359] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:57:22,360] {{logging_mixin.py:95}} INFO - [2019-10-04 17:57:22,359] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:52:22.359932+00:00
[2019-10-04 17:57:22,368] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.285 seconds
[2019-10-04 17:57:33,570] {{logging_mixin.py:95}} INFO - [2019-10-04 17:57:33,570] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:57:33,573] {{jobs.py:386}} INFO - Started process (PID=4743) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:57:33,576] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:57:33,577] {{logging_mixin.py:95}} INFO - [2019-10-04 17:57:33,577] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:57:33,601] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:57:34,186] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:57:34,192] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:57:34,201] {{logging_mixin.py:95}} INFO - [2019-10-04 17:57:34,201] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:57:34,203] {{logging_mixin.py:95}} INFO - [2019-10-04 17:57:34,202] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:52:34.202672+00:00
[2019-10-04 17:57:34,210] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.637 seconds
[2019-10-04 17:57:45,783] {{logging_mixin.py:95}} INFO - [2019-10-04 17:57:45,673] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:57:45,851] {{jobs.py:386}} INFO - Started process (PID=4747) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:57:46,480] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:57:46,481] {{logging_mixin.py:95}} INFO - [2019-10-04 17:57:46,480] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:57:47,788] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:57:48,624] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:57:48,660] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:57:48,668] {{logging_mixin.py:95}} INFO - [2019-10-04 17:57:48,668] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:57:48,669] {{logging_mixin.py:95}} INFO - [2019-10-04 17:57:48,668] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:52:48.668914+00:00
[2019-10-04 17:57:48,710] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.858 seconds
[2019-10-04 17:58:00,778] {{logging_mixin.py:95}} INFO - [2019-10-04 17:58:00,631] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:58:00,807] {{jobs.py:386}} INFO - Started process (PID=4751) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:58:01,063] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:58:01,064] {{logging_mixin.py:95}} INFO - [2019-10-04 17:58:01,064] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:58:02,064] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:58:06,017] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:58:06,151] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:58:06,159] {{logging_mixin.py:95}} INFO - [2019-10-04 17:58:06,159] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:58:06,161] {{logging_mixin.py:95}} INFO - [2019-10-04 17:58:06,160] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:53:06.160310+00:00
[2019-10-04 17:58:06,170] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 5.363 seconds
[2019-10-04 17:58:17,457] {{logging_mixin.py:95}} INFO - [2019-10-04 17:58:17,443] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:58:17,506] {{jobs.py:386}} INFO - Started process (PID=4760) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:58:18,154] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:58:18,155] {{logging_mixin.py:95}} INFO - [2019-10-04 17:58:18,155] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:58:18,940] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:58:37,750] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:58:38,618] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:58:38,626] {{logging_mixin.py:95}} INFO - [2019-10-04 17:58:38,626] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:58:38,628] {{logging_mixin.py:95}} INFO - [2019-10-04 17:58:38,627] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:53:38.627632+00:00
[2019-10-04 17:58:39,474] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 21.969 seconds
[2019-10-04 17:58:51,571] {{logging_mixin.py:95}} INFO - [2019-10-04 17:58:51,571] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:58:51,631] {{jobs.py:386}} INFO - Started process (PID=4772) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:58:51,805] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:58:51,805] {{logging_mixin.py:95}} INFO - [2019-10-04 17:58:51,805] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:58:53,237] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:58:53,562] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:58:53,576] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:58:53,592] {{logging_mixin.py:95}} INFO - [2019-10-04 17:58:53,592] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:58:53,593] {{logging_mixin.py:95}} INFO - [2019-10-04 17:58:53,593] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:53:53.593060+00:00
[2019-10-04 17:58:53,600] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.970 seconds
[2019-10-04 17:59:04,873] {{logging_mixin.py:95}} INFO - [2019-10-04 17:59:04,872] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:59:04,876] {{jobs.py:386}} INFO - Started process (PID=4776) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:59:04,880] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:59:04,881] {{logging_mixin.py:95}} INFO - [2019-10-04 17:59:04,881] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:59:04,940] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:59:05,338] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:59:05,375] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:59:05,466] {{logging_mixin.py:95}} INFO - [2019-10-04 17:59:05,466] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:59:05,486] {{logging_mixin.py:95}} INFO - [2019-10-04 17:59:05,485] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:54:05.485293+00:00
[2019-10-04 17:59:05,503] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.627 seconds
[2019-10-04 17:59:16,367] {{logging_mixin.py:95}} INFO - [2019-10-04 17:59:16,367] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:59:16,377] {{jobs.py:386}} INFO - Started process (PID=4780) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:59:16,518] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:59:16,519] {{logging_mixin.py:95}} INFO - [2019-10-04 17:59:16,518] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:59:16,649] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:59:17,074] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:59:17,081] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:59:17,091] {{logging_mixin.py:95}} INFO - [2019-10-04 17:59:17,090] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:59:17,092] {{logging_mixin.py:95}} INFO - [2019-10-04 17:59:17,092] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:54:17.092002+00:00
[2019-10-04 17:59:17,100] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.723 seconds
[2019-10-04 17:59:27,776] {{logging_mixin.py:95}} INFO - [2019-10-04 17:59:27,776] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:59:27,870] {{jobs.py:386}} INFO - Started process (PID=4789) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:59:28,003] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:59:28,007] {{logging_mixin.py:95}} INFO - [2019-10-04 17:59:28,007] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:59:28,604] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:59:29,638] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:59:29,644] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:59:29,653] {{logging_mixin.py:95}} INFO - [2019-10-04 17:59:29,653] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:59:29,655] {{logging_mixin.py:95}} INFO - [2019-10-04 17:59:29,654] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:54:29.654916+00:00
[2019-10-04 17:59:29,662] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.792 seconds
[2019-10-04 17:59:40,338] {{logging_mixin.py:95}} INFO - [2019-10-04 17:59:40,338] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:59:40,396] {{jobs.py:386}} INFO - Started process (PID=4793) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:59:40,602] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:59:40,658] {{logging_mixin.py:95}} INFO - [2019-10-04 17:59:40,658] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:59:40,707] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:59:41,263] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:59:41,347] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:59:41,356] {{logging_mixin.py:95}} INFO - [2019-10-04 17:59:41,356] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:59:41,358] {{logging_mixin.py:95}} INFO - [2019-10-04 17:59:41,357] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:54:41.357614+00:00
[2019-10-04 17:59:41,367] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.972 seconds
[2019-10-04 17:59:53,346] {{logging_mixin.py:95}} INFO - [2019-10-04 17:59:53,345] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 17:59:53,519] {{jobs.py:386}} INFO - Started process (PID=4797) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:59:53,659] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 17:59:53,660] {{logging_mixin.py:95}} INFO - [2019-10-04 17:59:53,660] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:59:53,821] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 17:59:55,056] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 17:59:55,062] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 17:59:55,076] {{logging_mixin.py:95}} INFO - [2019-10-04 17:59:55,076] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 17:59:55,077] {{logging_mixin.py:95}} INFO - [2019-10-04 17:59:55,076] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:54:55.076807+00:00
[2019-10-04 17:59:55,085] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.566 seconds
[2019-10-04 18:00:07,217] {{logging_mixin.py:95}} INFO - [2019-10-04 18:00:07,195] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:00:07,259] {{jobs.py:386}} INFO - Started process (PID=4806) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:00:07,996] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:00:07,998] {{logging_mixin.py:95}} INFO - [2019-10-04 18:00:07,998] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:00:11,750] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:00:23,571] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:00:23,628] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:00:23,640] {{logging_mixin.py:95}} INFO - [2019-10-04 18:00:23,640] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:00:23,642] {{logging_mixin.py:95}} INFO - [2019-10-04 18:00:23,641] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:55:23.641789+00:00
[2019-10-04 18:00:23,747] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 16.488 seconds
[2019-10-04 18:00:36,285] {{logging_mixin.py:95}} INFO - [2019-10-04 18:00:36,241] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:00:36,332] {{jobs.py:386}} INFO - Started process (PID=4810) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:00:37,160] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:00:37,162] {{logging_mixin.py:95}} INFO - [2019-10-04 18:00:37,162] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:00:38,454] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:00:45,176] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:00:45,225] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:00:45,233] {{logging_mixin.py:95}} INFO - [2019-10-04 18:00:45,233] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:00:45,234] {{logging_mixin.py:95}} INFO - [2019-10-04 18:00:45,234] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:55:45.234372+00:00
[2019-10-04 18:00:45,243] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 8.911 seconds
[2019-10-04 18:00:55,956] {{logging_mixin.py:95}} INFO - [2019-10-04 18:00:55,955] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:00:55,960] {{jobs.py:386}} INFO - Started process (PID=4814) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:00:56,033] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:00:56,035] {{logging_mixin.py:95}} INFO - [2019-10-04 18:00:56,035] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:00:56,063] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:00:56,314] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:00:56,367] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:00:56,378] {{logging_mixin.py:95}} INFO - [2019-10-04 18:00:56,378] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:00:56,380] {{logging_mixin.py:95}} INFO - [2019-10-04 18:00:56,380] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:55:56.380376+00:00
[2019-10-04 18:00:56,391] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.431 seconds
[2019-10-04 18:01:07,592] {{logging_mixin.py:95}} INFO - [2019-10-04 18:01:07,592] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:01:07,598] {{jobs.py:386}} INFO - Started process (PID=4823) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:01:07,601] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:01:07,603] {{logging_mixin.py:95}} INFO - [2019-10-04 18:01:07,603] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:01:07,636] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:01:07,986] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:01:07,995] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:01:08,004] {{logging_mixin.py:95}} INFO - [2019-10-04 18:01:08,004] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:01:08,005] {{logging_mixin.py:95}} INFO - [2019-10-04 18:01:08,005] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:56:08.005237+00:00
[2019-10-04 18:01:08,013] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.416 seconds
[2019-10-04 18:01:18,883] {{logging_mixin.py:95}} INFO - [2019-10-04 18:01:18,883] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:01:18,917] {{jobs.py:386}} INFO - Started process (PID=4827) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:01:18,922] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:01:18,935] {{logging_mixin.py:95}} INFO - [2019-10-04 18:01:18,934] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:01:19,298] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:01:21,234] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:01:21,240] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:01:21,251] {{logging_mixin.py:95}} INFO - [2019-10-04 18:01:21,251] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:01:21,252] {{logging_mixin.py:95}} INFO - [2019-10-04 18:01:21,252] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:56:21.252085+00:00
[2019-10-04 18:01:21,261] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.344 seconds
[2019-10-04 18:01:32,733] {{logging_mixin.py:95}} INFO - [2019-10-04 18:01:32,733] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:01:32,737] {{jobs.py:386}} INFO - Started process (PID=4832) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:01:32,740] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:01:32,741] {{logging_mixin.py:95}} INFO - [2019-10-04 18:01:32,741] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:01:32,987] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:01:33,250] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:01:33,321] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:01:33,334] {{logging_mixin.py:95}} INFO - [2019-10-04 18:01:33,333] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:01:33,337] {{logging_mixin.py:95}} INFO - [2019-10-04 18:01:33,336] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:56:33.336731+00:00
[2019-10-04 18:01:33,345] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.607 seconds
[2019-10-04 18:01:44,611] {{logging_mixin.py:95}} INFO - [2019-10-04 18:01:44,611] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:01:44,615] {{jobs.py:386}} INFO - Started process (PID=4840) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:01:44,618] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:01:44,621] {{logging_mixin.py:95}} INFO - [2019-10-04 18:01:44,620] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:01:44,879] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:01:49,289] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:01:49,466] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:01:49,477] {{logging_mixin.py:95}} INFO - [2019-10-04 18:01:49,477] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:01:49,478] {{logging_mixin.py:95}} INFO - [2019-10-04 18:01:49,478] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:56:49.478202+00:00
[2019-10-04 18:01:49,486] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.870 seconds
[2019-10-04 18:02:00,260] {{logging_mixin.py:95}} INFO - [2019-10-04 18:02:00,260] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:02:00,263] {{jobs.py:386}} INFO - Started process (PID=4844) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:02:00,266] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:02:00,268] {{logging_mixin.py:95}} INFO - [2019-10-04 18:02:00,268] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:02:00,304] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:02:00,566] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:02:00,572] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:02:00,581] {{logging_mixin.py:95}} INFO - [2019-10-04 18:02:00,581] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:02:00,583] {{logging_mixin.py:95}} INFO - [2019-10-04 18:02:00,582] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:57:00.582474+00:00
[2019-10-04 18:02:00,591] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.328 seconds
[2019-10-04 18:02:11,569] {{logging_mixin.py:95}} INFO - [2019-10-04 18:02:11,569] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:02:11,573] {{jobs.py:386}} INFO - Started process (PID=4853) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:02:11,578] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:02:11,579] {{logging_mixin.py:95}} INFO - [2019-10-04 18:02:11,579] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:02:11,609] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:02:11,934] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:02:11,940] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:02:11,949] {{logging_mixin.py:95}} INFO - [2019-10-04 18:02:11,949] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:02:11,950] {{logging_mixin.py:95}} INFO - [2019-10-04 18:02:11,949] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:57:11.949512+00:00
[2019-10-04 18:02:11,966] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.393 seconds
[2019-10-04 18:02:22,937] {{logging_mixin.py:95}} INFO - [2019-10-04 18:02:22,937] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:02:22,941] {{jobs.py:386}} INFO - Started process (PID=4857) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:02:22,944] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:02:22,947] {{logging_mixin.py:95}} INFO - [2019-10-04 18:02:22,947] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:02:22,986] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:02:24,705] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:02:24,710] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:02:24,719] {{logging_mixin.py:95}} INFO - [2019-10-04 18:02:24,719] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:02:24,721] {{logging_mixin.py:95}} INFO - [2019-10-04 18:02:24,720] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:57:24.720567+00:00
[2019-10-04 18:02:24,729] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.788 seconds
[2019-10-04 18:02:35,318] {{logging_mixin.py:95}} INFO - [2019-10-04 18:02:35,318] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:02:35,404] {{jobs.py:386}} INFO - Started process (PID=4861) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:02:35,834] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:02:35,835] {{logging_mixin.py:95}} INFO - [2019-10-04 18:02:35,835] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:02:36,034] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:02:36,723] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:02:36,730] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:02:36,780] {{logging_mixin.py:95}} INFO - [2019-10-04 18:02:36,780] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:02:36,781] {{logging_mixin.py:95}} INFO - [2019-10-04 18:02:36,781] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:57:36.781301+00:00
[2019-10-04 18:02:36,789] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.385 seconds
[2019-10-04 18:02:51,073] {{logging_mixin.py:95}} INFO - [2019-10-04 18:02:51,073] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:02:51,411] {{jobs.py:386}} INFO - Started process (PID=4870) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:02:53,109] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:02:53,110] {{logging_mixin.py:95}} INFO - [2019-10-04 18:02:53,110] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:02:57,448] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:03:03,462] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:03:03,546] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:03:03,557] {{logging_mixin.py:95}} INFO - [2019-10-04 18:03:03,556] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:03:03,557] {{logging_mixin.py:95}} INFO - [2019-10-04 18:03:03,557] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:58:03.557247+00:00
[2019-10-04 18:03:03,721] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 12.311 seconds
[2019-10-04 18:03:15,238] {{logging_mixin.py:95}} INFO - [2019-10-04 18:03:15,238] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:03:15,269] {{jobs.py:386}} INFO - Started process (PID=4874) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:03:15,296] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:03:15,297] {{logging_mixin.py:95}} INFO - [2019-10-04 18:03:15,297] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:03:15,334] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:03:17,026] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:03:17,037] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:03:17,047] {{logging_mixin.py:95}} INFO - [2019-10-04 18:03:17,047] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:03:17,049] {{logging_mixin.py:95}} INFO - [2019-10-04 18:03:17,048] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:58:17.048863+00:00
[2019-10-04 18:03:17,060] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.791 seconds
[2019-10-04 18:03:27,998] {{logging_mixin.py:95}} INFO - [2019-10-04 18:03:27,997] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:03:28,038] {{jobs.py:386}} INFO - Started process (PID=4884) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:03:28,125] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:03:28,127] {{logging_mixin.py:95}} INFO - [2019-10-04 18:03:28,127] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:03:28,211] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:03:29,712] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:03:29,836] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:03:29,848] {{logging_mixin.py:95}} INFO - [2019-10-04 18:03:29,848] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:03:29,850] {{logging_mixin.py:95}} INFO - [2019-10-04 18:03:29,849] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:58:29.849688+00:00
[2019-10-04 18:03:29,858] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.819 seconds
[2019-10-04 18:03:46,683] {{logging_mixin.py:95}} INFO - [2019-10-04 18:03:46,508] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:03:47,883] {{jobs.py:386}} INFO - Started process (PID=4888) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:03:51,169] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:03:51,171] {{logging_mixin.py:95}} INFO - [2019-10-04 18:03:51,171] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:03:55,718] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:04:10,301] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:04:10,436] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:04:10,454] {{logging_mixin.py:95}} INFO - [2019-10-04 18:04:10,454] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:04:10,455] {{logging_mixin.py:95}} INFO - [2019-10-04 18:04:10,455] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:59:10.455337+00:00
[2019-10-04 18:04:10,824] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 22.941 seconds
[2019-10-04 18:04:25,181] {{logging_mixin.py:95}} INFO - [2019-10-04 18:04:25,181] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:04:25,558] {{jobs.py:386}} INFO - Started process (PID=4892) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:04:27,729] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:04:27,731] {{logging_mixin.py:95}} INFO - [2019-10-04 18:04:27,730] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:04:31,227] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:04:38,325] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:04:38,450] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:04:38,566] {{logging_mixin.py:95}} INFO - [2019-10-04 18:04:38,566] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:04:38,568] {{logging_mixin.py:95}} INFO - [2019-10-04 18:04:38,567] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:59:38.567784+00:00
[2019-10-04 18:04:38,659] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 13.100 seconds
[2019-10-04 18:04:50,154] {{logging_mixin.py:95}} INFO - [2019-10-04 18:04:50,153] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:04:50,158] {{jobs.py:386}} INFO - Started process (PID=4896) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:04:50,328] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:04:50,330] {{logging_mixin.py:95}} INFO - [2019-10-04 18:04:50,330] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:04:50,369] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:04:50,666] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:04:50,672] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:04:50,681] {{logging_mixin.py:95}} INFO - [2019-10-04 18:04:50,681] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:04:50,682] {{logging_mixin.py:95}} INFO - [2019-10-04 18:04:50,682] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 17:59:50.682175+00:00
[2019-10-04 18:04:50,689] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.531 seconds
[2019-10-04 18:05:01,416] {{logging_mixin.py:95}} INFO - [2019-10-04 18:05:01,415] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:05:01,419] {{jobs.py:386}} INFO - Started process (PID=4900) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:05:01,421] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:05:01,422] {{logging_mixin.py:95}} INFO - [2019-10-04 18:05:01,422] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:05:01,444] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:05:01,665] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:05:01,679] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:05:01,697] {{logging_mixin.py:95}} INFO - [2019-10-04 18:05:01,697] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:05:01,702] {{logging_mixin.py:95}} INFO - [2019-10-04 18:05:01,697] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 18:00:01.697390+00:00
[2019-10-04 18:05:01,711] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.292 seconds
[2019-10-04 18:05:13,196] {{logging_mixin.py:95}} INFO - [2019-10-04 18:05:13,196] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:05:13,199] {{jobs.py:386}} INFO - Started process (PID=4909) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:05:13,202] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:05:13,203] {{logging_mixin.py:95}} INFO - [2019-10-04 18:05:13,203] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:05:13,224] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:05:14,404] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:05:14,477] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:05:14,485] {{logging_mixin.py:95}} INFO - [2019-10-04 18:05:14,485] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:05:14,487] {{logging_mixin.py:95}} INFO - [2019-10-04 18:05:14,486] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 18:00:14.486379+00:00
[2019-10-04 18:05:14,496] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.297 seconds
[2019-10-04 18:05:26,069] {{logging_mixin.py:95}} INFO - [2019-10-04 18:05:26,069] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:05:26,134] {{jobs.py:386}} INFO - Started process (PID=4913) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:05:26,598] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:05:26,599] {{logging_mixin.py:95}} INFO - [2019-10-04 18:05:26,599] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:05:27,579] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:05:29,699] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:05:29,706] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:05:29,719] {{logging_mixin.py:95}} INFO - [2019-10-04 18:05:29,719] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:05:29,720] {{logging_mixin.py:95}} INFO - [2019-10-04 18:05:29,720] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 18:00:29.719993+00:00
[2019-10-04 18:05:29,727] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 3.593 seconds
[2019-10-04 18:05:40,674] {{logging_mixin.py:95}} INFO - [2019-10-04 18:05:40,673] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:05:40,677] {{jobs.py:386}} INFO - Started process (PID=4923) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:05:40,680] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:05:40,681] {{logging_mixin.py:95}} INFO - [2019-10-04 18:05:40,681] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:05:40,743] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:05:41,002] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:05:41,009] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:05:41,017] {{logging_mixin.py:95}} INFO - [2019-10-04 18:05:41,017] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:05:41,017] {{logging_mixin.py:95}} INFO - [2019-10-04 18:05:41,017] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 18:00:41.017393+00:00
[2019-10-04 18:05:41,026] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.349 seconds
[2019-10-04 18:05:53,276] {{logging_mixin.py:95}} INFO - [2019-10-04 18:05:53,275] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:05:53,284] {{jobs.py:386}} INFO - Started process (PID=4927) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:05:53,559] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:05:53,560] {{logging_mixin.py:95}} INFO - [2019-10-04 18:05:53,560] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:05:54,240] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:05:57,818] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:05:57,963] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:05:57,970] {{logging_mixin.py:95}} INFO - [2019-10-04 18:05:57,970] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:05:57,972] {{logging_mixin.py:95}} INFO - [2019-10-04 18:05:57,971] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 18:00:57.971687+00:00
[2019-10-04 18:05:57,982] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 4.697 seconds
[2019-10-04 18:06:08,993] {{logging_mixin.py:95}} INFO - [2019-10-04 18:06:08,993] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:06:08,998] {{jobs.py:386}} INFO - Started process (PID=4931) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:06:09,500] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:06:09,505] {{logging_mixin.py:95}} INFO - [2019-10-04 18:06:09,504] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:06:09,984] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:06:11,915] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:06:11,923] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:06:11,930] {{logging_mixin.py:95}} INFO - [2019-10-04 18:06:11,930] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:06:11,932] {{logging_mixin.py:95}} INFO - [2019-10-04 18:06:11,931] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 18:01:11.931463+00:00
[2019-10-04 18:06:11,942] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 2.944 seconds
[2019-10-04 18:06:23,869] {{logging_mixin.py:95}} INFO - [2019-10-04 18:06:23,869] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:06:24,435] {{jobs.py:386}} INFO - Started process (PID=4940) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:06:26,191] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:06:26,192] {{logging_mixin.py:95}} INFO - [2019-10-04 18:06:26,192] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:06:28,539] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:06:39,228] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:06:39,232] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:06:39,241] {{logging_mixin.py:95}} INFO - [2019-10-04 18:06:39,241] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:06:39,241] {{logging_mixin.py:95}} INFO - [2019-10-04 18:06:39,241] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 18:01:39.241374+00:00
[2019-10-04 18:06:40,567] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 16.131 seconds
[2019-10-04 18:06:53,568] {{logging_mixin.py:95}} INFO - [2019-10-04 18:06:53,568] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:06:53,941] {{jobs.py:386}} INFO - Started process (PID=4944) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:06:55,290] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:06:55,292] {{logging_mixin.py:95}} INFO - [2019-10-04 18:06:55,291] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:06:56,390] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:07:15,267] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 18:07:34,731] {{logging_mixin.py:95}} INFO - [2019-10-04 18:07:34,504] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:07:35,032] {{jobs.py:386}} INFO - Started process (PID=4947) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:07:37,017] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:07:37,018] {{logging_mixin.py:95}} INFO - [2019-10-04 18:07:37,018] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:07:40,269] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:07:49,371] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:07:49,377] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:07:49,387] {{logging_mixin.py:95}} INFO - [2019-10-04 18:07:49,387] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:07:49,390] {{logging_mixin.py:95}} INFO - [2019-10-04 18:07:49,389] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 18:02:49.389763+00:00
[2019-10-04 18:07:49,401] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 14.369 seconds
[2019-10-04 18:08:00,473] {{logging_mixin.py:95}} INFO - [2019-10-04 18:08:00,472] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:08:00,476] {{jobs.py:386}} INFO - Started process (PID=4956) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:08:00,480] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:08:00,481] {{logging_mixin.py:95}} INFO - [2019-10-04 18:08:00,480] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:08:00,508] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:08:00,636] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:08:00,641] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:08:00,649] {{logging_mixin.py:95}} INFO - [2019-10-04 18:08:00,649] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:08:00,650] {{logging_mixin.py:95}} INFO - [2019-10-04 18:08:00,650] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 18:03:00.650214+00:00
[2019-10-04 18:08:00,657] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.180 seconds
[2019-10-04 18:08:11,694] {{logging_mixin.py:95}} INFO - [2019-10-04 18:08:11,694] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:08:11,698] {{jobs.py:386}} INFO - Started process (PID=4960) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:08:11,700] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:08:11,751] {{logging_mixin.py:95}} INFO - [2019-10-04 18:08:11,751] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:08:11,945] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:08:12,394] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:08:12,399] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:08:12,408] {{logging_mixin.py:95}} INFO - [2019-10-04 18:08:12,407] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:08:12,409] {{logging_mixin.py:95}} INFO - [2019-10-04 18:08:12,408] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 18:03:12.408443+00:00
[2019-10-04 18:08:12,416] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.718 seconds
[2019-10-04 18:08:23,183] {{logging_mixin.py:95}} INFO - [2019-10-04 18:08:23,183] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:08:23,186] {{jobs.py:386}} INFO - Started process (PID=4969) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:08:23,189] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:08:23,199] {{logging_mixin.py:95}} INFO - [2019-10-04 18:08:23,199] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:08:23,473] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:08:23,766] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:08:23,770] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:08:23,778] {{logging_mixin.py:95}} INFO - [2019-10-04 18:08:23,778] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:08:23,780] {{logging_mixin.py:95}} INFO - [2019-10-04 18:08:23,779] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 18:03:23.779584+00:00
[2019-10-04 18:08:23,787] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.601 seconds
[2019-10-04 18:08:34,613] {{logging_mixin.py:95}} INFO - [2019-10-04 18:08:34,542] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:08:34,678] {{jobs.py:386}} INFO - Started process (PID=4973) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:08:34,836] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:08:34,837] {{logging_mixin.py:95}} INFO - [2019-10-04 18:08:34,837] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:08:35,452] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:08:35,919] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:08:35,926] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:08:35,939] {{logging_mixin.py:95}} INFO - [2019-10-04 18:08:35,939] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:08:35,941] {{logging_mixin.py:95}} INFO - [2019-10-04 18:08:35,940] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 18:03:35.940804+00:00
[2019-10-04 18:08:35,949] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 1.271 seconds
[2019-10-04 18:08:49,996] {{logging_mixin.py:95}} INFO - [2019-10-04 18:08:49,911] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:08:50,228] {{jobs.py:386}} INFO - Started process (PID=4977) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:08:51,435] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:08:51,435] {{logging_mixin.py:95}} INFO - [2019-10-04 18:08:51,435] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:08:53,002] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:08:57,480] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:08:57,498] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:08:57,506] {{logging_mixin.py:95}} INFO - [2019-10-04 18:08:57,506] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:08:57,507] {{logging_mixin.py:95}} INFO - [2019-10-04 18:08:57,506] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 18:03:57.506868+00:00
[2019-10-04 18:08:57,547] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 7.319 seconds
[2019-10-04 18:09:08,688] {{logging_mixin.py:95}} INFO - [2019-10-04 18:09:08,688] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:09:08,702] {{jobs.py:386}} INFO - Started process (PID=4987) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:09:08,709] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:09:08,710] {{logging_mixin.py:95}} INFO - [2019-10-04 18:09:08,710] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:09:08,759] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:09:09,022] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:09:09,046] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:09:09,060] {{logging_mixin.py:95}} INFO - [2019-10-04 18:09:09,060] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:09:09,061] {{logging_mixin.py:95}} INFO - [2019-10-04 18:09:09,061] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 18:04:09.061215+00:00
[2019-10-04 18:09:09,068] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 0.366 seconds
[2019-10-04 18:09:20,928] {{logging_mixin.py:95}} INFO - [2019-10-04 18:09:20,927] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:09:21,385] {{jobs.py:386}} INFO - Started process (PID=4991) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:09:22,183] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:09:22,184] {{logging_mixin.py:95}} INFO - [2019-10-04 18:09:22,184] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:09:23,433] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:09:32,763] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:09:32,770] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:09:32,778] {{logging_mixin.py:95}} INFO - [2019-10-04 18:09:32,778] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:09:32,779] {{logging_mixin.py:95}} INFO - [2019-10-04 18:09:32,779] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 18:04:32.779401+00:00
[2019-10-04 18:09:32,904] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 11.519 seconds
[2019-10-04 18:09:48,116] {{logging_mixin.py:95}} INFO - [2019-10-04 18:09:47,842] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:09:48,442] {{jobs.py:386}} INFO - Started process (PID=5000) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:09:48,745] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:09:48,745] {{logging_mixin.py:95}} INFO - [2019-10-04 18:09:48,745] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:09:51,591] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:10:10,416] {{jobs.py:1424}} INFO - Processing hello_world2
[2019-10-04 18:10:10,586] {{jobs.py:615}} INFO - Skipping SLA check for <DAG: hello_world2> because no tasks in DAG have SLAs
[2019-10-04 18:10:10,678] {{logging_mixin.py:95}} INFO - [2019-10-04 18:10:10,678] {{models.py:456}} INFO - Finding 'running' jobs without a recent heartbeat
[2019-10-04 18:10:10,680] {{logging_mixin.py:95}} INFO - [2019-10-04 18:10:10,679] {{models.py:460}} INFO - Failing jobs without heartbeat after 2019-10-04 18:05:10.679913+00:00
[2019-10-04 18:10:12,088] {{jobs.py:393}} INFO - Processing /usr/local/airflow/dags/Hello_world2.py took 23.646 seconds
[2019-10-04 18:10:26,127] {{logging_mixin.py:95}} INFO - [2019-10-04 18:10:26,127] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:10:26,415] {{jobs.py:386}} INFO - Started process (PID=5004) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:10:27,755] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:10:27,757] {{logging_mixin.py:95}} INFO - [2019-10-04 18:10:27,756] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:10:30,523] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:10:53,066] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

[2019-10-04 18:11:29,604] {{logging_mixin.py:95}} INFO - [2019-10-04 18:11:28,871] {{settings.py:174}} INFO - setting.configure_orm(): Using pool settings. pool_size=5, pool_recycle=1800
[2019-10-04 18:11:30,321] {{jobs.py:386}} INFO - Started process (PID=5006) to work on /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:11:32,594] {{jobs.py:1796}} INFO - Processing file /usr/local/airflow/dags/Hello_world2.py for tasks to queue
[2019-10-04 18:11:32,595] {{logging_mixin.py:95}} INFO - [2019-10-04 18:11:32,595] {{models.py:271}} INFO - Filling up the DagBag from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:11:35,917] {{jobs.py:1808}} INFO - DAG(s) dict_keys(['hello_world2']) retrieved from /usr/local/airflow/dags/Hello_world2.py
[2019-10-04 18:11:49,983] {{jobs.py:397}} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1124, in _do_get
    return self._pool.get(wait, self._timeout)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/queue.py", line 145, in get
    raise Empty
sqlalchemy.util.queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 389, in helper
    pickle_dags)
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/jobs.py", line 1816, in process_file
    dag.sync_to_db()
  File "/usr/local/lib/python3.6/site-packages/airflow/utils/db.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/airflow/models.py", line 4296, in sync_to_db
    DagModel).filter(DagModel.dag_id == self.dag_id).first()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2755, in first
    ret = list(self[0:1])
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2547, in __getitem__
    return list(res)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2855, in __iter__
    return self._execute_and_instances(context)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2876, in _execute_and_instances
    close_with_result=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2885, in _get_bind_args
    **kw
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/query.py", line 2867, in _connection_from_session
    conn = self.session.connection(**kw)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1019, in connection
    execution_options=execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 1024, in _connection_for_bind
    engine, execution_options)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 409, in _connection_for_bind
    conn = bind.contextual_connect()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2112, in contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2151, in _wrap_pool_connect
    e, dialect, self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1465, in _handle_dbapi_exception_noconnection
    exc_info
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 203, in raise_from_cause
    reraise(type(exception), exception, tb=exc_tb, cause=cause)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 186, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 2147, in _wrap_pool_connect
    return fn()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 387, in connect
    return _ConnectionFairy._checkout(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 768, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 516, in checkout
    rec = pool._do_get()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1140, in _do_get
    self._dec_overflow()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 66, in __exit__
    compat.reraise(exc_type, exc_value, exc_tb)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 187, in reraise
    raise value
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 1137, in _do_get
    return self._create_connection()
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 333, in _create_connection
    return _ConnectionRecord(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 461, in __init__
    self.__connect(first_connect_check=True)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/pool.py", line 651, in __connect
    connection = pool._invoke_creator(self)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/strategies.py", line 105, in connect
    return dialect.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 393, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

